{"version":3,"file":"index.js","mappings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zDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACzDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC1RA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACtDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACrEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC3oBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACjFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxYA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjnEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/5DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzCA;;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtKA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxGA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACr0BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/IA;AACA;AACA;AACA;AACA;;;;;;;;ACJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1uEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5TA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClf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zgBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5lBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClnBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5kBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnmEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACj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jBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACroBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACv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vYA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/UA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACrRA;;;;;;;;ACAA;;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACdA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1KA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7MA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9VA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClSA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9SA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvVA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACXA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChoBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC9EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC5CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACtBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC1GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC7EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACpCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChCA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;;;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACZA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjTA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7LA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACbA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5NA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxMA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/UA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjLA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC7DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC1BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClHA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/GA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9rBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC57BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AClBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACfA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9CA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/DA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACrFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACnEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC3EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC5EA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACjFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC/FA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACxGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACpJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AC9HA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AChJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACtFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACvJA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;ACzUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC3OA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;AC7BA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;;;;ACAA;AACA;;;;;;;;;;ACDA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AA6IA;;;ACtkhBA;AAEA;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AAEA;AACA;AACA;AAEA;AAEA;AAEA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAGA;AAEA;AACA;AACA;AAEA;;;;AClWA;AAEA;AAUA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAIA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAGA;AAEA;AACA;AACA;AAEA;;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;;;ACl0IA;AAEA;AA2EA;;;;;;AAMA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;;AAKA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;;AAIA;AACA;AACA;;;ACjgBA;AASA;AACA;AAAA;AACA;AADA;AAEA;AAEA;AACA;AACA;AAEA;AAWA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;ACzFA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAAA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AAAA;AACA;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AC9EA;AAEA;AACA;AAEA;AACA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;AC9BA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AAEA;AACA;AACA;AAAA;AACA;AACA;AAEA;AACA;AACA;AAEA;AACA;AAAA;AAEA;AACA;;;AChCA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAOA;AACA;;AAEA;AAEA;AACA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAGA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;AAOA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;;;;;AC3FA;AACA;AACA;AACA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AAEA;AACA;AAEA;AACA;AAEA;AACA;AACA;AAEA;AACA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA;AACA;;;AChCA;AAEA","sources":[".././node_modules/@actions/core/lib/command.js",".././node_modules/@actions/core/lib/core.js",".././node_modules/@actions/core/lib/file-command.js",".././node_modules/@actions/core/lib/oidc-utils.js",".././node_modules/@actions/core/lib/path-utils.js",".././node_modules/@actions/core/lib/summary.js",".././node_modules/@actions/core/lib/utils.js",".././node_modules/@actions/github/lib/context.js",".././node_modules/@actions/github/lib/github.js",".././node_modules/@actions/github/lib/internal/utils.js",".././node_modules/@actions/github/lib/utils.js",".././node_modules/@actions/http-client/lib/auth.js",".././node_modules/@actions/http-client/lib/index.js",".././node_modules/@actions/http-client/lib/proxy.js",".././node_modules/@octokit/auth-token/dist-node/index.js",".././node_modules/@octokit/core/dist-node/index.js",".././node_modules/@octokit/endpoint/dist-node/index.js",".././node_modules/@octokit/graphql/dist-node/index.js",".././node_modules/@octokit/plugin-paginate-rest/dist-node/index.js",".././node_modules/@octokit/plugin-rest-endpoint-methods/dist-node/index.js",".././node_modules/@octokit/request-error/dist-node/index.js",".././node_modules/@octokit/request/dist-node/index.js",".././node_modules/before-after-hook/index.js",".././node_modules/before-after-hook/lib/add.js",".././node_modules/before-after-hook/lib/register.js",".././node_modules/before-after-hook/lib/remove.js",".././node_modules/deprecation/dist-node/index.js",".././node_modules/humanize-duration/humanize-duration.js",".././node_modules/once/once.js",".././node_modules/tunnel/index.js",".././node_modules/tunnel/lib/tunnel.js",".././node_modules/undici/index.js",".././node_modules/undici/lib/agent.js",".././node_modules/undici/lib/api/abort-signal.js",".././node_modules/undici/lib/api/api-connect.js",".././node_modules/undici/lib/api/api-pipeline.js",".././node_modules/undici/lib/api/api-request.js",".././node_modules/undici/lib/api/api-stream.js",".././node_modules/undici/lib/api/api-upgrade.js",".././node_modules/undici/lib/api/index.js",".././node_modules/undici/lib/api/readable.js",".././node_modules/undici/lib/api/util.js",".././node_modules/undici/lib/balanced-pool.js",".././node_modules/undici/lib/cache/cache.js",".././node_modules/undici/lib/cache/cachestorage.js",".././node_modules/undici/lib/cache/symbols.js",".././node_modules/undici/lib/cache/util.js",".././node_modules/undici/lib/client.js",".././node_modules/undici/lib/compat/dispatcher-weakref.js",".././node_modules/undici/lib/cookies/constants.js",".././node_modules/undici/lib/cookies/index.js",".././node_modules/undici/lib/cookies/parse.js",".././node_modules/undici/lib/cookies/util.js",".././node_modules/undici/lib/core/connect.js",".././node_modules/undici/lib/core/constants.js",".././node_modules/undici/lib/core/errors.js",".././node_modules/undici/lib/core/request.js",".././node_modules/undici/lib/core/symbols.js",".././node_modules/undici/lib/core/util.js",".././node_modules/undici/lib/dispatcher-base.js",".././node_modules/undici/lib/dispatcher.js",".././node_modules/undici/lib/fetch/body.js",".././node_modules/undici/lib/fetch/constants.js",".././node_modules/undici/lib/fetch/dataURL.js",".././node_modules/undici/lib/fetch/file.js",".././node_modules/undici/lib/fetch/formdata.js",".././node_modules/undici/lib/fetch/global.js",".././node_modules/undici/lib/fetch/headers.js",".././node_modules/undici/lib/fetch/index.js",".././node_modules/undici/lib/fetch/request.js",".././node_modules/undici/lib/fetch/response.js",".././node_modules/undici/lib/fetch/symbols.js",".././node_modules/undici/lib/fetch/util.js",".././node_modules/undici/lib/fetch/webidl.js",".././node_modules/undici/lib/fileapi/encoding.js",".././node_modules/undici/lib/fileapi/filereader.js",".././node_modules/undici/lib/fileapi/progressevent.js",".././node_modules/undici/lib/fileapi/symbols.js",".././node_modules/undici/lib/fileapi/util.js",".././node_modules/undici/lib/global.js",".././node_modules/undici/lib/handler/DecoratorHandler.js",".././node_modules/undici/lib/handler/RedirectHandler.js",".././node_modules/undici/lib/handler/RetryHandler.js",".././node_modules/undici/lib/interceptor/redirectInterceptor.js",".././node_modules/undici/lib/llhttp/constants.js",".././node_modules/undici/lib/llhttp/llhttp-wasm.js",".././node_modules/undici/lib/llhttp/llhttp_simd-wasm.js",".././node_modules/undici/lib/llhttp/utils.js",".././node_modules/undici/lib/mock/mock-agent.js",".././node_modules/undici/lib/mock/mock-client.js",".././node_modules/undici/lib/mock/mock-errors.js",".././node_modules/undici/lib/mock/mock-interceptor.js",".././node_modules/undici/lib/mock/mock-pool.js",".././node_modules/undici/lib/mock/mock-symbols.js",".././node_modules/undici/lib/mock/mock-utils.js",".././node_modules/undici/lib/mock/pending-interceptors-formatter.js",".././node_modules/undici/lib/mock/pluralizer.js",".././node_modules/undici/lib/node/fixed-queue.js",".././node_modules/undici/lib/pool-base.js",".././node_modules/undici/lib/pool-stats.js",".././node_modules/undici/lib/pool.js",".././node_modules/undici/lib/proxy-agent.js",".././node_modules/undici/lib/timers.js",".././node_modules/undici/lib/websocket/connection.js",".././node_modules/undici/lib/websocket/constants.js",".././node_modules/undici/lib/websocket/events.js",".././node_modules/undici/lib/websocket/frame.js",".././node_modules/undici/lib/websocket/receiver.js",".././node_modules/undici/lib/websocket/symbols.js",".././node_modules/undici/lib/websocket/util.js",".././node_modules/undici/lib/websocket/websocket.js",".././node_modules/universal-user-agent/dist-node/index.js",".././node_modules/uuid/dist/index.js",".././node_modules/uuid/dist/md5.js",".././node_modules/uuid/dist/nil.js",".././node_modules/uuid/dist/parse.js",".././node_modules/uuid/dist/regex.js",".././node_modules/uuid/dist/rng.js",".././node_modules/uuid/dist/sha1.js",".././node_modules/uuid/dist/stringify.js",".././node_modules/uuid/dist/v1.js",".././node_modules/uuid/dist/v3.js",".././node_modules/uuid/dist/v35.js",".././node_modules/uuid/dist/v4.js",".././node_modules/uuid/dist/v5.js",".././node_modules/uuid/dist/validate.js",".././node_modules/uuid/dist/version.js",".././node_modules/wrappy/wrappy.js","../external node-commonjs \"assert\"","../external node-commonjs \"async_hooks\"","../external node-commonjs \"buffer\"","../external node-commonjs \"console\"","../external node-commonjs \"crypto\"","../external node-commonjs \"diagnostics_channel\"","../external node-commonjs \"events\"","../external node-commonjs \"fs\"","../external node-commonjs \"http\"","../external node-commonjs \"http2\"","../external node-commonjs \"https\"","../external node-commonjs \"net\"","../external node-commonjs \"node:events\"","../external node-commonjs \"node:stream\"","../external node-commonjs \"node:util\"","../external node-commonjs \"os\"","../external node-commonjs \"path\"","../external node-commonjs \"perf_hooks\"","../external node-commonjs \"querystring\"","../external node-commonjs \"stream\"","../external node-commonjs \"stream/web\"","../external node-commonjs \"string_decoder\"","../external node-commonjs \"tls\"","../external node-commonjs \"url\"","../external node-commonjs \"util\"","../external node-commonjs \"util/types\"","../external node-commonjs \"worker_threads\"","../external node-commonjs \"zlib\"",".././node_modules/@fastify/busboy/deps/dicer/lib/Dicer.js",".././node_modules/@fastify/busboy/deps/dicer/lib/HeaderParser.js",".././node_modules/@fastify/busboy/deps/dicer/lib/PartStream.js",".././node_modules/@fastify/busboy/deps/streamsearch/sbmh.js",".././node_modules/@fastify/busboy/lib/main.js",".././node_modules/@fastify/busboy/lib/types/multipart.js",".././node_modules/@fastify/busboy/lib/types/urlencoded.js",".././node_modules/@fastify/busboy/lib/utils/Decoder.js",".././node_modules/@fastify/busboy/lib/utils/basename.js",".././node_modules/@fastify/busboy/lib/utils/decodeText.js",".././node_modules/@fastify/busboy/lib/utils/getLimit.js",".././node_modules/@fastify/busboy/lib/utils/parseParams.js",".././node_modules/yaml/dist/compose/compose-collection.js",".././node_modules/yaml/dist/compose/compose-doc.js",".././node_modules/yaml/dist/compose/compose-node.js",".././node_modules/yaml/dist/compose/compose-scalar.js",".././node_modules/yaml/dist/compose/composer.js",".././node_modules/yaml/dist/compose/resolve-block-map.js",".././node_modules/yaml/dist/compose/resolve-block-scalar.js",".././node_modules/yaml/dist/compose/resolve-block-seq.js",".././node_modules/yaml/dist/compose/resolve-end.js",".././node_modules/yaml/dist/compose/resolve-flow-collection.js",".././node_modules/yaml/dist/compose/resolve-flow-scalar.js",".././node_modules/yaml/dist/compose/resolve-props.js",".././node_modules/yaml/dist/compose/util-contains-newline.js",".././node_modules/yaml/dist/compose/util-empty-scalar-position.js",".././node_modules/yaml/dist/compose/util-flow-indent-check.js",".././node_modules/yaml/dist/compose/util-map-includes.js",".././node_modules/yaml/dist/doc/Document.js",".././node_modules/yaml/dist/doc/anchors.js",".././node_modules/yaml/dist/doc/applyReviver.js",".././node_modules/yaml/dist/doc/createNode.js",".././node_modules/yaml/dist/doc/directives.js",".././node_modules/yaml/dist/errors.js",".././node_modules/yaml/dist/index.js",".././node_modules/yaml/dist/log.js",".././node_modules/yaml/dist/nodes/Alias.js",".././node_modules/yaml/dist/nodes/Collection.js",".././node_modules/yaml/dist/nodes/Node.js",".././node_modules/yaml/dist/nodes/Pair.js",".././node_modules/yaml/dist/nodes/Scalar.js",".././node_modules/yaml/dist/nodes/YAMLMap.js",".././node_modules/yaml/dist/nodes/YAMLSeq.js",".././node_modules/yaml/dist/nodes/addPairToJSMap.js",".././node_modules/yaml/dist/nodes/identity.js",".././node_modules/yaml/dist/nodes/toJS.js",".././node_modules/yaml/dist/parse/cst-scalar.js",".././node_modules/yaml/dist/parse/cst-stringify.js",".././node_modules/yaml/dist/parse/cst-visit.js",".././node_modules/yaml/dist/parse/cst.js",".././node_modules/yaml/dist/parse/lexer.js",".././node_modules/yaml/dist/parse/line-counter.js",".././node_modules/yaml/dist/parse/parser.js",".././node_modules/yaml/dist/public-api.js",".././node_modules/yaml/dist/schema/Schema.js",".././node_modules/yaml/dist/schema/common/map.js",".././node_modules/yaml/dist/schema/common/null.js",".././node_modules/yaml/dist/schema/common/seq.js",".././node_modules/yaml/dist/schema/common/string.js",".././node_modules/yaml/dist/schema/core/bool.js",".././node_modules/yaml/dist/schema/core/float.js",".././node_modules/yaml/dist/schema/core/int.js",".././node_modules/yaml/dist/schema/core/schema.js",".././node_modules/yaml/dist/schema/json/schema.js",".././node_modules/yaml/dist/schema/tags.js",".././node_modules/yaml/dist/schema/yaml-1.1/binary.js",".././node_modules/yaml/dist/schema/yaml-1.1/bool.js",".././node_modules/yaml/dist/schema/yaml-1.1/float.js",".././node_modules/yaml/dist/schema/yaml-1.1/int.js",".././node_modules/yaml/dist/schema/yaml-1.1/omap.js",".././node_modules/yaml/dist/schema/yaml-1.1/pairs.js",".././node_modules/yaml/dist/schema/yaml-1.1/schema.js",".././node_modules/yaml/dist/schema/yaml-1.1/set.js",".././node_modules/yaml/dist/schema/yaml-1.1/timestamp.js",".././node_modules/yaml/dist/stringify/foldFlowLines.js",".././node_modules/yaml/dist/stringify/stringify.js",".././node_modules/yaml/dist/stringify/stringifyCollection.js",".././node_modules/yaml/dist/stringify/stringifyComment.js",".././node_modules/yaml/dist/stringify/stringifyDocument.js",".././node_modules/yaml/dist/stringify/stringifyNumber.js",".././node_modules/yaml/dist/stringify/stringifyPair.js",".././node_modules/yaml/dist/stringify/stringifyString.js",".././node_modules/yaml/dist/visit.js","../webpack/bootstrap","../webpack/runtime/compat get default export","../webpack/runtime/define property getters","../webpack/runtime/hasOwnProperty shorthand","../webpack/runtime/compat",".././node_modules/antlr4ng/dist/index.mjs",".././src/generated/DaedalusLexer.ts",".././src/generated/DaedalusParser.ts",".././src/generated/DaedalusVisitor.ts",".././src/class.ts",".././src/parse.ts",".././src/validate.ts",".././src/inputs.ts",".././src/write.ts",".././src/main.ts",".././src/index.ts"],"sourcesContent":["\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.issue = exports.issueCommand = void 0;\nconst os = __importStar(require(\"os\"));\nconst utils_1 = require(\"./utils\");\n/**\n * Commands\n *\n * Command Format:\n *   ::name key=value,key=value::message\n *\n * Examples:\n *   ::warning::This is the message\n *   ::set-env name=MY_VAR::some value\n */\nfunction issueCommand(command, properties, message) {\n    const cmd = new Command(command, properties, message);\n    process.stdout.write(cmd.toString() + os.EOL);\n}\nexports.issueCommand = issueCommand;\nfunction issue(name, message = '') {\n    issueCommand(name, {}, message);\n}\nexports.issue = issue;\nconst CMD_STRING = '::';\nclass Command {\n    constructor(command, properties, message) {\n        if (!command) {\n            command = 'missing.command';\n        }\n        this.command = command;\n        this.properties = properties;\n        this.message = message;\n    }\n    toString() {\n        let cmdStr = CMD_STRING + this.command;\n        if (this.properties && Object.keys(this.properties).length > 0) {\n            cmdStr += ' ';\n            let first = true;\n            for (const key in this.properties) {\n                if (this.properties.hasOwnProperty(key)) {\n                    const val = this.properties[key];\n                    if (val) {\n                        if (first) {\n                            first = false;\n                        }\n                        else {\n                            cmdStr += ',';\n                        }\n                        cmdStr += `${key}=${escapeProperty(val)}`;\n                    }\n                }\n            }\n        }\n        cmdStr += `${CMD_STRING}${escapeData(this.message)}`;\n        return cmdStr;\n    }\n}\nfunction escapeData(s) {\n    return utils_1.toCommandValue(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A');\n}\nfunction escapeProperty(s) {\n    return utils_1.toCommandValue(s)\n        .replace(/%/g, '%25')\n        .replace(/\\r/g, '%0D')\n        .replace(/\\n/g, '%0A')\n        .replace(/:/g, '%3A')\n        .replace(/,/g, '%2C');\n}\n//# sourceMappingURL=command.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getIDToken = exports.getState = exports.saveState = exports.group = exports.endGroup = exports.startGroup = exports.info = exports.notice = exports.warning = exports.error = exports.debug = exports.isDebug = exports.setFailed = exports.setCommandEcho = exports.setOutput = exports.getBooleanInput = exports.getMultilineInput = exports.getInput = exports.addPath = exports.setSecret = exports.exportVariable = exports.ExitCode = void 0;\nconst command_1 = require(\"./command\");\nconst file_command_1 = require(\"./file-command\");\nconst utils_1 = require(\"./utils\");\nconst os = __importStar(require(\"os\"));\nconst path = __importStar(require(\"path\"));\nconst oidc_utils_1 = require(\"./oidc-utils\");\n/**\n * The code to exit an action\n */\nvar ExitCode;\n(function (ExitCode) {\n    /**\n     * A code indicating that the action was successful\n     */\n    ExitCode[ExitCode[\"Success\"] = 0] = \"Success\";\n    /**\n     * A code indicating that the action was a failure\n     */\n    ExitCode[ExitCode[\"Failure\"] = 1] = \"Failure\";\n})(ExitCode = exports.ExitCode || (exports.ExitCode = {}));\n//-----------------------------------------------------------------------\n// Variables\n//-----------------------------------------------------------------------\n/**\n * Sets env variable for this action and future actions in the job\n * @param name the name of the variable to set\n * @param val the value of the variable. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction exportVariable(name, val) {\n    const convertedVal = utils_1.toCommandValue(val);\n    process.env[name] = convertedVal;\n    const filePath = process.env['GITHUB_ENV'] || '';\n    if (filePath) {\n        return file_command_1.issueFileCommand('ENV', file_command_1.prepareKeyValueMessage(name, val));\n    }\n    command_1.issueCommand('set-env', { name }, convertedVal);\n}\nexports.exportVariable = exportVariable;\n/**\n * Registers a secret which will get masked from logs\n * @param secret value of the secret\n */\nfunction setSecret(secret) {\n    command_1.issueCommand('add-mask', {}, secret);\n}\nexports.setSecret = setSecret;\n/**\n * Prepends inputPath to the PATH (for this action and future actions)\n * @param inputPath\n */\nfunction addPath(inputPath) {\n    const filePath = process.env['GITHUB_PATH'] || '';\n    if (filePath) {\n        file_command_1.issueFileCommand('PATH', inputPath);\n    }\n    else {\n        command_1.issueCommand('add-path', {}, inputPath);\n    }\n    process.env['PATH'] = `${inputPath}${path.delimiter}${process.env['PATH']}`;\n}\nexports.addPath = addPath;\n/**\n * Gets the value of an input.\n * Unless trimWhitespace is set to false in InputOptions, the value is also trimmed.\n * Returns an empty string if the value is not defined.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string\n */\nfunction getInput(name, options) {\n    const val = process.env[`INPUT_${name.replace(/ /g, '_').toUpperCase()}`] || '';\n    if (options && options.required && !val) {\n        throw new Error(`Input required and not supplied: ${name}`);\n    }\n    if (options && options.trimWhitespace === false) {\n        return val;\n    }\n    return val.trim();\n}\nexports.getInput = getInput;\n/**\n * Gets the values of an multiline input.  Each value is also trimmed.\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   string[]\n *\n */\nfunction getMultilineInput(name, options) {\n    const inputs = getInput(name, options)\n        .split('\\n')\n        .filter(x => x !== '');\n    if (options && options.trimWhitespace === false) {\n        return inputs;\n    }\n    return inputs.map(input => input.trim());\n}\nexports.getMultilineInput = getMultilineInput;\n/**\n * Gets the input value of the boolean type in the YAML 1.2 \"core schema\" specification.\n * Support boolean input list: `true | True | TRUE | false | False | FALSE` .\n * The return value is also in boolean type.\n * ref: https://yaml.org/spec/1.2/spec.html#id2804923\n *\n * @param     name     name of the input to get\n * @param     options  optional. See InputOptions.\n * @returns   boolean\n */\nfunction getBooleanInput(name, options) {\n    const trueValue = ['true', 'True', 'TRUE'];\n    const falseValue = ['false', 'False', 'FALSE'];\n    const val = getInput(name, options);\n    if (trueValue.includes(val))\n        return true;\n    if (falseValue.includes(val))\n        return false;\n    throw new TypeError(`Input does not meet YAML 1.2 \"Core Schema\" specification: ${name}\\n` +\n        `Support boolean input list: \\`true | True | TRUE | false | False | FALSE\\``);\n}\nexports.getBooleanInput = getBooleanInput;\n/**\n * Sets the value of an output.\n *\n * @param     name     name of the output to set\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction setOutput(name, value) {\n    const filePath = process.env['GITHUB_OUTPUT'] || '';\n    if (filePath) {\n        return file_command_1.issueFileCommand('OUTPUT', file_command_1.prepareKeyValueMessage(name, value));\n    }\n    process.stdout.write(os.EOL);\n    command_1.issueCommand('set-output', { name }, utils_1.toCommandValue(value));\n}\nexports.setOutput = setOutput;\n/**\n * Enables or disables the echoing of commands into stdout for the rest of the step.\n * Echoing is disabled by default if ACTIONS_STEP_DEBUG is not set.\n *\n */\nfunction setCommandEcho(enabled) {\n    command_1.issue('echo', enabled ? 'on' : 'off');\n}\nexports.setCommandEcho = setCommandEcho;\n//-----------------------------------------------------------------------\n// Results\n//-----------------------------------------------------------------------\n/**\n * Sets the action status to failed.\n * When the action exits it will be with an exit code of 1\n * @param message add error issue message\n */\nfunction setFailed(message) {\n    process.exitCode = ExitCode.Failure;\n    error(message);\n}\nexports.setFailed = setFailed;\n//-----------------------------------------------------------------------\n// Logging Commands\n//-----------------------------------------------------------------------\n/**\n * Gets whether Actions Step Debug is on or not\n */\nfunction isDebug() {\n    return process.env['RUNNER_DEBUG'] === '1';\n}\nexports.isDebug = isDebug;\n/**\n * Writes debug message to user log\n * @param message debug message\n */\nfunction debug(message) {\n    command_1.issueCommand('debug', {}, message);\n}\nexports.debug = debug;\n/**\n * Adds an error issue\n * @param message error issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction error(message, properties = {}) {\n    command_1.issueCommand('error', utils_1.toCommandProperties(properties), message instanceof Error ? message.toString() : message);\n}\nexports.error = error;\n/**\n * Adds a warning issue\n * @param message warning issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction warning(message, properties = {}) {\n    command_1.issueCommand('warning', utils_1.toCommandProperties(properties), message instanceof Error ? message.toString() : message);\n}\nexports.warning = warning;\n/**\n * Adds a notice issue\n * @param message notice issue message. Errors will be converted to string via toString()\n * @param properties optional properties to add to the annotation.\n */\nfunction notice(message, properties = {}) {\n    command_1.issueCommand('notice', utils_1.toCommandProperties(properties), message instanceof Error ? message.toString() : message);\n}\nexports.notice = notice;\n/**\n * Writes info to log with console.log.\n * @param message info message\n */\nfunction info(message) {\n    process.stdout.write(message + os.EOL);\n}\nexports.info = info;\n/**\n * Begin an output group.\n *\n * Output until the next `groupEnd` will be foldable in this group\n *\n * @param name The name of the output group\n */\nfunction startGroup(name) {\n    command_1.issue('group', name);\n}\nexports.startGroup = startGroup;\n/**\n * End an output group.\n */\nfunction endGroup() {\n    command_1.issue('endgroup');\n}\nexports.endGroup = endGroup;\n/**\n * Wrap an asynchronous function call in a group.\n *\n * Returns the same type as the function itself.\n *\n * @param name The name of the group\n * @param fn The function to wrap in the group\n */\nfunction group(name, fn) {\n    return __awaiter(this, void 0, void 0, function* () {\n        startGroup(name);\n        let result;\n        try {\n            result = yield fn();\n        }\n        finally {\n            endGroup();\n        }\n        return result;\n    });\n}\nexports.group = group;\n//-----------------------------------------------------------------------\n// Wrapper action state\n//-----------------------------------------------------------------------\n/**\n * Saves state for current action, the state can only be retrieved by this action's post job execution.\n *\n * @param     name     name of the state to store\n * @param     value    value to store. Non-string values will be converted to a string via JSON.stringify\n */\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nfunction saveState(name, value) {\n    const filePath = process.env['GITHUB_STATE'] || '';\n    if (filePath) {\n        return file_command_1.issueFileCommand('STATE', file_command_1.prepareKeyValueMessage(name, value));\n    }\n    command_1.issueCommand('save-state', { name }, utils_1.toCommandValue(value));\n}\nexports.saveState = saveState;\n/**\n * Gets the value of an state set by this action's main execution.\n *\n * @param     name     name of the state to get\n * @returns   string\n */\nfunction getState(name) {\n    return process.env[`STATE_${name}`] || '';\n}\nexports.getState = getState;\nfunction getIDToken(aud) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return yield oidc_utils_1.OidcClient.getIDToken(aud);\n    });\n}\nexports.getIDToken = getIDToken;\n/**\n * Summary exports\n */\nvar summary_1 = require(\"./summary\");\nObject.defineProperty(exports, \"summary\", { enumerable: true, get: function () { return summary_1.summary; } });\n/**\n * @deprecated use core.summary\n */\nvar summary_2 = require(\"./summary\");\nObject.defineProperty(exports, \"markdownSummary\", { enumerable: true, get: function () { return summary_2.markdownSummary; } });\n/**\n * Path exports\n */\nvar path_utils_1 = require(\"./path-utils\");\nObject.defineProperty(exports, \"toPosixPath\", { enumerable: true, get: function () { return path_utils_1.toPosixPath; } });\nObject.defineProperty(exports, \"toWin32Path\", { enumerable: true, get: function () { return path_utils_1.toWin32Path; } });\nObject.defineProperty(exports, \"toPlatformPath\", { enumerable: true, get: function () { return path_utils_1.toPlatformPath; } });\n//# sourceMappingURL=core.js.map","\"use strict\";\n// For internal use, subject to change.\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.prepareKeyValueMessage = exports.issueFileCommand = void 0;\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nconst fs = __importStar(require(\"fs\"));\nconst os = __importStar(require(\"os\"));\nconst uuid_1 = require(\"uuid\");\nconst utils_1 = require(\"./utils\");\nfunction issueFileCommand(command, message) {\n    const filePath = process.env[`GITHUB_${command}`];\n    if (!filePath) {\n        throw new Error(`Unable to find environment variable for file command ${command}`);\n    }\n    if (!fs.existsSync(filePath)) {\n        throw new Error(`Missing file at path: ${filePath}`);\n    }\n    fs.appendFileSync(filePath, `${utils_1.toCommandValue(message)}${os.EOL}`, {\n        encoding: 'utf8'\n    });\n}\nexports.issueFileCommand = issueFileCommand;\nfunction prepareKeyValueMessage(key, value) {\n    const delimiter = `ghadelimiter_${uuid_1.v4()}`;\n    const convertedValue = utils_1.toCommandValue(value);\n    // These should realistically never happen, but just in case someone finds a\n    // way to exploit uuid generation let's not allow keys or values that contain\n    // the delimiter.\n    if (key.includes(delimiter)) {\n        throw new Error(`Unexpected input: name should not contain the delimiter \"${delimiter}\"`);\n    }\n    if (convertedValue.includes(delimiter)) {\n        throw new Error(`Unexpected input: value should not contain the delimiter \"${delimiter}\"`);\n    }\n    return `${key}<<${delimiter}${os.EOL}${convertedValue}${os.EOL}${delimiter}`;\n}\nexports.prepareKeyValueMessage = prepareKeyValueMessage;\n//# sourceMappingURL=file-command.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.OidcClient = void 0;\nconst http_client_1 = require(\"@actions/http-client\");\nconst auth_1 = require(\"@actions/http-client/lib/auth\");\nconst core_1 = require(\"./core\");\nclass OidcClient {\n    static createHttpClient(allowRetry = true, maxRetry = 10) {\n        const requestOptions = {\n            allowRetries: allowRetry,\n            maxRetries: maxRetry\n        };\n        return new http_client_1.HttpClient('actions/oidc-client', [new auth_1.BearerCredentialHandler(OidcClient.getRequestToken())], requestOptions);\n    }\n    static getRequestToken() {\n        const token = process.env['ACTIONS_ID_TOKEN_REQUEST_TOKEN'];\n        if (!token) {\n            throw new Error('Unable to get ACTIONS_ID_TOKEN_REQUEST_TOKEN env variable');\n        }\n        return token;\n    }\n    static getIDTokenUrl() {\n        const runtimeUrl = process.env['ACTIONS_ID_TOKEN_REQUEST_URL'];\n        if (!runtimeUrl) {\n            throw new Error('Unable to get ACTIONS_ID_TOKEN_REQUEST_URL env variable');\n        }\n        return runtimeUrl;\n    }\n    static getCall(id_token_url) {\n        var _a;\n        return __awaiter(this, void 0, void 0, function* () {\n            const httpclient = OidcClient.createHttpClient();\n            const res = yield httpclient\n                .getJson(id_token_url)\n                .catch(error => {\n                throw new Error(`Failed to get ID Token. \\n \n        Error Code : ${error.statusCode}\\n \n        Error Message: ${error.message}`);\n            });\n            const id_token = (_a = res.result) === null || _a === void 0 ? void 0 : _a.value;\n            if (!id_token) {\n                throw new Error('Response json body do not have ID Token field');\n            }\n            return id_token;\n        });\n    }\n    static getIDToken(audience) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                // New ID Token is requested from action service\n                let id_token_url = OidcClient.getIDTokenUrl();\n                if (audience) {\n                    const encodedAudience = encodeURIComponent(audience);\n                    id_token_url = `${id_token_url}&audience=${encodedAudience}`;\n                }\n                core_1.debug(`ID token url is ${id_token_url}`);\n                const id_token = yield OidcClient.getCall(id_token_url);\n                core_1.setSecret(id_token);\n                return id_token;\n            }\n            catch (error) {\n                throw new Error(`Error message: ${error.message}`);\n            }\n        });\n    }\n}\nexports.OidcClient = OidcClient;\n//# sourceMappingURL=oidc-utils.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toPlatformPath = exports.toWin32Path = exports.toPosixPath = void 0;\nconst path = __importStar(require(\"path\"));\n/**\n * toPosixPath converts the given path to the posix form. On Windows, \\\\ will be\n * replaced with /.\n *\n * @param pth. Path to transform.\n * @return string Posix path.\n */\nfunction toPosixPath(pth) {\n    return pth.replace(/[\\\\]/g, '/');\n}\nexports.toPosixPath = toPosixPath;\n/**\n * toWin32Path converts the given path to the win32 form. On Linux, / will be\n * replaced with \\\\.\n *\n * @param pth. Path to transform.\n * @return string Win32 path.\n */\nfunction toWin32Path(pth) {\n    return pth.replace(/[/]/g, '\\\\');\n}\nexports.toWin32Path = toWin32Path;\n/**\n * toPlatformPath converts the given path to a platform-specific path. It does\n * this by replacing instances of / and \\ with the platform-specific path\n * separator.\n *\n * @param pth The path to platformize.\n * @return string The platform-specific path.\n */\nfunction toPlatformPath(pth) {\n    return pth.replace(/[/\\\\]/g, path.sep);\n}\nexports.toPlatformPath = toPlatformPath;\n//# sourceMappingURL=path-utils.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.summary = exports.markdownSummary = exports.SUMMARY_DOCS_URL = exports.SUMMARY_ENV_VAR = void 0;\nconst os_1 = require(\"os\");\nconst fs_1 = require(\"fs\");\nconst { access, appendFile, writeFile } = fs_1.promises;\nexports.SUMMARY_ENV_VAR = 'GITHUB_STEP_SUMMARY';\nexports.SUMMARY_DOCS_URL = 'https://docs.github.com/actions/using-workflows/workflow-commands-for-github-actions#adding-a-job-summary';\nclass Summary {\n    constructor() {\n        this._buffer = '';\n    }\n    /**\n     * Finds the summary file path from the environment, rejects if env var is not found or file does not exist\n     * Also checks r/w permissions.\n     *\n     * @returns step summary file path\n     */\n    filePath() {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this._filePath) {\n                return this._filePath;\n            }\n            const pathFromEnv = process.env[exports.SUMMARY_ENV_VAR];\n            if (!pathFromEnv) {\n                throw new Error(`Unable to find environment variable for $${exports.SUMMARY_ENV_VAR}. Check if your runtime environment supports job summaries.`);\n            }\n            try {\n                yield access(pathFromEnv, fs_1.constants.R_OK | fs_1.constants.W_OK);\n            }\n            catch (_a) {\n                throw new Error(`Unable to access summary file: '${pathFromEnv}'. Check if the file has correct read/write permissions.`);\n            }\n            this._filePath = pathFromEnv;\n            return this._filePath;\n        });\n    }\n    /**\n     * Wraps content in an HTML tag, adding any HTML attributes\n     *\n     * @param {string} tag HTML tag to wrap\n     * @param {string | null} content content within the tag\n     * @param {[attribute: string]: string} attrs key-value list of HTML attributes to add\n     *\n     * @returns {string} content wrapped in HTML element\n     */\n    wrap(tag, content, attrs = {}) {\n        const htmlAttrs = Object.entries(attrs)\n            .map(([key, value]) => ` ${key}=\"${value}\"`)\n            .join('');\n        if (!content) {\n            return `<${tag}${htmlAttrs}>`;\n        }\n        return `<${tag}${htmlAttrs}>${content}</${tag}>`;\n    }\n    /**\n     * Writes text in the buffer to the summary buffer file and empties buffer. Will append by default.\n     *\n     * @param {SummaryWriteOptions} [options] (optional) options for write operation\n     *\n     * @returns {Promise<Summary>} summary instance\n     */\n    write(options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const overwrite = !!(options === null || options === void 0 ? void 0 : options.overwrite);\n            const filePath = yield this.filePath();\n            const writeFunc = overwrite ? writeFile : appendFile;\n            yield writeFunc(filePath, this._buffer, { encoding: 'utf8' });\n            return this.emptyBuffer();\n        });\n    }\n    /**\n     * Clears the summary buffer and wipes the summary file\n     *\n     * @returns {Summary} summary instance\n     */\n    clear() {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.emptyBuffer().write({ overwrite: true });\n        });\n    }\n    /**\n     * Returns the current summary buffer as a string\n     *\n     * @returns {string} string of summary buffer\n     */\n    stringify() {\n        return this._buffer;\n    }\n    /**\n     * If the summary buffer is empty\n     *\n     * @returns {boolen} true if the buffer is empty\n     */\n    isEmptyBuffer() {\n        return this._buffer.length === 0;\n    }\n    /**\n     * Resets the summary buffer without writing to summary file\n     *\n     * @returns {Summary} summary instance\n     */\n    emptyBuffer() {\n        this._buffer = '';\n        return this;\n    }\n    /**\n     * Adds raw text to the summary buffer\n     *\n     * @param {string} text content to add\n     * @param {boolean} [addEOL=false] (optional) append an EOL to the raw text (default: false)\n     *\n     * @returns {Summary} summary instance\n     */\n    addRaw(text, addEOL = false) {\n        this._buffer += text;\n        return addEOL ? this.addEOL() : this;\n    }\n    /**\n     * Adds the operating system-specific end-of-line marker to the buffer\n     *\n     * @returns {Summary} summary instance\n     */\n    addEOL() {\n        return this.addRaw(os_1.EOL);\n    }\n    /**\n     * Adds an HTML codeblock to the summary buffer\n     *\n     * @param {string} code content to render within fenced code block\n     * @param {string} lang (optional) language to syntax highlight code\n     *\n     * @returns {Summary} summary instance\n     */\n    addCodeBlock(code, lang) {\n        const attrs = Object.assign({}, (lang && { lang }));\n        const element = this.wrap('pre', this.wrap('code', code), attrs);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML list to the summary buffer\n     *\n     * @param {string[]} items list of items to render\n     * @param {boolean} [ordered=false] (optional) if the rendered list should be ordered or not (default: false)\n     *\n     * @returns {Summary} summary instance\n     */\n    addList(items, ordered = false) {\n        const tag = ordered ? 'ol' : 'ul';\n        const listItems = items.map(item => this.wrap('li', item)).join('');\n        const element = this.wrap(tag, listItems);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML table to the summary buffer\n     *\n     * @param {SummaryTableCell[]} rows table rows\n     *\n     * @returns {Summary} summary instance\n     */\n    addTable(rows) {\n        const tableBody = rows\n            .map(row => {\n            const cells = row\n                .map(cell => {\n                if (typeof cell === 'string') {\n                    return this.wrap('td', cell);\n                }\n                const { header, data, colspan, rowspan } = cell;\n                const tag = header ? 'th' : 'td';\n                const attrs = Object.assign(Object.assign({}, (colspan && { colspan })), (rowspan && { rowspan }));\n                return this.wrap(tag, data, attrs);\n            })\n                .join('');\n            return this.wrap('tr', cells);\n        })\n            .join('');\n        const element = this.wrap('table', tableBody);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds a collapsable HTML details element to the summary buffer\n     *\n     * @param {string} label text for the closed state\n     * @param {string} content collapsable content\n     *\n     * @returns {Summary} summary instance\n     */\n    addDetails(label, content) {\n        const element = this.wrap('details', this.wrap('summary', label) + content);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML image tag to the summary buffer\n     *\n     * @param {string} src path to the image you to embed\n     * @param {string} alt text description of the image\n     * @param {SummaryImageOptions} options (optional) addition image attributes\n     *\n     * @returns {Summary} summary instance\n     */\n    addImage(src, alt, options) {\n        const { width, height } = options || {};\n        const attrs = Object.assign(Object.assign({}, (width && { width })), (height && { height }));\n        const element = this.wrap('img', null, Object.assign({ src, alt }, attrs));\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML section heading element\n     *\n     * @param {string} text heading text\n     * @param {number | string} [level=1] (optional) the heading level, default: 1\n     *\n     * @returns {Summary} summary instance\n     */\n    addHeading(text, level) {\n        const tag = `h${level}`;\n        const allowedTag = ['h1', 'h2', 'h3', 'h4', 'h5', 'h6'].includes(tag)\n            ? tag\n            : 'h1';\n        const element = this.wrap(allowedTag, text);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML thematic break (<hr>) to the summary buffer\n     *\n     * @returns {Summary} summary instance\n     */\n    addSeparator() {\n        const element = this.wrap('hr', null);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML line break (<br>) to the summary buffer\n     *\n     * @returns {Summary} summary instance\n     */\n    addBreak() {\n        const element = this.wrap('br', null);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML blockquote to the summary buffer\n     *\n     * @param {string} text quote text\n     * @param {string} cite (optional) citation url\n     *\n     * @returns {Summary} summary instance\n     */\n    addQuote(text, cite) {\n        const attrs = Object.assign({}, (cite && { cite }));\n        const element = this.wrap('blockquote', text, attrs);\n        return this.addRaw(element).addEOL();\n    }\n    /**\n     * Adds an HTML anchor tag to the summary buffer\n     *\n     * @param {string} text link text/content\n     * @param {string} href hyperlink\n     *\n     * @returns {Summary} summary instance\n     */\n    addLink(text, href) {\n        const element = this.wrap('a', text, { href });\n        return this.addRaw(element).addEOL();\n    }\n}\nconst _summary = new Summary();\n/**\n * @deprecated use `core.summary`\n */\nexports.markdownSummary = _summary;\nexports.summary = _summary;\n//# sourceMappingURL=summary.js.map","\"use strict\";\n// We use any as a valid input type\n/* eslint-disable @typescript-eslint/no-explicit-any */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.toCommandProperties = exports.toCommandValue = void 0;\n/**\n * Sanitizes an input into a string so it can be passed into issueCommand safely\n * @param input input to sanitize into a string\n */\nfunction toCommandValue(input) {\n    if (input === null || input === undefined) {\n        return '';\n    }\n    else if (typeof input === 'string' || input instanceof String) {\n        return input;\n    }\n    return JSON.stringify(input);\n}\nexports.toCommandValue = toCommandValue;\n/**\n *\n * @param annotationProperties\n * @returns The command properties to send with the actual annotation command\n * See IssueCommandProperties: https://github.com/actions/runner/blob/main/src/Runner.Worker/ActionCommandManager.cs#L646\n */\nfunction toCommandProperties(annotationProperties) {\n    if (!Object.keys(annotationProperties).length) {\n        return {};\n    }\n    return {\n        title: annotationProperties.title,\n        file: annotationProperties.file,\n        line: annotationProperties.startLine,\n        endLine: annotationProperties.endLine,\n        col: annotationProperties.startColumn,\n        endColumn: annotationProperties.endColumn\n    };\n}\nexports.toCommandProperties = toCommandProperties;\n//# sourceMappingURL=utils.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Context = void 0;\nconst fs_1 = require(\"fs\");\nconst os_1 = require(\"os\");\nclass Context {\n    /**\n     * Hydrate the context from the environment\n     */\n    constructor() {\n        var _a, _b, _c;\n        this.payload = {};\n        if (process.env.GITHUB_EVENT_PATH) {\n            if ((0, fs_1.existsSync)(process.env.GITHUB_EVENT_PATH)) {\n                this.payload = JSON.parse((0, fs_1.readFileSync)(process.env.GITHUB_EVENT_PATH, { encoding: 'utf8' }));\n            }\n            else {\n                const path = process.env.GITHUB_EVENT_PATH;\n                process.stdout.write(`GITHUB_EVENT_PATH ${path} does not exist${os_1.EOL}`);\n            }\n        }\n        this.eventName = process.env.GITHUB_EVENT_NAME;\n        this.sha = process.env.GITHUB_SHA;\n        this.ref = process.env.GITHUB_REF;\n        this.workflow = process.env.GITHUB_WORKFLOW;\n        this.action = process.env.GITHUB_ACTION;\n        this.actor = process.env.GITHUB_ACTOR;\n        this.job = process.env.GITHUB_JOB;\n        this.runNumber = parseInt(process.env.GITHUB_RUN_NUMBER, 10);\n        this.runId = parseInt(process.env.GITHUB_RUN_ID, 10);\n        this.apiUrl = (_a = process.env.GITHUB_API_URL) !== null && _a !== void 0 ? _a : `https://api.github.com`;\n        this.serverUrl = (_b = process.env.GITHUB_SERVER_URL) !== null && _b !== void 0 ? _b : `https://github.com`;\n        this.graphqlUrl =\n            (_c = process.env.GITHUB_GRAPHQL_URL) !== null && _c !== void 0 ? _c : `https://api.github.com/graphql`;\n    }\n    get issue() {\n        const payload = this.payload;\n        return Object.assign(Object.assign({}, this.repo), { number: (payload.issue || payload.pull_request || payload).number });\n    }\n    get repo() {\n        if (process.env.GITHUB_REPOSITORY) {\n            const [owner, repo] = process.env.GITHUB_REPOSITORY.split('/');\n            return { owner, repo };\n        }\n        if (this.payload.repository) {\n            return {\n                owner: this.payload.repository.owner.login,\n                repo: this.payload.repository.name\n            };\n        }\n        throw new Error(\"context.repo requires a GITHUB_REPOSITORY environment variable like 'owner/repo'\");\n    }\n}\nexports.Context = Context;\n//# sourceMappingURL=context.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getOctokit = exports.context = void 0;\nconst Context = __importStar(require(\"./context\"));\nconst utils_1 = require(\"./utils\");\nexports.context = new Context.Context();\n/**\n * Returns a hydrated octokit ready to use for GitHub Actions\n *\n * @param     token    the repo PAT or GITHUB_TOKEN\n * @param     options  other options to set\n */\nfunction getOctokit(token, options, ...additionalPlugins) {\n    const GitHubWithPlugins = utils_1.GitHub.plugin(...additionalPlugins);\n    return new GitHubWithPlugins((0, utils_1.getOctokitOptions)(token, options));\n}\nexports.getOctokit = getOctokit;\n//# sourceMappingURL=github.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getApiBaseUrl = exports.getProxyFetch = exports.getProxyAgentDispatcher = exports.getProxyAgent = exports.getAuthString = void 0;\nconst httpClient = __importStar(require(\"@actions/http-client\"));\nconst undici_1 = require(\"undici\");\nfunction getAuthString(token, options) {\n    if (!token && !options.auth) {\n        throw new Error('Parameter token or opts.auth is required');\n    }\n    else if (token && options.auth) {\n        throw new Error('Parameters token and opts.auth may not both be specified');\n    }\n    return typeof options.auth === 'string' ? options.auth : `token ${token}`;\n}\nexports.getAuthString = getAuthString;\nfunction getProxyAgent(destinationUrl) {\n    const hc = new httpClient.HttpClient();\n    return hc.getAgent(destinationUrl);\n}\nexports.getProxyAgent = getProxyAgent;\nfunction getProxyAgentDispatcher(destinationUrl) {\n    const hc = new httpClient.HttpClient();\n    return hc.getAgentDispatcher(destinationUrl);\n}\nexports.getProxyAgentDispatcher = getProxyAgentDispatcher;\nfunction getProxyFetch(destinationUrl) {\n    const httpDispatcher = getProxyAgentDispatcher(destinationUrl);\n    const proxyFetch = (url, opts) => __awaiter(this, void 0, void 0, function* () {\n        return (0, undici_1.fetch)(url, Object.assign(Object.assign({}, opts), { dispatcher: httpDispatcher }));\n    });\n    return proxyFetch;\n}\nexports.getProxyFetch = getProxyFetch;\nfunction getApiBaseUrl() {\n    return process.env['GITHUB_API_URL'] || 'https://api.github.com';\n}\nexports.getApiBaseUrl = getApiBaseUrl;\n//# sourceMappingURL=utils.js.map","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.getOctokitOptions = exports.GitHub = exports.defaults = exports.context = void 0;\nconst Context = __importStar(require(\"./context\"));\nconst Utils = __importStar(require(\"./internal/utils\"));\n// octokit + plugins\nconst core_1 = require(\"@octokit/core\");\nconst plugin_rest_endpoint_methods_1 = require(\"@octokit/plugin-rest-endpoint-methods\");\nconst plugin_paginate_rest_1 = require(\"@octokit/plugin-paginate-rest\");\nexports.context = new Context.Context();\nconst baseUrl = Utils.getApiBaseUrl();\nexports.defaults = {\n    baseUrl,\n    request: {\n        agent: Utils.getProxyAgent(baseUrl),\n        fetch: Utils.getProxyFetch(baseUrl)\n    }\n};\nexports.GitHub = core_1.Octokit.plugin(plugin_rest_endpoint_methods_1.restEndpointMethods, plugin_paginate_rest_1.paginateRest).defaults(exports.defaults);\n/**\n * Convience function to correctly format Octokit Options to pass into the constructor.\n *\n * @param     token    the repo PAT or GITHUB_TOKEN\n * @param     options  other options to set\n */\nfunction getOctokitOptions(token, options) {\n    const opts = Object.assign({}, options || {}); // Shallow clone - don't mutate the object provided by the caller\n    // Auth\n    const auth = Utils.getAuthString(token, opts);\n    if (auth) {\n        opts.auth = auth;\n    }\n    return opts;\n}\nexports.getOctokitOptions = getOctokitOptions;\n//# sourceMappingURL=utils.js.map","\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.PersonalAccessTokenCredentialHandler = exports.BearerCredentialHandler = exports.BasicCredentialHandler = void 0;\nclass BasicCredentialHandler {\n    constructor(username, password) {\n        this.username = username;\n        this.password = password;\n    }\n    prepareRequest(options) {\n        if (!options.headers) {\n            throw Error('The request has no headers');\n        }\n        options.headers['Authorization'] = `Basic ${Buffer.from(`${this.username}:${this.password}`).toString('base64')}`;\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication() {\n        return false;\n    }\n    handleAuthentication() {\n        return __awaiter(this, void 0, void 0, function* () {\n            throw new Error('not implemented');\n        });\n    }\n}\nexports.BasicCredentialHandler = BasicCredentialHandler;\nclass BearerCredentialHandler {\n    constructor(token) {\n        this.token = token;\n    }\n    // currently implements pre-authorization\n    // TODO: support preAuth = false where it hooks on 401\n    prepareRequest(options) {\n        if (!options.headers) {\n            throw Error('The request has no headers');\n        }\n        options.headers['Authorization'] = `Bearer ${this.token}`;\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication() {\n        return false;\n    }\n    handleAuthentication() {\n        return __awaiter(this, void 0, void 0, function* () {\n            throw new Error('not implemented');\n        });\n    }\n}\nexports.BearerCredentialHandler = BearerCredentialHandler;\nclass PersonalAccessTokenCredentialHandler {\n    constructor(token) {\n        this.token = token;\n    }\n    // currently implements pre-authorization\n    // TODO: support preAuth = false where it hooks on 401\n    prepareRequest(options) {\n        if (!options.headers) {\n            throw Error('The request has no headers');\n        }\n        options.headers['Authorization'] = `Basic ${Buffer.from(`PAT:${this.token}`).toString('base64')}`;\n    }\n    // This handler cannot handle 401\n    canHandleAuthentication() {\n        return false;\n    }\n    handleAuthentication() {\n        return __awaiter(this, void 0, void 0, function* () {\n            throw new Error('not implemented');\n        });\n    }\n}\nexports.PersonalAccessTokenCredentialHandler = PersonalAccessTokenCredentialHandler;\n//# sourceMappingURL=auth.js.map","\"use strict\";\n/* eslint-disable @typescript-eslint/no-explicit-any */\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.HttpClient = exports.isHttps = exports.HttpClientResponse = exports.HttpClientError = exports.getProxyUrl = exports.MediaTypes = exports.Headers = exports.HttpCodes = void 0;\nconst http = __importStar(require(\"http\"));\nconst https = __importStar(require(\"https\"));\nconst pm = __importStar(require(\"./proxy\"));\nconst tunnel = __importStar(require(\"tunnel\"));\nconst undici_1 = require(\"undici\");\nvar HttpCodes;\n(function (HttpCodes) {\n    HttpCodes[HttpCodes[\"OK\"] = 200] = \"OK\";\n    HttpCodes[HttpCodes[\"MultipleChoices\"] = 300] = \"MultipleChoices\";\n    HttpCodes[HttpCodes[\"MovedPermanently\"] = 301] = \"MovedPermanently\";\n    HttpCodes[HttpCodes[\"ResourceMoved\"] = 302] = \"ResourceMoved\";\n    HttpCodes[HttpCodes[\"SeeOther\"] = 303] = \"SeeOther\";\n    HttpCodes[HttpCodes[\"NotModified\"] = 304] = \"NotModified\";\n    HttpCodes[HttpCodes[\"UseProxy\"] = 305] = \"UseProxy\";\n    HttpCodes[HttpCodes[\"SwitchProxy\"] = 306] = \"SwitchProxy\";\n    HttpCodes[HttpCodes[\"TemporaryRedirect\"] = 307] = \"TemporaryRedirect\";\n    HttpCodes[HttpCodes[\"PermanentRedirect\"] = 308] = \"PermanentRedirect\";\n    HttpCodes[HttpCodes[\"BadRequest\"] = 400] = \"BadRequest\";\n    HttpCodes[HttpCodes[\"Unauthorized\"] = 401] = \"Unauthorized\";\n    HttpCodes[HttpCodes[\"PaymentRequired\"] = 402] = \"PaymentRequired\";\n    HttpCodes[HttpCodes[\"Forbidden\"] = 403] = \"Forbidden\";\n    HttpCodes[HttpCodes[\"NotFound\"] = 404] = \"NotFound\";\n    HttpCodes[HttpCodes[\"MethodNotAllowed\"] = 405] = \"MethodNotAllowed\";\n    HttpCodes[HttpCodes[\"NotAcceptable\"] = 406] = \"NotAcceptable\";\n    HttpCodes[HttpCodes[\"ProxyAuthenticationRequired\"] = 407] = \"ProxyAuthenticationRequired\";\n    HttpCodes[HttpCodes[\"RequestTimeout\"] = 408] = \"RequestTimeout\";\n    HttpCodes[HttpCodes[\"Conflict\"] = 409] = \"Conflict\";\n    HttpCodes[HttpCodes[\"Gone\"] = 410] = \"Gone\";\n    HttpCodes[HttpCodes[\"TooManyRequests\"] = 429] = \"TooManyRequests\";\n    HttpCodes[HttpCodes[\"InternalServerError\"] = 500] = \"InternalServerError\";\n    HttpCodes[HttpCodes[\"NotImplemented\"] = 501] = \"NotImplemented\";\n    HttpCodes[HttpCodes[\"BadGateway\"] = 502] = \"BadGateway\";\n    HttpCodes[HttpCodes[\"ServiceUnavailable\"] = 503] = \"ServiceUnavailable\";\n    HttpCodes[HttpCodes[\"GatewayTimeout\"] = 504] = \"GatewayTimeout\";\n})(HttpCodes || (exports.HttpCodes = HttpCodes = {}));\nvar Headers;\n(function (Headers) {\n    Headers[\"Accept\"] = \"accept\";\n    Headers[\"ContentType\"] = \"content-type\";\n})(Headers || (exports.Headers = Headers = {}));\nvar MediaTypes;\n(function (MediaTypes) {\n    MediaTypes[\"ApplicationJson\"] = \"application/json\";\n})(MediaTypes || (exports.MediaTypes = MediaTypes = {}));\n/**\n * Returns the proxy URL, depending upon the supplied url and proxy environment variables.\n * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com\n */\nfunction getProxyUrl(serverUrl) {\n    const proxyUrl = pm.getProxyUrl(new URL(serverUrl));\n    return proxyUrl ? proxyUrl.href : '';\n}\nexports.getProxyUrl = getProxyUrl;\nconst HttpRedirectCodes = [\n    HttpCodes.MovedPermanently,\n    HttpCodes.ResourceMoved,\n    HttpCodes.SeeOther,\n    HttpCodes.TemporaryRedirect,\n    HttpCodes.PermanentRedirect\n];\nconst HttpResponseRetryCodes = [\n    HttpCodes.BadGateway,\n    HttpCodes.ServiceUnavailable,\n    HttpCodes.GatewayTimeout\n];\nconst RetryableHttpVerbs = ['OPTIONS', 'GET', 'DELETE', 'HEAD'];\nconst ExponentialBackoffCeiling = 10;\nconst ExponentialBackoffTimeSlice = 5;\nclass HttpClientError extends Error {\n    constructor(message, statusCode) {\n        super(message);\n        this.name = 'HttpClientError';\n        this.statusCode = statusCode;\n        Object.setPrototypeOf(this, HttpClientError.prototype);\n    }\n}\nexports.HttpClientError = HttpClientError;\nclass HttpClientResponse {\n    constructor(message) {\n        this.message = message;\n    }\n    readBody() {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve) => __awaiter(this, void 0, void 0, function* () {\n                let output = Buffer.alloc(0);\n                this.message.on('data', (chunk) => {\n                    output = Buffer.concat([output, chunk]);\n                });\n                this.message.on('end', () => {\n                    resolve(output.toString());\n                });\n            }));\n        });\n    }\n    readBodyBuffer() {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve) => __awaiter(this, void 0, void 0, function* () {\n                const chunks = [];\n                this.message.on('data', (chunk) => {\n                    chunks.push(chunk);\n                });\n                this.message.on('end', () => {\n                    resolve(Buffer.concat(chunks));\n                });\n            }));\n        });\n    }\n}\nexports.HttpClientResponse = HttpClientResponse;\nfunction isHttps(requestUrl) {\n    const parsedUrl = new URL(requestUrl);\n    return parsedUrl.protocol === 'https:';\n}\nexports.isHttps = isHttps;\nclass HttpClient {\n    constructor(userAgent, handlers, requestOptions) {\n        this._ignoreSslError = false;\n        this._allowRedirects = true;\n        this._allowRedirectDowngrade = false;\n        this._maxRedirects = 50;\n        this._allowRetries = false;\n        this._maxRetries = 1;\n        this._keepAlive = false;\n        this._disposed = false;\n        this.userAgent = userAgent;\n        this.handlers = handlers || [];\n        this.requestOptions = requestOptions;\n        if (requestOptions) {\n            if (requestOptions.ignoreSslError != null) {\n                this._ignoreSslError = requestOptions.ignoreSslError;\n            }\n            this._socketTimeout = requestOptions.socketTimeout;\n            if (requestOptions.allowRedirects != null) {\n                this._allowRedirects = requestOptions.allowRedirects;\n            }\n            if (requestOptions.allowRedirectDowngrade != null) {\n                this._allowRedirectDowngrade = requestOptions.allowRedirectDowngrade;\n            }\n            if (requestOptions.maxRedirects != null) {\n                this._maxRedirects = Math.max(requestOptions.maxRedirects, 0);\n            }\n            if (requestOptions.keepAlive != null) {\n                this._keepAlive = requestOptions.keepAlive;\n            }\n            if (requestOptions.allowRetries != null) {\n                this._allowRetries = requestOptions.allowRetries;\n            }\n            if (requestOptions.maxRetries != null) {\n                this._maxRetries = requestOptions.maxRetries;\n            }\n        }\n    }\n    options(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('OPTIONS', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    get(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('GET', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    del(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('DELETE', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    post(requestUrl, data, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('POST', requestUrl, data, additionalHeaders || {});\n        });\n    }\n    patch(requestUrl, data, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('PATCH', requestUrl, data, additionalHeaders || {});\n        });\n    }\n    put(requestUrl, data, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('PUT', requestUrl, data, additionalHeaders || {});\n        });\n    }\n    head(requestUrl, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request('HEAD', requestUrl, null, additionalHeaders || {});\n        });\n    }\n    sendStream(verb, requestUrl, stream, additionalHeaders) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.request(verb, requestUrl, stream, additionalHeaders);\n        });\n    }\n    /**\n     * Gets a typed object from an endpoint\n     * Be aware that not found returns a null.  Other errors (4xx, 5xx) reject the promise\n     */\n    getJson(requestUrl, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            const res = yield this.get(requestUrl, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    postJson(requestUrl, obj, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const data = JSON.stringify(obj, null, 2);\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n            const res = yield this.post(requestUrl, data, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    putJson(requestUrl, obj, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const data = JSON.stringify(obj, null, 2);\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n            const res = yield this.put(requestUrl, data, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    patchJson(requestUrl, obj, additionalHeaders = {}) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const data = JSON.stringify(obj, null, 2);\n            additionalHeaders[Headers.Accept] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.Accept, MediaTypes.ApplicationJson);\n            additionalHeaders[Headers.ContentType] = this._getExistingOrDefaultHeader(additionalHeaders, Headers.ContentType, MediaTypes.ApplicationJson);\n            const res = yield this.patch(requestUrl, data, additionalHeaders);\n            return this._processResponse(res, this.requestOptions);\n        });\n    }\n    /**\n     * Makes a raw http request.\n     * All other methods such as get, post, patch, and request ultimately call this.\n     * Prefer get, del, post and patch\n     */\n    request(verb, requestUrl, data, headers) {\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this._disposed) {\n                throw new Error('Client has already been disposed.');\n            }\n            const parsedUrl = new URL(requestUrl);\n            let info = this._prepareRequest(verb, parsedUrl, headers);\n            // Only perform retries on reads since writes may not be idempotent.\n            const maxTries = this._allowRetries && RetryableHttpVerbs.includes(verb)\n                ? this._maxRetries + 1\n                : 1;\n            let numTries = 0;\n            let response;\n            do {\n                response = yield this.requestRaw(info, data);\n                // Check if it's an authentication challenge\n                if (response &&\n                    response.message &&\n                    response.message.statusCode === HttpCodes.Unauthorized) {\n                    let authenticationHandler;\n                    for (const handler of this.handlers) {\n                        if (handler.canHandleAuthentication(response)) {\n                            authenticationHandler = handler;\n                            break;\n                        }\n                    }\n                    if (authenticationHandler) {\n                        return authenticationHandler.handleAuthentication(this, info, data);\n                    }\n                    else {\n                        // We have received an unauthorized response but have no handlers to handle it.\n                        // Let the response return to the caller.\n                        return response;\n                    }\n                }\n                let redirectsRemaining = this._maxRedirects;\n                while (response.message.statusCode &&\n                    HttpRedirectCodes.includes(response.message.statusCode) &&\n                    this._allowRedirects &&\n                    redirectsRemaining > 0) {\n                    const redirectUrl = response.message.headers['location'];\n                    if (!redirectUrl) {\n                        // if there's no location to redirect to, we won't\n                        break;\n                    }\n                    const parsedRedirectUrl = new URL(redirectUrl);\n                    if (parsedUrl.protocol === 'https:' &&\n                        parsedUrl.protocol !== parsedRedirectUrl.protocol &&\n                        !this._allowRedirectDowngrade) {\n                        throw new Error('Redirect from HTTPS to HTTP protocol. This downgrade is not allowed for security reasons. If you want to allow this behavior, set the allowRedirectDowngrade option to true.');\n                    }\n                    // we need to finish reading the response before reassigning response\n                    // which will leak the open socket.\n                    yield response.readBody();\n                    // strip authorization header if redirected to a different hostname\n                    if (parsedRedirectUrl.hostname !== parsedUrl.hostname) {\n                        for (const header in headers) {\n                            // header names are case insensitive\n                            if (header.toLowerCase() === 'authorization') {\n                                delete headers[header];\n                            }\n                        }\n                    }\n                    // let's make the request with the new redirectUrl\n                    info = this._prepareRequest(verb, parsedRedirectUrl, headers);\n                    response = yield this.requestRaw(info, data);\n                    redirectsRemaining--;\n                }\n                if (!response.message.statusCode ||\n                    !HttpResponseRetryCodes.includes(response.message.statusCode)) {\n                    // If not a retry code, return immediately instead of retrying\n                    return response;\n                }\n                numTries += 1;\n                if (numTries < maxTries) {\n                    yield response.readBody();\n                    yield this._performExponentialBackoff(numTries);\n                }\n            } while (numTries < maxTries);\n            return response;\n        });\n    }\n    /**\n     * Needs to be called if keepAlive is set to true in request options.\n     */\n    dispose() {\n        if (this._agent) {\n            this._agent.destroy();\n        }\n        this._disposed = true;\n    }\n    /**\n     * Raw request.\n     * @param info\n     * @param data\n     */\n    requestRaw(info, data) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve, reject) => {\n                function callbackForResult(err, res) {\n                    if (err) {\n                        reject(err);\n                    }\n                    else if (!res) {\n                        // If `err` is not passed, then `res` must be passed.\n                        reject(new Error('Unknown error'));\n                    }\n                    else {\n                        resolve(res);\n                    }\n                }\n                this.requestRawWithCallback(info, data, callbackForResult);\n            });\n        });\n    }\n    /**\n     * Raw request with callback.\n     * @param info\n     * @param data\n     * @param onResult\n     */\n    requestRawWithCallback(info, data, onResult) {\n        if (typeof data === 'string') {\n            if (!info.options.headers) {\n                info.options.headers = {};\n            }\n            info.options.headers['Content-Length'] = Buffer.byteLength(data, 'utf8');\n        }\n        let callbackCalled = false;\n        function handleResult(err, res) {\n            if (!callbackCalled) {\n                callbackCalled = true;\n                onResult(err, res);\n            }\n        }\n        const req = info.httpModule.request(info.options, (msg) => {\n            const res = new HttpClientResponse(msg);\n            handleResult(undefined, res);\n        });\n        let socket;\n        req.on('socket', sock => {\n            socket = sock;\n        });\n        // If we ever get disconnected, we want the socket to timeout eventually\n        req.setTimeout(this._socketTimeout || 3 * 60000, () => {\n            if (socket) {\n                socket.end();\n            }\n            handleResult(new Error(`Request timeout: ${info.options.path}`));\n        });\n        req.on('error', function (err) {\n            // err has statusCode property\n            // res should have headers\n            handleResult(err);\n        });\n        if (data && typeof data === 'string') {\n            req.write(data, 'utf8');\n        }\n        if (data && typeof data !== 'string') {\n            data.on('close', function () {\n                req.end();\n            });\n            data.pipe(req);\n        }\n        else {\n            req.end();\n        }\n    }\n    /**\n     * Gets an http agent. This function is useful when you need an http agent that handles\n     * routing through a proxy server - depending upon the url and proxy environment variables.\n     * @param serverUrl  The server URL where the request will be sent. For example, https://api.github.com\n     */\n    getAgent(serverUrl) {\n        const parsedUrl = new URL(serverUrl);\n        return this._getAgent(parsedUrl);\n    }\n    getAgentDispatcher(serverUrl) {\n        const parsedUrl = new URL(serverUrl);\n        const proxyUrl = pm.getProxyUrl(parsedUrl);\n        const useProxy = proxyUrl && proxyUrl.hostname;\n        if (!useProxy) {\n            return;\n        }\n        return this._getProxyAgentDispatcher(parsedUrl, proxyUrl);\n    }\n    _prepareRequest(method, requestUrl, headers) {\n        const info = {};\n        info.parsedUrl = requestUrl;\n        const usingSsl = info.parsedUrl.protocol === 'https:';\n        info.httpModule = usingSsl ? https : http;\n        const defaultPort = usingSsl ? 443 : 80;\n        info.options = {};\n        info.options.host = info.parsedUrl.hostname;\n        info.options.port = info.parsedUrl.port\n            ? parseInt(info.parsedUrl.port)\n            : defaultPort;\n        info.options.path =\n            (info.parsedUrl.pathname || '') + (info.parsedUrl.search || '');\n        info.options.method = method;\n        info.options.headers = this._mergeHeaders(headers);\n        if (this.userAgent != null) {\n            info.options.headers['user-agent'] = this.userAgent;\n        }\n        info.options.agent = this._getAgent(info.parsedUrl);\n        // gives handlers an opportunity to participate\n        if (this.handlers) {\n            for (const handler of this.handlers) {\n                handler.prepareRequest(info.options);\n            }\n        }\n        return info;\n    }\n    _mergeHeaders(headers) {\n        if (this.requestOptions && this.requestOptions.headers) {\n            return Object.assign({}, lowercaseKeys(this.requestOptions.headers), lowercaseKeys(headers || {}));\n        }\n        return lowercaseKeys(headers || {});\n    }\n    _getExistingOrDefaultHeader(additionalHeaders, header, _default) {\n        let clientHeader;\n        if (this.requestOptions && this.requestOptions.headers) {\n            clientHeader = lowercaseKeys(this.requestOptions.headers)[header];\n        }\n        return additionalHeaders[header] || clientHeader || _default;\n    }\n    _getAgent(parsedUrl) {\n        let agent;\n        const proxyUrl = pm.getProxyUrl(parsedUrl);\n        const useProxy = proxyUrl && proxyUrl.hostname;\n        if (this._keepAlive && useProxy) {\n            agent = this._proxyAgent;\n        }\n        if (!useProxy) {\n            agent = this._agent;\n        }\n        // if agent is already assigned use that agent.\n        if (agent) {\n            return agent;\n        }\n        const usingSsl = parsedUrl.protocol === 'https:';\n        let maxSockets = 100;\n        if (this.requestOptions) {\n            maxSockets = this.requestOptions.maxSockets || http.globalAgent.maxSockets;\n        }\n        // This is `useProxy` again, but we need to check `proxyURl` directly for TypeScripts's flow analysis.\n        if (proxyUrl && proxyUrl.hostname) {\n            const agentOptions = {\n                maxSockets,\n                keepAlive: this._keepAlive,\n                proxy: Object.assign(Object.assign({}, ((proxyUrl.username || proxyUrl.password) && {\n                    proxyAuth: `${proxyUrl.username}:${proxyUrl.password}`\n                })), { host: proxyUrl.hostname, port: proxyUrl.port })\n            };\n            let tunnelAgent;\n            const overHttps = proxyUrl.protocol === 'https:';\n            if (usingSsl) {\n                tunnelAgent = overHttps ? tunnel.httpsOverHttps : tunnel.httpsOverHttp;\n            }\n            else {\n                tunnelAgent = overHttps ? tunnel.httpOverHttps : tunnel.httpOverHttp;\n            }\n            agent = tunnelAgent(agentOptions);\n            this._proxyAgent = agent;\n        }\n        // if tunneling agent isn't assigned create a new agent\n        if (!agent) {\n            const options = { keepAlive: this._keepAlive, maxSockets };\n            agent = usingSsl ? new https.Agent(options) : new http.Agent(options);\n            this._agent = agent;\n        }\n        if (usingSsl && this._ignoreSslError) {\n            // we don't want to set NODE_TLS_REJECT_UNAUTHORIZED=0 since that will affect request for entire process\n            // http.RequestOptions doesn't expose a way to modify RequestOptions.agent.options\n            // we have to cast it to any and change it directly\n            agent.options = Object.assign(agent.options || {}, {\n                rejectUnauthorized: false\n            });\n        }\n        return agent;\n    }\n    _getProxyAgentDispatcher(parsedUrl, proxyUrl) {\n        let proxyAgent;\n        if (this._keepAlive) {\n            proxyAgent = this._proxyAgentDispatcher;\n        }\n        // if agent is already assigned use that agent.\n        if (proxyAgent) {\n            return proxyAgent;\n        }\n        const usingSsl = parsedUrl.protocol === 'https:';\n        proxyAgent = new undici_1.ProxyAgent(Object.assign({ uri: proxyUrl.href, pipelining: !this._keepAlive ? 0 : 1 }, ((proxyUrl.username || proxyUrl.password) && {\n            token: `${proxyUrl.username}:${proxyUrl.password}`\n        })));\n        this._proxyAgentDispatcher = proxyAgent;\n        if (usingSsl && this._ignoreSslError) {\n            // we don't want to set NODE_TLS_REJECT_UNAUTHORIZED=0 since that will affect request for entire process\n            // http.RequestOptions doesn't expose a way to modify RequestOptions.agent.options\n            // we have to cast it to any and change it directly\n            proxyAgent.options = Object.assign(proxyAgent.options.requestTls || {}, {\n                rejectUnauthorized: false\n            });\n        }\n        return proxyAgent;\n    }\n    _performExponentialBackoff(retryNumber) {\n        return __awaiter(this, void 0, void 0, function* () {\n            retryNumber = Math.min(ExponentialBackoffCeiling, retryNumber);\n            const ms = ExponentialBackoffTimeSlice * Math.pow(2, retryNumber);\n            return new Promise(resolve => setTimeout(() => resolve(), ms));\n        });\n    }\n    _processResponse(res, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return new Promise((resolve, reject) => __awaiter(this, void 0, void 0, function* () {\n                const statusCode = res.message.statusCode || 0;\n                const response = {\n                    statusCode,\n                    result: null,\n                    headers: {}\n                };\n                // not found leads to null obj returned\n                if (statusCode === HttpCodes.NotFound) {\n                    resolve(response);\n                }\n                // get the result from the body\n                function dateTimeDeserializer(key, value) {\n                    if (typeof value === 'string') {\n                        const a = new Date(value);\n                        if (!isNaN(a.valueOf())) {\n                            return a;\n                        }\n                    }\n                    return value;\n                }\n                let obj;\n                let contents;\n                try {\n                    contents = yield res.readBody();\n                    if (contents && contents.length > 0) {\n                        if (options && options.deserializeDates) {\n                            obj = JSON.parse(contents, dateTimeDeserializer);\n                        }\n                        else {\n                            obj = JSON.parse(contents);\n                        }\n                        response.result = obj;\n                    }\n                    response.headers = res.message.headers;\n                }\n                catch (err) {\n                    // Invalid resource (contents not json);  leaving result obj null\n                }\n                // note that 3xx redirects are handled by the http layer.\n                if (statusCode > 299) {\n                    let msg;\n                    // if exception/error in body, attempt to get better error\n                    if (obj && obj.message) {\n                        msg = obj.message;\n                    }\n                    else if (contents && contents.length > 0) {\n                        // it may be the case that the exception is in the body message as string\n                        msg = contents;\n                    }\n                    else {\n                        msg = `Failed request: (${statusCode})`;\n                    }\n                    const err = new HttpClientError(msg, statusCode);\n                    err.result = response.result;\n                    reject(err);\n                }\n                else {\n                    resolve(response);\n                }\n            }));\n        });\n    }\n}\nexports.HttpClient = HttpClient;\nconst lowercaseKeys = (obj) => Object.keys(obj).reduce((c, k) => ((c[k.toLowerCase()] = obj[k]), c), {});\n//# sourceMappingURL=index.js.map","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.checkBypass = exports.getProxyUrl = void 0;\nfunction getProxyUrl(reqUrl) {\n    const usingSsl = reqUrl.protocol === 'https:';\n    if (checkBypass(reqUrl)) {\n        return undefined;\n    }\n    const proxyVar = (() => {\n        if (usingSsl) {\n            return process.env['https_proxy'] || process.env['HTTPS_PROXY'];\n        }\n        else {\n            return process.env['http_proxy'] || process.env['HTTP_PROXY'];\n        }\n    })();\n    if (proxyVar) {\n        try {\n            return new URL(proxyVar);\n        }\n        catch (_a) {\n            if (!proxyVar.startsWith('http://') && !proxyVar.startsWith('https://'))\n                return new URL(`http://${proxyVar}`);\n        }\n    }\n    else {\n        return undefined;\n    }\n}\nexports.getProxyUrl = getProxyUrl;\nfunction checkBypass(reqUrl) {\n    if (!reqUrl.hostname) {\n        return false;\n    }\n    const reqHost = reqUrl.hostname;\n    if (isLoopbackAddress(reqHost)) {\n        return true;\n    }\n    const noProxy = process.env['no_proxy'] || process.env['NO_PROXY'] || '';\n    if (!noProxy) {\n        return false;\n    }\n    // Determine the request port\n    let reqPort;\n    if (reqUrl.port) {\n        reqPort = Number(reqUrl.port);\n    }\n    else if (reqUrl.protocol === 'http:') {\n        reqPort = 80;\n    }\n    else if (reqUrl.protocol === 'https:') {\n        reqPort = 443;\n    }\n    // Format the request hostname and hostname with port\n    const upperReqHosts = [reqUrl.hostname.toUpperCase()];\n    if (typeof reqPort === 'number') {\n        upperReqHosts.push(`${upperReqHosts[0]}:${reqPort}`);\n    }\n    // Compare request host against noproxy\n    for (const upperNoProxyItem of noProxy\n        .split(',')\n        .map(x => x.trim().toUpperCase())\n        .filter(x => x)) {\n        if (upperNoProxyItem === '*' ||\n            upperReqHosts.some(x => x === upperNoProxyItem ||\n                x.endsWith(`.${upperNoProxyItem}`) ||\n                (upperNoProxyItem.startsWith('.') &&\n                    x.endsWith(`${upperNoProxyItem}`)))) {\n            return true;\n        }\n    }\n    return false;\n}\nexports.checkBypass = checkBypass;\nfunction isLoopbackAddress(host) {\n    const hostLower = host.toLowerCase();\n    return (hostLower === 'localhost' ||\n        hostLower.startsWith('127.') ||\n        hostLower.startsWith('[::1]') ||\n        hostLower.startsWith('[0:0:0:0:0:0:0:1]'));\n}\n//# sourceMappingURL=proxy.js.map","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar dist_src_exports = {};\n__export(dist_src_exports, {\n  createTokenAuth: () => createTokenAuth\n});\nmodule.exports = __toCommonJS(dist_src_exports);\n\n// pkg/dist-src/auth.js\nvar REGEX_IS_INSTALLATION_LEGACY = /^v1\\./;\nvar REGEX_IS_INSTALLATION = /^ghs_/;\nvar REGEX_IS_USER_TO_SERVER = /^ghu_/;\nasync function auth(token) {\n  const isApp = token.split(/\\./).length === 3;\n  const isInstallation = REGEX_IS_INSTALLATION_LEGACY.test(token) || REGEX_IS_INSTALLATION.test(token);\n  const isUserToServer = REGEX_IS_USER_TO_SERVER.test(token);\n  const tokenType = isApp ? \"app\" : isInstallation ? \"installation\" : isUserToServer ? \"user-to-server\" : \"oauth\";\n  return {\n    type: \"token\",\n    token,\n    tokenType\n  };\n}\n\n// pkg/dist-src/with-authorization-prefix.js\nfunction withAuthorizationPrefix(token) {\n  if (token.split(/\\./).length === 3) {\n    return `bearer ${token}`;\n  }\n  return `token ${token}`;\n}\n\n// pkg/dist-src/hook.js\nasync function hook(token, request, route, parameters) {\n  const endpoint = request.endpoint.merge(\n    route,\n    parameters\n  );\n  endpoint.headers.authorization = withAuthorizationPrefix(token);\n  return request(endpoint);\n}\n\n// pkg/dist-src/index.js\nvar createTokenAuth = function createTokenAuth2(token) {\n  if (!token) {\n    throw new Error(\"[@octokit/auth-token] No token passed to createTokenAuth\");\n  }\n  if (typeof token !== \"string\") {\n    throw new Error(\n      \"[@octokit/auth-token] Token passed to createTokenAuth is not a string\"\n    );\n  }\n  token = token.replace(/^(token|bearer) +/i, \"\");\n  return Object.assign(auth.bind(null, token), {\n    hook: hook.bind(null, token)\n  });\n};\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  createTokenAuth\n});\n","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar dist_src_exports = {};\n__export(dist_src_exports, {\n  Octokit: () => Octokit\n});\nmodule.exports = __toCommonJS(dist_src_exports);\nvar import_universal_user_agent = require(\"universal-user-agent\");\nvar import_before_after_hook = require(\"before-after-hook\");\nvar import_request = require(\"@octokit/request\");\nvar import_graphql = require(\"@octokit/graphql\");\nvar import_auth_token = require(\"@octokit/auth-token\");\n\n// pkg/dist-src/version.js\nvar VERSION = \"5.2.0\";\n\n// pkg/dist-src/index.js\nvar noop = () => {\n};\nvar consoleWarn = console.warn.bind(console);\nvar consoleError = console.error.bind(console);\nvar userAgentTrail = `octokit-core.js/${VERSION} ${(0, import_universal_user_agent.getUserAgent)()}`;\nvar Octokit = class {\n  static {\n    this.VERSION = VERSION;\n  }\n  static defaults(defaults) {\n    const OctokitWithDefaults = class extends this {\n      constructor(...args) {\n        const options = args[0] || {};\n        if (typeof defaults === \"function\") {\n          super(defaults(options));\n          return;\n        }\n        super(\n          Object.assign(\n            {},\n            defaults,\n            options,\n            options.userAgent && defaults.userAgent ? {\n              userAgent: `${options.userAgent} ${defaults.userAgent}`\n            } : null\n          )\n        );\n      }\n    };\n    return OctokitWithDefaults;\n  }\n  static {\n    this.plugins = [];\n  }\n  /**\n   * Attach a plugin (or many) to your Octokit instance.\n   *\n   * @example\n   * const API = Octokit.plugin(plugin1, plugin2, plugin3, ...)\n   */\n  static plugin(...newPlugins) {\n    const currentPlugins = this.plugins;\n    const NewOctokit = class extends this {\n      static {\n        this.plugins = currentPlugins.concat(\n          newPlugins.filter((plugin) => !currentPlugins.includes(plugin))\n        );\n      }\n    };\n    return NewOctokit;\n  }\n  constructor(options = {}) {\n    const hook = new import_before_after_hook.Collection();\n    const requestDefaults = {\n      baseUrl: import_request.request.endpoint.DEFAULTS.baseUrl,\n      headers: {},\n      request: Object.assign({}, options.request, {\n        // @ts-ignore internal usage only, no need to type\n        hook: hook.bind(null, \"request\")\n      }),\n      mediaType: {\n        previews: [],\n        format: \"\"\n      }\n    };\n    requestDefaults.headers[\"user-agent\"] = options.userAgent ? `${options.userAgent} ${userAgentTrail}` : userAgentTrail;\n    if (options.baseUrl) {\n      requestDefaults.baseUrl = options.baseUrl;\n    }\n    if (options.previews) {\n      requestDefaults.mediaType.previews = options.previews;\n    }\n    if (options.timeZone) {\n      requestDefaults.headers[\"time-zone\"] = options.timeZone;\n    }\n    this.request = import_request.request.defaults(requestDefaults);\n    this.graphql = (0, import_graphql.withCustomRequest)(this.request).defaults(requestDefaults);\n    this.log = Object.assign(\n      {\n        debug: noop,\n        info: noop,\n        warn: consoleWarn,\n        error: consoleError\n      },\n      options.log\n    );\n    this.hook = hook;\n    if (!options.authStrategy) {\n      if (!options.auth) {\n        this.auth = async () => ({\n          type: \"unauthenticated\"\n        });\n      } else {\n        const auth = (0, import_auth_token.createTokenAuth)(options.auth);\n        hook.wrap(\"request\", auth.hook);\n        this.auth = auth;\n      }\n    } else {\n      const { authStrategy, ...otherOptions } = options;\n      const auth = authStrategy(\n        Object.assign(\n          {\n            request: this.request,\n            log: this.log,\n            // we pass the current octokit instance as well as its constructor options\n            // to allow for authentication strategies that return a new octokit instance\n            // that shares the same internal state as the current one. The original\n            // requirement for this was the \"event-octokit\" authentication strategy\n            // of https://github.com/probot/octokit-auth-probot.\n            octokit: this,\n            octokitOptions: otherOptions\n          },\n          options.auth\n        )\n      );\n      hook.wrap(\"request\", auth.hook);\n      this.auth = auth;\n    }\n    const classConstructor = this.constructor;\n    for (let i = 0; i < classConstructor.plugins.length; ++i) {\n      Object.assign(this, classConstructor.plugins[i](this, options));\n    }\n  }\n};\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  Octokit\n});\n","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar dist_src_exports = {};\n__export(dist_src_exports, {\n  endpoint: () => endpoint\n});\nmodule.exports = __toCommonJS(dist_src_exports);\n\n// pkg/dist-src/defaults.js\nvar import_universal_user_agent = require(\"universal-user-agent\");\n\n// pkg/dist-src/version.js\nvar VERSION = \"9.0.5\";\n\n// pkg/dist-src/defaults.js\nvar userAgent = `octokit-endpoint.js/${VERSION} ${(0, import_universal_user_agent.getUserAgent)()}`;\nvar DEFAULTS = {\n  method: \"GET\",\n  baseUrl: \"https://api.github.com\",\n  headers: {\n    accept: \"application/vnd.github.v3+json\",\n    \"user-agent\": userAgent\n  },\n  mediaType: {\n    format: \"\"\n  }\n};\n\n// pkg/dist-src/util/lowercase-keys.js\nfunction lowercaseKeys(object) {\n  if (!object) {\n    return {};\n  }\n  return Object.keys(object).reduce((newObj, key) => {\n    newObj[key.toLowerCase()] = object[key];\n    return newObj;\n  }, {});\n}\n\n// pkg/dist-src/util/is-plain-object.js\nfunction isPlainObject(value) {\n  if (typeof value !== \"object\" || value === null)\n    return false;\n  if (Object.prototype.toString.call(value) !== \"[object Object]\")\n    return false;\n  const proto = Object.getPrototypeOf(value);\n  if (proto === null)\n    return true;\n  const Ctor = Object.prototype.hasOwnProperty.call(proto, \"constructor\") && proto.constructor;\n  return typeof Ctor === \"function\" && Ctor instanceof Ctor && Function.prototype.call(Ctor) === Function.prototype.call(value);\n}\n\n// pkg/dist-src/util/merge-deep.js\nfunction mergeDeep(defaults, options) {\n  const result = Object.assign({}, defaults);\n  Object.keys(options).forEach((key) => {\n    if (isPlainObject(options[key])) {\n      if (!(key in defaults))\n        Object.assign(result, { [key]: options[key] });\n      else\n        result[key] = mergeDeep(defaults[key], options[key]);\n    } else {\n      Object.assign(result, { [key]: options[key] });\n    }\n  });\n  return result;\n}\n\n// pkg/dist-src/util/remove-undefined-properties.js\nfunction removeUndefinedProperties(obj) {\n  for (const key in obj) {\n    if (obj[key] === void 0) {\n      delete obj[key];\n    }\n  }\n  return obj;\n}\n\n// pkg/dist-src/merge.js\nfunction merge(defaults, route, options) {\n  if (typeof route === \"string\") {\n    let [method, url] = route.split(\" \");\n    options = Object.assign(url ? { method, url } : { url: method }, options);\n  } else {\n    options = Object.assign({}, route);\n  }\n  options.headers = lowercaseKeys(options.headers);\n  removeUndefinedProperties(options);\n  removeUndefinedProperties(options.headers);\n  const mergedOptions = mergeDeep(defaults || {}, options);\n  if (options.url === \"/graphql\") {\n    if (defaults && defaults.mediaType.previews?.length) {\n      mergedOptions.mediaType.previews = defaults.mediaType.previews.filter(\n        (preview) => !mergedOptions.mediaType.previews.includes(preview)\n      ).concat(mergedOptions.mediaType.previews);\n    }\n    mergedOptions.mediaType.previews = (mergedOptions.mediaType.previews || []).map((preview) => preview.replace(/-preview/, \"\"));\n  }\n  return mergedOptions;\n}\n\n// pkg/dist-src/util/add-query-parameters.js\nfunction addQueryParameters(url, parameters) {\n  const separator = /\\?/.test(url) ? \"&\" : \"?\";\n  const names = Object.keys(parameters);\n  if (names.length === 0) {\n    return url;\n  }\n  return url + separator + names.map((name) => {\n    if (name === \"q\") {\n      return \"q=\" + parameters.q.split(\"+\").map(encodeURIComponent).join(\"+\");\n    }\n    return `${name}=${encodeURIComponent(parameters[name])}`;\n  }).join(\"&\");\n}\n\n// pkg/dist-src/util/extract-url-variable-names.js\nvar urlVariableRegex = /\\{[^}]+\\}/g;\nfunction removeNonChars(variableName) {\n  return variableName.replace(/^\\W+|\\W+$/g, \"\").split(/,/);\n}\nfunction extractUrlVariableNames(url) {\n  const matches = url.match(urlVariableRegex);\n  if (!matches) {\n    return [];\n  }\n  return matches.map(removeNonChars).reduce((a, b) => a.concat(b), []);\n}\n\n// pkg/dist-src/util/omit.js\nfunction omit(object, keysToOmit) {\n  const result = { __proto__: null };\n  for (const key of Object.keys(object)) {\n    if (keysToOmit.indexOf(key) === -1) {\n      result[key] = object[key];\n    }\n  }\n  return result;\n}\n\n// pkg/dist-src/util/url-template.js\nfunction encodeReserved(str) {\n  return str.split(/(%[0-9A-Fa-f]{2})/g).map(function(part) {\n    if (!/%[0-9A-Fa-f]/.test(part)) {\n      part = encodeURI(part).replace(/%5B/g, \"[\").replace(/%5D/g, \"]\");\n    }\n    return part;\n  }).join(\"\");\n}\nfunction encodeUnreserved(str) {\n  return encodeURIComponent(str).replace(/[!'()*]/g, function(c) {\n    return \"%\" + c.charCodeAt(0).toString(16).toUpperCase();\n  });\n}\nfunction encodeValue(operator, value, key) {\n  value = operator === \"+\" || operator === \"#\" ? encodeReserved(value) : encodeUnreserved(value);\n  if (key) {\n    return encodeUnreserved(key) + \"=\" + value;\n  } else {\n    return value;\n  }\n}\nfunction isDefined(value) {\n  return value !== void 0 && value !== null;\n}\nfunction isKeyOperator(operator) {\n  return operator === \";\" || operator === \"&\" || operator === \"?\";\n}\nfunction getValues(context, operator, key, modifier) {\n  var value = context[key], result = [];\n  if (isDefined(value) && value !== \"\") {\n    if (typeof value === \"string\" || typeof value === \"number\" || typeof value === \"boolean\") {\n      value = value.toString();\n      if (modifier && modifier !== \"*\") {\n        value = value.substring(0, parseInt(modifier, 10));\n      }\n      result.push(\n        encodeValue(operator, value, isKeyOperator(operator) ? key : \"\")\n      );\n    } else {\n      if (modifier === \"*\") {\n        if (Array.isArray(value)) {\n          value.filter(isDefined).forEach(function(value2) {\n            result.push(\n              encodeValue(operator, value2, isKeyOperator(operator) ? key : \"\")\n            );\n          });\n        } else {\n          Object.keys(value).forEach(function(k) {\n            if (isDefined(value[k])) {\n              result.push(encodeValue(operator, value[k], k));\n            }\n          });\n        }\n      } else {\n        const tmp = [];\n        if (Array.isArray(value)) {\n          value.filter(isDefined).forEach(function(value2) {\n            tmp.push(encodeValue(operator, value2));\n          });\n        } else {\n          Object.keys(value).forEach(function(k) {\n            if (isDefined(value[k])) {\n              tmp.push(encodeUnreserved(k));\n              tmp.push(encodeValue(operator, value[k].toString()));\n            }\n          });\n        }\n        if (isKeyOperator(operator)) {\n          result.push(encodeUnreserved(key) + \"=\" + tmp.join(\",\"));\n        } else if (tmp.length !== 0) {\n          result.push(tmp.join(\",\"));\n        }\n      }\n    }\n  } else {\n    if (operator === \";\") {\n      if (isDefined(value)) {\n        result.push(encodeUnreserved(key));\n      }\n    } else if (value === \"\" && (operator === \"&\" || operator === \"?\")) {\n      result.push(encodeUnreserved(key) + \"=\");\n    } else if (value === \"\") {\n      result.push(\"\");\n    }\n  }\n  return result;\n}\nfunction parseUrl(template) {\n  return {\n    expand: expand.bind(null, template)\n  };\n}\nfunction expand(template, context) {\n  var operators = [\"+\", \"#\", \".\", \"/\", \";\", \"?\", \"&\"];\n  template = template.replace(\n    /\\{([^\\{\\}]+)\\}|([^\\{\\}]+)/g,\n    function(_, expression, literal) {\n      if (expression) {\n        let operator = \"\";\n        const values = [];\n        if (operators.indexOf(expression.charAt(0)) !== -1) {\n          operator = expression.charAt(0);\n          expression = expression.substr(1);\n        }\n        expression.split(/,/g).forEach(function(variable) {\n          var tmp = /([^:\\*]*)(?::(\\d+)|(\\*))?/.exec(variable);\n          values.push(getValues(context, operator, tmp[1], tmp[2] || tmp[3]));\n        });\n        if (operator && operator !== \"+\") {\n          var separator = \",\";\n          if (operator === \"?\") {\n            separator = \"&\";\n          } else if (operator !== \"#\") {\n            separator = operator;\n          }\n          return (values.length !== 0 ? operator : \"\") + values.join(separator);\n        } else {\n          return values.join(\",\");\n        }\n      } else {\n        return encodeReserved(literal);\n      }\n    }\n  );\n  if (template === \"/\") {\n    return template;\n  } else {\n    return template.replace(/\\/$/, \"\");\n  }\n}\n\n// pkg/dist-src/parse.js\nfunction parse(options) {\n  let method = options.method.toUpperCase();\n  let url = (options.url || \"/\").replace(/:([a-z]\\w+)/g, \"{$1}\");\n  let headers = Object.assign({}, options.headers);\n  let body;\n  let parameters = omit(options, [\n    \"method\",\n    \"baseUrl\",\n    \"url\",\n    \"headers\",\n    \"request\",\n    \"mediaType\"\n  ]);\n  const urlVariableNames = extractUrlVariableNames(url);\n  url = parseUrl(url).expand(parameters);\n  if (!/^http/.test(url)) {\n    url = options.baseUrl + url;\n  }\n  const omittedParameters = Object.keys(options).filter((option) => urlVariableNames.includes(option)).concat(\"baseUrl\");\n  const remainingParameters = omit(parameters, omittedParameters);\n  const isBinaryRequest = /application\\/octet-stream/i.test(headers.accept);\n  if (!isBinaryRequest) {\n    if (options.mediaType.format) {\n      headers.accept = headers.accept.split(/,/).map(\n        (format) => format.replace(\n          /application\\/vnd(\\.\\w+)(\\.v3)?(\\.\\w+)?(\\+json)?$/,\n          `application/vnd$1$2.${options.mediaType.format}`\n        )\n      ).join(\",\");\n    }\n    if (url.endsWith(\"/graphql\")) {\n      if (options.mediaType.previews?.length) {\n        const previewsFromAcceptHeader = headers.accept.match(/[\\w-]+(?=-preview)/g) || [];\n        headers.accept = previewsFromAcceptHeader.concat(options.mediaType.previews).map((preview) => {\n          const format = options.mediaType.format ? `.${options.mediaType.format}` : \"+json\";\n          return `application/vnd.github.${preview}-preview${format}`;\n        }).join(\",\");\n      }\n    }\n  }\n  if ([\"GET\", \"HEAD\"].includes(method)) {\n    url = addQueryParameters(url, remainingParameters);\n  } else {\n    if (\"data\" in remainingParameters) {\n      body = remainingParameters.data;\n    } else {\n      if (Object.keys(remainingParameters).length) {\n        body = remainingParameters;\n      }\n    }\n  }\n  if (!headers[\"content-type\"] && typeof body !== \"undefined\") {\n    headers[\"content-type\"] = \"application/json; charset=utf-8\";\n  }\n  if ([\"PATCH\", \"PUT\"].includes(method) && typeof body === \"undefined\") {\n    body = \"\";\n  }\n  return Object.assign(\n    { method, url, headers },\n    typeof body !== \"undefined\" ? { body } : null,\n    options.request ? { request: options.request } : null\n  );\n}\n\n// pkg/dist-src/endpoint-with-defaults.js\nfunction endpointWithDefaults(defaults, route, options) {\n  return parse(merge(defaults, route, options));\n}\n\n// pkg/dist-src/with-defaults.js\nfunction withDefaults(oldDefaults, newDefaults) {\n  const DEFAULTS2 = merge(oldDefaults, newDefaults);\n  const endpoint2 = endpointWithDefaults.bind(null, DEFAULTS2);\n  return Object.assign(endpoint2, {\n    DEFAULTS: DEFAULTS2,\n    defaults: withDefaults.bind(null, DEFAULTS2),\n    merge: merge.bind(null, DEFAULTS2),\n    parse\n  });\n}\n\n// pkg/dist-src/index.js\nvar endpoint = withDefaults(null, DEFAULTS);\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  endpoint\n});\n","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar dist_src_exports = {};\n__export(dist_src_exports, {\n  GraphqlResponseError: () => GraphqlResponseError,\n  graphql: () => graphql2,\n  withCustomRequest: () => withCustomRequest\n});\nmodule.exports = __toCommonJS(dist_src_exports);\nvar import_request3 = require(\"@octokit/request\");\nvar import_universal_user_agent = require(\"universal-user-agent\");\n\n// pkg/dist-src/version.js\nvar VERSION = \"7.1.0\";\n\n// pkg/dist-src/with-defaults.js\nvar import_request2 = require(\"@octokit/request\");\n\n// pkg/dist-src/graphql.js\nvar import_request = require(\"@octokit/request\");\n\n// pkg/dist-src/error.js\nfunction _buildMessageForResponseErrors(data) {\n  return `Request failed due to following response errors:\n` + data.errors.map((e) => ` - ${e.message}`).join(\"\\n\");\n}\nvar GraphqlResponseError = class extends Error {\n  constructor(request2, headers, response) {\n    super(_buildMessageForResponseErrors(response));\n    this.request = request2;\n    this.headers = headers;\n    this.response = response;\n    this.name = \"GraphqlResponseError\";\n    this.errors = response.errors;\n    this.data = response.data;\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n  }\n};\n\n// pkg/dist-src/graphql.js\nvar NON_VARIABLE_OPTIONS = [\n  \"method\",\n  \"baseUrl\",\n  \"url\",\n  \"headers\",\n  \"request\",\n  \"query\",\n  \"mediaType\"\n];\nvar FORBIDDEN_VARIABLE_OPTIONS = [\"query\", \"method\", \"url\"];\nvar GHES_V3_SUFFIX_REGEX = /\\/api\\/v3\\/?$/;\nfunction graphql(request2, query, options) {\n  if (options) {\n    if (typeof query === \"string\" && \"query\" in options) {\n      return Promise.reject(\n        new Error(`[@octokit/graphql] \"query\" cannot be used as variable name`)\n      );\n    }\n    for (const key in options) {\n      if (!FORBIDDEN_VARIABLE_OPTIONS.includes(key))\n        continue;\n      return Promise.reject(\n        new Error(\n          `[@octokit/graphql] \"${key}\" cannot be used as variable name`\n        )\n      );\n    }\n  }\n  const parsedOptions = typeof query === \"string\" ? Object.assign({ query }, options) : query;\n  const requestOptions = Object.keys(\n    parsedOptions\n  ).reduce((result, key) => {\n    if (NON_VARIABLE_OPTIONS.includes(key)) {\n      result[key] = parsedOptions[key];\n      return result;\n    }\n    if (!result.variables) {\n      result.variables = {};\n    }\n    result.variables[key] = parsedOptions[key];\n    return result;\n  }, {});\n  const baseUrl = parsedOptions.baseUrl || request2.endpoint.DEFAULTS.baseUrl;\n  if (GHES_V3_SUFFIX_REGEX.test(baseUrl)) {\n    requestOptions.url = baseUrl.replace(GHES_V3_SUFFIX_REGEX, \"/api/graphql\");\n  }\n  return request2(requestOptions).then((response) => {\n    if (response.data.errors) {\n      const headers = {};\n      for (const key of Object.keys(response.headers)) {\n        headers[key] = response.headers[key];\n      }\n      throw new GraphqlResponseError(\n        requestOptions,\n        headers,\n        response.data\n      );\n    }\n    return response.data.data;\n  });\n}\n\n// pkg/dist-src/with-defaults.js\nfunction withDefaults(request2, newDefaults) {\n  const newRequest = request2.defaults(newDefaults);\n  const newApi = (query, options) => {\n    return graphql(newRequest, query, options);\n  };\n  return Object.assign(newApi, {\n    defaults: withDefaults.bind(null, newRequest),\n    endpoint: newRequest.endpoint\n  });\n}\n\n// pkg/dist-src/index.js\nvar graphql2 = withDefaults(import_request3.request, {\n  headers: {\n    \"user-agent\": `octokit-graphql.js/${VERSION} ${(0, import_universal_user_agent.getUserAgent)()}`\n  },\n  method: \"POST\",\n  url: \"/graphql\"\n});\nfunction withCustomRequest(customRequest) {\n  return withDefaults(customRequest, {\n    method: \"POST\",\n    url: \"/graphql\"\n  });\n}\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  GraphqlResponseError,\n  graphql,\n  withCustomRequest\n});\n","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar dist_src_exports = {};\n__export(dist_src_exports, {\n  composePaginateRest: () => composePaginateRest,\n  isPaginatingEndpoint: () => isPaginatingEndpoint,\n  paginateRest: () => paginateRest,\n  paginatingEndpoints: () => paginatingEndpoints\n});\nmodule.exports = __toCommonJS(dist_src_exports);\n\n// pkg/dist-src/version.js\nvar VERSION = \"9.2.1\";\n\n// pkg/dist-src/normalize-paginated-list-response.js\nfunction normalizePaginatedListResponse(response) {\n  if (!response.data) {\n    return {\n      ...response,\n      data: []\n    };\n  }\n  const responseNeedsNormalization = \"total_count\" in response.data && !(\"url\" in response.data);\n  if (!responseNeedsNormalization)\n    return response;\n  const incompleteResults = response.data.incomplete_results;\n  const repositorySelection = response.data.repository_selection;\n  const totalCount = response.data.total_count;\n  delete response.data.incomplete_results;\n  delete response.data.repository_selection;\n  delete response.data.total_count;\n  const namespaceKey = Object.keys(response.data)[0];\n  const data = response.data[namespaceKey];\n  response.data = data;\n  if (typeof incompleteResults !== \"undefined\") {\n    response.data.incomplete_results = incompleteResults;\n  }\n  if (typeof repositorySelection !== \"undefined\") {\n    response.data.repository_selection = repositorySelection;\n  }\n  response.data.total_count = totalCount;\n  return response;\n}\n\n// pkg/dist-src/iterator.js\nfunction iterator(octokit, route, parameters) {\n  const options = typeof route === \"function\" ? route.endpoint(parameters) : octokit.request.endpoint(route, parameters);\n  const requestMethod = typeof route === \"function\" ? route : octokit.request;\n  const method = options.method;\n  const headers = options.headers;\n  let url = options.url;\n  return {\n    [Symbol.asyncIterator]: () => ({\n      async next() {\n        if (!url)\n          return { done: true };\n        try {\n          const response = await requestMethod({ method, url, headers });\n          const normalizedResponse = normalizePaginatedListResponse(response);\n          url = ((normalizedResponse.headers.link || \"\").match(\n            /<([^>]+)>;\\s*rel=\"next\"/\n          ) || [])[1];\n          return { value: normalizedResponse };\n        } catch (error) {\n          if (error.status !== 409)\n            throw error;\n          url = \"\";\n          return {\n            value: {\n              status: 200,\n              headers: {},\n              data: []\n            }\n          };\n        }\n      }\n    })\n  };\n}\n\n// pkg/dist-src/paginate.js\nfunction paginate(octokit, route, parameters, mapFn) {\n  if (typeof parameters === \"function\") {\n    mapFn = parameters;\n    parameters = void 0;\n  }\n  return gather(\n    octokit,\n    [],\n    iterator(octokit, route, parameters)[Symbol.asyncIterator](),\n    mapFn\n  );\n}\nfunction gather(octokit, results, iterator2, mapFn) {\n  return iterator2.next().then((result) => {\n    if (result.done) {\n      return results;\n    }\n    let earlyExit = false;\n    function done() {\n      earlyExit = true;\n    }\n    results = results.concat(\n      mapFn ? mapFn(result.value, done) : result.value.data\n    );\n    if (earlyExit) {\n      return results;\n    }\n    return gather(octokit, results, iterator2, mapFn);\n  });\n}\n\n// pkg/dist-src/compose-paginate.js\nvar composePaginateRest = Object.assign(paginate, {\n  iterator\n});\n\n// pkg/dist-src/generated/paginating-endpoints.js\nvar paginatingEndpoints = [\n  \"GET /advisories\",\n  \"GET /app/hook/deliveries\",\n  \"GET /app/installation-requests\",\n  \"GET /app/installations\",\n  \"GET /assignments/{assignment_id}/accepted_assignments\",\n  \"GET /classrooms\",\n  \"GET /classrooms/{classroom_id}/assignments\",\n  \"GET /enterprises/{enterprise}/dependabot/alerts\",\n  \"GET /enterprises/{enterprise}/secret-scanning/alerts\",\n  \"GET /events\",\n  \"GET /gists\",\n  \"GET /gists/public\",\n  \"GET /gists/starred\",\n  \"GET /gists/{gist_id}/comments\",\n  \"GET /gists/{gist_id}/commits\",\n  \"GET /gists/{gist_id}/forks\",\n  \"GET /installation/repositories\",\n  \"GET /issues\",\n  \"GET /licenses\",\n  \"GET /marketplace_listing/plans\",\n  \"GET /marketplace_listing/plans/{plan_id}/accounts\",\n  \"GET /marketplace_listing/stubbed/plans\",\n  \"GET /marketplace_listing/stubbed/plans/{plan_id}/accounts\",\n  \"GET /networks/{owner}/{repo}/events\",\n  \"GET /notifications\",\n  \"GET /organizations\",\n  \"GET /orgs/{org}/actions/cache/usage-by-repository\",\n  \"GET /orgs/{org}/actions/permissions/repositories\",\n  \"GET /orgs/{org}/actions/runners\",\n  \"GET /orgs/{org}/actions/secrets\",\n  \"GET /orgs/{org}/actions/secrets/{secret_name}/repositories\",\n  \"GET /orgs/{org}/actions/variables\",\n  \"GET /orgs/{org}/actions/variables/{name}/repositories\",\n  \"GET /orgs/{org}/blocks\",\n  \"GET /orgs/{org}/code-scanning/alerts\",\n  \"GET /orgs/{org}/codespaces\",\n  \"GET /orgs/{org}/codespaces/secrets\",\n  \"GET /orgs/{org}/codespaces/secrets/{secret_name}/repositories\",\n  \"GET /orgs/{org}/copilot/billing/seats\",\n  \"GET /orgs/{org}/dependabot/alerts\",\n  \"GET /orgs/{org}/dependabot/secrets\",\n  \"GET /orgs/{org}/dependabot/secrets/{secret_name}/repositories\",\n  \"GET /orgs/{org}/events\",\n  \"GET /orgs/{org}/failed_invitations\",\n  \"GET /orgs/{org}/hooks\",\n  \"GET /orgs/{org}/hooks/{hook_id}/deliveries\",\n  \"GET /orgs/{org}/installations\",\n  \"GET /orgs/{org}/invitations\",\n  \"GET /orgs/{org}/invitations/{invitation_id}/teams\",\n  \"GET /orgs/{org}/issues\",\n  \"GET /orgs/{org}/members\",\n  \"GET /orgs/{org}/members/{username}/codespaces\",\n  \"GET /orgs/{org}/migrations\",\n  \"GET /orgs/{org}/migrations/{migration_id}/repositories\",\n  \"GET /orgs/{org}/organization-roles/{role_id}/teams\",\n  \"GET /orgs/{org}/organization-roles/{role_id}/users\",\n  \"GET /orgs/{org}/outside_collaborators\",\n  \"GET /orgs/{org}/packages\",\n  \"GET /orgs/{org}/packages/{package_type}/{package_name}/versions\",\n  \"GET /orgs/{org}/personal-access-token-requests\",\n  \"GET /orgs/{org}/personal-access-token-requests/{pat_request_id}/repositories\",\n  \"GET /orgs/{org}/personal-access-tokens\",\n  \"GET /orgs/{org}/personal-access-tokens/{pat_id}/repositories\",\n  \"GET /orgs/{org}/projects\",\n  \"GET /orgs/{org}/properties/values\",\n  \"GET /orgs/{org}/public_members\",\n  \"GET /orgs/{org}/repos\",\n  \"GET /orgs/{org}/rulesets\",\n  \"GET /orgs/{org}/rulesets/rule-suites\",\n  \"GET /orgs/{org}/secret-scanning/alerts\",\n  \"GET /orgs/{org}/security-advisories\",\n  \"GET /orgs/{org}/teams\",\n  \"GET /orgs/{org}/teams/{team_slug}/discussions\",\n  \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments\",\n  \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions\",\n  \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions\",\n  \"GET /orgs/{org}/teams/{team_slug}/invitations\",\n  \"GET /orgs/{org}/teams/{team_slug}/members\",\n  \"GET /orgs/{org}/teams/{team_slug}/projects\",\n  \"GET /orgs/{org}/teams/{team_slug}/repos\",\n  \"GET /orgs/{org}/teams/{team_slug}/teams\",\n  \"GET /projects/columns/{column_id}/cards\",\n  \"GET /projects/{project_id}/collaborators\",\n  \"GET /projects/{project_id}/columns\",\n  \"GET /repos/{owner}/{repo}/actions/artifacts\",\n  \"GET /repos/{owner}/{repo}/actions/caches\",\n  \"GET /repos/{owner}/{repo}/actions/organization-secrets\",\n  \"GET /repos/{owner}/{repo}/actions/organization-variables\",\n  \"GET /repos/{owner}/{repo}/actions/runners\",\n  \"GET /repos/{owner}/{repo}/actions/runs\",\n  \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/artifacts\",\n  \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}/jobs\",\n  \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/jobs\",\n  \"GET /repos/{owner}/{repo}/actions/secrets\",\n  \"GET /repos/{owner}/{repo}/actions/variables\",\n  \"GET /repos/{owner}/{repo}/actions/workflows\",\n  \"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/runs\",\n  \"GET /repos/{owner}/{repo}/activity\",\n  \"GET /repos/{owner}/{repo}/assignees\",\n  \"GET /repos/{owner}/{repo}/branches\",\n  \"GET /repos/{owner}/{repo}/check-runs/{check_run_id}/annotations\",\n  \"GET /repos/{owner}/{repo}/check-suites/{check_suite_id}/check-runs\",\n  \"GET /repos/{owner}/{repo}/code-scanning/alerts\",\n  \"GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances\",\n  \"GET /repos/{owner}/{repo}/code-scanning/analyses\",\n  \"GET /repos/{owner}/{repo}/codespaces\",\n  \"GET /repos/{owner}/{repo}/codespaces/devcontainers\",\n  \"GET /repos/{owner}/{repo}/codespaces/secrets\",\n  \"GET /repos/{owner}/{repo}/collaborators\",\n  \"GET /repos/{owner}/{repo}/comments\",\n  \"GET /repos/{owner}/{repo}/comments/{comment_id}/reactions\",\n  \"GET /repos/{owner}/{repo}/commits\",\n  \"GET /repos/{owner}/{repo}/commits/{commit_sha}/comments\",\n  \"GET /repos/{owner}/{repo}/commits/{commit_sha}/pulls\",\n  \"GET /repos/{owner}/{repo}/commits/{ref}/check-runs\",\n  \"GET /repos/{owner}/{repo}/commits/{ref}/check-suites\",\n  \"GET /repos/{owner}/{repo}/commits/{ref}/status\",\n  \"GET /repos/{owner}/{repo}/commits/{ref}/statuses\",\n  \"GET /repos/{owner}/{repo}/contributors\",\n  \"GET /repos/{owner}/{repo}/dependabot/alerts\",\n  \"GET /repos/{owner}/{repo}/dependabot/secrets\",\n  \"GET /repos/{owner}/{repo}/deployments\",\n  \"GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses\",\n  \"GET /repos/{owner}/{repo}/environments\",\n  \"GET /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies\",\n  \"GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/apps\",\n  \"GET /repos/{owner}/{repo}/events\",\n  \"GET /repos/{owner}/{repo}/forks\",\n  \"GET /repos/{owner}/{repo}/hooks\",\n  \"GET /repos/{owner}/{repo}/hooks/{hook_id}/deliveries\",\n  \"GET /repos/{owner}/{repo}/invitations\",\n  \"GET /repos/{owner}/{repo}/issues\",\n  \"GET /repos/{owner}/{repo}/issues/comments\",\n  \"GET /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions\",\n  \"GET /repos/{owner}/{repo}/issues/events\",\n  \"GET /repos/{owner}/{repo}/issues/{issue_number}/comments\",\n  \"GET /repos/{owner}/{repo}/issues/{issue_number}/events\",\n  \"GET /repos/{owner}/{repo}/issues/{issue_number}/labels\",\n  \"GET /repos/{owner}/{repo}/issues/{issue_number}/reactions\",\n  \"GET /repos/{owner}/{repo}/issues/{issue_number}/timeline\",\n  \"GET /repos/{owner}/{repo}/keys\",\n  \"GET /repos/{owner}/{repo}/labels\",\n  \"GET /repos/{owner}/{repo}/milestones\",\n  \"GET /repos/{owner}/{repo}/milestones/{milestone_number}/labels\",\n  \"GET /repos/{owner}/{repo}/notifications\",\n  \"GET /repos/{owner}/{repo}/pages/builds\",\n  \"GET /repos/{owner}/{repo}/projects\",\n  \"GET /repos/{owner}/{repo}/pulls\",\n  \"GET /repos/{owner}/{repo}/pulls/comments\",\n  \"GET /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions\",\n  \"GET /repos/{owner}/{repo}/pulls/{pull_number}/comments\",\n  \"GET /repos/{owner}/{repo}/pulls/{pull_number}/commits\",\n  \"GET /repos/{owner}/{repo}/pulls/{pull_number}/files\",\n  \"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews\",\n  \"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/comments\",\n  \"GET /repos/{owner}/{repo}/releases\",\n  \"GET /repos/{owner}/{repo}/releases/{release_id}/assets\",\n  \"GET /repos/{owner}/{repo}/releases/{release_id}/reactions\",\n  \"GET /repos/{owner}/{repo}/rules/branches/{branch}\",\n  \"GET /repos/{owner}/{repo}/rulesets\",\n  \"GET /repos/{owner}/{repo}/rulesets/rule-suites\",\n  \"GET /repos/{owner}/{repo}/secret-scanning/alerts\",\n  \"GET /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}/locations\",\n  \"GET /repos/{owner}/{repo}/security-advisories\",\n  \"GET /repos/{owner}/{repo}/stargazers\",\n  \"GET /repos/{owner}/{repo}/subscribers\",\n  \"GET /repos/{owner}/{repo}/tags\",\n  \"GET /repos/{owner}/{repo}/teams\",\n  \"GET /repos/{owner}/{repo}/topics\",\n  \"GET /repositories\",\n  \"GET /repositories/{repository_id}/environments/{environment_name}/secrets\",\n  \"GET /repositories/{repository_id}/environments/{environment_name}/variables\",\n  \"GET /search/code\",\n  \"GET /search/commits\",\n  \"GET /search/issues\",\n  \"GET /search/labels\",\n  \"GET /search/repositories\",\n  \"GET /search/topics\",\n  \"GET /search/users\",\n  \"GET /teams/{team_id}/discussions\",\n  \"GET /teams/{team_id}/discussions/{discussion_number}/comments\",\n  \"GET /teams/{team_id}/discussions/{discussion_number}/comments/{comment_number}/reactions\",\n  \"GET /teams/{team_id}/discussions/{discussion_number}/reactions\",\n  \"GET /teams/{team_id}/invitations\",\n  \"GET /teams/{team_id}/members\",\n  \"GET /teams/{team_id}/projects\",\n  \"GET /teams/{team_id}/repos\",\n  \"GET /teams/{team_id}/teams\",\n  \"GET /user/blocks\",\n  \"GET /user/codespaces\",\n  \"GET /user/codespaces/secrets\",\n  \"GET /user/emails\",\n  \"GET /user/followers\",\n  \"GET /user/following\",\n  \"GET /user/gpg_keys\",\n  \"GET /user/installations\",\n  \"GET /user/installations/{installation_id}/repositories\",\n  \"GET /user/issues\",\n  \"GET /user/keys\",\n  \"GET /user/marketplace_purchases\",\n  \"GET /user/marketplace_purchases/stubbed\",\n  \"GET /user/memberships/orgs\",\n  \"GET /user/migrations\",\n  \"GET /user/migrations/{migration_id}/repositories\",\n  \"GET /user/orgs\",\n  \"GET /user/packages\",\n  \"GET /user/packages/{package_type}/{package_name}/versions\",\n  \"GET /user/public_emails\",\n  \"GET /user/repos\",\n  \"GET /user/repository_invitations\",\n  \"GET /user/social_accounts\",\n  \"GET /user/ssh_signing_keys\",\n  \"GET /user/starred\",\n  \"GET /user/subscriptions\",\n  \"GET /user/teams\",\n  \"GET /users\",\n  \"GET /users/{username}/events\",\n  \"GET /users/{username}/events/orgs/{org}\",\n  \"GET /users/{username}/events/public\",\n  \"GET /users/{username}/followers\",\n  \"GET /users/{username}/following\",\n  \"GET /users/{username}/gists\",\n  \"GET /users/{username}/gpg_keys\",\n  \"GET /users/{username}/keys\",\n  \"GET /users/{username}/orgs\",\n  \"GET /users/{username}/packages\",\n  \"GET /users/{username}/projects\",\n  \"GET /users/{username}/received_events\",\n  \"GET /users/{username}/received_events/public\",\n  \"GET /users/{username}/repos\",\n  \"GET /users/{username}/social_accounts\",\n  \"GET /users/{username}/ssh_signing_keys\",\n  \"GET /users/{username}/starred\",\n  \"GET /users/{username}/subscriptions\"\n];\n\n// pkg/dist-src/paginating-endpoints.js\nfunction isPaginatingEndpoint(arg) {\n  if (typeof arg === \"string\") {\n    return paginatingEndpoints.includes(arg);\n  } else {\n    return false;\n  }\n}\n\n// pkg/dist-src/index.js\nfunction paginateRest(octokit) {\n  return {\n    paginate: Object.assign(paginate.bind(null, octokit), {\n      iterator: iterator.bind(null, octokit)\n    })\n  };\n}\npaginateRest.VERSION = VERSION;\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  composePaginateRest,\n  isPaginatingEndpoint,\n  paginateRest,\n  paginatingEndpoints\n});\n","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar dist_src_exports = {};\n__export(dist_src_exports, {\n  legacyRestEndpointMethods: () => legacyRestEndpointMethods,\n  restEndpointMethods: () => restEndpointMethods\n});\nmodule.exports = __toCommonJS(dist_src_exports);\n\n// pkg/dist-src/version.js\nvar VERSION = \"10.4.1\";\n\n// pkg/dist-src/generated/endpoints.js\nvar Endpoints = {\n  actions: {\n    addCustomLabelsToSelfHostedRunnerForOrg: [\n      \"POST /orgs/{org}/actions/runners/{runner_id}/labels\"\n    ],\n    addCustomLabelsToSelfHostedRunnerForRepo: [\n      \"POST /repos/{owner}/{repo}/actions/runners/{runner_id}/labels\"\n    ],\n    addSelectedRepoToOrgSecret: [\n      \"PUT /orgs/{org}/actions/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    addSelectedRepoToOrgVariable: [\n      \"PUT /orgs/{org}/actions/variables/{name}/repositories/{repository_id}\"\n    ],\n    approveWorkflowRun: [\n      \"POST /repos/{owner}/{repo}/actions/runs/{run_id}/approve\"\n    ],\n    cancelWorkflowRun: [\n      \"POST /repos/{owner}/{repo}/actions/runs/{run_id}/cancel\"\n    ],\n    createEnvironmentVariable: [\n      \"POST /repositories/{repository_id}/environments/{environment_name}/variables\"\n    ],\n    createOrUpdateEnvironmentSecret: [\n      \"PUT /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}\"\n    ],\n    createOrUpdateOrgSecret: [\"PUT /orgs/{org}/actions/secrets/{secret_name}\"],\n    createOrUpdateRepoSecret: [\n      \"PUT /repos/{owner}/{repo}/actions/secrets/{secret_name}\"\n    ],\n    createOrgVariable: [\"POST /orgs/{org}/actions/variables\"],\n    createRegistrationTokenForOrg: [\n      \"POST /orgs/{org}/actions/runners/registration-token\"\n    ],\n    createRegistrationTokenForRepo: [\n      \"POST /repos/{owner}/{repo}/actions/runners/registration-token\"\n    ],\n    createRemoveTokenForOrg: [\"POST /orgs/{org}/actions/runners/remove-token\"],\n    createRemoveTokenForRepo: [\n      \"POST /repos/{owner}/{repo}/actions/runners/remove-token\"\n    ],\n    createRepoVariable: [\"POST /repos/{owner}/{repo}/actions/variables\"],\n    createWorkflowDispatch: [\n      \"POST /repos/{owner}/{repo}/actions/workflows/{workflow_id}/dispatches\"\n    ],\n    deleteActionsCacheById: [\n      \"DELETE /repos/{owner}/{repo}/actions/caches/{cache_id}\"\n    ],\n    deleteActionsCacheByKey: [\n      \"DELETE /repos/{owner}/{repo}/actions/caches{?key,ref}\"\n    ],\n    deleteArtifact: [\n      \"DELETE /repos/{owner}/{repo}/actions/artifacts/{artifact_id}\"\n    ],\n    deleteEnvironmentSecret: [\n      \"DELETE /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}\"\n    ],\n    deleteEnvironmentVariable: [\n      \"DELETE /repositories/{repository_id}/environments/{environment_name}/variables/{name}\"\n    ],\n    deleteOrgSecret: [\"DELETE /orgs/{org}/actions/secrets/{secret_name}\"],\n    deleteOrgVariable: [\"DELETE /orgs/{org}/actions/variables/{name}\"],\n    deleteRepoSecret: [\n      \"DELETE /repos/{owner}/{repo}/actions/secrets/{secret_name}\"\n    ],\n    deleteRepoVariable: [\n      \"DELETE /repos/{owner}/{repo}/actions/variables/{name}\"\n    ],\n    deleteSelfHostedRunnerFromOrg: [\n      \"DELETE /orgs/{org}/actions/runners/{runner_id}\"\n    ],\n    deleteSelfHostedRunnerFromRepo: [\n      \"DELETE /repos/{owner}/{repo}/actions/runners/{runner_id}\"\n    ],\n    deleteWorkflowRun: [\"DELETE /repos/{owner}/{repo}/actions/runs/{run_id}\"],\n    deleteWorkflowRunLogs: [\n      \"DELETE /repos/{owner}/{repo}/actions/runs/{run_id}/logs\"\n    ],\n    disableSelectedRepositoryGithubActionsOrganization: [\n      \"DELETE /orgs/{org}/actions/permissions/repositories/{repository_id}\"\n    ],\n    disableWorkflow: [\n      \"PUT /repos/{owner}/{repo}/actions/workflows/{workflow_id}/disable\"\n    ],\n    downloadArtifact: [\n      \"GET /repos/{owner}/{repo}/actions/artifacts/{artifact_id}/{archive_format}\"\n    ],\n    downloadJobLogsForWorkflowRun: [\n      \"GET /repos/{owner}/{repo}/actions/jobs/{job_id}/logs\"\n    ],\n    downloadWorkflowRunAttemptLogs: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}/logs\"\n    ],\n    downloadWorkflowRunLogs: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/logs\"\n    ],\n    enableSelectedRepositoryGithubActionsOrganization: [\n      \"PUT /orgs/{org}/actions/permissions/repositories/{repository_id}\"\n    ],\n    enableWorkflow: [\n      \"PUT /repos/{owner}/{repo}/actions/workflows/{workflow_id}/enable\"\n    ],\n    forceCancelWorkflowRun: [\n      \"POST /repos/{owner}/{repo}/actions/runs/{run_id}/force-cancel\"\n    ],\n    generateRunnerJitconfigForOrg: [\n      \"POST /orgs/{org}/actions/runners/generate-jitconfig\"\n    ],\n    generateRunnerJitconfigForRepo: [\n      \"POST /repos/{owner}/{repo}/actions/runners/generate-jitconfig\"\n    ],\n    getActionsCacheList: [\"GET /repos/{owner}/{repo}/actions/caches\"],\n    getActionsCacheUsage: [\"GET /repos/{owner}/{repo}/actions/cache/usage\"],\n    getActionsCacheUsageByRepoForOrg: [\n      \"GET /orgs/{org}/actions/cache/usage-by-repository\"\n    ],\n    getActionsCacheUsageForOrg: [\"GET /orgs/{org}/actions/cache/usage\"],\n    getAllowedActionsOrganization: [\n      \"GET /orgs/{org}/actions/permissions/selected-actions\"\n    ],\n    getAllowedActionsRepository: [\n      \"GET /repos/{owner}/{repo}/actions/permissions/selected-actions\"\n    ],\n    getArtifact: [\"GET /repos/{owner}/{repo}/actions/artifacts/{artifact_id}\"],\n    getCustomOidcSubClaimForRepo: [\n      \"GET /repos/{owner}/{repo}/actions/oidc/customization/sub\"\n    ],\n    getEnvironmentPublicKey: [\n      \"GET /repositories/{repository_id}/environments/{environment_name}/secrets/public-key\"\n    ],\n    getEnvironmentSecret: [\n      \"GET /repositories/{repository_id}/environments/{environment_name}/secrets/{secret_name}\"\n    ],\n    getEnvironmentVariable: [\n      \"GET /repositories/{repository_id}/environments/{environment_name}/variables/{name}\"\n    ],\n    getGithubActionsDefaultWorkflowPermissionsOrganization: [\n      \"GET /orgs/{org}/actions/permissions/workflow\"\n    ],\n    getGithubActionsDefaultWorkflowPermissionsRepository: [\n      \"GET /repos/{owner}/{repo}/actions/permissions/workflow\"\n    ],\n    getGithubActionsPermissionsOrganization: [\n      \"GET /orgs/{org}/actions/permissions\"\n    ],\n    getGithubActionsPermissionsRepository: [\n      \"GET /repos/{owner}/{repo}/actions/permissions\"\n    ],\n    getJobForWorkflowRun: [\"GET /repos/{owner}/{repo}/actions/jobs/{job_id}\"],\n    getOrgPublicKey: [\"GET /orgs/{org}/actions/secrets/public-key\"],\n    getOrgSecret: [\"GET /orgs/{org}/actions/secrets/{secret_name}\"],\n    getOrgVariable: [\"GET /orgs/{org}/actions/variables/{name}\"],\n    getPendingDeploymentsForRun: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/pending_deployments\"\n    ],\n    getRepoPermissions: [\n      \"GET /repos/{owner}/{repo}/actions/permissions\",\n      {},\n      { renamed: [\"actions\", \"getGithubActionsPermissionsRepository\"] }\n    ],\n    getRepoPublicKey: [\"GET /repos/{owner}/{repo}/actions/secrets/public-key\"],\n    getRepoSecret: [\"GET /repos/{owner}/{repo}/actions/secrets/{secret_name}\"],\n    getRepoVariable: [\"GET /repos/{owner}/{repo}/actions/variables/{name}\"],\n    getReviewsForRun: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/approvals\"\n    ],\n    getSelfHostedRunnerForOrg: [\"GET /orgs/{org}/actions/runners/{runner_id}\"],\n    getSelfHostedRunnerForRepo: [\n      \"GET /repos/{owner}/{repo}/actions/runners/{runner_id}\"\n    ],\n    getWorkflow: [\"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}\"],\n    getWorkflowAccessToRepository: [\n      \"GET /repos/{owner}/{repo}/actions/permissions/access\"\n    ],\n    getWorkflowRun: [\"GET /repos/{owner}/{repo}/actions/runs/{run_id}\"],\n    getWorkflowRunAttempt: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}\"\n    ],\n    getWorkflowRunUsage: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/timing\"\n    ],\n    getWorkflowUsage: [\n      \"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/timing\"\n    ],\n    listArtifactsForRepo: [\"GET /repos/{owner}/{repo}/actions/artifacts\"],\n    listEnvironmentSecrets: [\n      \"GET /repositories/{repository_id}/environments/{environment_name}/secrets\"\n    ],\n    listEnvironmentVariables: [\n      \"GET /repositories/{repository_id}/environments/{environment_name}/variables\"\n    ],\n    listJobsForWorkflowRun: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/jobs\"\n    ],\n    listJobsForWorkflowRunAttempt: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/attempts/{attempt_number}/jobs\"\n    ],\n    listLabelsForSelfHostedRunnerForOrg: [\n      \"GET /orgs/{org}/actions/runners/{runner_id}/labels\"\n    ],\n    listLabelsForSelfHostedRunnerForRepo: [\n      \"GET /repos/{owner}/{repo}/actions/runners/{runner_id}/labels\"\n    ],\n    listOrgSecrets: [\"GET /orgs/{org}/actions/secrets\"],\n    listOrgVariables: [\"GET /orgs/{org}/actions/variables\"],\n    listRepoOrganizationSecrets: [\n      \"GET /repos/{owner}/{repo}/actions/organization-secrets\"\n    ],\n    listRepoOrganizationVariables: [\n      \"GET /repos/{owner}/{repo}/actions/organization-variables\"\n    ],\n    listRepoSecrets: [\"GET /repos/{owner}/{repo}/actions/secrets\"],\n    listRepoVariables: [\"GET /repos/{owner}/{repo}/actions/variables\"],\n    listRepoWorkflows: [\"GET /repos/{owner}/{repo}/actions/workflows\"],\n    listRunnerApplicationsForOrg: [\"GET /orgs/{org}/actions/runners/downloads\"],\n    listRunnerApplicationsForRepo: [\n      \"GET /repos/{owner}/{repo}/actions/runners/downloads\"\n    ],\n    listSelectedReposForOrgSecret: [\n      \"GET /orgs/{org}/actions/secrets/{secret_name}/repositories\"\n    ],\n    listSelectedReposForOrgVariable: [\n      \"GET /orgs/{org}/actions/variables/{name}/repositories\"\n    ],\n    listSelectedRepositoriesEnabledGithubActionsOrganization: [\n      \"GET /orgs/{org}/actions/permissions/repositories\"\n    ],\n    listSelfHostedRunnersForOrg: [\"GET /orgs/{org}/actions/runners\"],\n    listSelfHostedRunnersForRepo: [\"GET /repos/{owner}/{repo}/actions/runners\"],\n    listWorkflowRunArtifacts: [\n      \"GET /repos/{owner}/{repo}/actions/runs/{run_id}/artifacts\"\n    ],\n    listWorkflowRuns: [\n      \"GET /repos/{owner}/{repo}/actions/workflows/{workflow_id}/runs\"\n    ],\n    listWorkflowRunsForRepo: [\"GET /repos/{owner}/{repo}/actions/runs\"],\n    reRunJobForWorkflowRun: [\n      \"POST /repos/{owner}/{repo}/actions/jobs/{job_id}/rerun\"\n    ],\n    reRunWorkflow: [\"POST /repos/{owner}/{repo}/actions/runs/{run_id}/rerun\"],\n    reRunWorkflowFailedJobs: [\n      \"POST /repos/{owner}/{repo}/actions/runs/{run_id}/rerun-failed-jobs\"\n    ],\n    removeAllCustomLabelsFromSelfHostedRunnerForOrg: [\n      \"DELETE /orgs/{org}/actions/runners/{runner_id}/labels\"\n    ],\n    removeAllCustomLabelsFromSelfHostedRunnerForRepo: [\n      \"DELETE /repos/{owner}/{repo}/actions/runners/{runner_id}/labels\"\n    ],\n    removeCustomLabelFromSelfHostedRunnerForOrg: [\n      \"DELETE /orgs/{org}/actions/runners/{runner_id}/labels/{name}\"\n    ],\n    removeCustomLabelFromSelfHostedRunnerForRepo: [\n      \"DELETE /repos/{owner}/{repo}/actions/runners/{runner_id}/labels/{name}\"\n    ],\n    removeSelectedRepoFromOrgSecret: [\n      \"DELETE /orgs/{org}/actions/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    removeSelectedRepoFromOrgVariable: [\n      \"DELETE /orgs/{org}/actions/variables/{name}/repositories/{repository_id}\"\n    ],\n    reviewCustomGatesForRun: [\n      \"POST /repos/{owner}/{repo}/actions/runs/{run_id}/deployment_protection_rule\"\n    ],\n    reviewPendingDeploymentsForRun: [\n      \"POST /repos/{owner}/{repo}/actions/runs/{run_id}/pending_deployments\"\n    ],\n    setAllowedActionsOrganization: [\n      \"PUT /orgs/{org}/actions/permissions/selected-actions\"\n    ],\n    setAllowedActionsRepository: [\n      \"PUT /repos/{owner}/{repo}/actions/permissions/selected-actions\"\n    ],\n    setCustomLabelsForSelfHostedRunnerForOrg: [\n      \"PUT /orgs/{org}/actions/runners/{runner_id}/labels\"\n    ],\n    setCustomLabelsForSelfHostedRunnerForRepo: [\n      \"PUT /repos/{owner}/{repo}/actions/runners/{runner_id}/labels\"\n    ],\n    setCustomOidcSubClaimForRepo: [\n      \"PUT /repos/{owner}/{repo}/actions/oidc/customization/sub\"\n    ],\n    setGithubActionsDefaultWorkflowPermissionsOrganization: [\n      \"PUT /orgs/{org}/actions/permissions/workflow\"\n    ],\n    setGithubActionsDefaultWorkflowPermissionsRepository: [\n      \"PUT /repos/{owner}/{repo}/actions/permissions/workflow\"\n    ],\n    setGithubActionsPermissionsOrganization: [\n      \"PUT /orgs/{org}/actions/permissions\"\n    ],\n    setGithubActionsPermissionsRepository: [\n      \"PUT /repos/{owner}/{repo}/actions/permissions\"\n    ],\n    setSelectedReposForOrgSecret: [\n      \"PUT /orgs/{org}/actions/secrets/{secret_name}/repositories\"\n    ],\n    setSelectedReposForOrgVariable: [\n      \"PUT /orgs/{org}/actions/variables/{name}/repositories\"\n    ],\n    setSelectedRepositoriesEnabledGithubActionsOrganization: [\n      \"PUT /orgs/{org}/actions/permissions/repositories\"\n    ],\n    setWorkflowAccessToRepository: [\n      \"PUT /repos/{owner}/{repo}/actions/permissions/access\"\n    ],\n    updateEnvironmentVariable: [\n      \"PATCH /repositories/{repository_id}/environments/{environment_name}/variables/{name}\"\n    ],\n    updateOrgVariable: [\"PATCH /orgs/{org}/actions/variables/{name}\"],\n    updateRepoVariable: [\n      \"PATCH /repos/{owner}/{repo}/actions/variables/{name}\"\n    ]\n  },\n  activity: {\n    checkRepoIsStarredByAuthenticatedUser: [\"GET /user/starred/{owner}/{repo}\"],\n    deleteRepoSubscription: [\"DELETE /repos/{owner}/{repo}/subscription\"],\n    deleteThreadSubscription: [\n      \"DELETE /notifications/threads/{thread_id}/subscription\"\n    ],\n    getFeeds: [\"GET /feeds\"],\n    getRepoSubscription: [\"GET /repos/{owner}/{repo}/subscription\"],\n    getThread: [\"GET /notifications/threads/{thread_id}\"],\n    getThreadSubscriptionForAuthenticatedUser: [\n      \"GET /notifications/threads/{thread_id}/subscription\"\n    ],\n    listEventsForAuthenticatedUser: [\"GET /users/{username}/events\"],\n    listNotificationsForAuthenticatedUser: [\"GET /notifications\"],\n    listOrgEventsForAuthenticatedUser: [\n      \"GET /users/{username}/events/orgs/{org}\"\n    ],\n    listPublicEvents: [\"GET /events\"],\n    listPublicEventsForRepoNetwork: [\"GET /networks/{owner}/{repo}/events\"],\n    listPublicEventsForUser: [\"GET /users/{username}/events/public\"],\n    listPublicOrgEvents: [\"GET /orgs/{org}/events\"],\n    listReceivedEventsForUser: [\"GET /users/{username}/received_events\"],\n    listReceivedPublicEventsForUser: [\n      \"GET /users/{username}/received_events/public\"\n    ],\n    listRepoEvents: [\"GET /repos/{owner}/{repo}/events\"],\n    listRepoNotificationsForAuthenticatedUser: [\n      \"GET /repos/{owner}/{repo}/notifications\"\n    ],\n    listReposStarredByAuthenticatedUser: [\"GET /user/starred\"],\n    listReposStarredByUser: [\"GET /users/{username}/starred\"],\n    listReposWatchedByUser: [\"GET /users/{username}/subscriptions\"],\n    listStargazersForRepo: [\"GET /repos/{owner}/{repo}/stargazers\"],\n    listWatchedReposForAuthenticatedUser: [\"GET /user/subscriptions\"],\n    listWatchersForRepo: [\"GET /repos/{owner}/{repo}/subscribers\"],\n    markNotificationsAsRead: [\"PUT /notifications\"],\n    markRepoNotificationsAsRead: [\"PUT /repos/{owner}/{repo}/notifications\"],\n    markThreadAsDone: [\"DELETE /notifications/threads/{thread_id}\"],\n    markThreadAsRead: [\"PATCH /notifications/threads/{thread_id}\"],\n    setRepoSubscription: [\"PUT /repos/{owner}/{repo}/subscription\"],\n    setThreadSubscription: [\n      \"PUT /notifications/threads/{thread_id}/subscription\"\n    ],\n    starRepoForAuthenticatedUser: [\"PUT /user/starred/{owner}/{repo}\"],\n    unstarRepoForAuthenticatedUser: [\"DELETE /user/starred/{owner}/{repo}\"]\n  },\n  apps: {\n    addRepoToInstallation: [\n      \"PUT /user/installations/{installation_id}/repositories/{repository_id}\",\n      {},\n      { renamed: [\"apps\", \"addRepoToInstallationForAuthenticatedUser\"] }\n    ],\n    addRepoToInstallationForAuthenticatedUser: [\n      \"PUT /user/installations/{installation_id}/repositories/{repository_id}\"\n    ],\n    checkToken: [\"POST /applications/{client_id}/token\"],\n    createFromManifest: [\"POST /app-manifests/{code}/conversions\"],\n    createInstallationAccessToken: [\n      \"POST /app/installations/{installation_id}/access_tokens\"\n    ],\n    deleteAuthorization: [\"DELETE /applications/{client_id}/grant\"],\n    deleteInstallation: [\"DELETE /app/installations/{installation_id}\"],\n    deleteToken: [\"DELETE /applications/{client_id}/token\"],\n    getAuthenticated: [\"GET /app\"],\n    getBySlug: [\"GET /apps/{app_slug}\"],\n    getInstallation: [\"GET /app/installations/{installation_id}\"],\n    getOrgInstallation: [\"GET /orgs/{org}/installation\"],\n    getRepoInstallation: [\"GET /repos/{owner}/{repo}/installation\"],\n    getSubscriptionPlanForAccount: [\n      \"GET /marketplace_listing/accounts/{account_id}\"\n    ],\n    getSubscriptionPlanForAccountStubbed: [\n      \"GET /marketplace_listing/stubbed/accounts/{account_id}\"\n    ],\n    getUserInstallation: [\"GET /users/{username}/installation\"],\n    getWebhookConfigForApp: [\"GET /app/hook/config\"],\n    getWebhookDelivery: [\"GET /app/hook/deliveries/{delivery_id}\"],\n    listAccountsForPlan: [\"GET /marketplace_listing/plans/{plan_id}/accounts\"],\n    listAccountsForPlanStubbed: [\n      \"GET /marketplace_listing/stubbed/plans/{plan_id}/accounts\"\n    ],\n    listInstallationReposForAuthenticatedUser: [\n      \"GET /user/installations/{installation_id}/repositories\"\n    ],\n    listInstallationRequestsForAuthenticatedApp: [\n      \"GET /app/installation-requests\"\n    ],\n    listInstallations: [\"GET /app/installations\"],\n    listInstallationsForAuthenticatedUser: [\"GET /user/installations\"],\n    listPlans: [\"GET /marketplace_listing/plans\"],\n    listPlansStubbed: [\"GET /marketplace_listing/stubbed/plans\"],\n    listReposAccessibleToInstallation: [\"GET /installation/repositories\"],\n    listSubscriptionsForAuthenticatedUser: [\"GET /user/marketplace_purchases\"],\n    listSubscriptionsForAuthenticatedUserStubbed: [\n      \"GET /user/marketplace_purchases/stubbed\"\n    ],\n    listWebhookDeliveries: [\"GET /app/hook/deliveries\"],\n    redeliverWebhookDelivery: [\n      \"POST /app/hook/deliveries/{delivery_id}/attempts\"\n    ],\n    removeRepoFromInstallation: [\n      \"DELETE /user/installations/{installation_id}/repositories/{repository_id}\",\n      {},\n      { renamed: [\"apps\", \"removeRepoFromInstallationForAuthenticatedUser\"] }\n    ],\n    removeRepoFromInstallationForAuthenticatedUser: [\n      \"DELETE /user/installations/{installation_id}/repositories/{repository_id}\"\n    ],\n    resetToken: [\"PATCH /applications/{client_id}/token\"],\n    revokeInstallationAccessToken: [\"DELETE /installation/token\"],\n    scopeToken: [\"POST /applications/{client_id}/token/scoped\"],\n    suspendInstallation: [\"PUT /app/installations/{installation_id}/suspended\"],\n    unsuspendInstallation: [\n      \"DELETE /app/installations/{installation_id}/suspended\"\n    ],\n    updateWebhookConfigForApp: [\"PATCH /app/hook/config\"]\n  },\n  billing: {\n    getGithubActionsBillingOrg: [\"GET /orgs/{org}/settings/billing/actions\"],\n    getGithubActionsBillingUser: [\n      \"GET /users/{username}/settings/billing/actions\"\n    ],\n    getGithubPackagesBillingOrg: [\"GET /orgs/{org}/settings/billing/packages\"],\n    getGithubPackagesBillingUser: [\n      \"GET /users/{username}/settings/billing/packages\"\n    ],\n    getSharedStorageBillingOrg: [\n      \"GET /orgs/{org}/settings/billing/shared-storage\"\n    ],\n    getSharedStorageBillingUser: [\n      \"GET /users/{username}/settings/billing/shared-storage\"\n    ]\n  },\n  checks: {\n    create: [\"POST /repos/{owner}/{repo}/check-runs\"],\n    createSuite: [\"POST /repos/{owner}/{repo}/check-suites\"],\n    get: [\"GET /repos/{owner}/{repo}/check-runs/{check_run_id}\"],\n    getSuite: [\"GET /repos/{owner}/{repo}/check-suites/{check_suite_id}\"],\n    listAnnotations: [\n      \"GET /repos/{owner}/{repo}/check-runs/{check_run_id}/annotations\"\n    ],\n    listForRef: [\"GET /repos/{owner}/{repo}/commits/{ref}/check-runs\"],\n    listForSuite: [\n      \"GET /repos/{owner}/{repo}/check-suites/{check_suite_id}/check-runs\"\n    ],\n    listSuitesForRef: [\"GET /repos/{owner}/{repo}/commits/{ref}/check-suites\"],\n    rerequestRun: [\n      \"POST /repos/{owner}/{repo}/check-runs/{check_run_id}/rerequest\"\n    ],\n    rerequestSuite: [\n      \"POST /repos/{owner}/{repo}/check-suites/{check_suite_id}/rerequest\"\n    ],\n    setSuitesPreferences: [\n      \"PATCH /repos/{owner}/{repo}/check-suites/preferences\"\n    ],\n    update: [\"PATCH /repos/{owner}/{repo}/check-runs/{check_run_id}\"]\n  },\n  codeScanning: {\n    deleteAnalysis: [\n      \"DELETE /repos/{owner}/{repo}/code-scanning/analyses/{analysis_id}{?confirm_delete}\"\n    ],\n    getAlert: [\n      \"GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}\",\n      {},\n      { renamedParameters: { alert_id: \"alert_number\" } }\n    ],\n    getAnalysis: [\n      \"GET /repos/{owner}/{repo}/code-scanning/analyses/{analysis_id}\"\n    ],\n    getCodeqlDatabase: [\n      \"GET /repos/{owner}/{repo}/code-scanning/codeql/databases/{language}\"\n    ],\n    getDefaultSetup: [\"GET /repos/{owner}/{repo}/code-scanning/default-setup\"],\n    getSarif: [\"GET /repos/{owner}/{repo}/code-scanning/sarifs/{sarif_id}\"],\n    listAlertInstances: [\n      \"GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances\"\n    ],\n    listAlertsForOrg: [\"GET /orgs/{org}/code-scanning/alerts\"],\n    listAlertsForRepo: [\"GET /repos/{owner}/{repo}/code-scanning/alerts\"],\n    listAlertsInstances: [\n      \"GET /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}/instances\",\n      {},\n      { renamed: [\"codeScanning\", \"listAlertInstances\"] }\n    ],\n    listCodeqlDatabases: [\n      \"GET /repos/{owner}/{repo}/code-scanning/codeql/databases\"\n    ],\n    listRecentAnalyses: [\"GET /repos/{owner}/{repo}/code-scanning/analyses\"],\n    updateAlert: [\n      \"PATCH /repos/{owner}/{repo}/code-scanning/alerts/{alert_number}\"\n    ],\n    updateDefaultSetup: [\n      \"PATCH /repos/{owner}/{repo}/code-scanning/default-setup\"\n    ],\n    uploadSarif: [\"POST /repos/{owner}/{repo}/code-scanning/sarifs\"]\n  },\n  codesOfConduct: {\n    getAllCodesOfConduct: [\"GET /codes_of_conduct\"],\n    getConductCode: [\"GET /codes_of_conduct/{key}\"]\n  },\n  codespaces: {\n    addRepositoryForSecretForAuthenticatedUser: [\n      \"PUT /user/codespaces/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    addSelectedRepoToOrgSecret: [\n      \"PUT /orgs/{org}/codespaces/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    checkPermissionsForDevcontainer: [\n      \"GET /repos/{owner}/{repo}/codespaces/permissions_check\"\n    ],\n    codespaceMachinesForAuthenticatedUser: [\n      \"GET /user/codespaces/{codespace_name}/machines\"\n    ],\n    createForAuthenticatedUser: [\"POST /user/codespaces\"],\n    createOrUpdateOrgSecret: [\n      \"PUT /orgs/{org}/codespaces/secrets/{secret_name}\"\n    ],\n    createOrUpdateRepoSecret: [\n      \"PUT /repos/{owner}/{repo}/codespaces/secrets/{secret_name}\"\n    ],\n    createOrUpdateSecretForAuthenticatedUser: [\n      \"PUT /user/codespaces/secrets/{secret_name}\"\n    ],\n    createWithPrForAuthenticatedUser: [\n      \"POST /repos/{owner}/{repo}/pulls/{pull_number}/codespaces\"\n    ],\n    createWithRepoForAuthenticatedUser: [\n      \"POST /repos/{owner}/{repo}/codespaces\"\n    ],\n    deleteForAuthenticatedUser: [\"DELETE /user/codespaces/{codespace_name}\"],\n    deleteFromOrganization: [\n      \"DELETE /orgs/{org}/members/{username}/codespaces/{codespace_name}\"\n    ],\n    deleteOrgSecret: [\"DELETE /orgs/{org}/codespaces/secrets/{secret_name}\"],\n    deleteRepoSecret: [\n      \"DELETE /repos/{owner}/{repo}/codespaces/secrets/{secret_name}\"\n    ],\n    deleteSecretForAuthenticatedUser: [\n      \"DELETE /user/codespaces/secrets/{secret_name}\"\n    ],\n    exportForAuthenticatedUser: [\n      \"POST /user/codespaces/{codespace_name}/exports\"\n    ],\n    getCodespacesForUserInOrg: [\n      \"GET /orgs/{org}/members/{username}/codespaces\"\n    ],\n    getExportDetailsForAuthenticatedUser: [\n      \"GET /user/codespaces/{codespace_name}/exports/{export_id}\"\n    ],\n    getForAuthenticatedUser: [\"GET /user/codespaces/{codespace_name}\"],\n    getOrgPublicKey: [\"GET /orgs/{org}/codespaces/secrets/public-key\"],\n    getOrgSecret: [\"GET /orgs/{org}/codespaces/secrets/{secret_name}\"],\n    getPublicKeyForAuthenticatedUser: [\n      \"GET /user/codespaces/secrets/public-key\"\n    ],\n    getRepoPublicKey: [\n      \"GET /repos/{owner}/{repo}/codespaces/secrets/public-key\"\n    ],\n    getRepoSecret: [\n      \"GET /repos/{owner}/{repo}/codespaces/secrets/{secret_name}\"\n    ],\n    getSecretForAuthenticatedUser: [\n      \"GET /user/codespaces/secrets/{secret_name}\"\n    ],\n    listDevcontainersInRepositoryForAuthenticatedUser: [\n      \"GET /repos/{owner}/{repo}/codespaces/devcontainers\"\n    ],\n    listForAuthenticatedUser: [\"GET /user/codespaces\"],\n    listInOrganization: [\n      \"GET /orgs/{org}/codespaces\",\n      {},\n      { renamedParameters: { org_id: \"org\" } }\n    ],\n    listInRepositoryForAuthenticatedUser: [\n      \"GET /repos/{owner}/{repo}/codespaces\"\n    ],\n    listOrgSecrets: [\"GET /orgs/{org}/codespaces/secrets\"],\n    listRepoSecrets: [\"GET /repos/{owner}/{repo}/codespaces/secrets\"],\n    listRepositoriesForSecretForAuthenticatedUser: [\n      \"GET /user/codespaces/secrets/{secret_name}/repositories\"\n    ],\n    listSecretsForAuthenticatedUser: [\"GET /user/codespaces/secrets\"],\n    listSelectedReposForOrgSecret: [\n      \"GET /orgs/{org}/codespaces/secrets/{secret_name}/repositories\"\n    ],\n    preFlightWithRepoForAuthenticatedUser: [\n      \"GET /repos/{owner}/{repo}/codespaces/new\"\n    ],\n    publishForAuthenticatedUser: [\n      \"POST /user/codespaces/{codespace_name}/publish\"\n    ],\n    removeRepositoryForSecretForAuthenticatedUser: [\n      \"DELETE /user/codespaces/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    removeSelectedRepoFromOrgSecret: [\n      \"DELETE /orgs/{org}/codespaces/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    repoMachinesForAuthenticatedUser: [\n      \"GET /repos/{owner}/{repo}/codespaces/machines\"\n    ],\n    setRepositoriesForSecretForAuthenticatedUser: [\n      \"PUT /user/codespaces/secrets/{secret_name}/repositories\"\n    ],\n    setSelectedReposForOrgSecret: [\n      \"PUT /orgs/{org}/codespaces/secrets/{secret_name}/repositories\"\n    ],\n    startForAuthenticatedUser: [\"POST /user/codespaces/{codespace_name}/start\"],\n    stopForAuthenticatedUser: [\"POST /user/codespaces/{codespace_name}/stop\"],\n    stopInOrganization: [\n      \"POST /orgs/{org}/members/{username}/codespaces/{codespace_name}/stop\"\n    ],\n    updateForAuthenticatedUser: [\"PATCH /user/codespaces/{codespace_name}\"]\n  },\n  copilot: {\n    addCopilotSeatsForTeams: [\n      \"POST /orgs/{org}/copilot/billing/selected_teams\"\n    ],\n    addCopilotSeatsForUsers: [\n      \"POST /orgs/{org}/copilot/billing/selected_users\"\n    ],\n    cancelCopilotSeatAssignmentForTeams: [\n      \"DELETE /orgs/{org}/copilot/billing/selected_teams\"\n    ],\n    cancelCopilotSeatAssignmentForUsers: [\n      \"DELETE /orgs/{org}/copilot/billing/selected_users\"\n    ],\n    getCopilotOrganizationDetails: [\"GET /orgs/{org}/copilot/billing\"],\n    getCopilotSeatDetailsForUser: [\n      \"GET /orgs/{org}/members/{username}/copilot\"\n    ],\n    listCopilotSeats: [\"GET /orgs/{org}/copilot/billing/seats\"]\n  },\n  dependabot: {\n    addSelectedRepoToOrgSecret: [\n      \"PUT /orgs/{org}/dependabot/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    createOrUpdateOrgSecret: [\n      \"PUT /orgs/{org}/dependabot/secrets/{secret_name}\"\n    ],\n    createOrUpdateRepoSecret: [\n      \"PUT /repos/{owner}/{repo}/dependabot/secrets/{secret_name}\"\n    ],\n    deleteOrgSecret: [\"DELETE /orgs/{org}/dependabot/secrets/{secret_name}\"],\n    deleteRepoSecret: [\n      \"DELETE /repos/{owner}/{repo}/dependabot/secrets/{secret_name}\"\n    ],\n    getAlert: [\"GET /repos/{owner}/{repo}/dependabot/alerts/{alert_number}\"],\n    getOrgPublicKey: [\"GET /orgs/{org}/dependabot/secrets/public-key\"],\n    getOrgSecret: [\"GET /orgs/{org}/dependabot/secrets/{secret_name}\"],\n    getRepoPublicKey: [\n      \"GET /repos/{owner}/{repo}/dependabot/secrets/public-key\"\n    ],\n    getRepoSecret: [\n      \"GET /repos/{owner}/{repo}/dependabot/secrets/{secret_name}\"\n    ],\n    listAlertsForEnterprise: [\n      \"GET /enterprises/{enterprise}/dependabot/alerts\"\n    ],\n    listAlertsForOrg: [\"GET /orgs/{org}/dependabot/alerts\"],\n    listAlertsForRepo: [\"GET /repos/{owner}/{repo}/dependabot/alerts\"],\n    listOrgSecrets: [\"GET /orgs/{org}/dependabot/secrets\"],\n    listRepoSecrets: [\"GET /repos/{owner}/{repo}/dependabot/secrets\"],\n    listSelectedReposForOrgSecret: [\n      \"GET /orgs/{org}/dependabot/secrets/{secret_name}/repositories\"\n    ],\n    removeSelectedRepoFromOrgSecret: [\n      \"DELETE /orgs/{org}/dependabot/secrets/{secret_name}/repositories/{repository_id}\"\n    ],\n    setSelectedReposForOrgSecret: [\n      \"PUT /orgs/{org}/dependabot/secrets/{secret_name}/repositories\"\n    ],\n    updateAlert: [\n      \"PATCH /repos/{owner}/{repo}/dependabot/alerts/{alert_number}\"\n    ]\n  },\n  dependencyGraph: {\n    createRepositorySnapshot: [\n      \"POST /repos/{owner}/{repo}/dependency-graph/snapshots\"\n    ],\n    diffRange: [\n      \"GET /repos/{owner}/{repo}/dependency-graph/compare/{basehead}\"\n    ],\n    exportSbom: [\"GET /repos/{owner}/{repo}/dependency-graph/sbom\"]\n  },\n  emojis: { get: [\"GET /emojis\"] },\n  gists: {\n    checkIsStarred: [\"GET /gists/{gist_id}/star\"],\n    create: [\"POST /gists\"],\n    createComment: [\"POST /gists/{gist_id}/comments\"],\n    delete: [\"DELETE /gists/{gist_id}\"],\n    deleteComment: [\"DELETE /gists/{gist_id}/comments/{comment_id}\"],\n    fork: [\"POST /gists/{gist_id}/forks\"],\n    get: [\"GET /gists/{gist_id}\"],\n    getComment: [\"GET /gists/{gist_id}/comments/{comment_id}\"],\n    getRevision: [\"GET /gists/{gist_id}/{sha}\"],\n    list: [\"GET /gists\"],\n    listComments: [\"GET /gists/{gist_id}/comments\"],\n    listCommits: [\"GET /gists/{gist_id}/commits\"],\n    listForUser: [\"GET /users/{username}/gists\"],\n    listForks: [\"GET /gists/{gist_id}/forks\"],\n    listPublic: [\"GET /gists/public\"],\n    listStarred: [\"GET /gists/starred\"],\n    star: [\"PUT /gists/{gist_id}/star\"],\n    unstar: [\"DELETE /gists/{gist_id}/star\"],\n    update: [\"PATCH /gists/{gist_id}\"],\n    updateComment: [\"PATCH /gists/{gist_id}/comments/{comment_id}\"]\n  },\n  git: {\n    createBlob: [\"POST /repos/{owner}/{repo}/git/blobs\"],\n    createCommit: [\"POST /repos/{owner}/{repo}/git/commits\"],\n    createRef: [\"POST /repos/{owner}/{repo}/git/refs\"],\n    createTag: [\"POST /repos/{owner}/{repo}/git/tags\"],\n    createTree: [\"POST /repos/{owner}/{repo}/git/trees\"],\n    deleteRef: [\"DELETE /repos/{owner}/{repo}/git/refs/{ref}\"],\n    getBlob: [\"GET /repos/{owner}/{repo}/git/blobs/{file_sha}\"],\n    getCommit: [\"GET /repos/{owner}/{repo}/git/commits/{commit_sha}\"],\n    getRef: [\"GET /repos/{owner}/{repo}/git/ref/{ref}\"],\n    getTag: [\"GET /repos/{owner}/{repo}/git/tags/{tag_sha}\"],\n    getTree: [\"GET /repos/{owner}/{repo}/git/trees/{tree_sha}\"],\n    listMatchingRefs: [\"GET /repos/{owner}/{repo}/git/matching-refs/{ref}\"],\n    updateRef: [\"PATCH /repos/{owner}/{repo}/git/refs/{ref}\"]\n  },\n  gitignore: {\n    getAllTemplates: [\"GET /gitignore/templates\"],\n    getTemplate: [\"GET /gitignore/templates/{name}\"]\n  },\n  interactions: {\n    getRestrictionsForAuthenticatedUser: [\"GET /user/interaction-limits\"],\n    getRestrictionsForOrg: [\"GET /orgs/{org}/interaction-limits\"],\n    getRestrictionsForRepo: [\"GET /repos/{owner}/{repo}/interaction-limits\"],\n    getRestrictionsForYourPublicRepos: [\n      \"GET /user/interaction-limits\",\n      {},\n      { renamed: [\"interactions\", \"getRestrictionsForAuthenticatedUser\"] }\n    ],\n    removeRestrictionsForAuthenticatedUser: [\"DELETE /user/interaction-limits\"],\n    removeRestrictionsForOrg: [\"DELETE /orgs/{org}/interaction-limits\"],\n    removeRestrictionsForRepo: [\n      \"DELETE /repos/{owner}/{repo}/interaction-limits\"\n    ],\n    removeRestrictionsForYourPublicRepos: [\n      \"DELETE /user/interaction-limits\",\n      {},\n      { renamed: [\"interactions\", \"removeRestrictionsForAuthenticatedUser\"] }\n    ],\n    setRestrictionsForAuthenticatedUser: [\"PUT /user/interaction-limits\"],\n    setRestrictionsForOrg: [\"PUT /orgs/{org}/interaction-limits\"],\n    setRestrictionsForRepo: [\"PUT /repos/{owner}/{repo}/interaction-limits\"],\n    setRestrictionsForYourPublicRepos: [\n      \"PUT /user/interaction-limits\",\n      {},\n      { renamed: [\"interactions\", \"setRestrictionsForAuthenticatedUser\"] }\n    ]\n  },\n  issues: {\n    addAssignees: [\n      \"POST /repos/{owner}/{repo}/issues/{issue_number}/assignees\"\n    ],\n    addLabels: [\"POST /repos/{owner}/{repo}/issues/{issue_number}/labels\"],\n    checkUserCanBeAssigned: [\"GET /repos/{owner}/{repo}/assignees/{assignee}\"],\n    checkUserCanBeAssignedToIssue: [\n      \"GET /repos/{owner}/{repo}/issues/{issue_number}/assignees/{assignee}\"\n    ],\n    create: [\"POST /repos/{owner}/{repo}/issues\"],\n    createComment: [\n      \"POST /repos/{owner}/{repo}/issues/{issue_number}/comments\"\n    ],\n    createLabel: [\"POST /repos/{owner}/{repo}/labels\"],\n    createMilestone: [\"POST /repos/{owner}/{repo}/milestones\"],\n    deleteComment: [\n      \"DELETE /repos/{owner}/{repo}/issues/comments/{comment_id}\"\n    ],\n    deleteLabel: [\"DELETE /repos/{owner}/{repo}/labels/{name}\"],\n    deleteMilestone: [\n      \"DELETE /repos/{owner}/{repo}/milestones/{milestone_number}\"\n    ],\n    get: [\"GET /repos/{owner}/{repo}/issues/{issue_number}\"],\n    getComment: [\"GET /repos/{owner}/{repo}/issues/comments/{comment_id}\"],\n    getEvent: [\"GET /repos/{owner}/{repo}/issues/events/{event_id}\"],\n    getLabel: [\"GET /repos/{owner}/{repo}/labels/{name}\"],\n    getMilestone: [\"GET /repos/{owner}/{repo}/milestones/{milestone_number}\"],\n    list: [\"GET /issues\"],\n    listAssignees: [\"GET /repos/{owner}/{repo}/assignees\"],\n    listComments: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/comments\"],\n    listCommentsForRepo: [\"GET /repos/{owner}/{repo}/issues/comments\"],\n    listEvents: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/events\"],\n    listEventsForRepo: [\"GET /repos/{owner}/{repo}/issues/events\"],\n    listEventsForTimeline: [\n      \"GET /repos/{owner}/{repo}/issues/{issue_number}/timeline\"\n    ],\n    listForAuthenticatedUser: [\"GET /user/issues\"],\n    listForOrg: [\"GET /orgs/{org}/issues\"],\n    listForRepo: [\"GET /repos/{owner}/{repo}/issues\"],\n    listLabelsForMilestone: [\n      \"GET /repos/{owner}/{repo}/milestones/{milestone_number}/labels\"\n    ],\n    listLabelsForRepo: [\"GET /repos/{owner}/{repo}/labels\"],\n    listLabelsOnIssue: [\n      \"GET /repos/{owner}/{repo}/issues/{issue_number}/labels\"\n    ],\n    listMilestones: [\"GET /repos/{owner}/{repo}/milestones\"],\n    lock: [\"PUT /repos/{owner}/{repo}/issues/{issue_number}/lock\"],\n    removeAllLabels: [\n      \"DELETE /repos/{owner}/{repo}/issues/{issue_number}/labels\"\n    ],\n    removeAssignees: [\n      \"DELETE /repos/{owner}/{repo}/issues/{issue_number}/assignees\"\n    ],\n    removeLabel: [\n      \"DELETE /repos/{owner}/{repo}/issues/{issue_number}/labels/{name}\"\n    ],\n    setLabels: [\"PUT /repos/{owner}/{repo}/issues/{issue_number}/labels\"],\n    unlock: [\"DELETE /repos/{owner}/{repo}/issues/{issue_number}/lock\"],\n    update: [\"PATCH /repos/{owner}/{repo}/issues/{issue_number}\"],\n    updateComment: [\"PATCH /repos/{owner}/{repo}/issues/comments/{comment_id}\"],\n    updateLabel: [\"PATCH /repos/{owner}/{repo}/labels/{name}\"],\n    updateMilestone: [\n      \"PATCH /repos/{owner}/{repo}/milestones/{milestone_number}\"\n    ]\n  },\n  licenses: {\n    get: [\"GET /licenses/{license}\"],\n    getAllCommonlyUsed: [\"GET /licenses\"],\n    getForRepo: [\"GET /repos/{owner}/{repo}/license\"]\n  },\n  markdown: {\n    render: [\"POST /markdown\"],\n    renderRaw: [\n      \"POST /markdown/raw\",\n      { headers: { \"content-type\": \"text/plain; charset=utf-8\" } }\n    ]\n  },\n  meta: {\n    get: [\"GET /meta\"],\n    getAllVersions: [\"GET /versions\"],\n    getOctocat: [\"GET /octocat\"],\n    getZen: [\"GET /zen\"],\n    root: [\"GET /\"]\n  },\n  migrations: {\n    cancelImport: [\n      \"DELETE /repos/{owner}/{repo}/import\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.cancelImport() is deprecated, see https://docs.github.com/rest/migrations/source-imports#cancel-an-import\"\n      }\n    ],\n    deleteArchiveForAuthenticatedUser: [\n      \"DELETE /user/migrations/{migration_id}/archive\"\n    ],\n    deleteArchiveForOrg: [\n      \"DELETE /orgs/{org}/migrations/{migration_id}/archive\"\n    ],\n    downloadArchiveForOrg: [\n      \"GET /orgs/{org}/migrations/{migration_id}/archive\"\n    ],\n    getArchiveForAuthenticatedUser: [\n      \"GET /user/migrations/{migration_id}/archive\"\n    ],\n    getCommitAuthors: [\n      \"GET /repos/{owner}/{repo}/import/authors\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.getCommitAuthors() is deprecated, see https://docs.github.com/rest/migrations/source-imports#get-commit-authors\"\n      }\n    ],\n    getImportStatus: [\n      \"GET /repos/{owner}/{repo}/import\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.getImportStatus() is deprecated, see https://docs.github.com/rest/migrations/source-imports#get-an-import-status\"\n      }\n    ],\n    getLargeFiles: [\n      \"GET /repos/{owner}/{repo}/import/large_files\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.getLargeFiles() is deprecated, see https://docs.github.com/rest/migrations/source-imports#get-large-files\"\n      }\n    ],\n    getStatusForAuthenticatedUser: [\"GET /user/migrations/{migration_id}\"],\n    getStatusForOrg: [\"GET /orgs/{org}/migrations/{migration_id}\"],\n    listForAuthenticatedUser: [\"GET /user/migrations\"],\n    listForOrg: [\"GET /orgs/{org}/migrations\"],\n    listReposForAuthenticatedUser: [\n      \"GET /user/migrations/{migration_id}/repositories\"\n    ],\n    listReposForOrg: [\"GET /orgs/{org}/migrations/{migration_id}/repositories\"],\n    listReposForUser: [\n      \"GET /user/migrations/{migration_id}/repositories\",\n      {},\n      { renamed: [\"migrations\", \"listReposForAuthenticatedUser\"] }\n    ],\n    mapCommitAuthor: [\n      \"PATCH /repos/{owner}/{repo}/import/authors/{author_id}\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.mapCommitAuthor() is deprecated, see https://docs.github.com/rest/migrations/source-imports#map-a-commit-author\"\n      }\n    ],\n    setLfsPreference: [\n      \"PATCH /repos/{owner}/{repo}/import/lfs\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.setLfsPreference() is deprecated, see https://docs.github.com/rest/migrations/source-imports#update-git-lfs-preference\"\n      }\n    ],\n    startForAuthenticatedUser: [\"POST /user/migrations\"],\n    startForOrg: [\"POST /orgs/{org}/migrations\"],\n    startImport: [\n      \"PUT /repos/{owner}/{repo}/import\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.startImport() is deprecated, see https://docs.github.com/rest/migrations/source-imports#start-an-import\"\n      }\n    ],\n    unlockRepoForAuthenticatedUser: [\n      \"DELETE /user/migrations/{migration_id}/repos/{repo_name}/lock\"\n    ],\n    unlockRepoForOrg: [\n      \"DELETE /orgs/{org}/migrations/{migration_id}/repos/{repo_name}/lock\"\n    ],\n    updateImport: [\n      \"PATCH /repos/{owner}/{repo}/import\",\n      {},\n      {\n        deprecated: \"octokit.rest.migrations.updateImport() is deprecated, see https://docs.github.com/rest/migrations/source-imports#update-an-import\"\n      }\n    ]\n  },\n  oidc: {\n    getOidcCustomSubTemplateForOrg: [\n      \"GET /orgs/{org}/actions/oidc/customization/sub\"\n    ],\n    updateOidcCustomSubTemplateForOrg: [\n      \"PUT /orgs/{org}/actions/oidc/customization/sub\"\n    ]\n  },\n  orgs: {\n    addSecurityManagerTeam: [\n      \"PUT /orgs/{org}/security-managers/teams/{team_slug}\"\n    ],\n    assignTeamToOrgRole: [\n      \"PUT /orgs/{org}/organization-roles/teams/{team_slug}/{role_id}\"\n    ],\n    assignUserToOrgRole: [\n      \"PUT /orgs/{org}/organization-roles/users/{username}/{role_id}\"\n    ],\n    blockUser: [\"PUT /orgs/{org}/blocks/{username}\"],\n    cancelInvitation: [\"DELETE /orgs/{org}/invitations/{invitation_id}\"],\n    checkBlockedUser: [\"GET /orgs/{org}/blocks/{username}\"],\n    checkMembershipForUser: [\"GET /orgs/{org}/members/{username}\"],\n    checkPublicMembershipForUser: [\"GET /orgs/{org}/public_members/{username}\"],\n    convertMemberToOutsideCollaborator: [\n      \"PUT /orgs/{org}/outside_collaborators/{username}\"\n    ],\n    createCustomOrganizationRole: [\"POST /orgs/{org}/organization-roles\"],\n    createInvitation: [\"POST /orgs/{org}/invitations\"],\n    createOrUpdateCustomProperties: [\"PATCH /orgs/{org}/properties/schema\"],\n    createOrUpdateCustomPropertiesValuesForRepos: [\n      \"PATCH /orgs/{org}/properties/values\"\n    ],\n    createOrUpdateCustomProperty: [\n      \"PUT /orgs/{org}/properties/schema/{custom_property_name}\"\n    ],\n    createWebhook: [\"POST /orgs/{org}/hooks\"],\n    delete: [\"DELETE /orgs/{org}\"],\n    deleteCustomOrganizationRole: [\n      \"DELETE /orgs/{org}/organization-roles/{role_id}\"\n    ],\n    deleteWebhook: [\"DELETE /orgs/{org}/hooks/{hook_id}\"],\n    enableOrDisableSecurityProductOnAllOrgRepos: [\n      \"POST /orgs/{org}/{security_product}/{enablement}\"\n    ],\n    get: [\"GET /orgs/{org}\"],\n    getAllCustomProperties: [\"GET /orgs/{org}/properties/schema\"],\n    getCustomProperty: [\n      \"GET /orgs/{org}/properties/schema/{custom_property_name}\"\n    ],\n    getMembershipForAuthenticatedUser: [\"GET /user/memberships/orgs/{org}\"],\n    getMembershipForUser: [\"GET /orgs/{org}/memberships/{username}\"],\n    getOrgRole: [\"GET /orgs/{org}/organization-roles/{role_id}\"],\n    getWebhook: [\"GET /orgs/{org}/hooks/{hook_id}\"],\n    getWebhookConfigForOrg: [\"GET /orgs/{org}/hooks/{hook_id}/config\"],\n    getWebhookDelivery: [\n      \"GET /orgs/{org}/hooks/{hook_id}/deliveries/{delivery_id}\"\n    ],\n    list: [\"GET /organizations\"],\n    listAppInstallations: [\"GET /orgs/{org}/installations\"],\n    listBlockedUsers: [\"GET /orgs/{org}/blocks\"],\n    listCustomPropertiesValuesForRepos: [\"GET /orgs/{org}/properties/values\"],\n    listFailedInvitations: [\"GET /orgs/{org}/failed_invitations\"],\n    listForAuthenticatedUser: [\"GET /user/orgs\"],\n    listForUser: [\"GET /users/{username}/orgs\"],\n    listInvitationTeams: [\"GET /orgs/{org}/invitations/{invitation_id}/teams\"],\n    listMembers: [\"GET /orgs/{org}/members\"],\n    listMembershipsForAuthenticatedUser: [\"GET /user/memberships/orgs\"],\n    listOrgRoleTeams: [\"GET /orgs/{org}/organization-roles/{role_id}/teams\"],\n    listOrgRoleUsers: [\"GET /orgs/{org}/organization-roles/{role_id}/users\"],\n    listOrgRoles: [\"GET /orgs/{org}/organization-roles\"],\n    listOrganizationFineGrainedPermissions: [\n      \"GET /orgs/{org}/organization-fine-grained-permissions\"\n    ],\n    listOutsideCollaborators: [\"GET /orgs/{org}/outside_collaborators\"],\n    listPatGrantRepositories: [\n      \"GET /orgs/{org}/personal-access-tokens/{pat_id}/repositories\"\n    ],\n    listPatGrantRequestRepositories: [\n      \"GET /orgs/{org}/personal-access-token-requests/{pat_request_id}/repositories\"\n    ],\n    listPatGrantRequests: [\"GET /orgs/{org}/personal-access-token-requests\"],\n    listPatGrants: [\"GET /orgs/{org}/personal-access-tokens\"],\n    listPendingInvitations: [\"GET /orgs/{org}/invitations\"],\n    listPublicMembers: [\"GET /orgs/{org}/public_members\"],\n    listSecurityManagerTeams: [\"GET /orgs/{org}/security-managers\"],\n    listWebhookDeliveries: [\"GET /orgs/{org}/hooks/{hook_id}/deliveries\"],\n    listWebhooks: [\"GET /orgs/{org}/hooks\"],\n    patchCustomOrganizationRole: [\n      \"PATCH /orgs/{org}/organization-roles/{role_id}\"\n    ],\n    pingWebhook: [\"POST /orgs/{org}/hooks/{hook_id}/pings\"],\n    redeliverWebhookDelivery: [\n      \"POST /orgs/{org}/hooks/{hook_id}/deliveries/{delivery_id}/attempts\"\n    ],\n    removeCustomProperty: [\n      \"DELETE /orgs/{org}/properties/schema/{custom_property_name}\"\n    ],\n    removeMember: [\"DELETE /orgs/{org}/members/{username}\"],\n    removeMembershipForUser: [\"DELETE /orgs/{org}/memberships/{username}\"],\n    removeOutsideCollaborator: [\n      \"DELETE /orgs/{org}/outside_collaborators/{username}\"\n    ],\n    removePublicMembershipForAuthenticatedUser: [\n      \"DELETE /orgs/{org}/public_members/{username}\"\n    ],\n    removeSecurityManagerTeam: [\n      \"DELETE /orgs/{org}/security-managers/teams/{team_slug}\"\n    ],\n    reviewPatGrantRequest: [\n      \"POST /orgs/{org}/personal-access-token-requests/{pat_request_id}\"\n    ],\n    reviewPatGrantRequestsInBulk: [\n      \"POST /orgs/{org}/personal-access-token-requests\"\n    ],\n    revokeAllOrgRolesTeam: [\n      \"DELETE /orgs/{org}/organization-roles/teams/{team_slug}\"\n    ],\n    revokeAllOrgRolesUser: [\n      \"DELETE /orgs/{org}/organization-roles/users/{username}\"\n    ],\n    revokeOrgRoleTeam: [\n      \"DELETE /orgs/{org}/organization-roles/teams/{team_slug}/{role_id}\"\n    ],\n    revokeOrgRoleUser: [\n      \"DELETE /orgs/{org}/organization-roles/users/{username}/{role_id}\"\n    ],\n    setMembershipForUser: [\"PUT /orgs/{org}/memberships/{username}\"],\n    setPublicMembershipForAuthenticatedUser: [\n      \"PUT /orgs/{org}/public_members/{username}\"\n    ],\n    unblockUser: [\"DELETE /orgs/{org}/blocks/{username}\"],\n    update: [\"PATCH /orgs/{org}\"],\n    updateMembershipForAuthenticatedUser: [\n      \"PATCH /user/memberships/orgs/{org}\"\n    ],\n    updatePatAccess: [\"POST /orgs/{org}/personal-access-tokens/{pat_id}\"],\n    updatePatAccesses: [\"POST /orgs/{org}/personal-access-tokens\"],\n    updateWebhook: [\"PATCH /orgs/{org}/hooks/{hook_id}\"],\n    updateWebhookConfigForOrg: [\"PATCH /orgs/{org}/hooks/{hook_id}/config\"]\n  },\n  packages: {\n    deletePackageForAuthenticatedUser: [\n      \"DELETE /user/packages/{package_type}/{package_name}\"\n    ],\n    deletePackageForOrg: [\n      \"DELETE /orgs/{org}/packages/{package_type}/{package_name}\"\n    ],\n    deletePackageForUser: [\n      \"DELETE /users/{username}/packages/{package_type}/{package_name}\"\n    ],\n    deletePackageVersionForAuthenticatedUser: [\n      \"DELETE /user/packages/{package_type}/{package_name}/versions/{package_version_id}\"\n    ],\n    deletePackageVersionForOrg: [\n      \"DELETE /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}\"\n    ],\n    deletePackageVersionForUser: [\n      \"DELETE /users/{username}/packages/{package_type}/{package_name}/versions/{package_version_id}\"\n    ],\n    getAllPackageVersionsForAPackageOwnedByAnOrg: [\n      \"GET /orgs/{org}/packages/{package_type}/{package_name}/versions\",\n      {},\n      { renamed: [\"packages\", \"getAllPackageVersionsForPackageOwnedByOrg\"] }\n    ],\n    getAllPackageVersionsForAPackageOwnedByTheAuthenticatedUser: [\n      \"GET /user/packages/{package_type}/{package_name}/versions\",\n      {},\n      {\n        renamed: [\n          \"packages\",\n          \"getAllPackageVersionsForPackageOwnedByAuthenticatedUser\"\n        ]\n      }\n    ],\n    getAllPackageVersionsForPackageOwnedByAuthenticatedUser: [\n      \"GET /user/packages/{package_type}/{package_name}/versions\"\n    ],\n    getAllPackageVersionsForPackageOwnedByOrg: [\n      \"GET /orgs/{org}/packages/{package_type}/{package_name}/versions\"\n    ],\n    getAllPackageVersionsForPackageOwnedByUser: [\n      \"GET /users/{username}/packages/{package_type}/{package_name}/versions\"\n    ],\n    getPackageForAuthenticatedUser: [\n      \"GET /user/packages/{package_type}/{package_name}\"\n    ],\n    getPackageForOrganization: [\n      \"GET /orgs/{org}/packages/{package_type}/{package_name}\"\n    ],\n    getPackageForUser: [\n      \"GET /users/{username}/packages/{package_type}/{package_name}\"\n    ],\n    getPackageVersionForAuthenticatedUser: [\n      \"GET /user/packages/{package_type}/{package_name}/versions/{package_version_id}\"\n    ],\n    getPackageVersionForOrganization: [\n      \"GET /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}\"\n    ],\n    getPackageVersionForUser: [\n      \"GET /users/{username}/packages/{package_type}/{package_name}/versions/{package_version_id}\"\n    ],\n    listDockerMigrationConflictingPackagesForAuthenticatedUser: [\n      \"GET /user/docker/conflicts\"\n    ],\n    listDockerMigrationConflictingPackagesForOrganization: [\n      \"GET /orgs/{org}/docker/conflicts\"\n    ],\n    listDockerMigrationConflictingPackagesForUser: [\n      \"GET /users/{username}/docker/conflicts\"\n    ],\n    listPackagesForAuthenticatedUser: [\"GET /user/packages\"],\n    listPackagesForOrganization: [\"GET /orgs/{org}/packages\"],\n    listPackagesForUser: [\"GET /users/{username}/packages\"],\n    restorePackageForAuthenticatedUser: [\n      \"POST /user/packages/{package_type}/{package_name}/restore{?token}\"\n    ],\n    restorePackageForOrg: [\n      \"POST /orgs/{org}/packages/{package_type}/{package_name}/restore{?token}\"\n    ],\n    restorePackageForUser: [\n      \"POST /users/{username}/packages/{package_type}/{package_name}/restore{?token}\"\n    ],\n    restorePackageVersionForAuthenticatedUser: [\n      \"POST /user/packages/{package_type}/{package_name}/versions/{package_version_id}/restore\"\n    ],\n    restorePackageVersionForOrg: [\n      \"POST /orgs/{org}/packages/{package_type}/{package_name}/versions/{package_version_id}/restore\"\n    ],\n    restorePackageVersionForUser: [\n      \"POST /users/{username}/packages/{package_type}/{package_name}/versions/{package_version_id}/restore\"\n    ]\n  },\n  projects: {\n    addCollaborator: [\"PUT /projects/{project_id}/collaborators/{username}\"],\n    createCard: [\"POST /projects/columns/{column_id}/cards\"],\n    createColumn: [\"POST /projects/{project_id}/columns\"],\n    createForAuthenticatedUser: [\"POST /user/projects\"],\n    createForOrg: [\"POST /orgs/{org}/projects\"],\n    createForRepo: [\"POST /repos/{owner}/{repo}/projects\"],\n    delete: [\"DELETE /projects/{project_id}\"],\n    deleteCard: [\"DELETE /projects/columns/cards/{card_id}\"],\n    deleteColumn: [\"DELETE /projects/columns/{column_id}\"],\n    get: [\"GET /projects/{project_id}\"],\n    getCard: [\"GET /projects/columns/cards/{card_id}\"],\n    getColumn: [\"GET /projects/columns/{column_id}\"],\n    getPermissionForUser: [\n      \"GET /projects/{project_id}/collaborators/{username}/permission\"\n    ],\n    listCards: [\"GET /projects/columns/{column_id}/cards\"],\n    listCollaborators: [\"GET /projects/{project_id}/collaborators\"],\n    listColumns: [\"GET /projects/{project_id}/columns\"],\n    listForOrg: [\"GET /orgs/{org}/projects\"],\n    listForRepo: [\"GET /repos/{owner}/{repo}/projects\"],\n    listForUser: [\"GET /users/{username}/projects\"],\n    moveCard: [\"POST /projects/columns/cards/{card_id}/moves\"],\n    moveColumn: [\"POST /projects/columns/{column_id}/moves\"],\n    removeCollaborator: [\n      \"DELETE /projects/{project_id}/collaborators/{username}\"\n    ],\n    update: [\"PATCH /projects/{project_id}\"],\n    updateCard: [\"PATCH /projects/columns/cards/{card_id}\"],\n    updateColumn: [\"PATCH /projects/columns/{column_id}\"]\n  },\n  pulls: {\n    checkIfMerged: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/merge\"],\n    create: [\"POST /repos/{owner}/{repo}/pulls\"],\n    createReplyForReviewComment: [\n      \"POST /repos/{owner}/{repo}/pulls/{pull_number}/comments/{comment_id}/replies\"\n    ],\n    createReview: [\"POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews\"],\n    createReviewComment: [\n      \"POST /repos/{owner}/{repo}/pulls/{pull_number}/comments\"\n    ],\n    deletePendingReview: [\n      \"DELETE /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}\"\n    ],\n    deleteReviewComment: [\n      \"DELETE /repos/{owner}/{repo}/pulls/comments/{comment_id}\"\n    ],\n    dismissReview: [\n      \"PUT /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/dismissals\"\n    ],\n    get: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}\"],\n    getReview: [\n      \"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}\"\n    ],\n    getReviewComment: [\"GET /repos/{owner}/{repo}/pulls/comments/{comment_id}\"],\n    list: [\"GET /repos/{owner}/{repo}/pulls\"],\n    listCommentsForReview: [\n      \"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/comments\"\n    ],\n    listCommits: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/commits\"],\n    listFiles: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/files\"],\n    listRequestedReviewers: [\n      \"GET /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers\"\n    ],\n    listReviewComments: [\n      \"GET /repos/{owner}/{repo}/pulls/{pull_number}/comments\"\n    ],\n    listReviewCommentsForRepo: [\"GET /repos/{owner}/{repo}/pulls/comments\"],\n    listReviews: [\"GET /repos/{owner}/{repo}/pulls/{pull_number}/reviews\"],\n    merge: [\"PUT /repos/{owner}/{repo}/pulls/{pull_number}/merge\"],\n    removeRequestedReviewers: [\n      \"DELETE /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers\"\n    ],\n    requestReviewers: [\n      \"POST /repos/{owner}/{repo}/pulls/{pull_number}/requested_reviewers\"\n    ],\n    submitReview: [\n      \"POST /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}/events\"\n    ],\n    update: [\"PATCH /repos/{owner}/{repo}/pulls/{pull_number}\"],\n    updateBranch: [\n      \"PUT /repos/{owner}/{repo}/pulls/{pull_number}/update-branch\"\n    ],\n    updateReview: [\n      \"PUT /repos/{owner}/{repo}/pulls/{pull_number}/reviews/{review_id}\"\n    ],\n    updateReviewComment: [\n      \"PATCH /repos/{owner}/{repo}/pulls/comments/{comment_id}\"\n    ]\n  },\n  rateLimit: { get: [\"GET /rate_limit\"] },\n  reactions: {\n    createForCommitComment: [\n      \"POST /repos/{owner}/{repo}/comments/{comment_id}/reactions\"\n    ],\n    createForIssue: [\n      \"POST /repos/{owner}/{repo}/issues/{issue_number}/reactions\"\n    ],\n    createForIssueComment: [\n      \"POST /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions\"\n    ],\n    createForPullRequestReviewComment: [\n      \"POST /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions\"\n    ],\n    createForRelease: [\n      \"POST /repos/{owner}/{repo}/releases/{release_id}/reactions\"\n    ],\n    createForTeamDiscussionCommentInOrg: [\n      \"POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions\"\n    ],\n    createForTeamDiscussionInOrg: [\n      \"POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions\"\n    ],\n    deleteForCommitComment: [\n      \"DELETE /repos/{owner}/{repo}/comments/{comment_id}/reactions/{reaction_id}\"\n    ],\n    deleteForIssue: [\n      \"DELETE /repos/{owner}/{repo}/issues/{issue_number}/reactions/{reaction_id}\"\n    ],\n    deleteForIssueComment: [\n      \"DELETE /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions/{reaction_id}\"\n    ],\n    deleteForPullRequestComment: [\n      \"DELETE /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions/{reaction_id}\"\n    ],\n    deleteForRelease: [\n      \"DELETE /repos/{owner}/{repo}/releases/{release_id}/reactions/{reaction_id}\"\n    ],\n    deleteForTeamDiscussion: [\n      \"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions/{reaction_id}\"\n    ],\n    deleteForTeamDiscussionComment: [\n      \"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions/{reaction_id}\"\n    ],\n    listForCommitComment: [\n      \"GET /repos/{owner}/{repo}/comments/{comment_id}/reactions\"\n    ],\n    listForIssue: [\"GET /repos/{owner}/{repo}/issues/{issue_number}/reactions\"],\n    listForIssueComment: [\n      \"GET /repos/{owner}/{repo}/issues/comments/{comment_id}/reactions\"\n    ],\n    listForPullRequestReviewComment: [\n      \"GET /repos/{owner}/{repo}/pulls/comments/{comment_id}/reactions\"\n    ],\n    listForRelease: [\n      \"GET /repos/{owner}/{repo}/releases/{release_id}/reactions\"\n    ],\n    listForTeamDiscussionCommentInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}/reactions\"\n    ],\n    listForTeamDiscussionInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/reactions\"\n    ]\n  },\n  repos: {\n    acceptInvitation: [\n      \"PATCH /user/repository_invitations/{invitation_id}\",\n      {},\n      { renamed: [\"repos\", \"acceptInvitationForAuthenticatedUser\"] }\n    ],\n    acceptInvitationForAuthenticatedUser: [\n      \"PATCH /user/repository_invitations/{invitation_id}\"\n    ],\n    addAppAccessRestrictions: [\n      \"POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\",\n      {},\n      { mapToData: \"apps\" }\n    ],\n    addCollaborator: [\"PUT /repos/{owner}/{repo}/collaborators/{username}\"],\n    addStatusCheckContexts: [\n      \"POST /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\",\n      {},\n      { mapToData: \"contexts\" }\n    ],\n    addTeamAccessRestrictions: [\n      \"POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\",\n      {},\n      { mapToData: \"teams\" }\n    ],\n    addUserAccessRestrictions: [\n      \"POST /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\",\n      {},\n      { mapToData: \"users\" }\n    ],\n    cancelPagesDeployment: [\n      \"POST /repos/{owner}/{repo}/pages/deployments/{pages_deployment_id}/cancel\"\n    ],\n    checkAutomatedSecurityFixes: [\n      \"GET /repos/{owner}/{repo}/automated-security-fixes\"\n    ],\n    checkCollaborator: [\"GET /repos/{owner}/{repo}/collaborators/{username}\"],\n    checkVulnerabilityAlerts: [\n      \"GET /repos/{owner}/{repo}/vulnerability-alerts\"\n    ],\n    codeownersErrors: [\"GET /repos/{owner}/{repo}/codeowners/errors\"],\n    compareCommits: [\"GET /repos/{owner}/{repo}/compare/{base}...{head}\"],\n    compareCommitsWithBasehead: [\n      \"GET /repos/{owner}/{repo}/compare/{basehead}\"\n    ],\n    createAutolink: [\"POST /repos/{owner}/{repo}/autolinks\"],\n    createCommitComment: [\n      \"POST /repos/{owner}/{repo}/commits/{commit_sha}/comments\"\n    ],\n    createCommitSignatureProtection: [\n      \"POST /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures\"\n    ],\n    createCommitStatus: [\"POST /repos/{owner}/{repo}/statuses/{sha}\"],\n    createDeployKey: [\"POST /repos/{owner}/{repo}/keys\"],\n    createDeployment: [\"POST /repos/{owner}/{repo}/deployments\"],\n    createDeploymentBranchPolicy: [\n      \"POST /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies\"\n    ],\n    createDeploymentProtectionRule: [\n      \"POST /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules\"\n    ],\n    createDeploymentStatus: [\n      \"POST /repos/{owner}/{repo}/deployments/{deployment_id}/statuses\"\n    ],\n    createDispatchEvent: [\"POST /repos/{owner}/{repo}/dispatches\"],\n    createForAuthenticatedUser: [\"POST /user/repos\"],\n    createFork: [\"POST /repos/{owner}/{repo}/forks\"],\n    createInOrg: [\"POST /orgs/{org}/repos\"],\n    createOrUpdateCustomPropertiesValues: [\n      \"PATCH /repos/{owner}/{repo}/properties/values\"\n    ],\n    createOrUpdateEnvironment: [\n      \"PUT /repos/{owner}/{repo}/environments/{environment_name}\"\n    ],\n    createOrUpdateFileContents: [\"PUT /repos/{owner}/{repo}/contents/{path}\"],\n    createOrgRuleset: [\"POST /orgs/{org}/rulesets\"],\n    createPagesDeployment: [\"POST /repos/{owner}/{repo}/pages/deployments\"],\n    createPagesSite: [\"POST /repos/{owner}/{repo}/pages\"],\n    createRelease: [\"POST /repos/{owner}/{repo}/releases\"],\n    createRepoRuleset: [\"POST /repos/{owner}/{repo}/rulesets\"],\n    createTagProtection: [\"POST /repos/{owner}/{repo}/tags/protection\"],\n    createUsingTemplate: [\n      \"POST /repos/{template_owner}/{template_repo}/generate\"\n    ],\n    createWebhook: [\"POST /repos/{owner}/{repo}/hooks\"],\n    declineInvitation: [\n      \"DELETE /user/repository_invitations/{invitation_id}\",\n      {},\n      { renamed: [\"repos\", \"declineInvitationForAuthenticatedUser\"] }\n    ],\n    declineInvitationForAuthenticatedUser: [\n      \"DELETE /user/repository_invitations/{invitation_id}\"\n    ],\n    delete: [\"DELETE /repos/{owner}/{repo}\"],\n    deleteAccessRestrictions: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions\"\n    ],\n    deleteAdminBranchProtection: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins\"\n    ],\n    deleteAnEnvironment: [\n      \"DELETE /repos/{owner}/{repo}/environments/{environment_name}\"\n    ],\n    deleteAutolink: [\"DELETE /repos/{owner}/{repo}/autolinks/{autolink_id}\"],\n    deleteBranchProtection: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection\"\n    ],\n    deleteCommitComment: [\"DELETE /repos/{owner}/{repo}/comments/{comment_id}\"],\n    deleteCommitSignatureProtection: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures\"\n    ],\n    deleteDeployKey: [\"DELETE /repos/{owner}/{repo}/keys/{key_id}\"],\n    deleteDeployment: [\n      \"DELETE /repos/{owner}/{repo}/deployments/{deployment_id}\"\n    ],\n    deleteDeploymentBranchPolicy: [\n      \"DELETE /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies/{branch_policy_id}\"\n    ],\n    deleteFile: [\"DELETE /repos/{owner}/{repo}/contents/{path}\"],\n    deleteInvitation: [\n      \"DELETE /repos/{owner}/{repo}/invitations/{invitation_id}\"\n    ],\n    deleteOrgRuleset: [\"DELETE /orgs/{org}/rulesets/{ruleset_id}\"],\n    deletePagesSite: [\"DELETE /repos/{owner}/{repo}/pages\"],\n    deletePullRequestReviewProtection: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews\"\n    ],\n    deleteRelease: [\"DELETE /repos/{owner}/{repo}/releases/{release_id}\"],\n    deleteReleaseAsset: [\n      \"DELETE /repos/{owner}/{repo}/releases/assets/{asset_id}\"\n    ],\n    deleteRepoRuleset: [\"DELETE /repos/{owner}/{repo}/rulesets/{ruleset_id}\"],\n    deleteTagProtection: [\n      \"DELETE /repos/{owner}/{repo}/tags/protection/{tag_protection_id}\"\n    ],\n    deleteWebhook: [\"DELETE /repos/{owner}/{repo}/hooks/{hook_id}\"],\n    disableAutomatedSecurityFixes: [\n      \"DELETE /repos/{owner}/{repo}/automated-security-fixes\"\n    ],\n    disableDeploymentProtectionRule: [\n      \"DELETE /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/{protection_rule_id}\"\n    ],\n    disablePrivateVulnerabilityReporting: [\n      \"DELETE /repos/{owner}/{repo}/private-vulnerability-reporting\"\n    ],\n    disableVulnerabilityAlerts: [\n      \"DELETE /repos/{owner}/{repo}/vulnerability-alerts\"\n    ],\n    downloadArchive: [\n      \"GET /repos/{owner}/{repo}/zipball/{ref}\",\n      {},\n      { renamed: [\"repos\", \"downloadZipballArchive\"] }\n    ],\n    downloadTarballArchive: [\"GET /repos/{owner}/{repo}/tarball/{ref}\"],\n    downloadZipballArchive: [\"GET /repos/{owner}/{repo}/zipball/{ref}\"],\n    enableAutomatedSecurityFixes: [\n      \"PUT /repos/{owner}/{repo}/automated-security-fixes\"\n    ],\n    enablePrivateVulnerabilityReporting: [\n      \"PUT /repos/{owner}/{repo}/private-vulnerability-reporting\"\n    ],\n    enableVulnerabilityAlerts: [\n      \"PUT /repos/{owner}/{repo}/vulnerability-alerts\"\n    ],\n    generateReleaseNotes: [\n      \"POST /repos/{owner}/{repo}/releases/generate-notes\"\n    ],\n    get: [\"GET /repos/{owner}/{repo}\"],\n    getAccessRestrictions: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions\"\n    ],\n    getAdminBranchProtection: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins\"\n    ],\n    getAllDeploymentProtectionRules: [\n      \"GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules\"\n    ],\n    getAllEnvironments: [\"GET /repos/{owner}/{repo}/environments\"],\n    getAllStatusCheckContexts: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\"\n    ],\n    getAllTopics: [\"GET /repos/{owner}/{repo}/topics\"],\n    getAppsWithAccessToProtectedBranch: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\"\n    ],\n    getAutolink: [\"GET /repos/{owner}/{repo}/autolinks/{autolink_id}\"],\n    getBranch: [\"GET /repos/{owner}/{repo}/branches/{branch}\"],\n    getBranchProtection: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection\"\n    ],\n    getBranchRules: [\"GET /repos/{owner}/{repo}/rules/branches/{branch}\"],\n    getClones: [\"GET /repos/{owner}/{repo}/traffic/clones\"],\n    getCodeFrequencyStats: [\"GET /repos/{owner}/{repo}/stats/code_frequency\"],\n    getCollaboratorPermissionLevel: [\n      \"GET /repos/{owner}/{repo}/collaborators/{username}/permission\"\n    ],\n    getCombinedStatusForRef: [\"GET /repos/{owner}/{repo}/commits/{ref}/status\"],\n    getCommit: [\"GET /repos/{owner}/{repo}/commits/{ref}\"],\n    getCommitActivityStats: [\"GET /repos/{owner}/{repo}/stats/commit_activity\"],\n    getCommitComment: [\"GET /repos/{owner}/{repo}/comments/{comment_id}\"],\n    getCommitSignatureProtection: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_signatures\"\n    ],\n    getCommunityProfileMetrics: [\"GET /repos/{owner}/{repo}/community/profile\"],\n    getContent: [\"GET /repos/{owner}/{repo}/contents/{path}\"],\n    getContributorsStats: [\"GET /repos/{owner}/{repo}/stats/contributors\"],\n    getCustomDeploymentProtectionRule: [\n      \"GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/{protection_rule_id}\"\n    ],\n    getCustomPropertiesValues: [\"GET /repos/{owner}/{repo}/properties/values\"],\n    getDeployKey: [\"GET /repos/{owner}/{repo}/keys/{key_id}\"],\n    getDeployment: [\"GET /repos/{owner}/{repo}/deployments/{deployment_id}\"],\n    getDeploymentBranchPolicy: [\n      \"GET /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies/{branch_policy_id}\"\n    ],\n    getDeploymentStatus: [\n      \"GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses/{status_id}\"\n    ],\n    getEnvironment: [\n      \"GET /repos/{owner}/{repo}/environments/{environment_name}\"\n    ],\n    getLatestPagesBuild: [\"GET /repos/{owner}/{repo}/pages/builds/latest\"],\n    getLatestRelease: [\"GET /repos/{owner}/{repo}/releases/latest\"],\n    getOrgRuleSuite: [\"GET /orgs/{org}/rulesets/rule-suites/{rule_suite_id}\"],\n    getOrgRuleSuites: [\"GET /orgs/{org}/rulesets/rule-suites\"],\n    getOrgRuleset: [\"GET /orgs/{org}/rulesets/{ruleset_id}\"],\n    getOrgRulesets: [\"GET /orgs/{org}/rulesets\"],\n    getPages: [\"GET /repos/{owner}/{repo}/pages\"],\n    getPagesBuild: [\"GET /repos/{owner}/{repo}/pages/builds/{build_id}\"],\n    getPagesDeployment: [\n      \"GET /repos/{owner}/{repo}/pages/deployments/{pages_deployment_id}\"\n    ],\n    getPagesHealthCheck: [\"GET /repos/{owner}/{repo}/pages/health\"],\n    getParticipationStats: [\"GET /repos/{owner}/{repo}/stats/participation\"],\n    getPullRequestReviewProtection: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews\"\n    ],\n    getPunchCardStats: [\"GET /repos/{owner}/{repo}/stats/punch_card\"],\n    getReadme: [\"GET /repos/{owner}/{repo}/readme\"],\n    getReadmeInDirectory: [\"GET /repos/{owner}/{repo}/readme/{dir}\"],\n    getRelease: [\"GET /repos/{owner}/{repo}/releases/{release_id}\"],\n    getReleaseAsset: [\"GET /repos/{owner}/{repo}/releases/assets/{asset_id}\"],\n    getReleaseByTag: [\"GET /repos/{owner}/{repo}/releases/tags/{tag}\"],\n    getRepoRuleSuite: [\n      \"GET /repos/{owner}/{repo}/rulesets/rule-suites/{rule_suite_id}\"\n    ],\n    getRepoRuleSuites: [\"GET /repos/{owner}/{repo}/rulesets/rule-suites\"],\n    getRepoRuleset: [\"GET /repos/{owner}/{repo}/rulesets/{ruleset_id}\"],\n    getRepoRulesets: [\"GET /repos/{owner}/{repo}/rulesets\"],\n    getStatusChecksProtection: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\"\n    ],\n    getTeamsWithAccessToProtectedBranch: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\"\n    ],\n    getTopPaths: [\"GET /repos/{owner}/{repo}/traffic/popular/paths\"],\n    getTopReferrers: [\"GET /repos/{owner}/{repo}/traffic/popular/referrers\"],\n    getUsersWithAccessToProtectedBranch: [\n      \"GET /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\"\n    ],\n    getViews: [\"GET /repos/{owner}/{repo}/traffic/views\"],\n    getWebhook: [\"GET /repos/{owner}/{repo}/hooks/{hook_id}\"],\n    getWebhookConfigForRepo: [\n      \"GET /repos/{owner}/{repo}/hooks/{hook_id}/config\"\n    ],\n    getWebhookDelivery: [\n      \"GET /repos/{owner}/{repo}/hooks/{hook_id}/deliveries/{delivery_id}\"\n    ],\n    listActivities: [\"GET /repos/{owner}/{repo}/activity\"],\n    listAutolinks: [\"GET /repos/{owner}/{repo}/autolinks\"],\n    listBranches: [\"GET /repos/{owner}/{repo}/branches\"],\n    listBranchesForHeadCommit: [\n      \"GET /repos/{owner}/{repo}/commits/{commit_sha}/branches-where-head\"\n    ],\n    listCollaborators: [\"GET /repos/{owner}/{repo}/collaborators\"],\n    listCommentsForCommit: [\n      \"GET /repos/{owner}/{repo}/commits/{commit_sha}/comments\"\n    ],\n    listCommitCommentsForRepo: [\"GET /repos/{owner}/{repo}/comments\"],\n    listCommitStatusesForRef: [\n      \"GET /repos/{owner}/{repo}/commits/{ref}/statuses\"\n    ],\n    listCommits: [\"GET /repos/{owner}/{repo}/commits\"],\n    listContributors: [\"GET /repos/{owner}/{repo}/contributors\"],\n    listCustomDeploymentRuleIntegrations: [\n      \"GET /repos/{owner}/{repo}/environments/{environment_name}/deployment_protection_rules/apps\"\n    ],\n    listDeployKeys: [\"GET /repos/{owner}/{repo}/keys\"],\n    listDeploymentBranchPolicies: [\n      \"GET /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies\"\n    ],\n    listDeploymentStatuses: [\n      \"GET /repos/{owner}/{repo}/deployments/{deployment_id}/statuses\"\n    ],\n    listDeployments: [\"GET /repos/{owner}/{repo}/deployments\"],\n    listForAuthenticatedUser: [\"GET /user/repos\"],\n    listForOrg: [\"GET /orgs/{org}/repos\"],\n    listForUser: [\"GET /users/{username}/repos\"],\n    listForks: [\"GET /repos/{owner}/{repo}/forks\"],\n    listInvitations: [\"GET /repos/{owner}/{repo}/invitations\"],\n    listInvitationsForAuthenticatedUser: [\"GET /user/repository_invitations\"],\n    listLanguages: [\"GET /repos/{owner}/{repo}/languages\"],\n    listPagesBuilds: [\"GET /repos/{owner}/{repo}/pages/builds\"],\n    listPublic: [\"GET /repositories\"],\n    listPullRequestsAssociatedWithCommit: [\n      \"GET /repos/{owner}/{repo}/commits/{commit_sha}/pulls\"\n    ],\n    listReleaseAssets: [\n      \"GET /repos/{owner}/{repo}/releases/{release_id}/assets\"\n    ],\n    listReleases: [\"GET /repos/{owner}/{repo}/releases\"],\n    listTagProtection: [\"GET /repos/{owner}/{repo}/tags/protection\"],\n    listTags: [\"GET /repos/{owner}/{repo}/tags\"],\n    listTeams: [\"GET /repos/{owner}/{repo}/teams\"],\n    listWebhookDeliveries: [\n      \"GET /repos/{owner}/{repo}/hooks/{hook_id}/deliveries\"\n    ],\n    listWebhooks: [\"GET /repos/{owner}/{repo}/hooks\"],\n    merge: [\"POST /repos/{owner}/{repo}/merges\"],\n    mergeUpstream: [\"POST /repos/{owner}/{repo}/merge-upstream\"],\n    pingWebhook: [\"POST /repos/{owner}/{repo}/hooks/{hook_id}/pings\"],\n    redeliverWebhookDelivery: [\n      \"POST /repos/{owner}/{repo}/hooks/{hook_id}/deliveries/{delivery_id}/attempts\"\n    ],\n    removeAppAccessRestrictions: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\",\n      {},\n      { mapToData: \"apps\" }\n    ],\n    removeCollaborator: [\n      \"DELETE /repos/{owner}/{repo}/collaborators/{username}\"\n    ],\n    removeStatusCheckContexts: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\",\n      {},\n      { mapToData: \"contexts\" }\n    ],\n    removeStatusCheckProtection: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\"\n    ],\n    removeTeamAccessRestrictions: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\",\n      {},\n      { mapToData: \"teams\" }\n    ],\n    removeUserAccessRestrictions: [\n      \"DELETE /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\",\n      {},\n      { mapToData: \"users\" }\n    ],\n    renameBranch: [\"POST /repos/{owner}/{repo}/branches/{branch}/rename\"],\n    replaceAllTopics: [\"PUT /repos/{owner}/{repo}/topics\"],\n    requestPagesBuild: [\"POST /repos/{owner}/{repo}/pages/builds\"],\n    setAdminBranchProtection: [\n      \"POST /repos/{owner}/{repo}/branches/{branch}/protection/enforce_admins\"\n    ],\n    setAppAccessRestrictions: [\n      \"PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/apps\",\n      {},\n      { mapToData: \"apps\" }\n    ],\n    setStatusCheckContexts: [\n      \"PUT /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks/contexts\",\n      {},\n      { mapToData: \"contexts\" }\n    ],\n    setTeamAccessRestrictions: [\n      \"PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/teams\",\n      {},\n      { mapToData: \"teams\" }\n    ],\n    setUserAccessRestrictions: [\n      \"PUT /repos/{owner}/{repo}/branches/{branch}/protection/restrictions/users\",\n      {},\n      { mapToData: \"users\" }\n    ],\n    testPushWebhook: [\"POST /repos/{owner}/{repo}/hooks/{hook_id}/tests\"],\n    transfer: [\"POST /repos/{owner}/{repo}/transfer\"],\n    update: [\"PATCH /repos/{owner}/{repo}\"],\n    updateBranchProtection: [\n      \"PUT /repos/{owner}/{repo}/branches/{branch}/protection\"\n    ],\n    updateCommitComment: [\"PATCH /repos/{owner}/{repo}/comments/{comment_id}\"],\n    updateDeploymentBranchPolicy: [\n      \"PUT /repos/{owner}/{repo}/environments/{environment_name}/deployment-branch-policies/{branch_policy_id}\"\n    ],\n    updateInformationAboutPagesSite: [\"PUT /repos/{owner}/{repo}/pages\"],\n    updateInvitation: [\n      \"PATCH /repos/{owner}/{repo}/invitations/{invitation_id}\"\n    ],\n    updateOrgRuleset: [\"PUT /orgs/{org}/rulesets/{ruleset_id}\"],\n    updatePullRequestReviewProtection: [\n      \"PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_pull_request_reviews\"\n    ],\n    updateRelease: [\"PATCH /repos/{owner}/{repo}/releases/{release_id}\"],\n    updateReleaseAsset: [\n      \"PATCH /repos/{owner}/{repo}/releases/assets/{asset_id}\"\n    ],\n    updateRepoRuleset: [\"PUT /repos/{owner}/{repo}/rulesets/{ruleset_id}\"],\n    updateStatusCheckPotection: [\n      \"PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\",\n      {},\n      { renamed: [\"repos\", \"updateStatusCheckProtection\"] }\n    ],\n    updateStatusCheckProtection: [\n      \"PATCH /repos/{owner}/{repo}/branches/{branch}/protection/required_status_checks\"\n    ],\n    updateWebhook: [\"PATCH /repos/{owner}/{repo}/hooks/{hook_id}\"],\n    updateWebhookConfigForRepo: [\n      \"PATCH /repos/{owner}/{repo}/hooks/{hook_id}/config\"\n    ],\n    uploadReleaseAsset: [\n      \"POST /repos/{owner}/{repo}/releases/{release_id}/assets{?name,label}\",\n      { baseUrl: \"https://uploads.github.com\" }\n    ]\n  },\n  search: {\n    code: [\"GET /search/code\"],\n    commits: [\"GET /search/commits\"],\n    issuesAndPullRequests: [\"GET /search/issues\"],\n    labels: [\"GET /search/labels\"],\n    repos: [\"GET /search/repositories\"],\n    topics: [\"GET /search/topics\"],\n    users: [\"GET /search/users\"]\n  },\n  secretScanning: {\n    getAlert: [\n      \"GET /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}\"\n    ],\n    listAlertsForEnterprise: [\n      \"GET /enterprises/{enterprise}/secret-scanning/alerts\"\n    ],\n    listAlertsForOrg: [\"GET /orgs/{org}/secret-scanning/alerts\"],\n    listAlertsForRepo: [\"GET /repos/{owner}/{repo}/secret-scanning/alerts\"],\n    listLocationsForAlert: [\n      \"GET /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}/locations\"\n    ],\n    updateAlert: [\n      \"PATCH /repos/{owner}/{repo}/secret-scanning/alerts/{alert_number}\"\n    ]\n  },\n  securityAdvisories: {\n    createFork: [\n      \"POST /repos/{owner}/{repo}/security-advisories/{ghsa_id}/forks\"\n    ],\n    createPrivateVulnerabilityReport: [\n      \"POST /repos/{owner}/{repo}/security-advisories/reports\"\n    ],\n    createRepositoryAdvisory: [\n      \"POST /repos/{owner}/{repo}/security-advisories\"\n    ],\n    createRepositoryAdvisoryCveRequest: [\n      \"POST /repos/{owner}/{repo}/security-advisories/{ghsa_id}/cve\"\n    ],\n    getGlobalAdvisory: [\"GET /advisories/{ghsa_id}\"],\n    getRepositoryAdvisory: [\n      \"GET /repos/{owner}/{repo}/security-advisories/{ghsa_id}\"\n    ],\n    listGlobalAdvisories: [\"GET /advisories\"],\n    listOrgRepositoryAdvisories: [\"GET /orgs/{org}/security-advisories\"],\n    listRepositoryAdvisories: [\"GET /repos/{owner}/{repo}/security-advisories\"],\n    updateRepositoryAdvisory: [\n      \"PATCH /repos/{owner}/{repo}/security-advisories/{ghsa_id}\"\n    ]\n  },\n  teams: {\n    addOrUpdateMembershipForUserInOrg: [\n      \"PUT /orgs/{org}/teams/{team_slug}/memberships/{username}\"\n    ],\n    addOrUpdateProjectPermissionsInOrg: [\n      \"PUT /orgs/{org}/teams/{team_slug}/projects/{project_id}\"\n    ],\n    addOrUpdateRepoPermissionsInOrg: [\n      \"PUT /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}\"\n    ],\n    checkPermissionsForProjectInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/projects/{project_id}\"\n    ],\n    checkPermissionsForRepoInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}\"\n    ],\n    create: [\"POST /orgs/{org}/teams\"],\n    createDiscussionCommentInOrg: [\n      \"POST /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments\"\n    ],\n    createDiscussionInOrg: [\"POST /orgs/{org}/teams/{team_slug}/discussions\"],\n    deleteDiscussionCommentInOrg: [\n      \"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}\"\n    ],\n    deleteDiscussionInOrg: [\n      \"DELETE /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}\"\n    ],\n    deleteInOrg: [\"DELETE /orgs/{org}/teams/{team_slug}\"],\n    getByName: [\"GET /orgs/{org}/teams/{team_slug}\"],\n    getDiscussionCommentInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}\"\n    ],\n    getDiscussionInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}\"\n    ],\n    getMembershipForUserInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/memberships/{username}\"\n    ],\n    list: [\"GET /orgs/{org}/teams\"],\n    listChildInOrg: [\"GET /orgs/{org}/teams/{team_slug}/teams\"],\n    listDiscussionCommentsInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments\"\n    ],\n    listDiscussionsInOrg: [\"GET /orgs/{org}/teams/{team_slug}/discussions\"],\n    listForAuthenticatedUser: [\"GET /user/teams\"],\n    listMembersInOrg: [\"GET /orgs/{org}/teams/{team_slug}/members\"],\n    listPendingInvitationsInOrg: [\n      \"GET /orgs/{org}/teams/{team_slug}/invitations\"\n    ],\n    listProjectsInOrg: [\"GET /orgs/{org}/teams/{team_slug}/projects\"],\n    listReposInOrg: [\"GET /orgs/{org}/teams/{team_slug}/repos\"],\n    removeMembershipForUserInOrg: [\n      \"DELETE /orgs/{org}/teams/{team_slug}/memberships/{username}\"\n    ],\n    removeProjectInOrg: [\n      \"DELETE /orgs/{org}/teams/{team_slug}/projects/{project_id}\"\n    ],\n    removeRepoInOrg: [\n      \"DELETE /orgs/{org}/teams/{team_slug}/repos/{owner}/{repo}\"\n    ],\n    updateDiscussionCommentInOrg: [\n      \"PATCH /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}/comments/{comment_number}\"\n    ],\n    updateDiscussionInOrg: [\n      \"PATCH /orgs/{org}/teams/{team_slug}/discussions/{discussion_number}\"\n    ],\n    updateInOrg: [\"PATCH /orgs/{org}/teams/{team_slug}\"]\n  },\n  users: {\n    addEmailForAuthenticated: [\n      \"POST /user/emails\",\n      {},\n      { renamed: [\"users\", \"addEmailForAuthenticatedUser\"] }\n    ],\n    addEmailForAuthenticatedUser: [\"POST /user/emails\"],\n    addSocialAccountForAuthenticatedUser: [\"POST /user/social_accounts\"],\n    block: [\"PUT /user/blocks/{username}\"],\n    checkBlocked: [\"GET /user/blocks/{username}\"],\n    checkFollowingForUser: [\"GET /users/{username}/following/{target_user}\"],\n    checkPersonIsFollowedByAuthenticated: [\"GET /user/following/{username}\"],\n    createGpgKeyForAuthenticated: [\n      \"POST /user/gpg_keys\",\n      {},\n      { renamed: [\"users\", \"createGpgKeyForAuthenticatedUser\"] }\n    ],\n    createGpgKeyForAuthenticatedUser: [\"POST /user/gpg_keys\"],\n    createPublicSshKeyForAuthenticated: [\n      \"POST /user/keys\",\n      {},\n      { renamed: [\"users\", \"createPublicSshKeyForAuthenticatedUser\"] }\n    ],\n    createPublicSshKeyForAuthenticatedUser: [\"POST /user/keys\"],\n    createSshSigningKeyForAuthenticatedUser: [\"POST /user/ssh_signing_keys\"],\n    deleteEmailForAuthenticated: [\n      \"DELETE /user/emails\",\n      {},\n      { renamed: [\"users\", \"deleteEmailForAuthenticatedUser\"] }\n    ],\n    deleteEmailForAuthenticatedUser: [\"DELETE /user/emails\"],\n    deleteGpgKeyForAuthenticated: [\n      \"DELETE /user/gpg_keys/{gpg_key_id}\",\n      {},\n      { renamed: [\"users\", \"deleteGpgKeyForAuthenticatedUser\"] }\n    ],\n    deleteGpgKeyForAuthenticatedUser: [\"DELETE /user/gpg_keys/{gpg_key_id}\"],\n    deletePublicSshKeyForAuthenticated: [\n      \"DELETE /user/keys/{key_id}\",\n      {},\n      { renamed: [\"users\", \"deletePublicSshKeyForAuthenticatedUser\"] }\n    ],\n    deletePublicSshKeyForAuthenticatedUser: [\"DELETE /user/keys/{key_id}\"],\n    deleteSocialAccountForAuthenticatedUser: [\"DELETE /user/social_accounts\"],\n    deleteSshSigningKeyForAuthenticatedUser: [\n      \"DELETE /user/ssh_signing_keys/{ssh_signing_key_id}\"\n    ],\n    follow: [\"PUT /user/following/{username}\"],\n    getAuthenticated: [\"GET /user\"],\n    getByUsername: [\"GET /users/{username}\"],\n    getContextForUser: [\"GET /users/{username}/hovercard\"],\n    getGpgKeyForAuthenticated: [\n      \"GET /user/gpg_keys/{gpg_key_id}\",\n      {},\n      { renamed: [\"users\", \"getGpgKeyForAuthenticatedUser\"] }\n    ],\n    getGpgKeyForAuthenticatedUser: [\"GET /user/gpg_keys/{gpg_key_id}\"],\n    getPublicSshKeyForAuthenticated: [\n      \"GET /user/keys/{key_id}\",\n      {},\n      { renamed: [\"users\", \"getPublicSshKeyForAuthenticatedUser\"] }\n    ],\n    getPublicSshKeyForAuthenticatedUser: [\"GET /user/keys/{key_id}\"],\n    getSshSigningKeyForAuthenticatedUser: [\n      \"GET /user/ssh_signing_keys/{ssh_signing_key_id}\"\n    ],\n    list: [\"GET /users\"],\n    listBlockedByAuthenticated: [\n      \"GET /user/blocks\",\n      {},\n      { renamed: [\"users\", \"listBlockedByAuthenticatedUser\"] }\n    ],\n    listBlockedByAuthenticatedUser: [\"GET /user/blocks\"],\n    listEmailsForAuthenticated: [\n      \"GET /user/emails\",\n      {},\n      { renamed: [\"users\", \"listEmailsForAuthenticatedUser\"] }\n    ],\n    listEmailsForAuthenticatedUser: [\"GET /user/emails\"],\n    listFollowedByAuthenticated: [\n      \"GET /user/following\",\n      {},\n      { renamed: [\"users\", \"listFollowedByAuthenticatedUser\"] }\n    ],\n    listFollowedByAuthenticatedUser: [\"GET /user/following\"],\n    listFollowersForAuthenticatedUser: [\"GET /user/followers\"],\n    listFollowersForUser: [\"GET /users/{username}/followers\"],\n    listFollowingForUser: [\"GET /users/{username}/following\"],\n    listGpgKeysForAuthenticated: [\n      \"GET /user/gpg_keys\",\n      {},\n      { renamed: [\"users\", \"listGpgKeysForAuthenticatedUser\"] }\n    ],\n    listGpgKeysForAuthenticatedUser: [\"GET /user/gpg_keys\"],\n    listGpgKeysForUser: [\"GET /users/{username}/gpg_keys\"],\n    listPublicEmailsForAuthenticated: [\n      \"GET /user/public_emails\",\n      {},\n      { renamed: [\"users\", \"listPublicEmailsForAuthenticatedUser\"] }\n    ],\n    listPublicEmailsForAuthenticatedUser: [\"GET /user/public_emails\"],\n    listPublicKeysForUser: [\"GET /users/{username}/keys\"],\n    listPublicSshKeysForAuthenticated: [\n      \"GET /user/keys\",\n      {},\n      { renamed: [\"users\", \"listPublicSshKeysForAuthenticatedUser\"] }\n    ],\n    listPublicSshKeysForAuthenticatedUser: [\"GET /user/keys\"],\n    listSocialAccountsForAuthenticatedUser: [\"GET /user/social_accounts\"],\n    listSocialAccountsForUser: [\"GET /users/{username}/social_accounts\"],\n    listSshSigningKeysForAuthenticatedUser: [\"GET /user/ssh_signing_keys\"],\n    listSshSigningKeysForUser: [\"GET /users/{username}/ssh_signing_keys\"],\n    setPrimaryEmailVisibilityForAuthenticated: [\n      \"PATCH /user/email/visibility\",\n      {},\n      { renamed: [\"users\", \"setPrimaryEmailVisibilityForAuthenticatedUser\"] }\n    ],\n    setPrimaryEmailVisibilityForAuthenticatedUser: [\n      \"PATCH /user/email/visibility\"\n    ],\n    unblock: [\"DELETE /user/blocks/{username}\"],\n    unfollow: [\"DELETE /user/following/{username}\"],\n    updateAuthenticated: [\"PATCH /user\"]\n  }\n};\nvar endpoints_default = Endpoints;\n\n// pkg/dist-src/endpoints-to-methods.js\nvar endpointMethodsMap = /* @__PURE__ */ new Map();\nfor (const [scope, endpoints] of Object.entries(endpoints_default)) {\n  for (const [methodName, endpoint] of Object.entries(endpoints)) {\n    const [route, defaults, decorations] = endpoint;\n    const [method, url] = route.split(/ /);\n    const endpointDefaults = Object.assign(\n      {\n        method,\n        url\n      },\n      defaults\n    );\n    if (!endpointMethodsMap.has(scope)) {\n      endpointMethodsMap.set(scope, /* @__PURE__ */ new Map());\n    }\n    endpointMethodsMap.get(scope).set(methodName, {\n      scope,\n      methodName,\n      endpointDefaults,\n      decorations\n    });\n  }\n}\nvar handler = {\n  has({ scope }, methodName) {\n    return endpointMethodsMap.get(scope).has(methodName);\n  },\n  getOwnPropertyDescriptor(target, methodName) {\n    return {\n      value: this.get(target, methodName),\n      // ensures method is in the cache\n      configurable: true,\n      writable: true,\n      enumerable: true\n    };\n  },\n  defineProperty(target, methodName, descriptor) {\n    Object.defineProperty(target.cache, methodName, descriptor);\n    return true;\n  },\n  deleteProperty(target, methodName) {\n    delete target.cache[methodName];\n    return true;\n  },\n  ownKeys({ scope }) {\n    return [...endpointMethodsMap.get(scope).keys()];\n  },\n  set(target, methodName, value) {\n    return target.cache[methodName] = value;\n  },\n  get({ octokit, scope, cache }, methodName) {\n    if (cache[methodName]) {\n      return cache[methodName];\n    }\n    const method = endpointMethodsMap.get(scope).get(methodName);\n    if (!method) {\n      return void 0;\n    }\n    const { endpointDefaults, decorations } = method;\n    if (decorations) {\n      cache[methodName] = decorate(\n        octokit,\n        scope,\n        methodName,\n        endpointDefaults,\n        decorations\n      );\n    } else {\n      cache[methodName] = octokit.request.defaults(endpointDefaults);\n    }\n    return cache[methodName];\n  }\n};\nfunction endpointsToMethods(octokit) {\n  const newMethods = {};\n  for (const scope of endpointMethodsMap.keys()) {\n    newMethods[scope] = new Proxy({ octokit, scope, cache: {} }, handler);\n  }\n  return newMethods;\n}\nfunction decorate(octokit, scope, methodName, defaults, decorations) {\n  const requestWithDefaults = octokit.request.defaults(defaults);\n  function withDecorations(...args) {\n    let options = requestWithDefaults.endpoint.merge(...args);\n    if (decorations.mapToData) {\n      options = Object.assign({}, options, {\n        data: options[decorations.mapToData],\n        [decorations.mapToData]: void 0\n      });\n      return requestWithDefaults(options);\n    }\n    if (decorations.renamed) {\n      const [newScope, newMethodName] = decorations.renamed;\n      octokit.log.warn(\n        `octokit.${scope}.${methodName}() has been renamed to octokit.${newScope}.${newMethodName}()`\n      );\n    }\n    if (decorations.deprecated) {\n      octokit.log.warn(decorations.deprecated);\n    }\n    if (decorations.renamedParameters) {\n      const options2 = requestWithDefaults.endpoint.merge(...args);\n      for (const [name, alias] of Object.entries(\n        decorations.renamedParameters\n      )) {\n        if (name in options2) {\n          octokit.log.warn(\n            `\"${name}\" parameter is deprecated for \"octokit.${scope}.${methodName}()\". Use \"${alias}\" instead`\n          );\n          if (!(alias in options2)) {\n            options2[alias] = options2[name];\n          }\n          delete options2[name];\n        }\n      }\n      return requestWithDefaults(options2);\n    }\n    return requestWithDefaults(...args);\n  }\n  return Object.assign(withDecorations, requestWithDefaults);\n}\n\n// pkg/dist-src/index.js\nfunction restEndpointMethods(octokit) {\n  const api = endpointsToMethods(octokit);\n  return {\n    rest: api\n  };\n}\nrestEndpointMethods.VERSION = VERSION;\nfunction legacyRestEndpointMethods(octokit) {\n  const api = endpointsToMethods(octokit);\n  return {\n    ...api,\n    rest: api\n  };\n}\nlegacyRestEndpointMethods.VERSION = VERSION;\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  legacyRestEndpointMethods,\n  restEndpointMethods\n});\n","\"use strict\";\nvar __create = Object.create;\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __getProtoOf = Object.getPrototypeOf;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(\n  // If the importer is in node compatibility mode or this is not an ESM\n  // file that has been converted to a CommonJS file using a Babel-\n  // compatible transform (i.e. \"__esModule\" has not been set), then set\n  // \"default\" to the CommonJS \"module.exports\" for node compatibility.\n  isNodeMode || !mod || !mod.__esModule ? __defProp(target, \"default\", { value: mod, enumerable: true }) : target,\n  mod\n));\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar dist_src_exports = {};\n__export(dist_src_exports, {\n  RequestError: () => RequestError\n});\nmodule.exports = __toCommonJS(dist_src_exports);\nvar import_deprecation = require(\"deprecation\");\nvar import_once = __toESM(require(\"once\"));\nvar logOnceCode = (0, import_once.default)((deprecation) => console.warn(deprecation));\nvar logOnceHeaders = (0, import_once.default)((deprecation) => console.warn(deprecation));\nvar RequestError = class extends Error {\n  constructor(message, statusCode, options) {\n    super(message);\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n    this.name = \"HttpError\";\n    this.status = statusCode;\n    let headers;\n    if (\"headers\" in options && typeof options.headers !== \"undefined\") {\n      headers = options.headers;\n    }\n    if (\"response\" in options) {\n      this.response = options.response;\n      headers = options.response.headers;\n    }\n    const requestCopy = Object.assign({}, options.request);\n    if (options.request.headers.authorization) {\n      requestCopy.headers = Object.assign({}, options.request.headers, {\n        authorization: options.request.headers.authorization.replace(\n          / .*$/,\n          \" [REDACTED]\"\n        )\n      });\n    }\n    requestCopy.url = requestCopy.url.replace(/\\bclient_secret=\\w+/g, \"client_secret=[REDACTED]\").replace(/\\baccess_token=\\w+/g, \"access_token=[REDACTED]\");\n    this.request = requestCopy;\n    Object.defineProperty(this, \"code\", {\n      get() {\n        logOnceCode(\n          new import_deprecation.Deprecation(\n            \"[@octokit/request-error] `error.code` is deprecated, use `error.status`.\"\n          )\n        );\n        return statusCode;\n      }\n    });\n    Object.defineProperty(this, \"headers\", {\n      get() {\n        logOnceHeaders(\n          new import_deprecation.Deprecation(\n            \"[@octokit/request-error] `error.headers` is deprecated, use `error.response.headers`.\"\n          )\n        );\n        return headers || {};\n      }\n    });\n  }\n};\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  RequestError\n});\n","\"use strict\";\nvar __defProp = Object.defineProperty;\nvar __getOwnPropDesc = Object.getOwnPropertyDescriptor;\nvar __getOwnPropNames = Object.getOwnPropertyNames;\nvar __hasOwnProp = Object.prototype.hasOwnProperty;\nvar __export = (target, all) => {\n  for (var name in all)\n    __defProp(target, name, { get: all[name], enumerable: true });\n};\nvar __copyProps = (to, from, except, desc) => {\n  if (from && typeof from === \"object\" || typeof from === \"function\") {\n    for (let key of __getOwnPropNames(from))\n      if (!__hasOwnProp.call(to, key) && key !== except)\n        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });\n  }\n  return to;\n};\nvar __toCommonJS = (mod) => __copyProps(__defProp({}, \"__esModule\", { value: true }), mod);\n\n// pkg/dist-src/index.js\nvar dist_src_exports = {};\n__export(dist_src_exports, {\n  request: () => request\n});\nmodule.exports = __toCommonJS(dist_src_exports);\nvar import_endpoint = require(\"@octokit/endpoint\");\nvar import_universal_user_agent = require(\"universal-user-agent\");\n\n// pkg/dist-src/version.js\nvar VERSION = \"8.3.1\";\n\n// pkg/dist-src/is-plain-object.js\nfunction isPlainObject(value) {\n  if (typeof value !== \"object\" || value === null)\n    return false;\n  if (Object.prototype.toString.call(value) !== \"[object Object]\")\n    return false;\n  const proto = Object.getPrototypeOf(value);\n  if (proto === null)\n    return true;\n  const Ctor = Object.prototype.hasOwnProperty.call(proto, \"constructor\") && proto.constructor;\n  return typeof Ctor === \"function\" && Ctor instanceof Ctor && Function.prototype.call(Ctor) === Function.prototype.call(value);\n}\n\n// pkg/dist-src/fetch-wrapper.js\nvar import_request_error = require(\"@octokit/request-error\");\n\n// pkg/dist-src/get-buffer-response.js\nfunction getBufferResponse(response) {\n  return response.arrayBuffer();\n}\n\n// pkg/dist-src/fetch-wrapper.js\nfunction fetchWrapper(requestOptions) {\n  var _a, _b, _c;\n  const log = requestOptions.request && requestOptions.request.log ? requestOptions.request.log : console;\n  const parseSuccessResponseBody = ((_a = requestOptions.request) == null ? void 0 : _a.parseSuccessResponseBody) !== false;\n  if (isPlainObject(requestOptions.body) || Array.isArray(requestOptions.body)) {\n    requestOptions.body = JSON.stringify(requestOptions.body);\n  }\n  let headers = {};\n  let status;\n  let url;\n  let { fetch } = globalThis;\n  if ((_b = requestOptions.request) == null ? void 0 : _b.fetch) {\n    fetch = requestOptions.request.fetch;\n  }\n  if (!fetch) {\n    throw new Error(\n      \"fetch is not set. Please pass a fetch implementation as new Octokit({ request: { fetch }}). Learn more at https://github.com/octokit/octokit.js/#fetch-missing\"\n    );\n  }\n  return fetch(requestOptions.url, {\n    method: requestOptions.method,\n    body: requestOptions.body,\n    headers: requestOptions.headers,\n    signal: (_c = requestOptions.request) == null ? void 0 : _c.signal,\n    // duplex must be set if request.body is ReadableStream or Async Iterables.\n    // See https://fetch.spec.whatwg.org/#dom-requestinit-duplex.\n    ...requestOptions.body && { duplex: \"half\" }\n  }).then(async (response) => {\n    url = response.url;\n    status = response.status;\n    for (const keyAndValue of response.headers) {\n      headers[keyAndValue[0]] = keyAndValue[1];\n    }\n    if (\"deprecation\" in headers) {\n      const matches = headers.link && headers.link.match(/<([^>]+)>; rel=\"deprecation\"/);\n      const deprecationLink = matches && matches.pop();\n      log.warn(\n        `[@octokit/request] \"${requestOptions.method} ${requestOptions.url}\" is deprecated. It is scheduled to be removed on ${headers.sunset}${deprecationLink ? `. See ${deprecationLink}` : \"\"}`\n      );\n    }\n    if (status === 204 || status === 205) {\n      return;\n    }\n    if (requestOptions.method === \"HEAD\") {\n      if (status < 400) {\n        return;\n      }\n      throw new import_request_error.RequestError(response.statusText, status, {\n        response: {\n          url,\n          status,\n          headers,\n          data: void 0\n        },\n        request: requestOptions\n      });\n    }\n    if (status === 304) {\n      throw new import_request_error.RequestError(\"Not modified\", status, {\n        response: {\n          url,\n          status,\n          headers,\n          data: await getResponseData(response)\n        },\n        request: requestOptions\n      });\n    }\n    if (status >= 400) {\n      const data = await getResponseData(response);\n      const error = new import_request_error.RequestError(toErrorMessage(data), status, {\n        response: {\n          url,\n          status,\n          headers,\n          data\n        },\n        request: requestOptions\n      });\n      throw error;\n    }\n    return parseSuccessResponseBody ? await getResponseData(response) : response.body;\n  }).then((data) => {\n    return {\n      status,\n      url,\n      headers,\n      data\n    };\n  }).catch((error) => {\n    if (error instanceof import_request_error.RequestError)\n      throw error;\n    else if (error.name === \"AbortError\")\n      throw error;\n    let message = error.message;\n    if (error.name === \"TypeError\" && \"cause\" in error) {\n      if (error.cause instanceof Error) {\n        message = error.cause.message;\n      } else if (typeof error.cause === \"string\") {\n        message = error.cause;\n      }\n    }\n    throw new import_request_error.RequestError(message, 500, {\n      request: requestOptions\n    });\n  });\n}\nasync function getResponseData(response) {\n  const contentType = response.headers.get(\"content-type\");\n  if (/application\\/json/.test(contentType)) {\n    return response.json().catch(() => response.text()).catch(() => \"\");\n  }\n  if (!contentType || /^text\\/|charset=utf-8$/.test(contentType)) {\n    return response.text();\n  }\n  return getBufferResponse(response);\n}\nfunction toErrorMessage(data) {\n  if (typeof data === \"string\")\n    return data;\n  let suffix;\n  if (\"documentation_url\" in data) {\n    suffix = ` - ${data.documentation_url}`;\n  } else {\n    suffix = \"\";\n  }\n  if (\"message\" in data) {\n    if (Array.isArray(data.errors)) {\n      return `${data.message}: ${data.errors.map(JSON.stringify).join(\", \")}${suffix}`;\n    }\n    return `${data.message}${suffix}`;\n  }\n  return `Unknown error: ${JSON.stringify(data)}`;\n}\n\n// pkg/dist-src/with-defaults.js\nfunction withDefaults(oldEndpoint, newDefaults) {\n  const endpoint2 = oldEndpoint.defaults(newDefaults);\n  const newApi = function(route, parameters) {\n    const endpointOptions = endpoint2.merge(route, parameters);\n    if (!endpointOptions.request || !endpointOptions.request.hook) {\n      return fetchWrapper(endpoint2.parse(endpointOptions));\n    }\n    const request2 = (route2, parameters2) => {\n      return fetchWrapper(\n        endpoint2.parse(endpoint2.merge(route2, parameters2))\n      );\n    };\n    Object.assign(request2, {\n      endpoint: endpoint2,\n      defaults: withDefaults.bind(null, endpoint2)\n    });\n    return endpointOptions.request.hook(request2, endpointOptions);\n  };\n  return Object.assign(newApi, {\n    endpoint: endpoint2,\n    defaults: withDefaults.bind(null, endpoint2)\n  });\n}\n\n// pkg/dist-src/index.js\nvar request = withDefaults(import_endpoint.endpoint, {\n  headers: {\n    \"user-agent\": `octokit-request.js/${VERSION} ${(0, import_universal_user_agent.getUserAgent)()}`\n  }\n});\n// Annotate the CommonJS export names for ESM import in node:\n0 && (module.exports = {\n  request\n});\n","var register = require(\"./lib/register\");\nvar addHook = require(\"./lib/add\");\nvar removeHook = require(\"./lib/remove\");\n\n// bind with array of arguments: https://stackoverflow.com/a/21792913\nvar bind = Function.bind;\nvar bindable = bind.bind(bind);\n\nfunction bindApi(hook, state, name) {\n  var removeHookRef = bindable(removeHook, null).apply(\n    null,\n    name ? [state, name] : [state]\n  );\n  hook.api = { remove: removeHookRef };\n  hook.remove = removeHookRef;\n  [\"before\", \"error\", \"after\", \"wrap\"].forEach(function (kind) {\n    var args = name ? [state, kind, name] : [state, kind];\n    hook[kind] = hook.api[kind] = bindable(addHook, null).apply(null, args);\n  });\n}\n\nfunction HookSingular() {\n  var singularHookName = \"h\";\n  var singularHookState = {\n    registry: {},\n  };\n  var singularHook = register.bind(null, singularHookState, singularHookName);\n  bindApi(singularHook, singularHookState, singularHookName);\n  return singularHook;\n}\n\nfunction HookCollection() {\n  var state = {\n    registry: {},\n  };\n\n  var hook = register.bind(null, state);\n  bindApi(hook, state);\n\n  return hook;\n}\n\nvar collectionHookDeprecationMessageDisplayed = false;\nfunction Hook() {\n  if (!collectionHookDeprecationMessageDisplayed) {\n    console.warn(\n      '[before-after-hook]: \"Hook()\" repurposing warning, use \"Hook.Collection()\". Read more: https://git.io/upgrade-before-after-hook-to-1.4'\n    );\n    collectionHookDeprecationMessageDisplayed = true;\n  }\n  return HookCollection();\n}\n\nHook.Singular = HookSingular.bind();\nHook.Collection = HookCollection.bind();\n\nmodule.exports = Hook;\n// expose constructors as a named property for TypeScript\nmodule.exports.Hook = Hook;\nmodule.exports.Singular = Hook.Singular;\nmodule.exports.Collection = Hook.Collection;\n","module.exports = addHook;\n\nfunction addHook(state, kind, name, hook) {\n  var orig = hook;\n  if (!state.registry[name]) {\n    state.registry[name] = [];\n  }\n\n  if (kind === \"before\") {\n    hook = function (method, options) {\n      return Promise.resolve()\n        .then(orig.bind(null, options))\n        .then(method.bind(null, options));\n    };\n  }\n\n  if (kind === \"after\") {\n    hook = function (method, options) {\n      var result;\n      return Promise.resolve()\n        .then(method.bind(null, options))\n        .then(function (result_) {\n          result = result_;\n          return orig(result, options);\n        })\n        .then(function () {\n          return result;\n        });\n    };\n  }\n\n  if (kind === \"error\") {\n    hook = function (method, options) {\n      return Promise.resolve()\n        .then(method.bind(null, options))\n        .catch(function (error) {\n          return orig(error, options);\n        });\n    };\n  }\n\n  state.registry[name].push({\n    hook: hook,\n    orig: orig,\n  });\n}\n","module.exports = register;\n\nfunction register(state, name, method, options) {\n  if (typeof method !== \"function\") {\n    throw new Error(\"method for before hook must be a function\");\n  }\n\n  if (!options) {\n    options = {};\n  }\n\n  if (Array.isArray(name)) {\n    return name.reverse().reduce(function (callback, name) {\n      return register.bind(null, state, name, callback, options);\n    }, method)();\n  }\n\n  return Promise.resolve().then(function () {\n    if (!state.registry[name]) {\n      return method(options);\n    }\n\n    return state.registry[name].reduce(function (method, registered) {\n      return registered.hook.bind(null, method, options);\n    }, method)();\n  });\n}\n","module.exports = removeHook;\n\nfunction removeHook(state, name, method) {\n  if (!state.registry[name]) {\n    return;\n  }\n\n  var index = state.registry[name]\n    .map(function (registered) {\n      return registered.orig;\n    })\n    .indexOf(method);\n\n  if (index === -1) {\n    return;\n  }\n\n  state.registry[name].splice(index, 1);\n}\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nclass Deprecation extends Error {\n  constructor(message) {\n    super(message); // Maintains proper stack trace (only available on V8)\n\n    /* istanbul ignore next */\n\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, this.constructor);\n    }\n\n    this.name = 'Deprecation';\n  }\n\n}\n\nexports.Deprecation = Deprecation;\n","// HumanizeDuration.js - https://git.io/j0HgmQ\n\n// @ts-check\n\n/**\n * @typedef {string | ((unitCount: number) => string)} Unit\n */\n\n/**\n * @typedef {(\"y\" | \"mo\" | \"w\" | \"d\" | \"h\" | \"m\" | \"s\" | \"ms\")} UnitName\n */\n\n/**\n * @typedef {Object} UnitMeasures\n * @prop {number} y\n * @prop {number} mo\n * @prop {number} w\n * @prop {number} d\n * @prop {number} h\n * @prop {number} m\n * @prop {number} s\n * @prop {number} ms\n */\n\n/**\n * @internal\n * @typedef {[string, string, string, string, string, string, string, string, string, string]} DigitReplacements\n */\n\n/**\n * @typedef {Object} Language\n * @prop {Unit} y\n * @prop {Unit} mo\n * @prop {Unit} w\n * @prop {Unit} d\n * @prop {Unit} h\n * @prop {Unit} m\n * @prop {Unit} s\n * @prop {Unit} ms\n * @prop {string} [decimal]\n * @prop {string} [delimiter]\n * @prop {DigitReplacements} [_digitReplacements]\n * @prop {boolean} [_numberFirst]\n */\n\n/**\n * @typedef {Object} Options\n * @prop {string} [language]\n * @prop {Record<string, Language>} [languages]\n * @prop {string[]} [fallbacks]\n * @prop {string} [delimiter]\n * @prop {string} [spacer]\n * @prop {boolean} [round]\n * @prop {number} [largest]\n * @prop {UnitName[]} [units]\n * @prop {string} [decimal]\n * @prop {string} [conjunction]\n * @prop {number} [maxDecimalPoints]\n * @prop {UnitMeasures} [unitMeasures]\n * @prop {boolean} [serialComma]\n * @prop {DigitReplacements} [digitReplacements]\n */\n\n/**\n * @internal\n * @typedef {Required<Options>} NormalizedOptions\n */\n\n(function () {\n  // Fallback for `Object.assign` if relevant.\n  var assign =\n    Object.assign ||\n    /** @param {...any} destination */\n    function (destination) {\n      var source;\n      for (var i = 1; i < arguments.length; i++) {\n        source = arguments[i];\n        for (var prop in source) {\n          if (has(source, prop)) {\n            destination[prop] = source[prop];\n          }\n        }\n      }\n      return destination;\n    };\n\n  // Fallback for `Array.isArray` if relevant.\n  var isArray =\n    Array.isArray ||\n    function (arg) {\n      return Object.prototype.toString.call(arg) === \"[object Array]\";\n    };\n\n  // This has to be defined separately because of a bug: we want to alias\n  // `gr` and `el` for backwards-compatiblity. In a breaking change, we can\n  // remove `gr` entirely.\n  // See https://github.com/EvanHahn/HumanizeDuration.js/issues/143 for more.\n  var GREEK = language(\n    function (c) {\n      return c === 1 ? \"\" : \"\";\n    },\n    function (c) {\n      return c === 1 ? \"\" : \"\";\n    },\n    function (c) {\n      return c === 1 ? \"\" : \"\";\n    },\n    function (c) {\n      return c === 1 ? \"\" : \"\";\n    },\n    function (c) {\n      return c === 1 ? \"\" : \"\";\n    },\n    function (c) {\n      return c === 1 ? \"\" : \"\";\n    },\n    function (c) {\n      return c === 1 ? \"\" : \"\";\n    },\n    function (c) {\n      return (c === 1 ? \"\" : \"\") + \"  \";\n    },\n    \",\"\n  );\n\n  /**\n   * @internal\n   * @type {Record<string, Language>}\n   */\n  var LANGUAGES = {\n    af: language(\n      \"jaar\",\n      function (c) {\n        return \"maand\" + (c === 1 ? \"\" : \"e\");\n      },\n      function (c) {\n        return c === 1 ? \"week\" : \"weke\";\n      },\n      function (c) {\n        return c === 1 ? \"dag\" : \"dae\";\n      },\n      function (c) {\n        return c === 1 ? \"uur\" : \"ure\";\n      },\n      function (c) {\n        return c === 1 ? \"minuut\" : \"minute\";\n      },\n      function (c) {\n        return \"sekonde\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"millisekonde\" + (c === 1 ? \"\" : \"s\");\n      },\n      \",\"\n    ),\n    am: language(\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"),\n    ar: assign(\n      language(\n        function (c) {\n          return [\"\", \"\", \"\"][getArabicForm(c)];\n        },\n        function (c) {\n          return [\"\", \"\", \"\"][getArabicForm(c)];\n        },\n        function (c) {\n          return [\"\", \"\", \"\"][getArabicForm(c)];\n        },\n        function (c) {\n          return [\"\", \"\", \"\"][getArabicForm(c)];\n        },\n        function (c) {\n          return [\"\", \"\", \"\"][getArabicForm(c)];\n        },\n        function (c) {\n          return [\"\", \"\", \"\"][getArabicForm(c)];\n        },\n        function (c) {\n          return [\"\", \"\", \"\"][getArabicForm(c)];\n        },\n        function (c) {\n          return [\"  \", \"  \", \"  \"][\n            getArabicForm(c)\n          ];\n        },\n        \",\"\n      ),\n      {\n        delimiter: \"  \",\n        _digitReplacements: [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n      }\n    ),\n    bg: language(\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      \",\"\n    ),\n    bn: language(\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\"\n    ),\n    ca: language(\n      function (c) {\n        return \"any\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"mes\" + (c === 1 ? \"\" : \"os\");\n      },\n      function (c) {\n        return \"setman\" + (c === 1 ? \"a\" : \"es\");\n      },\n      function (c) {\n        return \"di\" + (c === 1 ? \"a\" : \"es\");\n      },\n      function (c) {\n        return \"hor\" + (c === 1 ? \"a\" : \"es\");\n      },\n      function (c) {\n        return \"minut\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"segon\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"milisegon\" + (c === 1 ? \"\" : \"s\");\n      },\n      \",\"\n    ),\n    ckb: language(\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \" \",\n      \".\"\n    ),\n    cs: language(\n      function (c) {\n        return [\"rok\", \"roku\", \"roky\", \"let\"][getCzechOrSlovakForm(c)];\n      },\n      function (c) {\n        return [\"msc\", \"msce\", \"msce\", \"msc\"][getCzechOrSlovakForm(c)];\n      },\n      function (c) {\n        return [\"tden\", \"tdne\", \"tdny\", \"tdn\"][getCzechOrSlovakForm(c)];\n      },\n      function (c) {\n        return [\"den\", \"dne\", \"dny\", \"dn\"][getCzechOrSlovakForm(c)];\n      },\n      function (c) {\n        return [\"hodina\", \"hodiny\", \"hodiny\", \"hodin\"][getCzechOrSlovakForm(c)];\n      },\n      function (c) {\n        return [\"minuta\", \"minuty\", \"minuty\", \"minut\"][getCzechOrSlovakForm(c)];\n      },\n      function (c) {\n        return [\"sekunda\", \"sekundy\", \"sekundy\", \"sekund\"][\n          getCzechOrSlovakForm(c)\n        ];\n      },\n      function (c) {\n        return [\"milisekunda\", \"milisekundy\", \"milisekundy\", \"milisekund\"][\n          getCzechOrSlovakForm(c)\n        ];\n      },\n      \",\"\n    ),\n    cy: language(\n      \"flwyddyn\",\n      \"mis\",\n      \"wythnos\",\n      \"diwrnod\",\n      \"awr\",\n      \"munud\",\n      \"eiliad\",\n      \"milieiliad\"\n    ),\n    da: language(\n      \"r\",\n      function (c) {\n        return \"mned\" + (c === 1 ? \"\" : \"er\");\n      },\n      function (c) {\n        return \"uge\" + (c === 1 ? \"\" : \"r\");\n      },\n      function (c) {\n        return \"dag\" + (c === 1 ? \"\" : \"e\");\n      },\n      function (c) {\n        return \"time\" + (c === 1 ? \"\" : \"r\");\n      },\n      function (c) {\n        return \"minut\" + (c === 1 ? \"\" : \"ter\");\n      },\n      function (c) {\n        return \"sekund\" + (c === 1 ? \"\" : \"er\");\n      },\n      function (c) {\n        return \"millisekund\" + (c === 1 ? \"\" : \"er\");\n      },\n      \",\"\n    ),\n    de: language(\n      function (c) {\n        return \"Jahr\" + (c === 1 ? \"\" : \"e\");\n      },\n      function (c) {\n        return \"Monat\" + (c === 1 ? \"\" : \"e\");\n      },\n      function (c) {\n        return \"Woche\" + (c === 1 ? \"\" : \"n\");\n      },\n      function (c) {\n        return \"Tag\" + (c === 1 ? \"\" : \"e\");\n      },\n      function (c) {\n        return \"Stunde\" + (c === 1 ? \"\" : \"n\");\n      },\n      function (c) {\n        return \"Minute\" + (c === 1 ? \"\" : \"n\");\n      },\n      function (c) {\n        return \"Sekunde\" + (c === 1 ? \"\" : \"n\");\n      },\n      function (c) {\n        return \"Millisekunde\" + (c === 1 ? \"\" : \"n\");\n      },\n      \",\"\n    ),\n    el: GREEK,\n    en: language(\n      function (c) {\n        return \"year\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"month\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"week\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"day\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"hour\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"minute\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"second\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"millisecond\" + (c === 1 ? \"\" : \"s\");\n      }\n    ),\n    eo: language(\n      function (c) {\n        return \"jaro\" + (c === 1 ? \"\" : \"j\");\n      },\n      function (c) {\n        return \"monato\" + (c === 1 ? \"\" : \"j\");\n      },\n      function (c) {\n        return \"semajno\" + (c === 1 ? \"\" : \"j\");\n      },\n      function (c) {\n        return \"tago\" + (c === 1 ? \"\" : \"j\");\n      },\n      function (c) {\n        return \"horo\" + (c === 1 ? \"\" : \"j\");\n      },\n      function (c) {\n        return \"minuto\" + (c === 1 ? \"\" : \"j\");\n      },\n      function (c) {\n        return \"sekundo\" + (c === 1 ? \"\" : \"j\");\n      },\n      function (c) {\n        return \"milisekundo\" + (c === 1 ? \"\" : \"j\");\n      },\n      \",\"\n    ),\n    es: language(\n      function (c) {\n        return \"ao\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"mes\" + (c === 1 ? \"\" : \"es\");\n      },\n      function (c) {\n        return \"semana\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"da\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"hora\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"minuto\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"segundo\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"milisegundo\" + (c === 1 ? \"\" : \"s\");\n      },\n      \",\"\n    ),\n    et: language(\n      function (c) {\n        return \"aasta\" + (c === 1 ? \"\" : \"t\");\n      },\n      function (c) {\n        return \"kuu\" + (c === 1 ? \"\" : \"d\");\n      },\n      function (c) {\n        return \"ndal\" + (c === 1 ? \"\" : \"at\");\n      },\n      function (c) {\n        return \"pev\" + (c === 1 ? \"\" : \"a\");\n      },\n      function (c) {\n        return \"tund\" + (c === 1 ? \"\" : \"i\");\n      },\n      function (c) {\n        return \"minut\" + (c === 1 ? \"\" : \"it\");\n      },\n      function (c) {\n        return \"sekund\" + (c === 1 ? \"\" : \"it\");\n      },\n      function (c) {\n        return \"millisekund\" + (c === 1 ? \"\" : \"it\");\n      },\n      \",\"\n    ),\n    eu: language(\n      \"urte\",\n      \"hilabete\",\n      \"aste\",\n      \"egun\",\n      \"ordu\",\n      \"minutu\",\n      \"segundo\",\n      \"milisegundo\",\n      \",\"\n    ),\n    fa: language(\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \" \"\n    ),\n    fi: language(\n      function (c) {\n        return c === 1 ? \"vuosi\" : \"vuotta\";\n      },\n      function (c) {\n        return c === 1 ? \"kuukausi\" : \"kuukautta\";\n      },\n      function (c) {\n        return \"viikko\" + (c === 1 ? \"\" : \"a\");\n      },\n      function (c) {\n        return \"piv\" + (c === 1 ? \"\" : \"\");\n      },\n      function (c) {\n        return \"tunti\" + (c === 1 ? \"\" : \"a\");\n      },\n      function (c) {\n        return \"minuutti\" + (c === 1 ? \"\" : \"a\");\n      },\n      function (c) {\n        return \"sekunti\" + (c === 1 ? \"\" : \"a\");\n      },\n      function (c) {\n        return \"millisekunti\" + (c === 1 ? \"\" : \"a\");\n      },\n      \",\"\n    ),\n    fo: language(\n      \"r\",\n      function (c) {\n        return c === 1 ? \"mnaur\" : \"mnair\";\n      },\n      function (c) {\n        return c === 1 ? \"vika\" : \"vikur\";\n      },\n      function (c) {\n        return c === 1 ? \"dagur\" : \"dagar\";\n      },\n      function (c) {\n        return c === 1 ? \"tmi\" : \"tmar\";\n      },\n      function (c) {\n        return c === 1 ? \"minuttur\" : \"minuttir\";\n      },\n      \"sekund\",\n      \"millisekund\",\n      \",\"\n    ),\n    fr: language(\n      function (c) {\n        return \"an\" + (c >= 2 ? \"s\" : \"\");\n      },\n      \"mois\",\n      function (c) {\n        return \"semaine\" + (c >= 2 ? \"s\" : \"\");\n      },\n      function (c) {\n        return \"jour\" + (c >= 2 ? \"s\" : \"\");\n      },\n      function (c) {\n        return \"heure\" + (c >= 2 ? \"s\" : \"\");\n      },\n      function (c) {\n        return \"minute\" + (c >= 2 ? \"s\" : \"\");\n      },\n      function (c) {\n        return \"seconde\" + (c >= 2 ? \"s\" : \"\");\n      },\n      function (c) {\n        return \"milliseconde\" + (c >= 2 ? \"s\" : \"\");\n      },\n      \",\"\n    ),\n    gr: GREEK,\n    he: language(\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      }\n    ),\n    hr: language(\n      function (c) {\n        if (c % 10 === 2 || c % 10 === 3 || c % 10 === 4) {\n          return \"godine\";\n        }\n        return \"godina\";\n      },\n      function (c) {\n        if (c === 1) {\n          return \"mjesec\";\n        } else if (c === 2 || c === 3 || c === 4) {\n          return \"mjeseca\";\n        }\n        return \"mjeseci\";\n      },\n      function (c) {\n        if (c % 10 === 1 && c !== 11) {\n          return \"tjedan\";\n        }\n        return \"tjedna\";\n      },\n      function (c) {\n        return c === 1 ? \"dan\" : \"dana\";\n      },\n      function (c) {\n        if (c === 1) {\n          return \"sat\";\n        } else if (c === 2 || c === 3 || c === 4) {\n          return \"sata\";\n        }\n        return \"sati\";\n      },\n      function (c) {\n        var mod10 = c % 10;\n        if ((mod10 === 2 || mod10 === 3 || mod10 === 4) && (c < 10 || c > 14)) {\n          return \"minute\";\n        }\n        return \"minuta\";\n      },\n      function (c) {\n        var mod10 = c % 10;\n        if (mod10 === 5 || (Math.floor(c) === c && c >= 10 && c <= 19)) {\n          return \"sekundi\";\n        } else if (mod10 === 1) {\n          return \"sekunda\";\n        } else if (mod10 === 2 || mod10 === 3 || mod10 === 4) {\n          return \"sekunde\";\n        }\n        return \"sekundi\";\n      },\n      function (c) {\n        if (c === 1) {\n          return \"milisekunda\";\n        } else if (c % 10 === 2 || c % 10 === 3 || c % 10 === 4) {\n          return \"milisekunde\";\n        }\n        return \"milisekundi\";\n      },\n      \",\"\n    ),\n    hi: language(\n      \"\",\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      \"\",\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      \"\",\n      \"\",\n      \"\"\n    ),\n    hu: language(\n      \"v\",\n      \"hnap\",\n      \"ht\",\n      \"nap\",\n      \"ra\",\n      \"perc\",\n      \"msodperc\",\n      \"ezredmsodperc\",\n      \",\"\n    ),\n    id: language(\n      \"tahun\",\n      \"bulan\",\n      \"minggu\",\n      \"hari\",\n      \"jam\",\n      \"menit\",\n      \"detik\",\n      \"milidetik\"\n    ),\n    is: language(\n      \"r\",\n      function (c) {\n        return \"mnu\" + (c === 1 ? \"ur\" : \"ir\");\n      },\n      function (c) {\n        return \"vik\" + (c === 1 ? \"a\" : \"ur\");\n      },\n      function (c) {\n        return \"dag\" + (c === 1 ? \"ur\" : \"ar\");\n      },\n      function (c) {\n        return \"klukkutm\" + (c === 1 ? \"i\" : \"ar\");\n      },\n      function (c) {\n        return \"mnt\" + (c === 1 ? \"a\" : \"ur\");\n      },\n      function (c) {\n        return \"seknd\" + (c === 1 ? \"a\" : \"ur\");\n      },\n      function (c) {\n        return \"milliseknd\" + (c === 1 ? \"a\" : \"ur\");\n      }\n    ),\n    it: language(\n      function (c) {\n        return \"ann\" + (c === 1 ? \"o\" : \"i\");\n      },\n      function (c) {\n        return \"mes\" + (c === 1 ? \"e\" : \"i\");\n      },\n      function (c) {\n        return \"settiman\" + (c === 1 ? \"a\" : \"e\");\n      },\n      function (c) {\n        return \"giorn\" + (c === 1 ? \"o\" : \"i\");\n      },\n      function (c) {\n        return \"or\" + (c === 1 ? \"a\" : \"e\");\n      },\n      function (c) {\n        return \"minut\" + (c === 1 ? \"o\" : \"i\");\n      },\n      function (c) {\n        return \"second\" + (c === 1 ? \"o\" : \"i\");\n      },\n      function (c) {\n        return \"millisecond\" + (c === 1 ? \"o\" : \"i\");\n      },\n      \",\"\n    ),\n    ja: language(\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"),\n    km: language(\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\"\n    ),\n    kn: language(\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      }\n    ),\n    ko: language(\"\", \"\", \"\", \"\", \"\", \"\", \"\", \" \"),\n    ku: language(\n      \"sal\",\n      \"meh\",\n      \"hefte\",\n      \"roj\",\n      \"seet\",\n      \"deqe\",\n      \"saniye\",\n      \"mlirk\",\n      \",\"\n    ),\n    lo: language(\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \",\"\n    ),\n    lt: language(\n      function (c) {\n        return c % 10 === 0 || (c % 100 >= 10 && c % 100 <= 20)\n          ? \"met\"\n          : \"metai\";\n      },\n      function (c) {\n        return [\"mnuo\", \"mnesiai\", \"mnesi\"][getLithuanianForm(c)];\n      },\n      function (c) {\n        return [\"savait\", \"savaits\", \"savaii\"][getLithuanianForm(c)];\n      },\n      function (c) {\n        return [\"diena\", \"dienos\", \"dien\"][getLithuanianForm(c)];\n      },\n      function (c) {\n        return [\"valanda\", \"valandos\", \"valand\"][getLithuanianForm(c)];\n      },\n      function (c) {\n        return [\"minut\", \"minuts\", \"minui\"][getLithuanianForm(c)];\n      },\n      function (c) {\n        return [\"sekund\", \"sekunds\", \"sekundi\"][getLithuanianForm(c)];\n      },\n      function (c) {\n        return [\"milisekund\", \"milisekunds\", \"milisekundi\"][\n          getLithuanianForm(c)\n        ];\n      },\n      \",\"\n    ),\n    lv: language(\n      function (c) {\n        return getLatvianForm(c) ? \"gads\" : \"gadi\";\n      },\n      function (c) {\n        return getLatvianForm(c) ? \"mnesis\" : \"mnei\";\n      },\n      function (c) {\n        return getLatvianForm(c) ? \"neda\" : \"nedas\";\n      },\n      function (c) {\n        return getLatvianForm(c) ? \"diena\" : \"dienas\";\n      },\n      function (c) {\n        return getLatvianForm(c) ? \"stunda\" : \"stundas\";\n      },\n      function (c) {\n        return getLatvianForm(c) ? \"minte\" : \"mintes\";\n      },\n      function (c) {\n        return getLatvianForm(c) ? \"sekunde\" : \"sekundes\";\n      },\n      function (c) {\n        return getLatvianForm(c) ? \"milisekunde\" : \"milisekundes\";\n      },\n      \",\"\n    ),\n    mk: language(\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      \",\"\n    ),\n    mn: language(\n      \"\",\n      \"\",\n      \" \",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\"\n    ),\n    mr: language(\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      \"\",\n      \"\",\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      \"\",\n      \"\"\n    ),\n    ms: language(\n      \"tahun\",\n      \"bulan\",\n      \"minggu\",\n      \"hari\",\n      \"jam\",\n      \"minit\",\n      \"saat\",\n      \"milisaat\"\n    ),\n    nl: language(\n      \"jaar\",\n      function (c) {\n        return c === 1 ? \"maand\" : \"maanden\";\n      },\n      function (c) {\n        return c === 1 ? \"week\" : \"weken\";\n      },\n      function (c) {\n        return c === 1 ? \"dag\" : \"dagen\";\n      },\n      \"uur\",\n      function (c) {\n        return c === 1 ? \"minuut\" : \"minuten\";\n      },\n      function (c) {\n        return c === 1 ? \"seconde\" : \"seconden\";\n      },\n      function (c) {\n        return c === 1 ? \"milliseconde\" : \"milliseconden\";\n      },\n      \",\"\n    ),\n    no: language(\n      \"r\",\n      function (c) {\n        return \"mned\" + (c === 1 ? \"\" : \"er\");\n      },\n      function (c) {\n        return \"uke\" + (c === 1 ? \"\" : \"r\");\n      },\n      function (c) {\n        return \"dag\" + (c === 1 ? \"\" : \"er\");\n      },\n      function (c) {\n        return \"time\" + (c === 1 ? \"\" : \"r\");\n      },\n      function (c) {\n        return \"minutt\" + (c === 1 ? \"\" : \"er\");\n      },\n      function (c) {\n        return \"sekund\" + (c === 1 ? \"\" : \"er\");\n      },\n      function (c) {\n        return \"millisekund\" + (c === 1 ? \"\" : \"er\");\n      },\n      \",\"\n    ),\n    pl: language(\n      function (c) {\n        return [\"rok\", \"roku\", \"lata\", \"lat\"][getPolishForm(c)];\n      },\n      function (c) {\n        return [\"miesic\", \"miesica\", \"miesice\", \"miesicy\"][\n          getPolishForm(c)\n        ];\n      },\n      function (c) {\n        return [\"tydzie\", \"tygodnia\", \"tygodnie\", \"tygodni\"][getPolishForm(c)];\n      },\n      function (c) {\n        return [\"dzie\", \"dnia\", \"dni\", \"dni\"][getPolishForm(c)];\n      },\n      function (c) {\n        return [\"godzina\", \"godziny\", \"godziny\", \"godzin\"][getPolishForm(c)];\n      },\n      function (c) {\n        return [\"minuta\", \"minuty\", \"minuty\", \"minut\"][getPolishForm(c)];\n      },\n      function (c) {\n        return [\"sekunda\", \"sekundy\", \"sekundy\", \"sekund\"][getPolishForm(c)];\n      },\n      function (c) {\n        return [\"milisekunda\", \"milisekundy\", \"milisekundy\", \"milisekund\"][\n          getPolishForm(c)\n        ];\n      },\n      \",\"\n    ),\n    pt: language(\n      function (c) {\n        return \"ano\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return c === 1 ? \"ms\" : \"meses\";\n      },\n      function (c) {\n        return \"semana\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"dia\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"hora\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"minuto\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"segundo\" + (c === 1 ? \"\" : \"s\");\n      },\n      function (c) {\n        return \"milissegundo\" + (c === 1 ? \"\" : \"s\");\n      },\n      \",\"\n    ),\n    ro: language(\n      function (c) {\n        return c === 1 ? \"an\" : \"ani\";\n      },\n      function (c) {\n        return c === 1 ? \"lun\" : \"luni\";\n      },\n      function (c) {\n        return c === 1 ? \"sptmn\" : \"sptmni\";\n      },\n      function (c) {\n        return c === 1 ? \"zi\" : \"zile\";\n      },\n      function (c) {\n        return c === 1 ? \"or\" : \"ore\";\n      },\n      function (c) {\n        return c === 1 ? \"minut\" : \"minute\";\n      },\n      function (c) {\n        return c === 1 ? \"secund\" : \"secunde\";\n      },\n      function (c) {\n        return c === 1 ? \"milisecund\" : \"milisecunde\";\n      },\n      \",\"\n    ),\n    ru: language(\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][\n          getSlavicForm(c)\n        ];\n      },\n      \",\"\n    ),\n    sq: language(\n      function (c) {\n        return c === 1 ? \"vit\" : \"vjet\";\n      },\n      \"muaj\",\n      \"jav\",\n      \"dit\",\n      \"or\",\n      function (c) {\n        return \"minut\" + (c === 1 ? \"\" : \"a\");\n      },\n      function (c) {\n        return \"sekond\" + (c === 1 ? \"\" : \"a\");\n      },\n      function (c) {\n        return \"milisekond\" + (c === 1 ? \"\" : \"a\");\n      },\n      \",\"\n    ),\n    sr: language(\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      \",\"\n    ),\n    ta: language(\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return \"\" + (c === 1 ? \"\" : \"\");\n      },\n      function (c) {\n        return \"\" + (c === 1 ? \"\" : \"\");\n      },\n      function (c) {\n        return \" \" + (c === 1 ? \"\" : \"\");\n      }\n    ),\n    te: language(\n      function (c) {\n        return \"\" + (c === 1 ? \"\" : \"\");\n      },\n      function (c) {\n        return \"\" + (c === 1 ? \"\" : \"\");\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return \"\" + (c === 1 ? \"\" : \"\");\n      },\n      function (c) {\n        return \"\" + (c === 1 ? \"\" : \"\");\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      }\n    ),\n    uk: language(\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      function (c) {\n        return [\"\", \"\", \"\"][getSlavicForm(c)];\n      },\n      \",\"\n    ),\n    ur: language(\n      \"\",\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      \"\",\n      function (c) {\n        return c === 1 ? \"\" : \"\";\n      },\n      \"\",\n      \"\",\n      \" \"\n    ),\n    sk: language(\n      function (c) {\n        return [\"rok\", \"roky\", \"roky\", \"rokov\"][getCzechOrSlovakForm(c)];\n      },\n      function (c) {\n        return [\"mesiac\", \"mesiace\", \"mesiace\", \"mesiacov\"][\n          getCzechOrSlovakForm(c)\n        ];\n      },\n      function (c) {\n        return [\"tde\", \"tdne\", \"tdne\", \"tdov\"][\n          getCzechOrSlovakForm(c)\n        ];\n      },\n      function (c) {\n        return [\"de\", \"dni\", \"dni\", \"dn\"][getCzechOrSlovakForm(c)];\n      },\n      function (c) {\n        return [\"hodina\", \"hodiny\", \"hodiny\", \"hodn\"][getCzechOrSlovakForm(c)];\n      },\n      function (c) {\n        return [\"minta\", \"minty\", \"minty\", \"mint\"][getCzechOrSlovakForm(c)];\n      },\n      function (c) {\n        return [\"sekunda\", \"sekundy\", \"sekundy\", \"seknd\"][\n          getCzechOrSlovakForm(c)\n        ];\n      },\n      function (c) {\n        return [\"milisekunda\", \"milisekundy\", \"milisekundy\", \"miliseknd\"][\n          getCzechOrSlovakForm(c)\n        ];\n      },\n      \",\"\n    ),\n    sl: language(\n      function (c) {\n        if (c % 10 === 1) {\n          return \"leto\";\n        } else if (c % 100 === 2) {\n          return \"leti\";\n        } else if (\n          c % 100 === 3 ||\n          c % 100 === 4 ||\n          (Math.floor(c) !== c && c % 100 <= 5)\n        ) {\n          return \"leta\";\n        } else {\n          return \"let\";\n        }\n      },\n      function (c) {\n        if (c % 10 === 1) {\n          return \"mesec\";\n        } else if (c % 100 === 2 || (Math.floor(c) !== c && c % 100 <= 5)) {\n          return \"meseca\";\n        } else if (c % 10 === 3 || c % 10 === 4) {\n          return \"mesece\";\n        } else {\n          return \"mesecev\";\n        }\n      },\n      function (c) {\n        if (c % 10 === 1) {\n          return \"teden\";\n        } else if (c % 10 === 2 || (Math.floor(c) !== c && c % 100 <= 4)) {\n          return \"tedna\";\n        } else if (c % 10 === 3 || c % 10 === 4) {\n          return \"tedne\";\n        } else {\n          return \"tednov\";\n        }\n      },\n      function (c) {\n        return c % 100 === 1 ? \"dan\" : \"dni\";\n      },\n      function (c) {\n        if (c % 10 === 1) {\n          return \"ura\";\n        } else if (c % 100 === 2) {\n          return \"uri\";\n        } else if (c % 10 === 3 || c % 10 === 4 || Math.floor(c) !== c) {\n          return \"ure\";\n        } else {\n          return \"ur\";\n        }\n      },\n      function (c) {\n        if (c % 10 === 1) {\n          return \"minuta\";\n        } else if (c % 10 === 2) {\n          return \"minuti\";\n        } else if (\n          c % 10 === 3 ||\n          c % 10 === 4 ||\n          (Math.floor(c) !== c && c % 100 <= 4)\n        ) {\n          return \"minute\";\n        } else {\n          return \"minut\";\n        }\n      },\n      function (c) {\n        if (c % 10 === 1) {\n          return \"sekunda\";\n        } else if (c % 100 === 2) {\n          return \"sekundi\";\n        } else if (c % 100 === 3 || c % 100 === 4 || Math.floor(c) !== c) {\n          return \"sekunde\";\n        } else {\n          return \"sekund\";\n        }\n      },\n      function (c) {\n        if (c % 10 === 1) {\n          return \"milisekunda\";\n        } else if (c % 100 === 2) {\n          return \"milisekundi\";\n        } else if (c % 100 === 3 || c % 100 === 4 || Math.floor(c) !== c) {\n          return \"milisekunde\";\n        } else {\n          return \"milisekund\";\n        }\n      },\n      \",\"\n    ),\n    sv: language(\n      \"r\",\n      function (c) {\n        return \"mnad\" + (c === 1 ? \"\" : \"er\");\n      },\n      function (c) {\n        return \"veck\" + (c === 1 ? \"a\" : \"or\");\n      },\n      function (c) {\n        return \"dag\" + (c === 1 ? \"\" : \"ar\");\n      },\n      function (c) {\n        return \"timm\" + (c === 1 ? \"e\" : \"ar\");\n      },\n      function (c) {\n        return \"minut\" + (c === 1 ? \"\" : \"er\");\n      },\n      function (c) {\n        return \"sekund\" + (c === 1 ? \"\" : \"er\");\n      },\n      function (c) {\n        return \"millisekund\" + (c === 1 ? \"\" : \"er\");\n      },\n      \",\"\n    ),\n    sw: assign(\n      language(\n        function (c) {\n          return c === 1 ? \"mwaka\" : \"miaka\";\n        },\n        function (c) {\n          return c === 1 ? \"mwezi\" : \"miezi\";\n        },\n        \"wiki\",\n        function (c) {\n          return c === 1 ? \"siku\" : \"masiku\";\n        },\n        function (c) {\n          return c === 1 ? \"saa\" : \"masaa\";\n        },\n        \"dakika\",\n        \"sekunde\",\n        \"milisekunde\"\n      ),\n      { _numberFirst: true }\n    ),\n    tr: language(\n      \"yl\",\n      \"ay\",\n      \"hafta\",\n      \"gn\",\n      \"saat\",\n      \"dakika\",\n      \"saniye\",\n      \"milisaniye\",\n      \",\"\n    ),\n    th: language(\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\"\n    ),\n    uz: language(\n      \"yil\",\n      \"oy\",\n      \"hafta\",\n      \"kun\",\n      \"soat\",\n      \"minut\",\n      \"sekund\",\n      \"millisekund\"\n    ),\n    uz_CYR: language(\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\",\n      \"\"\n    ),\n    vi: language(\n      \"nm\",\n      \"thng\",\n      \"tun\",\n      \"ngy\",\n      \"gi\",\n      \"pht\",\n      \"giy\",\n      \"mili giy\",\n      \",\"\n    ),\n    zh_CN: language(\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"),\n    zh_TW: language(\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\")\n  };\n\n  /**\n   * Helper function for creating language definitions.\n   *\n   * @internal\n   * @param {Unit} y\n   * @param {Unit} mo\n   * @param {Unit} w\n   * @param {Unit} d\n   * @param {Unit} h\n   * @param {Unit} m\n   * @param {Unit} s\n   * @param {Unit} ms\n   * @param {string} [decimal]\n   * @returns {Language}\n   */\n  function language(y, mo, w, d, h, m, s, ms, decimal) {\n    /** @type {Language} */\n    var result = { y: y, mo: mo, w: w, d: d, h: h, m: m, s: s, ms: ms };\n    if (typeof decimal !== \"undefined\") {\n      result.decimal = decimal;\n    }\n    return result;\n  }\n\n  /**\n   * Helper function for Arabic.\n   *\n   * @internal\n   * @param {number} c\n   * @returns {0 | 1 | 2}\n   */\n  function getArabicForm(c) {\n    if (c === 2) {\n      return 1;\n    }\n    if (c > 2 && c < 11) {\n      return 2;\n    }\n    return 0;\n  }\n\n  /**\n   * Helper function for Polish.\n   *\n   * @internal\n   * @param {number} c\n   * @returns {0 | 1 | 2 | 3}\n   */\n  function getPolishForm(c) {\n    if (c === 1) {\n      return 0;\n    }\n    if (Math.floor(c) !== c) {\n      return 1;\n    }\n    if (c % 10 >= 2 && c % 10 <= 4 && !(c % 100 > 10 && c % 100 < 20)) {\n      return 2;\n    }\n    return 3;\n  }\n\n  /**\n   * Helper function for Slavic languages.\n   *\n   * @internal\n   * @param {number} c\n   * @returns {0 | 1 | 2 | 3}\n   */\n  function getSlavicForm(c) {\n    if (Math.floor(c) !== c) {\n      return 2;\n    }\n    if (\n      (c % 100 >= 5 && c % 100 <= 20) ||\n      (c % 10 >= 5 && c % 10 <= 9) ||\n      c % 10 === 0\n    ) {\n      return 0;\n    }\n    if (c % 10 === 1) {\n      return 1;\n    }\n    if (c > 1) {\n      return 2;\n    }\n    return 0;\n  }\n\n  /**\n   * Helper function for Czech or Slovak.\n   *\n   * @internal\n   * @param {number} c\n   * @returns {0 | 1 | 2 | 3}\n   */\n  function getCzechOrSlovakForm(c) {\n    if (c === 1) {\n      return 0;\n    }\n    if (Math.floor(c) !== c) {\n      return 1;\n    }\n    if (c % 10 >= 2 && c % 10 <= 4 && c % 100 < 10) {\n      return 2;\n    }\n    return 3;\n  }\n\n  /**\n   * Helper function for Lithuanian.\n   *\n   * @internal\n   * @param {number} c\n   * @returns {0 | 1 | 2}\n   */\n  function getLithuanianForm(c) {\n    if (c === 1 || (c % 10 === 1 && c % 100 > 20)) {\n      return 0;\n    }\n    if (\n      Math.floor(c) !== c ||\n      (c % 10 >= 2 && c % 100 > 20) ||\n      (c % 10 >= 2 && c % 100 < 10)\n    ) {\n      return 1;\n    }\n    return 2;\n  }\n\n  /**\n   * Helper function for Latvian.\n   *\n   * @internal\n   * @param {number} c\n   * @returns {boolean}\n   */\n  function getLatvianForm(c) {\n    return c % 10 === 1 && c % 100 !== 11;\n  }\n\n  /**\n   * @internal\n   * @template T\n   * @param {T} obj\n   * @param {keyof T} key\n   * @returns {boolean}\n   */\n  function has(obj, key) {\n    return Object.prototype.hasOwnProperty.call(obj, key);\n  }\n\n  /**\n   * @internal\n   * @param {Pick<Required<Options>, \"language\" | \"fallbacks\" | \"languages\">} options\n   * @throws {Error} Throws an error if language is not found.\n   * @returns {Language}\n   */\n  function getLanguage(options) {\n    var possibleLanguages = [options.language];\n\n    if (has(options, \"fallbacks\")) {\n      if (isArray(options.fallbacks) && options.fallbacks.length) {\n        possibleLanguages = possibleLanguages.concat(options.fallbacks);\n      } else {\n        throw new Error(\"fallbacks must be an array with at least one element\");\n      }\n    }\n\n    for (var i = 0; i < possibleLanguages.length; i++) {\n      var languageToTry = possibleLanguages[i];\n      if (has(options.languages, languageToTry)) {\n        return options.languages[languageToTry];\n      }\n      if (has(LANGUAGES, languageToTry)) {\n        return LANGUAGES[languageToTry];\n      }\n    }\n\n    throw new Error(\"No language found.\");\n  }\n\n  /**\n   * @internal\n   * @param {Piece} piece\n   * @param {Language} language\n   * @param {Pick<Required<Options>, \"decimal\" | \"spacer\" | \"maxDecimalPoints\" | \"digitReplacements\">} options\n   */\n  function renderPiece(piece, language, options) {\n    var unitName = piece.unitName;\n    var unitCount = piece.unitCount;\n\n    var spacer = options.spacer;\n    var maxDecimalPoints = options.maxDecimalPoints;\n\n    /** @type {string} */\n    var decimal;\n    if (has(options, \"decimal\")) {\n      decimal = options.decimal;\n    } else if (has(language, \"decimal\")) {\n      decimal = language.decimal;\n    } else {\n      decimal = \".\";\n    }\n\n    /** @type {undefined | DigitReplacements} */\n    var digitReplacements;\n    if (\"digitReplacements\" in options) {\n      digitReplacements = options.digitReplacements;\n    } else if (\"_digitReplacements\" in language) {\n      digitReplacements = language._digitReplacements;\n    }\n\n    /** @type {string} */\n    var formattedCount;\n    var normalizedUnitCount =\n      maxDecimalPoints === void 0\n        ? unitCount\n        : Math.floor(unitCount * Math.pow(10, maxDecimalPoints)) /\n          Math.pow(10, maxDecimalPoints);\n    var countStr = normalizedUnitCount.toString();\n    if (digitReplacements) {\n      formattedCount = \"\";\n      for (var i = 0; i < countStr.length; i++) {\n        var char = countStr[i];\n        if (char === \".\") {\n          formattedCount += decimal;\n        } else {\n          // @ts-ignore because `char` should always be 0-9 at this point.\n          formattedCount += digitReplacements[char];\n        }\n      }\n    } else {\n      formattedCount = countStr.replace(\".\", decimal);\n    }\n\n    var languageWord = language[unitName];\n    var word;\n    if (typeof languageWord === \"function\") {\n      word = languageWord(unitCount);\n    } else {\n      word = languageWord;\n    }\n\n    if (language._numberFirst) {\n      return word + spacer + formattedCount;\n    }\n    return formattedCount + spacer + word;\n  }\n\n  /**\n   * @internal\n   * @typedef {Object} Piece\n   * @prop {UnitName} unitName\n   * @prop {number} unitCount\n   */\n\n  /**\n   * @internal\n   * @param {number} ms\n   * @param {Pick<Required<Options>, \"units\" | \"unitMeasures\" | \"largest\" | \"round\">} options\n   * @returns {Piece[]}\n   */\n  function getPieces(ms, options) {\n    /** @type {UnitName} */\n    var unitName;\n\n    /** @type {number} */\n    var i;\n\n    /** @type {number} */\n    var unitCount;\n\n    /** @type {number} */\n    var msRemaining;\n\n    var units = options.units;\n    var unitMeasures = options.unitMeasures;\n    var largest = \"largest\" in options ? options.largest : Infinity;\n\n    if (!units.length) return [];\n\n    // Get the counts for each unit. Doesn't round or truncate anything.\n    // For example, might create an object like `{ y: 7, m: 6, w: 0, d: 5, h: 23.99 }`.\n    /** @type {Partial<Record<UnitName, number>>} */\n    var unitCounts = {};\n    msRemaining = ms;\n    for (i = 0; i < units.length; i++) {\n      unitName = units[i];\n      var unitMs = unitMeasures[unitName];\n\n      var isLast = i === units.length - 1;\n      unitCount = isLast\n        ? msRemaining / unitMs\n        : Math.floor(msRemaining / unitMs);\n      unitCounts[unitName] = unitCount;\n\n      msRemaining -= unitCount * unitMs;\n    }\n\n    if (options.round) {\n      // Update counts based on the `largest` option.\n      // For example, if `largest === 2` and `unitCount` is `{ y: 7, m: 6, w: 0, d: 5, h: 23.99 }`,\n      // updates to something like `{ y: 7, m: 6.2 }`.\n      var unitsRemainingBeforeRound = largest;\n      for (i = 0; i < units.length; i++) {\n        unitName = units[i];\n        unitCount = unitCounts[unitName];\n\n        if (unitCount === 0) continue;\n\n        unitsRemainingBeforeRound--;\n\n        // \"Take\" the rest of the units into this one.\n        if (unitsRemainingBeforeRound === 0) {\n          for (var j = i + 1; j < units.length; j++) {\n            var smallerUnitName = units[j];\n            var smallerUnitCount = unitCounts[smallerUnitName];\n            unitCounts[unitName] +=\n              (smallerUnitCount * unitMeasures[smallerUnitName]) /\n              unitMeasures[unitName];\n            unitCounts[smallerUnitName] = 0;\n          }\n          break;\n        }\n      }\n\n      // Round the last piece (which should be the only non-integer).\n      //\n      // This can be a little tricky if the last piece \"bubbles up\" to a larger\n      // unit. For example, \"3 days, 23.99 hours\" should be rounded to \"4 days\".\n      // It can also require multiple passes. For example, \"6 days, 23.99 hours\"\n      // should become \"1 week\".\n      for (i = units.length - 1; i >= 0; i--) {\n        unitName = units[i];\n        unitCount = unitCounts[unitName];\n\n        if (unitCount === 0) continue;\n\n        var rounded = Math.round(unitCount);\n        unitCounts[unitName] = rounded;\n\n        if (i === 0) break;\n\n        var previousUnitName = units[i - 1];\n        var previousUnitMs = unitMeasures[previousUnitName];\n        var amountOfPreviousUnit = Math.floor(\n          (rounded * unitMeasures[unitName]) / previousUnitMs\n        );\n        if (amountOfPreviousUnit) {\n          unitCounts[previousUnitName] += amountOfPreviousUnit;\n          unitCounts[unitName] = 0;\n        } else {\n          break;\n        }\n      }\n    }\n\n    /** @type {Piece[]} */\n    var result = [];\n    for (i = 0; i < units.length && result.length < largest; i++) {\n      unitName = units[i];\n      unitCount = unitCounts[unitName];\n      if (unitCount) {\n        result.push({ unitName: unitName, unitCount: unitCount });\n      }\n    }\n    return result;\n  }\n\n  /**\n   * @internal\n   * @param {Piece[]} pieces\n   * @param {Pick<Required<Options>, \"units\" | \"language\" | \"languages\" | \"fallbacks\" | \"delimiter\" | \"spacer\" | \"decimal\" | \"conjunction\" | \"maxDecimalPoints\" | \"serialComma\" | \"digitReplacements\">} options\n   * @returns {string}\n   */\n  function formatPieces(pieces, options) {\n    var language = getLanguage(options);\n\n    if (!pieces.length) {\n      var units = options.units;\n      var smallestUnitName = units[units.length - 1];\n      return renderPiece(\n        { unitName: smallestUnitName, unitCount: 0 },\n        language,\n        options\n      );\n    }\n\n    var conjunction = options.conjunction;\n    var serialComma = options.serialComma;\n\n    var delimiter;\n    if (has(options, \"delimiter\")) {\n      delimiter = options.delimiter;\n    } else if (has(language, \"delimiter\")) {\n      delimiter = language.delimiter;\n    } else {\n      delimiter = \", \";\n    }\n\n    /** @type {string[]} */\n    var renderedPieces = [];\n    for (var i = 0; i < pieces.length; i++) {\n      renderedPieces.push(renderPiece(pieces[i], language, options));\n    }\n\n    if (!conjunction || pieces.length === 1) {\n      return renderedPieces.join(delimiter);\n    }\n\n    if (pieces.length === 2) {\n      return renderedPieces.join(conjunction);\n    }\n\n    return (\n      renderedPieces.slice(0, -1).join(delimiter) +\n      (serialComma ? \",\" : \"\") +\n      conjunction +\n      renderedPieces.slice(-1)\n    );\n  }\n\n  /**\n   * Create a humanizer, which lets you change the default options.\n   *\n   * @param {Options} [passedOptions]\n   */\n  function humanizer(passedOptions) {\n    /**\n     * @param {number} ms\n     * @param {Options} [humanizerOptions]\n     * @returns {string}\n     */\n    var result = function humanizer(ms, humanizerOptions) {\n      // Make sure we have a positive number.\n      //\n      // Has the nice side-effect of converting things to numbers. For example,\n      // converts `\"123\"` and `Number(123)` to `123`.\n      ms = Math.abs(ms);\n\n      var options = assign({}, result, humanizerOptions || {});\n\n      var pieces = getPieces(ms, options);\n\n      return formatPieces(pieces, options);\n    };\n\n    return assign(\n      result,\n      {\n        language: \"en\",\n        spacer: \" \",\n        conjunction: \"\",\n        serialComma: true,\n        units: [\"y\", \"mo\", \"w\", \"d\", \"h\", \"m\", \"s\"],\n        languages: {},\n        round: false,\n        unitMeasures: {\n          y: 31557600000,\n          mo: 2629800000,\n          w: 604800000,\n          d: 86400000,\n          h: 3600000,\n          m: 60000,\n          s: 1000,\n          ms: 1\n        }\n      },\n      passedOptions\n    );\n  }\n\n  /**\n   * Humanize a duration.\n   *\n   * This is a wrapper around the default humanizer.\n   */\n  var humanizeDuration = assign(humanizer({}), {\n    getSupportedLanguages: function getSupportedLanguages() {\n      var result = [];\n      for (var language in LANGUAGES) {\n        if (has(LANGUAGES, language) && language !== \"gr\") {\n          result.push(language);\n        }\n      }\n      return result;\n    },\n    humanizer: humanizer\n  });\n\n  // @ts-ignore\n  if (typeof define === \"function\" && define.amd) {\n    // @ts-ignore\n    define(function () {\n      return humanizeDuration;\n    });\n  } else if (typeof module !== \"undefined\" && module.exports) {\n    module.exports = humanizeDuration;\n  } else {\n    this.humanizeDuration = humanizeDuration;\n  }\n})();\n","var wrappy = require('wrappy')\nmodule.exports = wrappy(once)\nmodule.exports.strict = wrappy(onceStrict)\n\nonce.proto = once(function () {\n  Object.defineProperty(Function.prototype, 'once', {\n    value: function () {\n      return once(this)\n    },\n    configurable: true\n  })\n\n  Object.defineProperty(Function.prototype, 'onceStrict', {\n    value: function () {\n      return onceStrict(this)\n    },\n    configurable: true\n  })\n})\n\nfunction once (fn) {\n  var f = function () {\n    if (f.called) return f.value\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  f.called = false\n  return f\n}\n\nfunction onceStrict (fn) {\n  var f = function () {\n    if (f.called)\n      throw new Error(f.onceError)\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  var name = fn.name || 'Function wrapped with `once`'\n  f.onceError = name + \" shouldn't be called more than once\"\n  f.called = false\n  return f\n}\n","module.exports = require('./lib/tunnel');\n","'use strict';\n\nvar net = require('net');\nvar tls = require('tls');\nvar http = require('http');\nvar https = require('https');\nvar events = require('events');\nvar assert = require('assert');\nvar util = require('util');\n\n\nexports.httpOverHttp = httpOverHttp;\nexports.httpsOverHttp = httpsOverHttp;\nexports.httpOverHttps = httpOverHttps;\nexports.httpsOverHttps = httpsOverHttps;\n\n\nfunction httpOverHttp(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = http.request;\n  return agent;\n}\n\nfunction httpsOverHttp(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = http.request;\n  agent.createSocket = createSecureSocket;\n  agent.defaultPort = 443;\n  return agent;\n}\n\nfunction httpOverHttps(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = https.request;\n  return agent;\n}\n\nfunction httpsOverHttps(options) {\n  var agent = new TunnelingAgent(options);\n  agent.request = https.request;\n  agent.createSocket = createSecureSocket;\n  agent.defaultPort = 443;\n  return agent;\n}\n\n\nfunction TunnelingAgent(options) {\n  var self = this;\n  self.options = options || {};\n  self.proxyOptions = self.options.proxy || {};\n  self.maxSockets = self.options.maxSockets || http.Agent.defaultMaxSockets;\n  self.requests = [];\n  self.sockets = [];\n\n  self.on('free', function onFree(socket, host, port, localAddress) {\n    var options = toOptions(host, port, localAddress);\n    for (var i = 0, len = self.requests.length; i < len; ++i) {\n      var pending = self.requests[i];\n      if (pending.host === options.host && pending.port === options.port) {\n        // Detect the request to connect same origin server,\n        // reuse the connection.\n        self.requests.splice(i, 1);\n        pending.request.onSocket(socket);\n        return;\n      }\n    }\n    socket.destroy();\n    self.removeSocket(socket);\n  });\n}\nutil.inherits(TunnelingAgent, events.EventEmitter);\n\nTunnelingAgent.prototype.addRequest = function addRequest(req, host, port, localAddress) {\n  var self = this;\n  var options = mergeOptions({request: req}, self.options, toOptions(host, port, localAddress));\n\n  if (self.sockets.length >= this.maxSockets) {\n    // We are over limit so we'll add it to the queue.\n    self.requests.push(options);\n    return;\n  }\n\n  // If we are under maxSockets create a new one.\n  self.createSocket(options, function(socket) {\n    socket.on('free', onFree);\n    socket.on('close', onCloseOrRemove);\n    socket.on('agentRemove', onCloseOrRemove);\n    req.onSocket(socket);\n\n    function onFree() {\n      self.emit('free', socket, options);\n    }\n\n    function onCloseOrRemove(err) {\n      self.removeSocket(socket);\n      socket.removeListener('free', onFree);\n      socket.removeListener('close', onCloseOrRemove);\n      socket.removeListener('agentRemove', onCloseOrRemove);\n    }\n  });\n};\n\nTunnelingAgent.prototype.createSocket = function createSocket(options, cb) {\n  var self = this;\n  var placeholder = {};\n  self.sockets.push(placeholder);\n\n  var connectOptions = mergeOptions({}, self.proxyOptions, {\n    method: 'CONNECT',\n    path: options.host + ':' + options.port,\n    agent: false,\n    headers: {\n      host: options.host + ':' + options.port\n    }\n  });\n  if (options.localAddress) {\n    connectOptions.localAddress = options.localAddress;\n  }\n  if (connectOptions.proxyAuth) {\n    connectOptions.headers = connectOptions.headers || {};\n    connectOptions.headers['Proxy-Authorization'] = 'Basic ' +\n        new Buffer(connectOptions.proxyAuth).toString('base64');\n  }\n\n  debug('making CONNECT request');\n  var connectReq = self.request(connectOptions);\n  connectReq.useChunkedEncodingByDefault = false; // for v0.6\n  connectReq.once('response', onResponse); // for v0.6\n  connectReq.once('upgrade', onUpgrade);   // for v0.6\n  connectReq.once('connect', onConnect);   // for v0.7 or later\n  connectReq.once('error', onError);\n  connectReq.end();\n\n  function onResponse(res) {\n    // Very hacky. This is necessary to avoid http-parser leaks.\n    res.upgrade = true;\n  }\n\n  function onUpgrade(res, socket, head) {\n    // Hacky.\n    process.nextTick(function() {\n      onConnect(res, socket, head);\n    });\n  }\n\n  function onConnect(res, socket, head) {\n    connectReq.removeAllListeners();\n    socket.removeAllListeners();\n\n    if (res.statusCode !== 200) {\n      debug('tunneling socket could not be established, statusCode=%d',\n        res.statusCode);\n      socket.destroy();\n      var error = new Error('tunneling socket could not be established, ' +\n        'statusCode=' + res.statusCode);\n      error.code = 'ECONNRESET';\n      options.request.emit('error', error);\n      self.removeSocket(placeholder);\n      return;\n    }\n    if (head.length > 0) {\n      debug('got illegal response body from proxy');\n      socket.destroy();\n      var error = new Error('got illegal response body from proxy');\n      error.code = 'ECONNRESET';\n      options.request.emit('error', error);\n      self.removeSocket(placeholder);\n      return;\n    }\n    debug('tunneling connection has established');\n    self.sockets[self.sockets.indexOf(placeholder)] = socket;\n    return cb(socket);\n  }\n\n  function onError(cause) {\n    connectReq.removeAllListeners();\n\n    debug('tunneling socket could not be established, cause=%s\\n',\n          cause.message, cause.stack);\n    var error = new Error('tunneling socket could not be established, ' +\n                          'cause=' + cause.message);\n    error.code = 'ECONNRESET';\n    options.request.emit('error', error);\n    self.removeSocket(placeholder);\n  }\n};\n\nTunnelingAgent.prototype.removeSocket = function removeSocket(socket) {\n  var pos = this.sockets.indexOf(socket)\n  if (pos === -1) {\n    return;\n  }\n  this.sockets.splice(pos, 1);\n\n  var pending = this.requests.shift();\n  if (pending) {\n    // If we have pending requests and a socket gets closed a new one\n    // needs to be created to take over in the pool for the one that closed.\n    this.createSocket(pending, function(socket) {\n      pending.request.onSocket(socket);\n    });\n  }\n};\n\nfunction createSecureSocket(options, cb) {\n  var self = this;\n  TunnelingAgent.prototype.createSocket.call(self, options, function(socket) {\n    var hostHeader = options.request.getHeader('host');\n    var tlsOptions = mergeOptions({}, self.options, {\n      socket: socket,\n      servername: hostHeader ? hostHeader.replace(/:.*$/, '') : options.host\n    });\n\n    // 0 is dummy port for v0.6\n    var secureSocket = tls.connect(0, tlsOptions);\n    self.sockets[self.sockets.indexOf(socket)] = secureSocket;\n    cb(secureSocket);\n  });\n}\n\n\nfunction toOptions(host, port, localAddress) {\n  if (typeof host === 'string') { // since v0.10\n    return {\n      host: host,\n      port: port,\n      localAddress: localAddress\n    };\n  }\n  return host; // for v0.11 or later\n}\n\nfunction mergeOptions(target) {\n  for (var i = 1, len = arguments.length; i < len; ++i) {\n    var overrides = arguments[i];\n    if (typeof overrides === 'object') {\n      var keys = Object.keys(overrides);\n      for (var j = 0, keyLen = keys.length; j < keyLen; ++j) {\n        var k = keys[j];\n        if (overrides[k] !== undefined) {\n          target[k] = overrides[k];\n        }\n      }\n    }\n  }\n  return target;\n}\n\n\nvar debug;\nif (process.env.NODE_DEBUG && /\\btunnel\\b/.test(process.env.NODE_DEBUG)) {\n  debug = function() {\n    var args = Array.prototype.slice.call(arguments);\n    if (typeof args[0] === 'string') {\n      args[0] = 'TUNNEL: ' + args[0];\n    } else {\n      args.unshift('TUNNEL:');\n    }\n    console.error.apply(console, args);\n  }\n} else {\n  debug = function() {};\n}\nexports.debug = debug; // for test\n","'use strict'\n\nconst Client = require('./lib/client')\nconst Dispatcher = require('./lib/dispatcher')\nconst errors = require('./lib/core/errors')\nconst Pool = require('./lib/pool')\nconst BalancedPool = require('./lib/balanced-pool')\nconst Agent = require('./lib/agent')\nconst util = require('./lib/core/util')\nconst { InvalidArgumentError } = errors\nconst api = require('./lib/api')\nconst buildConnector = require('./lib/core/connect')\nconst MockClient = require('./lib/mock/mock-client')\nconst MockAgent = require('./lib/mock/mock-agent')\nconst MockPool = require('./lib/mock/mock-pool')\nconst mockErrors = require('./lib/mock/mock-errors')\nconst ProxyAgent = require('./lib/proxy-agent')\nconst RetryHandler = require('./lib/handler/RetryHandler')\nconst { getGlobalDispatcher, setGlobalDispatcher } = require('./lib/global')\nconst DecoratorHandler = require('./lib/handler/DecoratorHandler')\nconst RedirectHandler = require('./lib/handler/RedirectHandler')\nconst createRedirectInterceptor = require('./lib/interceptor/redirectInterceptor')\n\nlet hasCrypto\ntry {\n  require('crypto')\n  hasCrypto = true\n} catch {\n  hasCrypto = false\n}\n\nObject.assign(Dispatcher.prototype, api)\n\nmodule.exports.Dispatcher = Dispatcher\nmodule.exports.Client = Client\nmodule.exports.Pool = Pool\nmodule.exports.BalancedPool = BalancedPool\nmodule.exports.Agent = Agent\nmodule.exports.ProxyAgent = ProxyAgent\nmodule.exports.RetryHandler = RetryHandler\n\nmodule.exports.DecoratorHandler = DecoratorHandler\nmodule.exports.RedirectHandler = RedirectHandler\nmodule.exports.createRedirectInterceptor = createRedirectInterceptor\n\nmodule.exports.buildConnector = buildConnector\nmodule.exports.errors = errors\n\nfunction makeDispatcher (fn) {\n  return (url, opts, handler) => {\n    if (typeof opts === 'function') {\n      handler = opts\n      opts = null\n    }\n\n    if (!url || (typeof url !== 'string' && typeof url !== 'object' && !(url instanceof URL))) {\n      throw new InvalidArgumentError('invalid url')\n    }\n\n    if (opts != null && typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    if (opts && opts.path != null) {\n      if (typeof opts.path !== 'string') {\n        throw new InvalidArgumentError('invalid opts.path')\n      }\n\n      let path = opts.path\n      if (!opts.path.startsWith('/')) {\n        path = `/${path}`\n      }\n\n      url = new URL(util.parseOrigin(url).origin + path)\n    } else {\n      if (!opts) {\n        opts = typeof url === 'object' ? url : {}\n      }\n\n      url = util.parseURL(url)\n    }\n\n    const { agent, dispatcher = getGlobalDispatcher() } = opts\n\n    if (agent) {\n      throw new InvalidArgumentError('unsupported opts.agent. Did you mean opts.client?')\n    }\n\n    return fn.call(dispatcher, {\n      ...opts,\n      origin: url.origin,\n      path: url.search ? `${url.pathname}${url.search}` : url.pathname,\n      method: opts.method || (opts.body ? 'PUT' : 'GET')\n    }, handler)\n  }\n}\n\nmodule.exports.setGlobalDispatcher = setGlobalDispatcher\nmodule.exports.getGlobalDispatcher = getGlobalDispatcher\n\nif (util.nodeMajor > 16 || (util.nodeMajor === 16 && util.nodeMinor >= 8)) {\n  let fetchImpl = null\n  module.exports.fetch = async function fetch (resource) {\n    if (!fetchImpl) {\n      fetchImpl = require('./lib/fetch').fetch\n    }\n\n    try {\n      return await fetchImpl(...arguments)\n    } catch (err) {\n      if (typeof err === 'object') {\n        Error.captureStackTrace(err, this)\n      }\n\n      throw err\n    }\n  }\n  module.exports.Headers = require('./lib/fetch/headers').Headers\n  module.exports.Response = require('./lib/fetch/response').Response\n  module.exports.Request = require('./lib/fetch/request').Request\n  module.exports.FormData = require('./lib/fetch/formdata').FormData\n  module.exports.File = require('./lib/fetch/file').File\n  module.exports.FileReader = require('./lib/fileapi/filereader').FileReader\n\n  const { setGlobalOrigin, getGlobalOrigin } = require('./lib/fetch/global')\n\n  module.exports.setGlobalOrigin = setGlobalOrigin\n  module.exports.getGlobalOrigin = getGlobalOrigin\n\n  const { CacheStorage } = require('./lib/cache/cachestorage')\n  const { kConstruct } = require('./lib/cache/symbols')\n\n  // Cache & CacheStorage are tightly coupled with fetch. Even if it may run\n  // in an older version of Node, it doesn't have any use without fetch.\n  module.exports.caches = new CacheStorage(kConstruct)\n}\n\nif (util.nodeMajor >= 16) {\n  const { deleteCookie, getCookies, getSetCookies, setCookie } = require('./lib/cookies')\n\n  module.exports.deleteCookie = deleteCookie\n  module.exports.getCookies = getCookies\n  module.exports.getSetCookies = getSetCookies\n  module.exports.setCookie = setCookie\n\n  const { parseMIMEType, serializeAMimeType } = require('./lib/fetch/dataURL')\n\n  module.exports.parseMIMEType = parseMIMEType\n  module.exports.serializeAMimeType = serializeAMimeType\n}\n\nif (util.nodeMajor >= 18 && hasCrypto) {\n  const { WebSocket } = require('./lib/websocket/websocket')\n\n  module.exports.WebSocket = WebSocket\n}\n\nmodule.exports.request = makeDispatcher(api.request)\nmodule.exports.stream = makeDispatcher(api.stream)\nmodule.exports.pipeline = makeDispatcher(api.pipeline)\nmodule.exports.connect = makeDispatcher(api.connect)\nmodule.exports.upgrade = makeDispatcher(api.upgrade)\n\nmodule.exports.MockClient = MockClient\nmodule.exports.MockPool = MockPool\nmodule.exports.MockAgent = MockAgent\nmodule.exports.mockErrors = mockErrors\n","'use strict'\n\nconst { InvalidArgumentError } = require('./core/errors')\nconst { kClients, kRunning, kClose, kDestroy, kDispatch, kInterceptors } = require('./core/symbols')\nconst DispatcherBase = require('./dispatcher-base')\nconst Pool = require('./pool')\nconst Client = require('./client')\nconst util = require('./core/util')\nconst createRedirectInterceptor = require('./interceptor/redirectInterceptor')\nconst { WeakRef, FinalizationRegistry } = require('./compat/dispatcher-weakref')()\n\nconst kOnConnect = Symbol('onConnect')\nconst kOnDisconnect = Symbol('onDisconnect')\nconst kOnConnectionError = Symbol('onConnectionError')\nconst kMaxRedirections = Symbol('maxRedirections')\nconst kOnDrain = Symbol('onDrain')\nconst kFactory = Symbol('factory')\nconst kFinalizer = Symbol('finalizer')\nconst kOptions = Symbol('options')\n\nfunction defaultFactory (origin, opts) {\n  return opts && opts.connections === 1\n    ? new Client(origin, opts)\n    : new Pool(origin, opts)\n}\n\nclass Agent extends DispatcherBase {\n  constructor ({ factory = defaultFactory, maxRedirections = 0, connect, ...options } = {}) {\n    super()\n\n    if (typeof factory !== 'function') {\n      throw new InvalidArgumentError('factory must be a function.')\n    }\n\n    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {\n      throw new InvalidArgumentError('connect must be a function or an object')\n    }\n\n    if (!Number.isInteger(maxRedirections) || maxRedirections < 0) {\n      throw new InvalidArgumentError('maxRedirections must be a positive number')\n    }\n\n    if (connect && typeof connect !== 'function') {\n      connect = { ...connect }\n    }\n\n    this[kInterceptors] = options.interceptors && options.interceptors.Agent && Array.isArray(options.interceptors.Agent)\n      ? options.interceptors.Agent\n      : [createRedirectInterceptor({ maxRedirections })]\n\n    this[kOptions] = { ...util.deepClone(options), connect }\n    this[kOptions].interceptors = options.interceptors\n      ? { ...options.interceptors }\n      : undefined\n    this[kMaxRedirections] = maxRedirections\n    this[kFactory] = factory\n    this[kClients] = new Map()\n    this[kFinalizer] = new FinalizationRegistry(/* istanbul ignore next: gc is undeterministic */ key => {\n      const ref = this[kClients].get(key)\n      if (ref !== undefined && ref.deref() === undefined) {\n        this[kClients].delete(key)\n      }\n    })\n\n    const agent = this\n\n    this[kOnDrain] = (origin, targets) => {\n      agent.emit('drain', origin, [agent, ...targets])\n    }\n\n    this[kOnConnect] = (origin, targets) => {\n      agent.emit('connect', origin, [agent, ...targets])\n    }\n\n    this[kOnDisconnect] = (origin, targets, err) => {\n      agent.emit('disconnect', origin, [agent, ...targets], err)\n    }\n\n    this[kOnConnectionError] = (origin, targets, err) => {\n      agent.emit('connectionError', origin, [agent, ...targets], err)\n    }\n  }\n\n  get [kRunning] () {\n    let ret = 0\n    for (const ref of this[kClients].values()) {\n      const client = ref.deref()\n      /* istanbul ignore next: gc is undeterministic */\n      if (client) {\n        ret += client[kRunning]\n      }\n    }\n    return ret\n  }\n\n  [kDispatch] (opts, handler) {\n    let key\n    if (opts.origin && (typeof opts.origin === 'string' || opts.origin instanceof URL)) {\n      key = String(opts.origin)\n    } else {\n      throw new InvalidArgumentError('opts.origin must be a non-empty string or URL.')\n    }\n\n    const ref = this[kClients].get(key)\n\n    let dispatcher = ref ? ref.deref() : null\n    if (!dispatcher) {\n      dispatcher = this[kFactory](opts.origin, this[kOptions])\n        .on('drain', this[kOnDrain])\n        .on('connect', this[kOnConnect])\n        .on('disconnect', this[kOnDisconnect])\n        .on('connectionError', this[kOnConnectionError])\n\n      this[kClients].set(key, new WeakRef(dispatcher))\n      this[kFinalizer].register(dispatcher, key)\n    }\n\n    return dispatcher.dispatch(opts, handler)\n  }\n\n  async [kClose] () {\n    const closePromises = []\n    for (const ref of this[kClients].values()) {\n      const client = ref.deref()\n      /* istanbul ignore else: gc is undeterministic */\n      if (client) {\n        closePromises.push(client.close())\n      }\n    }\n\n    await Promise.all(closePromises)\n  }\n\n  async [kDestroy] (err) {\n    const destroyPromises = []\n    for (const ref of this[kClients].values()) {\n      const client = ref.deref()\n      /* istanbul ignore else: gc is undeterministic */\n      if (client) {\n        destroyPromises.push(client.destroy(err))\n      }\n    }\n\n    await Promise.all(destroyPromises)\n  }\n}\n\nmodule.exports = Agent\n","const { addAbortListener } = require('../core/util')\nconst { RequestAbortedError } = require('../core/errors')\n\nconst kListener = Symbol('kListener')\nconst kSignal = Symbol('kSignal')\n\nfunction abort (self) {\n  if (self.abort) {\n    self.abort()\n  } else {\n    self.onError(new RequestAbortedError())\n  }\n}\n\nfunction addSignal (self, signal) {\n  self[kSignal] = null\n  self[kListener] = null\n\n  if (!signal) {\n    return\n  }\n\n  if (signal.aborted) {\n    abort(self)\n    return\n  }\n\n  self[kSignal] = signal\n  self[kListener] = () => {\n    abort(self)\n  }\n\n  addAbortListener(self[kSignal], self[kListener])\n}\n\nfunction removeSignal (self) {\n  if (!self[kSignal]) {\n    return\n  }\n\n  if ('removeEventListener' in self[kSignal]) {\n    self[kSignal].removeEventListener('abort', self[kListener])\n  } else {\n    self[kSignal].removeListener('abort', self[kListener])\n  }\n\n  self[kSignal] = null\n  self[kListener] = null\n}\n\nmodule.exports = {\n  addSignal,\n  removeSignal\n}\n","'use strict'\n\nconst { AsyncResource } = require('async_hooks')\nconst { InvalidArgumentError, RequestAbortedError, SocketError } = require('../core/errors')\nconst util = require('../core/util')\nconst { addSignal, removeSignal } = require('./abort-signal')\n\nclass ConnectHandler extends AsyncResource {\n  constructor (opts, callback) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    if (typeof callback !== 'function') {\n      throw new InvalidArgumentError('invalid callback')\n    }\n\n    const { signal, opaque, responseHeaders } = opts\n\n    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n    }\n\n    super('UNDICI_CONNECT')\n\n    this.opaque = opaque || null\n    this.responseHeaders = responseHeaders || null\n    this.callback = callback\n    this.abort = null\n\n    addSignal(this, signal)\n  }\n\n  onConnect (abort, context) {\n    if (!this.callback) {\n      throw new RequestAbortedError()\n    }\n\n    this.abort = abort\n    this.context = context\n  }\n\n  onHeaders () {\n    throw new SocketError('bad connect', null)\n  }\n\n  onUpgrade (statusCode, rawHeaders, socket) {\n    const { callback, opaque, context } = this\n\n    removeSignal(this)\n\n    this.callback = null\n\n    let headers = rawHeaders\n    // Indicates is an HTTP2Session\n    if (headers != null) {\n      headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n    }\n\n    this.runInAsyncScope(callback, null, null, {\n      statusCode,\n      headers,\n      socket,\n      opaque,\n      context\n    })\n  }\n\n  onError (err) {\n    const { callback, opaque } = this\n\n    removeSignal(this)\n\n    if (callback) {\n      this.callback = null\n      queueMicrotask(() => {\n        this.runInAsyncScope(callback, null, err, { opaque })\n      })\n    }\n  }\n}\n\nfunction connect (opts, callback) {\n  if (callback === undefined) {\n    return new Promise((resolve, reject) => {\n      connect.call(this, opts, (err, data) => {\n        return err ? reject(err) : resolve(data)\n      })\n    })\n  }\n\n  try {\n    const connectHandler = new ConnectHandler(opts, callback)\n    this.dispatch({ ...opts, method: 'CONNECT' }, connectHandler)\n  } catch (err) {\n    if (typeof callback !== 'function') {\n      throw err\n    }\n    const opaque = opts && opts.opaque\n    queueMicrotask(() => callback(err, { opaque }))\n  }\n}\n\nmodule.exports = connect\n","'use strict'\n\nconst {\n  Readable,\n  Duplex,\n  PassThrough\n} = require('stream')\nconst {\n  InvalidArgumentError,\n  InvalidReturnValueError,\n  RequestAbortedError\n} = require('../core/errors')\nconst util = require('../core/util')\nconst { AsyncResource } = require('async_hooks')\nconst { addSignal, removeSignal } = require('./abort-signal')\nconst assert = require('assert')\n\nconst kResume = Symbol('resume')\n\nclass PipelineRequest extends Readable {\n  constructor () {\n    super({ autoDestroy: true })\n\n    this[kResume] = null\n  }\n\n  _read () {\n    const { [kResume]: resume } = this\n\n    if (resume) {\n      this[kResume] = null\n      resume()\n    }\n  }\n\n  _destroy (err, callback) {\n    this._read()\n\n    callback(err)\n  }\n}\n\nclass PipelineResponse extends Readable {\n  constructor (resume) {\n    super({ autoDestroy: true })\n    this[kResume] = resume\n  }\n\n  _read () {\n    this[kResume]()\n  }\n\n  _destroy (err, callback) {\n    if (!err && !this._readableState.endEmitted) {\n      err = new RequestAbortedError()\n    }\n\n    callback(err)\n  }\n}\n\nclass PipelineHandler extends AsyncResource {\n  constructor (opts, handler) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    if (typeof handler !== 'function') {\n      throw new InvalidArgumentError('invalid handler')\n    }\n\n    const { signal, method, opaque, onInfo, responseHeaders } = opts\n\n    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n    }\n\n    if (method === 'CONNECT') {\n      throw new InvalidArgumentError('invalid method')\n    }\n\n    if (onInfo && typeof onInfo !== 'function') {\n      throw new InvalidArgumentError('invalid onInfo callback')\n    }\n\n    super('UNDICI_PIPELINE')\n\n    this.opaque = opaque || null\n    this.responseHeaders = responseHeaders || null\n    this.handler = handler\n    this.abort = null\n    this.context = null\n    this.onInfo = onInfo || null\n\n    this.req = new PipelineRequest().on('error', util.nop)\n\n    this.ret = new Duplex({\n      readableObjectMode: opts.objectMode,\n      autoDestroy: true,\n      read: () => {\n        const { body } = this\n\n        if (body && body.resume) {\n          body.resume()\n        }\n      },\n      write: (chunk, encoding, callback) => {\n        const { req } = this\n\n        if (req.push(chunk, encoding) || req._readableState.destroyed) {\n          callback()\n        } else {\n          req[kResume] = callback\n        }\n      },\n      destroy: (err, callback) => {\n        const { body, req, res, ret, abort } = this\n\n        if (!err && !ret._readableState.endEmitted) {\n          err = new RequestAbortedError()\n        }\n\n        if (abort && err) {\n          abort()\n        }\n\n        util.destroy(body, err)\n        util.destroy(req, err)\n        util.destroy(res, err)\n\n        removeSignal(this)\n\n        callback(err)\n      }\n    }).on('prefinish', () => {\n      const { req } = this\n\n      // Node < 15 does not call _final in same tick.\n      req.push(null)\n    })\n\n    this.res = null\n\n    addSignal(this, signal)\n  }\n\n  onConnect (abort, context) {\n    const { ret, res } = this\n\n    assert(!res, 'pipeline cannot be retried')\n\n    if (ret.destroyed) {\n      throw new RequestAbortedError()\n    }\n\n    this.abort = abort\n    this.context = context\n  }\n\n  onHeaders (statusCode, rawHeaders, resume) {\n    const { opaque, handler, context } = this\n\n    if (statusCode < 200) {\n      if (this.onInfo) {\n        const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n        this.onInfo({ statusCode, headers })\n      }\n      return\n    }\n\n    this.res = new PipelineResponse(resume)\n\n    let body\n    try {\n      this.handler = null\n      const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n      body = this.runInAsyncScope(handler, null, {\n        statusCode,\n        headers,\n        opaque,\n        body: this.res,\n        context\n      })\n    } catch (err) {\n      this.res.on('error', util.nop)\n      throw err\n    }\n\n    if (!body || typeof body.on !== 'function') {\n      throw new InvalidReturnValueError('expected Readable')\n    }\n\n    body\n      .on('data', (chunk) => {\n        const { ret, body } = this\n\n        if (!ret.push(chunk) && body.pause) {\n          body.pause()\n        }\n      })\n      .on('error', (err) => {\n        const { ret } = this\n\n        util.destroy(ret, err)\n      })\n      .on('end', () => {\n        const { ret } = this\n\n        ret.push(null)\n      })\n      .on('close', () => {\n        const { ret } = this\n\n        if (!ret._readableState.ended) {\n          util.destroy(ret, new RequestAbortedError())\n        }\n      })\n\n    this.body = body\n  }\n\n  onData (chunk) {\n    const { res } = this\n    return res.push(chunk)\n  }\n\n  onComplete (trailers) {\n    const { res } = this\n    res.push(null)\n  }\n\n  onError (err) {\n    const { ret } = this\n    this.handler = null\n    util.destroy(ret, err)\n  }\n}\n\nfunction pipeline (opts, handler) {\n  try {\n    const pipelineHandler = new PipelineHandler(opts, handler)\n    this.dispatch({ ...opts, body: pipelineHandler.req }, pipelineHandler)\n    return pipelineHandler.ret\n  } catch (err) {\n    return new PassThrough().destroy(err)\n  }\n}\n\nmodule.exports = pipeline\n","'use strict'\n\nconst Readable = require('./readable')\nconst {\n  InvalidArgumentError,\n  RequestAbortedError\n} = require('../core/errors')\nconst util = require('../core/util')\nconst { getResolveErrorBodyCallback } = require('./util')\nconst { AsyncResource } = require('async_hooks')\nconst { addSignal, removeSignal } = require('./abort-signal')\n\nclass RequestHandler extends AsyncResource {\n  constructor (opts, callback) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    const { signal, method, opaque, body, onInfo, responseHeaders, throwOnError, highWaterMark } = opts\n\n    try {\n      if (typeof callback !== 'function') {\n        throw new InvalidArgumentError('invalid callback')\n      }\n\n      if (highWaterMark && (typeof highWaterMark !== 'number' || highWaterMark < 0)) {\n        throw new InvalidArgumentError('invalid highWaterMark')\n      }\n\n      if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n        throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n      }\n\n      if (method === 'CONNECT') {\n        throw new InvalidArgumentError('invalid method')\n      }\n\n      if (onInfo && typeof onInfo !== 'function') {\n        throw new InvalidArgumentError('invalid onInfo callback')\n      }\n\n      super('UNDICI_REQUEST')\n    } catch (err) {\n      if (util.isStream(body)) {\n        util.destroy(body.on('error', util.nop), err)\n      }\n      throw err\n    }\n\n    this.responseHeaders = responseHeaders || null\n    this.opaque = opaque || null\n    this.callback = callback\n    this.res = null\n    this.abort = null\n    this.body = body\n    this.trailers = {}\n    this.context = null\n    this.onInfo = onInfo || null\n    this.throwOnError = throwOnError\n    this.highWaterMark = highWaterMark\n\n    if (util.isStream(body)) {\n      body.on('error', (err) => {\n        this.onError(err)\n      })\n    }\n\n    addSignal(this, signal)\n  }\n\n  onConnect (abort, context) {\n    if (!this.callback) {\n      throw new RequestAbortedError()\n    }\n\n    this.abort = abort\n    this.context = context\n  }\n\n  onHeaders (statusCode, rawHeaders, resume, statusMessage) {\n    const { callback, opaque, abort, context, responseHeaders, highWaterMark } = this\n\n    const headers = responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n\n    if (statusCode < 200) {\n      if (this.onInfo) {\n        this.onInfo({ statusCode, headers })\n      }\n      return\n    }\n\n    const parsedHeaders = responseHeaders === 'raw' ? util.parseHeaders(rawHeaders) : headers\n    const contentType = parsedHeaders['content-type']\n    const body = new Readable({ resume, abort, contentType, highWaterMark })\n\n    this.callback = null\n    this.res = body\n    if (callback !== null) {\n      if (this.throwOnError && statusCode >= 400) {\n        this.runInAsyncScope(getResolveErrorBodyCallback, null,\n          { callback, body, contentType, statusCode, statusMessage, headers }\n        )\n      } else {\n        this.runInAsyncScope(callback, null, null, {\n          statusCode,\n          headers,\n          trailers: this.trailers,\n          opaque,\n          body,\n          context\n        })\n      }\n    }\n  }\n\n  onData (chunk) {\n    const { res } = this\n    return res.push(chunk)\n  }\n\n  onComplete (trailers) {\n    const { res } = this\n\n    removeSignal(this)\n\n    util.parseHeaders(trailers, this.trailers)\n\n    res.push(null)\n  }\n\n  onError (err) {\n    const { res, callback, body, opaque } = this\n\n    removeSignal(this)\n\n    if (callback) {\n      // TODO: Does this need queueMicrotask?\n      this.callback = null\n      queueMicrotask(() => {\n        this.runInAsyncScope(callback, null, err, { opaque })\n      })\n    }\n\n    if (res) {\n      this.res = null\n      // Ensure all queued handlers are invoked before destroying res.\n      queueMicrotask(() => {\n        util.destroy(res, err)\n      })\n    }\n\n    if (body) {\n      this.body = null\n      util.destroy(body, err)\n    }\n  }\n}\n\nfunction request (opts, callback) {\n  if (callback === undefined) {\n    return new Promise((resolve, reject) => {\n      request.call(this, opts, (err, data) => {\n        return err ? reject(err) : resolve(data)\n      })\n    })\n  }\n\n  try {\n    this.dispatch(opts, new RequestHandler(opts, callback))\n  } catch (err) {\n    if (typeof callback !== 'function') {\n      throw err\n    }\n    const opaque = opts && opts.opaque\n    queueMicrotask(() => callback(err, { opaque }))\n  }\n}\n\nmodule.exports = request\nmodule.exports.RequestHandler = RequestHandler\n","'use strict'\n\nconst { finished, PassThrough } = require('stream')\nconst {\n  InvalidArgumentError,\n  InvalidReturnValueError,\n  RequestAbortedError\n} = require('../core/errors')\nconst util = require('../core/util')\nconst { getResolveErrorBodyCallback } = require('./util')\nconst { AsyncResource } = require('async_hooks')\nconst { addSignal, removeSignal } = require('./abort-signal')\n\nclass StreamHandler extends AsyncResource {\n  constructor (opts, factory, callback) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    const { signal, method, opaque, body, onInfo, responseHeaders, throwOnError } = opts\n\n    try {\n      if (typeof callback !== 'function') {\n        throw new InvalidArgumentError('invalid callback')\n      }\n\n      if (typeof factory !== 'function') {\n        throw new InvalidArgumentError('invalid factory')\n      }\n\n      if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n        throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n      }\n\n      if (method === 'CONNECT') {\n        throw new InvalidArgumentError('invalid method')\n      }\n\n      if (onInfo && typeof onInfo !== 'function') {\n        throw new InvalidArgumentError('invalid onInfo callback')\n      }\n\n      super('UNDICI_STREAM')\n    } catch (err) {\n      if (util.isStream(body)) {\n        util.destroy(body.on('error', util.nop), err)\n      }\n      throw err\n    }\n\n    this.responseHeaders = responseHeaders || null\n    this.opaque = opaque || null\n    this.factory = factory\n    this.callback = callback\n    this.res = null\n    this.abort = null\n    this.context = null\n    this.trailers = null\n    this.body = body\n    this.onInfo = onInfo || null\n    this.throwOnError = throwOnError || false\n\n    if (util.isStream(body)) {\n      body.on('error', (err) => {\n        this.onError(err)\n      })\n    }\n\n    addSignal(this, signal)\n  }\n\n  onConnect (abort, context) {\n    if (!this.callback) {\n      throw new RequestAbortedError()\n    }\n\n    this.abort = abort\n    this.context = context\n  }\n\n  onHeaders (statusCode, rawHeaders, resume, statusMessage) {\n    const { factory, opaque, context, callback, responseHeaders } = this\n\n    const headers = responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n\n    if (statusCode < 200) {\n      if (this.onInfo) {\n        this.onInfo({ statusCode, headers })\n      }\n      return\n    }\n\n    this.factory = null\n\n    let res\n\n    if (this.throwOnError && statusCode >= 400) {\n      const parsedHeaders = responseHeaders === 'raw' ? util.parseHeaders(rawHeaders) : headers\n      const contentType = parsedHeaders['content-type']\n      res = new PassThrough()\n\n      this.callback = null\n      this.runInAsyncScope(getResolveErrorBodyCallback, null,\n        { callback, body: res, contentType, statusCode, statusMessage, headers }\n      )\n    } else {\n      if (factory === null) {\n        return\n      }\n\n      res = this.runInAsyncScope(factory, null, {\n        statusCode,\n        headers,\n        opaque,\n        context\n      })\n\n      if (\n        !res ||\n        typeof res.write !== 'function' ||\n        typeof res.end !== 'function' ||\n        typeof res.on !== 'function'\n      ) {\n        throw new InvalidReturnValueError('expected Writable')\n      }\n\n      // TODO: Avoid finished. It registers an unnecessary amount of listeners.\n      finished(res, { readable: false }, (err) => {\n        const { callback, res, opaque, trailers, abort } = this\n\n        this.res = null\n        if (err || !res.readable) {\n          util.destroy(res, err)\n        }\n\n        this.callback = null\n        this.runInAsyncScope(callback, null, err || null, { opaque, trailers })\n\n        if (err) {\n          abort()\n        }\n      })\n    }\n\n    res.on('drain', resume)\n\n    this.res = res\n\n    const needDrain = res.writableNeedDrain !== undefined\n      ? res.writableNeedDrain\n      : res._writableState && res._writableState.needDrain\n\n    return needDrain !== true\n  }\n\n  onData (chunk) {\n    const { res } = this\n\n    return res ? res.write(chunk) : true\n  }\n\n  onComplete (trailers) {\n    const { res } = this\n\n    removeSignal(this)\n\n    if (!res) {\n      return\n    }\n\n    this.trailers = util.parseHeaders(trailers)\n\n    res.end()\n  }\n\n  onError (err) {\n    const { res, callback, opaque, body } = this\n\n    removeSignal(this)\n\n    this.factory = null\n\n    if (res) {\n      this.res = null\n      util.destroy(res, err)\n    } else if (callback) {\n      this.callback = null\n      queueMicrotask(() => {\n        this.runInAsyncScope(callback, null, err, { opaque })\n      })\n    }\n\n    if (body) {\n      this.body = null\n      util.destroy(body, err)\n    }\n  }\n}\n\nfunction stream (opts, factory, callback) {\n  if (callback === undefined) {\n    return new Promise((resolve, reject) => {\n      stream.call(this, opts, factory, (err, data) => {\n        return err ? reject(err) : resolve(data)\n      })\n    })\n  }\n\n  try {\n    this.dispatch(opts, new StreamHandler(opts, factory, callback))\n  } catch (err) {\n    if (typeof callback !== 'function') {\n      throw err\n    }\n    const opaque = opts && opts.opaque\n    queueMicrotask(() => callback(err, { opaque }))\n  }\n}\n\nmodule.exports = stream\n","'use strict'\n\nconst { InvalidArgumentError, RequestAbortedError, SocketError } = require('../core/errors')\nconst { AsyncResource } = require('async_hooks')\nconst util = require('../core/util')\nconst { addSignal, removeSignal } = require('./abort-signal')\nconst assert = require('assert')\n\nclass UpgradeHandler extends AsyncResource {\n  constructor (opts, callback) {\n    if (!opts || typeof opts !== 'object') {\n      throw new InvalidArgumentError('invalid opts')\n    }\n\n    if (typeof callback !== 'function') {\n      throw new InvalidArgumentError('invalid callback')\n    }\n\n    const { signal, opaque, responseHeaders } = opts\n\n    if (signal && typeof signal.on !== 'function' && typeof signal.addEventListener !== 'function') {\n      throw new InvalidArgumentError('signal must be an EventEmitter or EventTarget')\n    }\n\n    super('UNDICI_UPGRADE')\n\n    this.responseHeaders = responseHeaders || null\n    this.opaque = opaque || null\n    this.callback = callback\n    this.abort = null\n    this.context = null\n\n    addSignal(this, signal)\n  }\n\n  onConnect (abort, context) {\n    if (!this.callback) {\n      throw new RequestAbortedError()\n    }\n\n    this.abort = abort\n    this.context = null\n  }\n\n  onHeaders () {\n    throw new SocketError('bad upgrade', null)\n  }\n\n  onUpgrade (statusCode, rawHeaders, socket) {\n    const { callback, opaque, context } = this\n\n    assert.strictEqual(statusCode, 101)\n\n    removeSignal(this)\n\n    this.callback = null\n    const headers = this.responseHeaders === 'raw' ? util.parseRawHeaders(rawHeaders) : util.parseHeaders(rawHeaders)\n    this.runInAsyncScope(callback, null, null, {\n      headers,\n      socket,\n      opaque,\n      context\n    })\n  }\n\n  onError (err) {\n    const { callback, opaque } = this\n\n    removeSignal(this)\n\n    if (callback) {\n      this.callback = null\n      queueMicrotask(() => {\n        this.runInAsyncScope(callback, null, err, { opaque })\n      })\n    }\n  }\n}\n\nfunction upgrade (opts, callback) {\n  if (callback === undefined) {\n    return new Promise((resolve, reject) => {\n      upgrade.call(this, opts, (err, data) => {\n        return err ? reject(err) : resolve(data)\n      })\n    })\n  }\n\n  try {\n    const upgradeHandler = new UpgradeHandler(opts, callback)\n    this.dispatch({\n      ...opts,\n      method: opts.method || 'GET',\n      upgrade: opts.protocol || 'Websocket'\n    }, upgradeHandler)\n  } catch (err) {\n    if (typeof callback !== 'function') {\n      throw err\n    }\n    const opaque = opts && opts.opaque\n    queueMicrotask(() => callback(err, { opaque }))\n  }\n}\n\nmodule.exports = upgrade\n","'use strict'\n\nmodule.exports.request = require('./api-request')\nmodule.exports.stream = require('./api-stream')\nmodule.exports.pipeline = require('./api-pipeline')\nmodule.exports.upgrade = require('./api-upgrade')\nmodule.exports.connect = require('./api-connect')\n","// Ported from https://github.com/nodejs/undici/pull/907\n\n'use strict'\n\nconst assert = require('assert')\nconst { Readable } = require('stream')\nconst { RequestAbortedError, NotSupportedError, InvalidArgumentError } = require('../core/errors')\nconst util = require('../core/util')\nconst { ReadableStreamFrom, toUSVString } = require('../core/util')\n\nlet Blob\n\nconst kConsume = Symbol('kConsume')\nconst kReading = Symbol('kReading')\nconst kBody = Symbol('kBody')\nconst kAbort = Symbol('abort')\nconst kContentType = Symbol('kContentType')\n\nconst noop = () => {}\n\nmodule.exports = class BodyReadable extends Readable {\n  constructor ({\n    resume,\n    abort,\n    contentType = '',\n    highWaterMark = 64 * 1024 // Same as nodejs fs streams.\n  }) {\n    super({\n      autoDestroy: true,\n      read: resume,\n      highWaterMark\n    })\n\n    this._readableState.dataEmitted = false\n\n    this[kAbort] = abort\n    this[kConsume] = null\n    this[kBody] = null\n    this[kContentType] = contentType\n\n    // Is stream being consumed through Readable API?\n    // This is an optimization so that we avoid checking\n    // for 'data' and 'readable' listeners in the hot path\n    // inside push().\n    this[kReading] = false\n  }\n\n  destroy (err) {\n    if (this.destroyed) {\n      // Node < 16\n      return this\n    }\n\n    if (!err && !this._readableState.endEmitted) {\n      err = new RequestAbortedError()\n    }\n\n    if (err) {\n      this[kAbort]()\n    }\n\n    return super.destroy(err)\n  }\n\n  emit (ev, ...args) {\n    if (ev === 'data') {\n      // Node < 16.7\n      this._readableState.dataEmitted = true\n    } else if (ev === 'error') {\n      // Node < 16\n      this._readableState.errorEmitted = true\n    }\n    return super.emit(ev, ...args)\n  }\n\n  on (ev, ...args) {\n    if (ev === 'data' || ev === 'readable') {\n      this[kReading] = true\n    }\n    return super.on(ev, ...args)\n  }\n\n  addListener (ev, ...args) {\n    return this.on(ev, ...args)\n  }\n\n  off (ev, ...args) {\n    const ret = super.off(ev, ...args)\n    if (ev === 'data' || ev === 'readable') {\n      this[kReading] = (\n        this.listenerCount('data') > 0 ||\n        this.listenerCount('readable') > 0\n      )\n    }\n    return ret\n  }\n\n  removeListener (ev, ...args) {\n    return this.off(ev, ...args)\n  }\n\n  push (chunk) {\n    if (this[kConsume] && chunk !== null && this.readableLength === 0) {\n      consumePush(this[kConsume], chunk)\n      return this[kReading] ? super.push(chunk) : true\n    }\n    return super.push(chunk)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-text\n  async text () {\n    return consume(this, 'text')\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-json\n  async json () {\n    return consume(this, 'json')\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-blob\n  async blob () {\n    return consume(this, 'blob')\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-arraybuffer\n  async arrayBuffer () {\n    return consume(this, 'arrayBuffer')\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-formdata\n  async formData () {\n    // TODO: Implement.\n    throw new NotSupportedError()\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-bodyused\n  get bodyUsed () {\n    return util.isDisturbed(this)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-body-body\n  get body () {\n    if (!this[kBody]) {\n      this[kBody] = ReadableStreamFrom(this)\n      if (this[kConsume]) {\n        // TODO: Is this the best way to force a lock?\n        this[kBody].getReader() // Ensure stream is locked.\n        assert(this[kBody].locked)\n      }\n    }\n    return this[kBody]\n  }\n\n  dump (opts) {\n    let limit = opts && Number.isFinite(opts.limit) ? opts.limit : 262144\n    const signal = opts && opts.signal\n\n    if (signal) {\n      try {\n        if (typeof signal !== 'object' || !('aborted' in signal)) {\n          throw new InvalidArgumentError('signal must be an AbortSignal')\n        }\n        util.throwIfAborted(signal)\n      } catch (err) {\n        return Promise.reject(err)\n      }\n    }\n\n    if (this.closed) {\n      return Promise.resolve(null)\n    }\n\n    return new Promise((resolve, reject) => {\n      const signalListenerCleanup = signal\n        ? util.addAbortListener(signal, () => {\n          this.destroy()\n        })\n        : noop\n\n      this\n        .on('close', function () {\n          signalListenerCleanup()\n          if (signal && signal.aborted) {\n            reject(signal.reason || Object.assign(new Error('The operation was aborted'), { name: 'AbortError' }))\n          } else {\n            resolve(null)\n          }\n        })\n        .on('error', noop)\n        .on('data', function (chunk) {\n          limit -= chunk.length\n          if (limit <= 0) {\n            this.destroy()\n          }\n        })\n        .resume()\n    })\n  }\n}\n\n// https://streams.spec.whatwg.org/#readablestream-locked\nfunction isLocked (self) {\n  // Consume is an implicit lock.\n  return (self[kBody] && self[kBody].locked === true) || self[kConsume]\n}\n\n// https://fetch.spec.whatwg.org/#body-unusable\nfunction isUnusable (self) {\n  return util.isDisturbed(self) || isLocked(self)\n}\n\nasync function consume (stream, type) {\n  if (isUnusable(stream)) {\n    throw new TypeError('unusable')\n  }\n\n  assert(!stream[kConsume])\n\n  return new Promise((resolve, reject) => {\n    stream[kConsume] = {\n      type,\n      stream,\n      resolve,\n      reject,\n      length: 0,\n      body: []\n    }\n\n    stream\n      .on('error', function (err) {\n        consumeFinish(this[kConsume], err)\n      })\n      .on('close', function () {\n        if (this[kConsume].body !== null) {\n          consumeFinish(this[kConsume], new RequestAbortedError())\n        }\n      })\n\n    process.nextTick(consumeStart, stream[kConsume])\n  })\n}\n\nfunction consumeStart (consume) {\n  if (consume.body === null) {\n    return\n  }\n\n  const { _readableState: state } = consume.stream\n\n  for (const chunk of state.buffer) {\n    consumePush(consume, chunk)\n  }\n\n  if (state.endEmitted) {\n    consumeEnd(this[kConsume])\n  } else {\n    consume.stream.on('end', function () {\n      consumeEnd(this[kConsume])\n    })\n  }\n\n  consume.stream.resume()\n\n  while (consume.stream.read() != null) {\n    // Loop\n  }\n}\n\nfunction consumeEnd (consume) {\n  const { type, body, resolve, stream, length } = consume\n\n  try {\n    if (type === 'text') {\n      resolve(toUSVString(Buffer.concat(body)))\n    } else if (type === 'json') {\n      resolve(JSON.parse(Buffer.concat(body)))\n    } else if (type === 'arrayBuffer') {\n      const dst = new Uint8Array(length)\n\n      let pos = 0\n      for (const buf of body) {\n        dst.set(buf, pos)\n        pos += buf.byteLength\n      }\n\n      resolve(dst.buffer)\n    } else if (type === 'blob') {\n      if (!Blob) {\n        Blob = require('buffer').Blob\n      }\n      resolve(new Blob(body, { type: stream[kContentType] }))\n    }\n\n    consumeFinish(consume)\n  } catch (err) {\n    stream.destroy(err)\n  }\n}\n\nfunction consumePush (consume, chunk) {\n  consume.length += chunk.length\n  consume.body.push(chunk)\n}\n\nfunction consumeFinish (consume, err) {\n  if (consume.body === null) {\n    return\n  }\n\n  if (err) {\n    consume.reject(err)\n  } else {\n    consume.resolve()\n  }\n\n  consume.type = null\n  consume.stream = null\n  consume.resolve = null\n  consume.reject = null\n  consume.length = 0\n  consume.body = null\n}\n","const assert = require('assert')\nconst {\n  ResponseStatusCodeError\n} = require('../core/errors')\nconst { toUSVString } = require('../core/util')\n\nasync function getResolveErrorBodyCallback ({ callback, body, contentType, statusCode, statusMessage, headers }) {\n  assert(body)\n\n  let chunks = []\n  let limit = 0\n\n  for await (const chunk of body) {\n    chunks.push(chunk)\n    limit += chunk.length\n    if (limit > 128 * 1024) {\n      chunks = null\n      break\n    }\n  }\n\n  if (statusCode === 204 || !contentType || !chunks) {\n    process.nextTick(callback, new ResponseStatusCodeError(`Response status code ${statusCode}${statusMessage ? `: ${statusMessage}` : ''}`, statusCode, headers))\n    return\n  }\n\n  try {\n    if (contentType.startsWith('application/json')) {\n      const payload = JSON.parse(toUSVString(Buffer.concat(chunks)))\n      process.nextTick(callback, new ResponseStatusCodeError(`Response status code ${statusCode}${statusMessage ? `: ${statusMessage}` : ''}`, statusCode, headers, payload))\n      return\n    }\n\n    if (contentType.startsWith('text/')) {\n      const payload = toUSVString(Buffer.concat(chunks))\n      process.nextTick(callback, new ResponseStatusCodeError(`Response status code ${statusCode}${statusMessage ? `: ${statusMessage}` : ''}`, statusCode, headers, payload))\n      return\n    }\n  } catch (err) {\n    // Process in a fallback if error\n  }\n\n  process.nextTick(callback, new ResponseStatusCodeError(`Response status code ${statusCode}${statusMessage ? `: ${statusMessage}` : ''}`, statusCode, headers))\n}\n\nmodule.exports = { getResolveErrorBodyCallback }\n","'use strict'\n\nconst {\n  BalancedPoolMissingUpstreamError,\n  InvalidArgumentError\n} = require('./core/errors')\nconst {\n  PoolBase,\n  kClients,\n  kNeedDrain,\n  kAddClient,\n  kRemoveClient,\n  kGetDispatcher\n} = require('./pool-base')\nconst Pool = require('./pool')\nconst { kUrl, kInterceptors } = require('./core/symbols')\nconst { parseOrigin } = require('./core/util')\nconst kFactory = Symbol('factory')\n\nconst kOptions = Symbol('options')\nconst kGreatestCommonDivisor = Symbol('kGreatestCommonDivisor')\nconst kCurrentWeight = Symbol('kCurrentWeight')\nconst kIndex = Symbol('kIndex')\nconst kWeight = Symbol('kWeight')\nconst kMaxWeightPerServer = Symbol('kMaxWeightPerServer')\nconst kErrorPenalty = Symbol('kErrorPenalty')\n\nfunction getGreatestCommonDivisor (a, b) {\n  if (b === 0) return a\n  return getGreatestCommonDivisor(b, a % b)\n}\n\nfunction defaultFactory (origin, opts) {\n  return new Pool(origin, opts)\n}\n\nclass BalancedPool extends PoolBase {\n  constructor (upstreams = [], { factory = defaultFactory, ...opts } = {}) {\n    super()\n\n    this[kOptions] = opts\n    this[kIndex] = -1\n    this[kCurrentWeight] = 0\n\n    this[kMaxWeightPerServer] = this[kOptions].maxWeightPerServer || 100\n    this[kErrorPenalty] = this[kOptions].errorPenalty || 15\n\n    if (!Array.isArray(upstreams)) {\n      upstreams = [upstreams]\n    }\n\n    if (typeof factory !== 'function') {\n      throw new InvalidArgumentError('factory must be a function.')\n    }\n\n    this[kInterceptors] = opts.interceptors && opts.interceptors.BalancedPool && Array.isArray(opts.interceptors.BalancedPool)\n      ? opts.interceptors.BalancedPool\n      : []\n    this[kFactory] = factory\n\n    for (const upstream of upstreams) {\n      this.addUpstream(upstream)\n    }\n    this._updateBalancedPoolStats()\n  }\n\n  addUpstream (upstream) {\n    const upstreamOrigin = parseOrigin(upstream).origin\n\n    if (this[kClients].find((pool) => (\n      pool[kUrl].origin === upstreamOrigin &&\n      pool.closed !== true &&\n      pool.destroyed !== true\n    ))) {\n      return this\n    }\n    const pool = this[kFactory](upstreamOrigin, Object.assign({}, this[kOptions]))\n\n    this[kAddClient](pool)\n    pool.on('connect', () => {\n      pool[kWeight] = Math.min(this[kMaxWeightPerServer], pool[kWeight] + this[kErrorPenalty])\n    })\n\n    pool.on('connectionError', () => {\n      pool[kWeight] = Math.max(1, pool[kWeight] - this[kErrorPenalty])\n      this._updateBalancedPoolStats()\n    })\n\n    pool.on('disconnect', (...args) => {\n      const err = args[2]\n      if (err && err.code === 'UND_ERR_SOCKET') {\n        // decrease the weight of the pool.\n        pool[kWeight] = Math.max(1, pool[kWeight] - this[kErrorPenalty])\n        this._updateBalancedPoolStats()\n      }\n    })\n\n    for (const client of this[kClients]) {\n      client[kWeight] = this[kMaxWeightPerServer]\n    }\n\n    this._updateBalancedPoolStats()\n\n    return this\n  }\n\n  _updateBalancedPoolStats () {\n    this[kGreatestCommonDivisor] = this[kClients].map(p => p[kWeight]).reduce(getGreatestCommonDivisor, 0)\n  }\n\n  removeUpstream (upstream) {\n    const upstreamOrigin = parseOrigin(upstream).origin\n\n    const pool = this[kClients].find((pool) => (\n      pool[kUrl].origin === upstreamOrigin &&\n      pool.closed !== true &&\n      pool.destroyed !== true\n    ))\n\n    if (pool) {\n      this[kRemoveClient](pool)\n    }\n\n    return this\n  }\n\n  get upstreams () {\n    return this[kClients]\n      .filter(dispatcher => dispatcher.closed !== true && dispatcher.destroyed !== true)\n      .map((p) => p[kUrl].origin)\n  }\n\n  [kGetDispatcher] () {\n    // We validate that pools is greater than 0,\n    // otherwise we would have to wait until an upstream\n    // is added, which might never happen.\n    if (this[kClients].length === 0) {\n      throw new BalancedPoolMissingUpstreamError()\n    }\n\n    const dispatcher = this[kClients].find(dispatcher => (\n      !dispatcher[kNeedDrain] &&\n      dispatcher.closed !== true &&\n      dispatcher.destroyed !== true\n    ))\n\n    if (!dispatcher) {\n      return\n    }\n\n    const allClientsBusy = this[kClients].map(pool => pool[kNeedDrain]).reduce((a, b) => a && b, true)\n\n    if (allClientsBusy) {\n      return\n    }\n\n    let counter = 0\n\n    let maxWeightIndex = this[kClients].findIndex(pool => !pool[kNeedDrain])\n\n    while (counter++ < this[kClients].length) {\n      this[kIndex] = (this[kIndex] + 1) % this[kClients].length\n      const pool = this[kClients][this[kIndex]]\n\n      // find pool index with the largest weight\n      if (pool[kWeight] > this[kClients][maxWeightIndex][kWeight] && !pool[kNeedDrain]) {\n        maxWeightIndex = this[kIndex]\n      }\n\n      // decrease the current weight every `this[kClients].length`.\n      if (this[kIndex] === 0) {\n        // Set the current weight to the next lower weight.\n        this[kCurrentWeight] = this[kCurrentWeight] - this[kGreatestCommonDivisor]\n\n        if (this[kCurrentWeight] <= 0) {\n          this[kCurrentWeight] = this[kMaxWeightPerServer]\n        }\n      }\n      if (pool[kWeight] >= this[kCurrentWeight] && (!pool[kNeedDrain])) {\n        return pool\n      }\n    }\n\n    this[kCurrentWeight] = this[kClients][maxWeightIndex][kWeight]\n    this[kIndex] = maxWeightIndex\n    return this[kClients][maxWeightIndex]\n  }\n}\n\nmodule.exports = BalancedPool\n","'use strict'\n\nconst { kConstruct } = require('./symbols')\nconst { urlEquals, fieldValues: getFieldValues } = require('./util')\nconst { kEnumerableProperty, isDisturbed } = require('../core/util')\nconst { kHeadersList } = require('../core/symbols')\nconst { webidl } = require('../fetch/webidl')\nconst { Response, cloneResponse } = require('../fetch/response')\nconst { Request } = require('../fetch/request')\nconst { kState, kHeaders, kGuard, kRealm } = require('../fetch/symbols')\nconst { fetching } = require('../fetch/index')\nconst { urlIsHttpHttpsScheme, createDeferredPromise, readAllBytes } = require('../fetch/util')\nconst assert = require('assert')\nconst { getGlobalDispatcher } = require('../global')\n\n/**\n * @see https://w3c.github.io/ServiceWorker/#dfn-cache-batch-operation\n * @typedef {Object} CacheBatchOperation\n * @property {'delete' | 'put'} type\n * @property {any} request\n * @property {any} response\n * @property {import('../../types/cache').CacheQueryOptions} options\n */\n\n/**\n * @see https://w3c.github.io/ServiceWorker/#dfn-request-response-list\n * @typedef {[any, any][]} requestResponseList\n */\n\nclass Cache {\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#dfn-relevant-request-response-list\n   * @type {requestResponseList}\n   */\n  #relevantRequestResponseList\n\n  constructor () {\n    if (arguments[0] !== kConstruct) {\n      webidl.illegalConstructor()\n    }\n\n    this.#relevantRequestResponseList = arguments[1]\n  }\n\n  async match (request, options = {}) {\n    webidl.brandCheck(this, Cache)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Cache.match' })\n\n    request = webidl.converters.RequestInfo(request)\n    options = webidl.converters.CacheQueryOptions(options)\n\n    const p = await this.matchAll(request, options)\n\n    if (p.length === 0) {\n      return\n    }\n\n    return p[0]\n  }\n\n  async matchAll (request = undefined, options = {}) {\n    webidl.brandCheck(this, Cache)\n\n    if (request !== undefined) request = webidl.converters.RequestInfo(request)\n    options = webidl.converters.CacheQueryOptions(options)\n\n    // 1.\n    let r = null\n\n    // 2.\n    if (request !== undefined) {\n      if (request instanceof Request) {\n        // 2.1.1\n        r = request[kState]\n\n        // 2.1.2\n        if (r.method !== 'GET' && !options.ignoreMethod) {\n          return []\n        }\n      } else if (typeof request === 'string') {\n        // 2.2.1\n        r = new Request(request)[kState]\n      }\n    }\n\n    // 5.\n    // 5.1\n    const responses = []\n\n    // 5.2\n    if (request === undefined) {\n      // 5.2.1\n      for (const requestResponse of this.#relevantRequestResponseList) {\n        responses.push(requestResponse[1])\n      }\n    } else { // 5.3\n      // 5.3.1\n      const requestResponses = this.#queryCache(r, options)\n\n      // 5.3.2\n      for (const requestResponse of requestResponses) {\n        responses.push(requestResponse[1])\n      }\n    }\n\n    // 5.4\n    // We don't implement CORs so we don't need to loop over the responses, yay!\n\n    // 5.5.1\n    const responseList = []\n\n    // 5.5.2\n    for (const response of responses) {\n      // 5.5.2.1\n      const responseObject = new Response(response.body?.source ?? null)\n      const body = responseObject[kState].body\n      responseObject[kState] = response\n      responseObject[kState].body = body\n      responseObject[kHeaders][kHeadersList] = response.headersList\n      responseObject[kHeaders][kGuard] = 'immutable'\n\n      responseList.push(responseObject)\n    }\n\n    // 6.\n    return Object.freeze(responseList)\n  }\n\n  async add (request) {\n    webidl.brandCheck(this, Cache)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Cache.add' })\n\n    request = webidl.converters.RequestInfo(request)\n\n    // 1.\n    const requests = [request]\n\n    // 2.\n    const responseArrayPromise = this.addAll(requests)\n\n    // 3.\n    return await responseArrayPromise\n  }\n\n  async addAll (requests) {\n    webidl.brandCheck(this, Cache)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Cache.addAll' })\n\n    requests = webidl.converters['sequence<RequestInfo>'](requests)\n\n    // 1.\n    const responsePromises = []\n\n    // 2.\n    const requestList = []\n\n    // 3.\n    for (const request of requests) {\n      if (typeof request === 'string') {\n        continue\n      }\n\n      // 3.1\n      const r = request[kState]\n\n      // 3.2\n      if (!urlIsHttpHttpsScheme(r.url) || r.method !== 'GET') {\n        throw webidl.errors.exception({\n          header: 'Cache.addAll',\n          message: 'Expected http/s scheme when method is not GET.'\n        })\n      }\n    }\n\n    // 4.\n    /** @type {ReturnType<typeof fetching>[]} */\n    const fetchControllers = []\n\n    // 5.\n    for (const request of requests) {\n      // 5.1\n      const r = new Request(request)[kState]\n\n      // 5.2\n      if (!urlIsHttpHttpsScheme(r.url)) {\n        throw webidl.errors.exception({\n          header: 'Cache.addAll',\n          message: 'Expected http/s scheme.'\n        })\n      }\n\n      // 5.4\n      r.initiator = 'fetch'\n      r.destination = 'subresource'\n\n      // 5.5\n      requestList.push(r)\n\n      // 5.6\n      const responsePromise = createDeferredPromise()\n\n      // 5.7\n      fetchControllers.push(fetching({\n        request: r,\n        dispatcher: getGlobalDispatcher(),\n        processResponse (response) {\n          // 1.\n          if (response.type === 'error' || response.status === 206 || response.status < 200 || response.status > 299) {\n            responsePromise.reject(webidl.errors.exception({\n              header: 'Cache.addAll',\n              message: 'Received an invalid status code or the request failed.'\n            }))\n          } else if (response.headersList.contains('vary')) { // 2.\n            // 2.1\n            const fieldValues = getFieldValues(response.headersList.get('vary'))\n\n            // 2.2\n            for (const fieldValue of fieldValues) {\n              // 2.2.1\n              if (fieldValue === '*') {\n                responsePromise.reject(webidl.errors.exception({\n                  header: 'Cache.addAll',\n                  message: 'invalid vary field value'\n                }))\n\n                for (const controller of fetchControllers) {\n                  controller.abort()\n                }\n\n                return\n              }\n            }\n          }\n        },\n        processResponseEndOfBody (response) {\n          // 1.\n          if (response.aborted) {\n            responsePromise.reject(new DOMException('aborted', 'AbortError'))\n            return\n          }\n\n          // 2.\n          responsePromise.resolve(response)\n        }\n      }))\n\n      // 5.8\n      responsePromises.push(responsePromise.promise)\n    }\n\n    // 6.\n    const p = Promise.all(responsePromises)\n\n    // 7.\n    const responses = await p\n\n    // 7.1\n    const operations = []\n\n    // 7.2\n    let index = 0\n\n    // 7.3\n    for (const response of responses) {\n      // 7.3.1\n      /** @type {CacheBatchOperation} */\n      const operation = {\n        type: 'put', // 7.3.2\n        request: requestList[index], // 7.3.3\n        response // 7.3.4\n      }\n\n      operations.push(operation) // 7.3.5\n\n      index++ // 7.3.6\n    }\n\n    // 7.5\n    const cacheJobPromise = createDeferredPromise()\n\n    // 7.6.1\n    let errorData = null\n\n    // 7.6.2\n    try {\n      this.#batchCacheOperations(operations)\n    } catch (e) {\n      errorData = e\n    }\n\n    // 7.6.3\n    queueMicrotask(() => {\n      // 7.6.3.1\n      if (errorData === null) {\n        cacheJobPromise.resolve(undefined)\n      } else {\n        // 7.6.3.2\n        cacheJobPromise.reject(errorData)\n      }\n    })\n\n    // 7.7\n    return cacheJobPromise.promise\n  }\n\n  async put (request, response) {\n    webidl.brandCheck(this, Cache)\n    webidl.argumentLengthCheck(arguments, 2, { header: 'Cache.put' })\n\n    request = webidl.converters.RequestInfo(request)\n    response = webidl.converters.Response(response)\n\n    // 1.\n    let innerRequest = null\n\n    // 2.\n    if (request instanceof Request) {\n      innerRequest = request[kState]\n    } else { // 3.\n      innerRequest = new Request(request)[kState]\n    }\n\n    // 4.\n    if (!urlIsHttpHttpsScheme(innerRequest.url) || innerRequest.method !== 'GET') {\n      throw webidl.errors.exception({\n        header: 'Cache.put',\n        message: 'Expected an http/s scheme when method is not GET'\n      })\n    }\n\n    // 5.\n    const innerResponse = response[kState]\n\n    // 6.\n    if (innerResponse.status === 206) {\n      throw webidl.errors.exception({\n        header: 'Cache.put',\n        message: 'Got 206 status'\n      })\n    }\n\n    // 7.\n    if (innerResponse.headersList.contains('vary')) {\n      // 7.1.\n      const fieldValues = getFieldValues(innerResponse.headersList.get('vary'))\n\n      // 7.2.\n      for (const fieldValue of fieldValues) {\n        // 7.2.1\n        if (fieldValue === '*') {\n          throw webidl.errors.exception({\n            header: 'Cache.put',\n            message: 'Got * vary field value'\n          })\n        }\n      }\n    }\n\n    // 8.\n    if (innerResponse.body && (isDisturbed(innerResponse.body.stream) || innerResponse.body.stream.locked)) {\n      throw webidl.errors.exception({\n        header: 'Cache.put',\n        message: 'Response body is locked or disturbed'\n      })\n    }\n\n    // 9.\n    const clonedResponse = cloneResponse(innerResponse)\n\n    // 10.\n    const bodyReadPromise = createDeferredPromise()\n\n    // 11.\n    if (innerResponse.body != null) {\n      // 11.1\n      const stream = innerResponse.body.stream\n\n      // 11.2\n      const reader = stream.getReader()\n\n      // 11.3\n      readAllBytes(reader).then(bodyReadPromise.resolve, bodyReadPromise.reject)\n    } else {\n      bodyReadPromise.resolve(undefined)\n    }\n\n    // 12.\n    /** @type {CacheBatchOperation[]} */\n    const operations = []\n\n    // 13.\n    /** @type {CacheBatchOperation} */\n    const operation = {\n      type: 'put', // 14.\n      request: innerRequest, // 15.\n      response: clonedResponse // 16.\n    }\n\n    // 17.\n    operations.push(operation)\n\n    // 19.\n    const bytes = await bodyReadPromise.promise\n\n    if (clonedResponse.body != null) {\n      clonedResponse.body.source = bytes\n    }\n\n    // 19.1\n    const cacheJobPromise = createDeferredPromise()\n\n    // 19.2.1\n    let errorData = null\n\n    // 19.2.2\n    try {\n      this.#batchCacheOperations(operations)\n    } catch (e) {\n      errorData = e\n    }\n\n    // 19.2.3\n    queueMicrotask(() => {\n      // 19.2.3.1\n      if (errorData === null) {\n        cacheJobPromise.resolve()\n      } else { // 19.2.3.2\n        cacheJobPromise.reject(errorData)\n      }\n    })\n\n    return cacheJobPromise.promise\n  }\n\n  async delete (request, options = {}) {\n    webidl.brandCheck(this, Cache)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Cache.delete' })\n\n    request = webidl.converters.RequestInfo(request)\n    options = webidl.converters.CacheQueryOptions(options)\n\n    /**\n     * @type {Request}\n     */\n    let r = null\n\n    if (request instanceof Request) {\n      r = request[kState]\n\n      if (r.method !== 'GET' && !options.ignoreMethod) {\n        return false\n      }\n    } else {\n      assert(typeof request === 'string')\n\n      r = new Request(request)[kState]\n    }\n\n    /** @type {CacheBatchOperation[]} */\n    const operations = []\n\n    /** @type {CacheBatchOperation} */\n    const operation = {\n      type: 'delete',\n      request: r,\n      options\n    }\n\n    operations.push(operation)\n\n    const cacheJobPromise = createDeferredPromise()\n\n    let errorData = null\n    let requestResponses\n\n    try {\n      requestResponses = this.#batchCacheOperations(operations)\n    } catch (e) {\n      errorData = e\n    }\n\n    queueMicrotask(() => {\n      if (errorData === null) {\n        cacheJobPromise.resolve(!!requestResponses?.length)\n      } else {\n        cacheJobPromise.reject(errorData)\n      }\n    })\n\n    return cacheJobPromise.promise\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#dom-cache-keys\n   * @param {any} request\n   * @param {import('../../types/cache').CacheQueryOptions} options\n   * @returns {readonly Request[]}\n   */\n  async keys (request = undefined, options = {}) {\n    webidl.brandCheck(this, Cache)\n\n    if (request !== undefined) request = webidl.converters.RequestInfo(request)\n    options = webidl.converters.CacheQueryOptions(options)\n\n    // 1.\n    let r = null\n\n    // 2.\n    if (request !== undefined) {\n      // 2.1\n      if (request instanceof Request) {\n        // 2.1.1\n        r = request[kState]\n\n        // 2.1.2\n        if (r.method !== 'GET' && !options.ignoreMethod) {\n          return []\n        }\n      } else if (typeof request === 'string') { // 2.2\n        r = new Request(request)[kState]\n      }\n    }\n\n    // 4.\n    const promise = createDeferredPromise()\n\n    // 5.\n    // 5.1\n    const requests = []\n\n    // 5.2\n    if (request === undefined) {\n      // 5.2.1\n      for (const requestResponse of this.#relevantRequestResponseList) {\n        // 5.2.1.1\n        requests.push(requestResponse[0])\n      }\n    } else { // 5.3\n      // 5.3.1\n      const requestResponses = this.#queryCache(r, options)\n\n      // 5.3.2\n      for (const requestResponse of requestResponses) {\n        // 5.3.2.1\n        requests.push(requestResponse[0])\n      }\n    }\n\n    // 5.4\n    queueMicrotask(() => {\n      // 5.4.1\n      const requestList = []\n\n      // 5.4.2\n      for (const request of requests) {\n        const requestObject = new Request('https://a')\n        requestObject[kState] = request\n        requestObject[kHeaders][kHeadersList] = request.headersList\n        requestObject[kHeaders][kGuard] = 'immutable'\n        requestObject[kRealm] = request.client\n\n        // 5.4.2.1\n        requestList.push(requestObject)\n      }\n\n      // 5.4.3\n      promise.resolve(Object.freeze(requestList))\n    })\n\n    return promise.promise\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#batch-cache-operations-algorithm\n   * @param {CacheBatchOperation[]} operations\n   * @returns {requestResponseList}\n   */\n  #batchCacheOperations (operations) {\n    // 1.\n    const cache = this.#relevantRequestResponseList\n\n    // 2.\n    const backupCache = [...cache]\n\n    // 3.\n    const addedItems = []\n\n    // 4.1\n    const resultList = []\n\n    try {\n      // 4.2\n      for (const operation of operations) {\n        // 4.2.1\n        if (operation.type !== 'delete' && operation.type !== 'put') {\n          throw webidl.errors.exception({\n            header: 'Cache.#batchCacheOperations',\n            message: 'operation type does not match \"delete\" or \"put\"'\n          })\n        }\n\n        // 4.2.2\n        if (operation.type === 'delete' && operation.response != null) {\n          throw webidl.errors.exception({\n            header: 'Cache.#batchCacheOperations',\n            message: 'delete operation should not have an associated response'\n          })\n        }\n\n        // 4.2.3\n        if (this.#queryCache(operation.request, operation.options, addedItems).length) {\n          throw new DOMException('???', 'InvalidStateError')\n        }\n\n        // 4.2.4\n        let requestResponses\n\n        // 4.2.5\n        if (operation.type === 'delete') {\n          // 4.2.5.1\n          requestResponses = this.#queryCache(operation.request, operation.options)\n\n          // TODO: the spec is wrong, this is needed to pass WPTs\n          if (requestResponses.length === 0) {\n            return []\n          }\n\n          // 4.2.5.2\n          for (const requestResponse of requestResponses) {\n            const idx = cache.indexOf(requestResponse)\n            assert(idx !== -1)\n\n            // 4.2.5.2.1\n            cache.splice(idx, 1)\n          }\n        } else if (operation.type === 'put') { // 4.2.6\n          // 4.2.6.1\n          if (operation.response == null) {\n            throw webidl.errors.exception({\n              header: 'Cache.#batchCacheOperations',\n              message: 'put operation should have an associated response'\n            })\n          }\n\n          // 4.2.6.2\n          const r = operation.request\n\n          // 4.2.6.3\n          if (!urlIsHttpHttpsScheme(r.url)) {\n            throw webidl.errors.exception({\n              header: 'Cache.#batchCacheOperations',\n              message: 'expected http or https scheme'\n            })\n          }\n\n          // 4.2.6.4\n          if (r.method !== 'GET') {\n            throw webidl.errors.exception({\n              header: 'Cache.#batchCacheOperations',\n              message: 'not get method'\n            })\n          }\n\n          // 4.2.6.5\n          if (operation.options != null) {\n            throw webidl.errors.exception({\n              header: 'Cache.#batchCacheOperations',\n              message: 'options must not be defined'\n            })\n          }\n\n          // 4.2.6.6\n          requestResponses = this.#queryCache(operation.request)\n\n          // 4.2.6.7\n          for (const requestResponse of requestResponses) {\n            const idx = cache.indexOf(requestResponse)\n            assert(idx !== -1)\n\n            // 4.2.6.7.1\n            cache.splice(idx, 1)\n          }\n\n          // 4.2.6.8\n          cache.push([operation.request, operation.response])\n\n          // 4.2.6.10\n          addedItems.push([operation.request, operation.response])\n        }\n\n        // 4.2.7\n        resultList.push([operation.request, operation.response])\n      }\n\n      // 4.3\n      return resultList\n    } catch (e) { // 5.\n      // 5.1\n      this.#relevantRequestResponseList.length = 0\n\n      // 5.2\n      this.#relevantRequestResponseList = backupCache\n\n      // 5.3\n      throw e\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#query-cache\n   * @param {any} requestQuery\n   * @param {import('../../types/cache').CacheQueryOptions} options\n   * @param {requestResponseList} targetStorage\n   * @returns {requestResponseList}\n   */\n  #queryCache (requestQuery, options, targetStorage) {\n    /** @type {requestResponseList} */\n    const resultList = []\n\n    const storage = targetStorage ?? this.#relevantRequestResponseList\n\n    for (const requestResponse of storage) {\n      const [cachedRequest, cachedResponse] = requestResponse\n      if (this.#requestMatchesCachedItem(requestQuery, cachedRequest, cachedResponse, options)) {\n        resultList.push(requestResponse)\n      }\n    }\n\n    return resultList\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#request-matches-cached-item-algorithm\n   * @param {any} requestQuery\n   * @param {any} request\n   * @param {any | null} response\n   * @param {import('../../types/cache').CacheQueryOptions | undefined} options\n   * @returns {boolean}\n   */\n  #requestMatchesCachedItem (requestQuery, request, response = null, options) {\n    // if (options?.ignoreMethod === false && request.method === 'GET') {\n    //   return false\n    // }\n\n    const queryURL = new URL(requestQuery.url)\n\n    const cachedURL = new URL(request.url)\n\n    if (options?.ignoreSearch) {\n      cachedURL.search = ''\n\n      queryURL.search = ''\n    }\n\n    if (!urlEquals(queryURL, cachedURL, true)) {\n      return false\n    }\n\n    if (\n      response == null ||\n      options?.ignoreVary ||\n      !response.headersList.contains('vary')\n    ) {\n      return true\n    }\n\n    const fieldValues = getFieldValues(response.headersList.get('vary'))\n\n    for (const fieldValue of fieldValues) {\n      if (fieldValue === '*') {\n        return false\n      }\n\n      const requestValue = request.headersList.get(fieldValue)\n      const queryValue = requestQuery.headersList.get(fieldValue)\n\n      // If one has the header and the other doesn't, or one has\n      // a different value than the other, return false\n      if (requestValue !== queryValue) {\n        return false\n      }\n    }\n\n    return true\n  }\n}\n\nObject.defineProperties(Cache.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'Cache',\n    configurable: true\n  },\n  match: kEnumerableProperty,\n  matchAll: kEnumerableProperty,\n  add: kEnumerableProperty,\n  addAll: kEnumerableProperty,\n  put: kEnumerableProperty,\n  delete: kEnumerableProperty,\n  keys: kEnumerableProperty\n})\n\nconst cacheQueryOptionConverters = [\n  {\n    key: 'ignoreSearch',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'ignoreMethod',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'ignoreVary',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  }\n]\n\nwebidl.converters.CacheQueryOptions = webidl.dictionaryConverter(cacheQueryOptionConverters)\n\nwebidl.converters.MultiCacheQueryOptions = webidl.dictionaryConverter([\n  ...cacheQueryOptionConverters,\n  {\n    key: 'cacheName',\n    converter: webidl.converters.DOMString\n  }\n])\n\nwebidl.converters.Response = webidl.interfaceConverter(Response)\n\nwebidl.converters['sequence<RequestInfo>'] = webidl.sequenceConverter(\n  webidl.converters.RequestInfo\n)\n\nmodule.exports = {\n  Cache\n}\n","'use strict'\n\nconst { kConstruct } = require('./symbols')\nconst { Cache } = require('./cache')\nconst { webidl } = require('../fetch/webidl')\nconst { kEnumerableProperty } = require('../core/util')\n\nclass CacheStorage {\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#dfn-relevant-name-to-cache-map\n   * @type {Map<string, import('./cache').requestResponseList}\n   */\n  #caches = new Map()\n\n  constructor () {\n    if (arguments[0] !== kConstruct) {\n      webidl.illegalConstructor()\n    }\n  }\n\n  async match (request, options = {}) {\n    webidl.brandCheck(this, CacheStorage)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'CacheStorage.match' })\n\n    request = webidl.converters.RequestInfo(request)\n    options = webidl.converters.MultiCacheQueryOptions(options)\n\n    // 1.\n    if (options.cacheName != null) {\n      // 1.1.1.1\n      if (this.#caches.has(options.cacheName)) {\n        // 1.1.1.1.1\n        const cacheList = this.#caches.get(options.cacheName)\n        const cache = new Cache(kConstruct, cacheList)\n\n        return await cache.match(request, options)\n      }\n    } else { // 2.\n      // 2.2\n      for (const cacheList of this.#caches.values()) {\n        const cache = new Cache(kConstruct, cacheList)\n\n        // 2.2.1.2\n        const response = await cache.match(request, options)\n\n        if (response !== undefined) {\n          return response\n        }\n      }\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#cache-storage-has\n   * @param {string} cacheName\n   * @returns {Promise<boolean>}\n   */\n  async has (cacheName) {\n    webidl.brandCheck(this, CacheStorage)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'CacheStorage.has' })\n\n    cacheName = webidl.converters.DOMString(cacheName)\n\n    // 2.1.1\n    // 2.2\n    return this.#caches.has(cacheName)\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#dom-cachestorage-open\n   * @param {string} cacheName\n   * @returns {Promise<Cache>}\n   */\n  async open (cacheName) {\n    webidl.brandCheck(this, CacheStorage)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'CacheStorage.open' })\n\n    cacheName = webidl.converters.DOMString(cacheName)\n\n    // 2.1\n    if (this.#caches.has(cacheName)) {\n      // await caches.open('v1') !== await caches.open('v1')\n\n      // 2.1.1\n      const cache = this.#caches.get(cacheName)\n\n      // 2.1.1.1\n      return new Cache(kConstruct, cache)\n    }\n\n    // 2.2\n    const cache = []\n\n    // 2.3\n    this.#caches.set(cacheName, cache)\n\n    // 2.4\n    return new Cache(kConstruct, cache)\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#cache-storage-delete\n   * @param {string} cacheName\n   * @returns {Promise<boolean>}\n   */\n  async delete (cacheName) {\n    webidl.brandCheck(this, CacheStorage)\n    webidl.argumentLengthCheck(arguments, 1, { header: 'CacheStorage.delete' })\n\n    cacheName = webidl.converters.DOMString(cacheName)\n\n    return this.#caches.delete(cacheName)\n  }\n\n  /**\n   * @see https://w3c.github.io/ServiceWorker/#cache-storage-keys\n   * @returns {string[]}\n   */\n  async keys () {\n    webidl.brandCheck(this, CacheStorage)\n\n    // 2.1\n    const keys = this.#caches.keys()\n\n    // 2.2\n    return [...keys]\n  }\n}\n\nObject.defineProperties(CacheStorage.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'CacheStorage',\n    configurable: true\n  },\n  match: kEnumerableProperty,\n  has: kEnumerableProperty,\n  open: kEnumerableProperty,\n  delete: kEnumerableProperty,\n  keys: kEnumerableProperty\n})\n\nmodule.exports = {\n  CacheStorage\n}\n","'use strict'\n\nmodule.exports = {\n  kConstruct: require('../core/symbols').kConstruct\n}\n","'use strict'\n\nconst assert = require('assert')\nconst { URLSerializer } = require('../fetch/dataURL')\nconst { isValidHeaderName } = require('../fetch/util')\n\n/**\n * @see https://url.spec.whatwg.org/#concept-url-equals\n * @param {URL} A\n * @param {URL} B\n * @param {boolean | undefined} excludeFragment\n * @returns {boolean}\n */\nfunction urlEquals (A, B, excludeFragment = false) {\n  const serializedA = URLSerializer(A, excludeFragment)\n\n  const serializedB = URLSerializer(B, excludeFragment)\n\n  return serializedA === serializedB\n}\n\n/**\n * @see https://github.com/chromium/chromium/blob/694d20d134cb553d8d89e5500b9148012b1ba299/content/browser/cache_storage/cache_storage_cache.cc#L260-L262\n * @param {string} header\n */\nfunction fieldValues (header) {\n  assert(header !== null)\n\n  const values = []\n\n  for (let value of header.split(',')) {\n    value = value.trim()\n\n    if (!value.length) {\n      continue\n    } else if (!isValidHeaderName(value)) {\n      continue\n    }\n\n    values.push(value)\n  }\n\n  return values\n}\n\nmodule.exports = {\n  urlEquals,\n  fieldValues\n}\n","// @ts-check\n\n'use strict'\n\n/* global WebAssembly */\n\nconst assert = require('assert')\nconst net = require('net')\nconst http = require('http')\nconst { pipeline } = require('stream')\nconst util = require('./core/util')\nconst timers = require('./timers')\nconst Request = require('./core/request')\nconst DispatcherBase = require('./dispatcher-base')\nconst {\n  RequestContentLengthMismatchError,\n  ResponseContentLengthMismatchError,\n  InvalidArgumentError,\n  RequestAbortedError,\n  HeadersTimeoutError,\n  HeadersOverflowError,\n  SocketError,\n  InformationalError,\n  BodyTimeoutError,\n  HTTPParserError,\n  ResponseExceededMaxSizeError,\n  ClientDestroyedError\n} = require('./core/errors')\nconst buildConnector = require('./core/connect')\nconst {\n  kUrl,\n  kReset,\n  kServerName,\n  kClient,\n  kBusy,\n  kParser,\n  kConnect,\n  kBlocking,\n  kResuming,\n  kRunning,\n  kPending,\n  kSize,\n  kWriting,\n  kQueue,\n  kConnected,\n  kConnecting,\n  kNeedDrain,\n  kNoRef,\n  kKeepAliveDefaultTimeout,\n  kHostHeader,\n  kPendingIdx,\n  kRunningIdx,\n  kError,\n  kPipelining,\n  kSocket,\n  kKeepAliveTimeoutValue,\n  kMaxHeadersSize,\n  kKeepAliveMaxTimeout,\n  kKeepAliveTimeoutThreshold,\n  kHeadersTimeout,\n  kBodyTimeout,\n  kStrictContentLength,\n  kConnector,\n  kMaxRedirections,\n  kMaxRequests,\n  kCounter,\n  kClose,\n  kDestroy,\n  kDispatch,\n  kInterceptors,\n  kLocalAddress,\n  kMaxResponseSize,\n  kHTTPConnVersion,\n  // HTTP2\n  kHost,\n  kHTTP2Session,\n  kHTTP2SessionState,\n  kHTTP2BuildRequest,\n  kHTTP2CopyHeaders,\n  kHTTP1BuildRequest\n} = require('./core/symbols')\n\n/** @type {import('http2')} */\nlet http2\ntry {\n  http2 = require('http2')\n} catch {\n  // @ts-ignore\n  http2 = { constants: {} }\n}\n\nconst {\n  constants: {\n    HTTP2_HEADER_AUTHORITY,\n    HTTP2_HEADER_METHOD,\n    HTTP2_HEADER_PATH,\n    HTTP2_HEADER_SCHEME,\n    HTTP2_HEADER_CONTENT_LENGTH,\n    HTTP2_HEADER_EXPECT,\n    HTTP2_HEADER_STATUS\n  }\n} = http2\n\n// Experimental\nlet h2ExperimentalWarned = false\n\nconst FastBuffer = Buffer[Symbol.species]\n\nconst kClosedResolve = Symbol('kClosedResolve')\n\nconst channels = {}\n\ntry {\n  const diagnosticsChannel = require('diagnostics_channel')\n  channels.sendHeaders = diagnosticsChannel.channel('undici:client:sendHeaders')\n  channels.beforeConnect = diagnosticsChannel.channel('undici:client:beforeConnect')\n  channels.connectError = diagnosticsChannel.channel('undici:client:connectError')\n  channels.connected = diagnosticsChannel.channel('undici:client:connected')\n} catch {\n  channels.sendHeaders = { hasSubscribers: false }\n  channels.beforeConnect = { hasSubscribers: false }\n  channels.connectError = { hasSubscribers: false }\n  channels.connected = { hasSubscribers: false }\n}\n\n/**\n * @type {import('../types/client').default}\n */\nclass Client extends DispatcherBase {\n  /**\n   *\n   * @param {string|URL} url\n   * @param {import('../types/client').Client.Options} options\n   */\n  constructor (url, {\n    interceptors,\n    maxHeaderSize,\n    headersTimeout,\n    socketTimeout,\n    requestTimeout,\n    connectTimeout,\n    bodyTimeout,\n    idleTimeout,\n    keepAlive,\n    keepAliveTimeout,\n    maxKeepAliveTimeout,\n    keepAliveMaxTimeout,\n    keepAliveTimeoutThreshold,\n    socketPath,\n    pipelining,\n    tls,\n    strictContentLength,\n    maxCachedSessions,\n    maxRedirections,\n    connect,\n    maxRequestsPerClient,\n    localAddress,\n    maxResponseSize,\n    autoSelectFamily,\n    autoSelectFamilyAttemptTimeout,\n    // h2\n    allowH2,\n    maxConcurrentStreams\n  } = {}) {\n    super()\n\n    if (keepAlive !== undefined) {\n      throw new InvalidArgumentError('unsupported keepAlive, use pipelining=0 instead')\n    }\n\n    if (socketTimeout !== undefined) {\n      throw new InvalidArgumentError('unsupported socketTimeout, use headersTimeout & bodyTimeout instead')\n    }\n\n    if (requestTimeout !== undefined) {\n      throw new InvalidArgumentError('unsupported requestTimeout, use headersTimeout & bodyTimeout instead')\n    }\n\n    if (idleTimeout !== undefined) {\n      throw new InvalidArgumentError('unsupported idleTimeout, use keepAliveTimeout instead')\n    }\n\n    if (maxKeepAliveTimeout !== undefined) {\n      throw new InvalidArgumentError('unsupported maxKeepAliveTimeout, use keepAliveMaxTimeout instead')\n    }\n\n    if (maxHeaderSize != null && !Number.isFinite(maxHeaderSize)) {\n      throw new InvalidArgumentError('invalid maxHeaderSize')\n    }\n\n    if (socketPath != null && typeof socketPath !== 'string') {\n      throw new InvalidArgumentError('invalid socketPath')\n    }\n\n    if (connectTimeout != null && (!Number.isFinite(connectTimeout) || connectTimeout < 0)) {\n      throw new InvalidArgumentError('invalid connectTimeout')\n    }\n\n    if (keepAliveTimeout != null && (!Number.isFinite(keepAliveTimeout) || keepAliveTimeout <= 0)) {\n      throw new InvalidArgumentError('invalid keepAliveTimeout')\n    }\n\n    if (keepAliveMaxTimeout != null && (!Number.isFinite(keepAliveMaxTimeout) || keepAliveMaxTimeout <= 0)) {\n      throw new InvalidArgumentError('invalid keepAliveMaxTimeout')\n    }\n\n    if (keepAliveTimeoutThreshold != null && !Number.isFinite(keepAliveTimeoutThreshold)) {\n      throw new InvalidArgumentError('invalid keepAliveTimeoutThreshold')\n    }\n\n    if (headersTimeout != null && (!Number.isInteger(headersTimeout) || headersTimeout < 0)) {\n      throw new InvalidArgumentError('headersTimeout must be a positive integer or zero')\n    }\n\n    if (bodyTimeout != null && (!Number.isInteger(bodyTimeout) || bodyTimeout < 0)) {\n      throw new InvalidArgumentError('bodyTimeout must be a positive integer or zero')\n    }\n\n    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {\n      throw new InvalidArgumentError('connect must be a function or an object')\n    }\n\n    if (maxRedirections != null && (!Number.isInteger(maxRedirections) || maxRedirections < 0)) {\n      throw new InvalidArgumentError('maxRedirections must be a positive number')\n    }\n\n    if (maxRequestsPerClient != null && (!Number.isInteger(maxRequestsPerClient) || maxRequestsPerClient < 0)) {\n      throw new InvalidArgumentError('maxRequestsPerClient must be a positive number')\n    }\n\n    if (localAddress != null && (typeof localAddress !== 'string' || net.isIP(localAddress) === 0)) {\n      throw new InvalidArgumentError('localAddress must be valid string IP address')\n    }\n\n    if (maxResponseSize != null && (!Number.isInteger(maxResponseSize) || maxResponseSize < -1)) {\n      throw new InvalidArgumentError('maxResponseSize must be a positive number')\n    }\n\n    if (\n      autoSelectFamilyAttemptTimeout != null &&\n      (!Number.isInteger(autoSelectFamilyAttemptTimeout) || autoSelectFamilyAttemptTimeout < -1)\n    ) {\n      throw new InvalidArgumentError('autoSelectFamilyAttemptTimeout must be a positive number')\n    }\n\n    // h2\n    if (allowH2 != null && typeof allowH2 !== 'boolean') {\n      throw new InvalidArgumentError('allowH2 must be a valid boolean value')\n    }\n\n    if (maxConcurrentStreams != null && (typeof maxConcurrentStreams !== 'number' || maxConcurrentStreams < 1)) {\n      throw new InvalidArgumentError('maxConcurrentStreams must be a possitive integer, greater than 0')\n    }\n\n    if (typeof connect !== 'function') {\n      connect = buildConnector({\n        ...tls,\n        maxCachedSessions,\n        allowH2,\n        socketPath,\n        timeout: connectTimeout,\n        ...(util.nodeHasAutoSelectFamily && autoSelectFamily ? { autoSelectFamily, autoSelectFamilyAttemptTimeout } : undefined),\n        ...connect\n      })\n    }\n\n    this[kInterceptors] = interceptors && interceptors.Client && Array.isArray(interceptors.Client)\n      ? interceptors.Client\n      : [createRedirectInterceptor({ maxRedirections })]\n    this[kUrl] = util.parseOrigin(url)\n    this[kConnector] = connect\n    this[kSocket] = null\n    this[kPipelining] = pipelining != null ? pipelining : 1\n    this[kMaxHeadersSize] = maxHeaderSize || http.maxHeaderSize\n    this[kKeepAliveDefaultTimeout] = keepAliveTimeout == null ? 4e3 : keepAliveTimeout\n    this[kKeepAliveMaxTimeout] = keepAliveMaxTimeout == null ? 600e3 : keepAliveMaxTimeout\n    this[kKeepAliveTimeoutThreshold] = keepAliveTimeoutThreshold == null ? 1e3 : keepAliveTimeoutThreshold\n    this[kKeepAliveTimeoutValue] = this[kKeepAliveDefaultTimeout]\n    this[kServerName] = null\n    this[kLocalAddress] = localAddress != null ? localAddress : null\n    this[kResuming] = 0 // 0, idle, 1, scheduled, 2 resuming\n    this[kNeedDrain] = 0 // 0, idle, 1, scheduled, 2 resuming\n    this[kHostHeader] = `host: ${this[kUrl].hostname}${this[kUrl].port ? `:${this[kUrl].port}` : ''}\\r\\n`\n    this[kBodyTimeout] = bodyTimeout != null ? bodyTimeout : 300e3\n    this[kHeadersTimeout] = headersTimeout != null ? headersTimeout : 300e3\n    this[kStrictContentLength] = strictContentLength == null ? true : strictContentLength\n    this[kMaxRedirections] = maxRedirections\n    this[kMaxRequests] = maxRequestsPerClient\n    this[kClosedResolve] = null\n    this[kMaxResponseSize] = maxResponseSize > -1 ? maxResponseSize : -1\n    this[kHTTPConnVersion] = 'h1'\n\n    // HTTP/2\n    this[kHTTP2Session] = null\n    this[kHTTP2SessionState] = !allowH2\n      ? null\n      : {\n        // streams: null, // Fixed queue of streams - For future support of `push`\n          openStreams: 0, // Keep track of them to decide wether or not unref the session\n          maxConcurrentStreams: maxConcurrentStreams != null ? maxConcurrentStreams : 100 // Max peerConcurrentStreams for a Node h2 server\n        }\n    this[kHost] = `${this[kUrl].hostname}${this[kUrl].port ? `:${this[kUrl].port}` : ''}`\n\n    // kQueue is built up of 3 sections separated by\n    // the kRunningIdx and kPendingIdx indices.\n    // |   complete   |   running   |   pending   |\n    //                ^ kRunningIdx ^ kPendingIdx ^ kQueue.length\n    // kRunningIdx points to the first running element.\n    // kPendingIdx points to the first pending element.\n    // This implements a fast queue with an amortized\n    // time of O(1).\n\n    this[kQueue] = []\n    this[kRunningIdx] = 0\n    this[kPendingIdx] = 0\n  }\n\n  get pipelining () {\n    return this[kPipelining]\n  }\n\n  set pipelining (value) {\n    this[kPipelining] = value\n    resume(this, true)\n  }\n\n  get [kPending] () {\n    return this[kQueue].length - this[kPendingIdx]\n  }\n\n  get [kRunning] () {\n    return this[kPendingIdx] - this[kRunningIdx]\n  }\n\n  get [kSize] () {\n    return this[kQueue].length - this[kRunningIdx]\n  }\n\n  get [kConnected] () {\n    return !!this[kSocket] && !this[kConnecting] && !this[kSocket].destroyed\n  }\n\n  get [kBusy] () {\n    const socket = this[kSocket]\n    return (\n      (socket && (socket[kReset] || socket[kWriting] || socket[kBlocking])) ||\n      (this[kSize] >= (this[kPipelining] || 1)) ||\n      this[kPending] > 0\n    )\n  }\n\n  /* istanbul ignore: only used for test */\n  [kConnect] (cb) {\n    connect(this)\n    this.once('connect', cb)\n  }\n\n  [kDispatch] (opts, handler) {\n    const origin = opts.origin || this[kUrl].origin\n\n    const request = this[kHTTPConnVersion] === 'h2'\n      ? Request[kHTTP2BuildRequest](origin, opts, handler)\n      : Request[kHTTP1BuildRequest](origin, opts, handler)\n\n    this[kQueue].push(request)\n    if (this[kResuming]) {\n      // Do nothing.\n    } else if (util.bodyLength(request.body) == null && util.isIterable(request.body)) {\n      // Wait a tick in case stream/iterator is ended in the same tick.\n      this[kResuming] = 1\n      process.nextTick(resume, this)\n    } else {\n      resume(this, true)\n    }\n\n    if (this[kResuming] && this[kNeedDrain] !== 2 && this[kBusy]) {\n      this[kNeedDrain] = 2\n    }\n\n    return this[kNeedDrain] < 2\n  }\n\n  async [kClose] () {\n    // TODO: for H2 we need to gracefully flush the remaining enqueued\n    // request and close each stream.\n    return new Promise((resolve) => {\n      if (!this[kSize]) {\n        resolve(null)\n      } else {\n        this[kClosedResolve] = resolve\n      }\n    })\n  }\n\n  async [kDestroy] (err) {\n    return new Promise((resolve) => {\n      const requests = this[kQueue].splice(this[kPendingIdx])\n      for (let i = 0; i < requests.length; i++) {\n        const request = requests[i]\n        errorRequest(this, request, err)\n      }\n\n      const callback = () => {\n        if (this[kClosedResolve]) {\n          // TODO (fix): Should we error here with ClientDestroyedError?\n          this[kClosedResolve]()\n          this[kClosedResolve] = null\n        }\n        resolve()\n      }\n\n      if (this[kHTTP2Session] != null) {\n        util.destroy(this[kHTTP2Session], err)\n        this[kHTTP2Session] = null\n        this[kHTTP2SessionState] = null\n      }\n\n      if (!this[kSocket]) {\n        queueMicrotask(callback)\n      } else {\n        util.destroy(this[kSocket].on('close', callback), err)\n      }\n\n      resume(this)\n    })\n  }\n}\n\nfunction onHttp2SessionError (err) {\n  assert(err.code !== 'ERR_TLS_CERT_ALTNAME_INVALID')\n\n  this[kSocket][kError] = err\n\n  onError(this[kClient], err)\n}\n\nfunction onHttp2FrameError (type, code, id) {\n  const err = new InformationalError(`HTTP/2: \"frameError\" received - type ${type}, code ${code}`)\n\n  if (id === 0) {\n    this[kSocket][kError] = err\n    onError(this[kClient], err)\n  }\n}\n\nfunction onHttp2SessionEnd () {\n  util.destroy(this, new SocketError('other side closed'))\n  util.destroy(this[kSocket], new SocketError('other side closed'))\n}\n\nfunction onHTTP2GoAway (code) {\n  const client = this[kClient]\n  const err = new InformationalError(`HTTP/2: \"GOAWAY\" frame received with code ${code}`)\n  client[kSocket] = null\n  client[kHTTP2Session] = null\n\n  if (client.destroyed) {\n    assert(this[kPending] === 0)\n\n    // Fail entire queue.\n    const requests = client[kQueue].splice(client[kRunningIdx])\n    for (let i = 0; i < requests.length; i++) {\n      const request = requests[i]\n      errorRequest(this, request, err)\n    }\n  } else if (client[kRunning] > 0) {\n    // Fail head of pipeline.\n    const request = client[kQueue][client[kRunningIdx]]\n    client[kQueue][client[kRunningIdx]++] = null\n\n    errorRequest(client, request, err)\n  }\n\n  client[kPendingIdx] = client[kRunningIdx]\n\n  assert(client[kRunning] === 0)\n\n  client.emit('disconnect',\n    client[kUrl],\n    [client],\n    err\n  )\n\n  resume(client)\n}\n\nconst constants = require('./llhttp/constants')\nconst createRedirectInterceptor = require('./interceptor/redirectInterceptor')\nconst EMPTY_BUF = Buffer.alloc(0)\n\nasync function lazyllhttp () {\n  const llhttpWasmData = process.env.JEST_WORKER_ID ? require('./llhttp/llhttp-wasm.js') : undefined\n\n  let mod\n  try {\n    mod = await WebAssembly.compile(Buffer.from(require('./llhttp/llhttp_simd-wasm.js'), 'base64'))\n  } catch (e) {\n    /* istanbul ignore next */\n\n    // We could check if the error was caused by the simd option not\n    // being enabled, but the occurring of this other error\n    // * https://github.com/emscripten-core/emscripten/issues/11495\n    // got me to remove that check to avoid breaking Node 12.\n    mod = await WebAssembly.compile(Buffer.from(llhttpWasmData || require('./llhttp/llhttp-wasm.js'), 'base64'))\n  }\n\n  return await WebAssembly.instantiate(mod, {\n    env: {\n      /* eslint-disable camelcase */\n\n      wasm_on_url: (p, at, len) => {\n        /* istanbul ignore next */\n        return 0\n      },\n      wasm_on_status: (p, at, len) => {\n        assert.strictEqual(currentParser.ptr, p)\n        const start = at - currentBufferPtr + currentBufferRef.byteOffset\n        return currentParser.onStatus(new FastBuffer(currentBufferRef.buffer, start, len)) || 0\n      },\n      wasm_on_message_begin: (p) => {\n        assert.strictEqual(currentParser.ptr, p)\n        return currentParser.onMessageBegin() || 0\n      },\n      wasm_on_header_field: (p, at, len) => {\n        assert.strictEqual(currentParser.ptr, p)\n        const start = at - currentBufferPtr + currentBufferRef.byteOffset\n        return currentParser.onHeaderField(new FastBuffer(currentBufferRef.buffer, start, len)) || 0\n      },\n      wasm_on_header_value: (p, at, len) => {\n        assert.strictEqual(currentParser.ptr, p)\n        const start = at - currentBufferPtr + currentBufferRef.byteOffset\n        return currentParser.onHeaderValue(new FastBuffer(currentBufferRef.buffer, start, len)) || 0\n      },\n      wasm_on_headers_complete: (p, statusCode, upgrade, shouldKeepAlive) => {\n        assert.strictEqual(currentParser.ptr, p)\n        return currentParser.onHeadersComplete(statusCode, Boolean(upgrade), Boolean(shouldKeepAlive)) || 0\n      },\n      wasm_on_body: (p, at, len) => {\n        assert.strictEqual(currentParser.ptr, p)\n        const start = at - currentBufferPtr + currentBufferRef.byteOffset\n        return currentParser.onBody(new FastBuffer(currentBufferRef.buffer, start, len)) || 0\n      },\n      wasm_on_message_complete: (p) => {\n        assert.strictEqual(currentParser.ptr, p)\n        return currentParser.onMessageComplete() || 0\n      }\n\n      /* eslint-enable camelcase */\n    }\n  })\n}\n\nlet llhttpInstance = null\nlet llhttpPromise = lazyllhttp()\nllhttpPromise.catch()\n\nlet currentParser = null\nlet currentBufferRef = null\nlet currentBufferSize = 0\nlet currentBufferPtr = null\n\nconst TIMEOUT_HEADERS = 1\nconst TIMEOUT_BODY = 2\nconst TIMEOUT_IDLE = 3\n\nclass Parser {\n  constructor (client, socket, { exports }) {\n    assert(Number.isFinite(client[kMaxHeadersSize]) && client[kMaxHeadersSize] > 0)\n\n    this.llhttp = exports\n    this.ptr = this.llhttp.llhttp_alloc(constants.TYPE.RESPONSE)\n    this.client = client\n    this.socket = socket\n    this.timeout = null\n    this.timeoutValue = null\n    this.timeoutType = null\n    this.statusCode = null\n    this.statusText = ''\n    this.upgrade = false\n    this.headers = []\n    this.headersSize = 0\n    this.headersMaxSize = client[kMaxHeadersSize]\n    this.shouldKeepAlive = false\n    this.paused = false\n    this.resume = this.resume.bind(this)\n\n    this.bytesRead = 0\n\n    this.keepAlive = ''\n    this.contentLength = ''\n    this.connection = ''\n    this.maxResponseSize = client[kMaxResponseSize]\n  }\n\n  setTimeout (value, type) {\n    this.timeoutType = type\n    if (value !== this.timeoutValue) {\n      timers.clearTimeout(this.timeout)\n      if (value) {\n        this.timeout = timers.setTimeout(onParserTimeout, value, this)\n        // istanbul ignore else: only for jest\n        if (this.timeout.unref) {\n          this.timeout.unref()\n        }\n      } else {\n        this.timeout = null\n      }\n      this.timeoutValue = value\n    } else if (this.timeout) {\n      // istanbul ignore else: only for jest\n      if (this.timeout.refresh) {\n        this.timeout.refresh()\n      }\n    }\n  }\n\n  resume () {\n    if (this.socket.destroyed || !this.paused) {\n      return\n    }\n\n    assert(this.ptr != null)\n    assert(currentParser == null)\n\n    this.llhttp.llhttp_resume(this.ptr)\n\n    assert(this.timeoutType === TIMEOUT_BODY)\n    if (this.timeout) {\n      // istanbul ignore else: only for jest\n      if (this.timeout.refresh) {\n        this.timeout.refresh()\n      }\n    }\n\n    this.paused = false\n    this.execute(this.socket.read() || EMPTY_BUF) // Flush parser.\n    this.readMore()\n  }\n\n  readMore () {\n    while (!this.paused && this.ptr) {\n      const chunk = this.socket.read()\n      if (chunk === null) {\n        break\n      }\n      this.execute(chunk)\n    }\n  }\n\n  execute (data) {\n    assert(this.ptr != null)\n    assert(currentParser == null)\n    assert(!this.paused)\n\n    const { socket, llhttp } = this\n\n    if (data.length > currentBufferSize) {\n      if (currentBufferPtr) {\n        llhttp.free(currentBufferPtr)\n      }\n      currentBufferSize = Math.ceil(data.length / 4096) * 4096\n      currentBufferPtr = llhttp.malloc(currentBufferSize)\n    }\n\n    new Uint8Array(llhttp.memory.buffer, currentBufferPtr, currentBufferSize).set(data)\n\n    // Call `execute` on the wasm parser.\n    // We pass the `llhttp_parser` pointer address, the pointer address of buffer view data,\n    // and finally the length of bytes to parse.\n    // The return value is an error code or `constants.ERROR.OK`.\n    try {\n      let ret\n\n      try {\n        currentBufferRef = data\n        currentParser = this\n        ret = llhttp.llhttp_execute(this.ptr, currentBufferPtr, data.length)\n        /* eslint-disable-next-line no-useless-catch */\n      } catch (err) {\n        /* istanbul ignore next: difficult to make a test case for */\n        throw err\n      } finally {\n        currentParser = null\n        currentBufferRef = null\n      }\n\n      const offset = llhttp.llhttp_get_error_pos(this.ptr) - currentBufferPtr\n\n      if (ret === constants.ERROR.PAUSED_UPGRADE) {\n        this.onUpgrade(data.slice(offset))\n      } else if (ret === constants.ERROR.PAUSED) {\n        this.paused = true\n        socket.unshift(data.slice(offset))\n      } else if (ret !== constants.ERROR.OK) {\n        const ptr = llhttp.llhttp_get_error_reason(this.ptr)\n        let message = ''\n        /* istanbul ignore else: difficult to make a test case for */\n        if (ptr) {\n          const len = new Uint8Array(llhttp.memory.buffer, ptr).indexOf(0)\n          message =\n            'Response does not match the HTTP/1.1 protocol (' +\n            Buffer.from(llhttp.memory.buffer, ptr, len).toString() +\n            ')'\n        }\n        throw new HTTPParserError(message, constants.ERROR[ret], data.slice(offset))\n      }\n    } catch (err) {\n      util.destroy(socket, err)\n    }\n  }\n\n  destroy () {\n    assert(this.ptr != null)\n    assert(currentParser == null)\n\n    this.llhttp.llhttp_free(this.ptr)\n    this.ptr = null\n\n    timers.clearTimeout(this.timeout)\n    this.timeout = null\n    this.timeoutValue = null\n    this.timeoutType = null\n\n    this.paused = false\n  }\n\n  onStatus (buf) {\n    this.statusText = buf.toString()\n  }\n\n  onMessageBegin () {\n    const { socket, client } = this\n\n    /* istanbul ignore next: difficult to make a test case for */\n    if (socket.destroyed) {\n      return -1\n    }\n\n    const request = client[kQueue][client[kRunningIdx]]\n    if (!request) {\n      return -1\n    }\n  }\n\n  onHeaderField (buf) {\n    const len = this.headers.length\n\n    if ((len & 1) === 0) {\n      this.headers.push(buf)\n    } else {\n      this.headers[len - 1] = Buffer.concat([this.headers[len - 1], buf])\n    }\n\n    this.trackHeader(buf.length)\n  }\n\n  onHeaderValue (buf) {\n    let len = this.headers.length\n\n    if ((len & 1) === 1) {\n      this.headers.push(buf)\n      len += 1\n    } else {\n      this.headers[len - 1] = Buffer.concat([this.headers[len - 1], buf])\n    }\n\n    const key = this.headers[len - 2]\n    if (key.length === 10 && key.toString().toLowerCase() === 'keep-alive') {\n      this.keepAlive += buf.toString()\n    } else if (key.length === 10 && key.toString().toLowerCase() === 'connection') {\n      this.connection += buf.toString()\n    } else if (key.length === 14 && key.toString().toLowerCase() === 'content-length') {\n      this.contentLength += buf.toString()\n    }\n\n    this.trackHeader(buf.length)\n  }\n\n  trackHeader (len) {\n    this.headersSize += len\n    if (this.headersSize >= this.headersMaxSize) {\n      util.destroy(this.socket, new HeadersOverflowError())\n    }\n  }\n\n  onUpgrade (head) {\n    const { upgrade, client, socket, headers, statusCode } = this\n\n    assert(upgrade)\n\n    const request = client[kQueue][client[kRunningIdx]]\n    assert(request)\n\n    assert(!socket.destroyed)\n    assert(socket === client[kSocket])\n    assert(!this.paused)\n    assert(request.upgrade || request.method === 'CONNECT')\n\n    this.statusCode = null\n    this.statusText = ''\n    this.shouldKeepAlive = null\n\n    assert(this.headers.length % 2 === 0)\n    this.headers = []\n    this.headersSize = 0\n\n    socket.unshift(head)\n\n    socket[kParser].destroy()\n    socket[kParser] = null\n\n    socket[kClient] = null\n    socket[kError] = null\n    socket\n      .removeListener('error', onSocketError)\n      .removeListener('readable', onSocketReadable)\n      .removeListener('end', onSocketEnd)\n      .removeListener('close', onSocketClose)\n\n    client[kSocket] = null\n    client[kQueue][client[kRunningIdx]++] = null\n    client.emit('disconnect', client[kUrl], [client], new InformationalError('upgrade'))\n\n    try {\n      request.onUpgrade(statusCode, headers, socket)\n    } catch (err) {\n      util.destroy(socket, err)\n    }\n\n    resume(client)\n  }\n\n  onHeadersComplete (statusCode, upgrade, shouldKeepAlive) {\n    const { client, socket, headers, statusText } = this\n\n    /* istanbul ignore next: difficult to make a test case for */\n    if (socket.destroyed) {\n      return -1\n    }\n\n    const request = client[kQueue][client[kRunningIdx]]\n\n    /* istanbul ignore next: difficult to make a test case for */\n    if (!request) {\n      return -1\n    }\n\n    assert(!this.upgrade)\n    assert(this.statusCode < 200)\n\n    if (statusCode === 100) {\n      util.destroy(socket, new SocketError('bad response', util.getSocketInfo(socket)))\n      return -1\n    }\n\n    /* this can only happen if server is misbehaving */\n    if (upgrade && !request.upgrade) {\n      util.destroy(socket, new SocketError('bad upgrade', util.getSocketInfo(socket)))\n      return -1\n    }\n\n    assert.strictEqual(this.timeoutType, TIMEOUT_HEADERS)\n\n    this.statusCode = statusCode\n    this.shouldKeepAlive = (\n      shouldKeepAlive ||\n      // Override llhttp value which does not allow keepAlive for HEAD.\n      (request.method === 'HEAD' && !socket[kReset] && this.connection.toLowerCase() === 'keep-alive')\n    )\n\n    if (this.statusCode >= 200) {\n      const bodyTimeout = request.bodyTimeout != null\n        ? request.bodyTimeout\n        : client[kBodyTimeout]\n      this.setTimeout(bodyTimeout, TIMEOUT_BODY)\n    } else if (this.timeout) {\n      // istanbul ignore else: only for jest\n      if (this.timeout.refresh) {\n        this.timeout.refresh()\n      }\n    }\n\n    if (request.method === 'CONNECT') {\n      assert(client[kRunning] === 1)\n      this.upgrade = true\n      return 2\n    }\n\n    if (upgrade) {\n      assert(client[kRunning] === 1)\n      this.upgrade = true\n      return 2\n    }\n\n    assert(this.headers.length % 2 === 0)\n    this.headers = []\n    this.headersSize = 0\n\n    if (this.shouldKeepAlive && client[kPipelining]) {\n      const keepAliveTimeout = this.keepAlive ? util.parseKeepAliveTimeout(this.keepAlive) : null\n\n      if (keepAliveTimeout != null) {\n        const timeout = Math.min(\n          keepAliveTimeout - client[kKeepAliveTimeoutThreshold],\n          client[kKeepAliveMaxTimeout]\n        )\n        if (timeout <= 0) {\n          socket[kReset] = true\n        } else {\n          client[kKeepAliveTimeoutValue] = timeout\n        }\n      } else {\n        client[kKeepAliveTimeoutValue] = client[kKeepAliveDefaultTimeout]\n      }\n    } else {\n      // Stop more requests from being dispatched.\n      socket[kReset] = true\n    }\n\n    const pause = request.onHeaders(statusCode, headers, this.resume, statusText) === false\n\n    if (request.aborted) {\n      return -1\n    }\n\n    if (request.method === 'HEAD') {\n      return 1\n    }\n\n    if (statusCode < 200) {\n      return 1\n    }\n\n    if (socket[kBlocking]) {\n      socket[kBlocking] = false\n      resume(client)\n    }\n\n    return pause ? constants.ERROR.PAUSED : 0\n  }\n\n  onBody (buf) {\n    const { client, socket, statusCode, maxResponseSize } = this\n\n    if (socket.destroyed) {\n      return -1\n    }\n\n    const request = client[kQueue][client[kRunningIdx]]\n    assert(request)\n\n    assert.strictEqual(this.timeoutType, TIMEOUT_BODY)\n    if (this.timeout) {\n      // istanbul ignore else: only for jest\n      if (this.timeout.refresh) {\n        this.timeout.refresh()\n      }\n    }\n\n    assert(statusCode >= 200)\n\n    if (maxResponseSize > -1 && this.bytesRead + buf.length > maxResponseSize) {\n      util.destroy(socket, new ResponseExceededMaxSizeError())\n      return -1\n    }\n\n    this.bytesRead += buf.length\n\n    if (request.onData(buf) === false) {\n      return constants.ERROR.PAUSED\n    }\n  }\n\n  onMessageComplete () {\n    const { client, socket, statusCode, upgrade, headers, contentLength, bytesRead, shouldKeepAlive } = this\n\n    if (socket.destroyed && (!statusCode || shouldKeepAlive)) {\n      return -1\n    }\n\n    if (upgrade) {\n      return\n    }\n\n    const request = client[kQueue][client[kRunningIdx]]\n    assert(request)\n\n    assert(statusCode >= 100)\n\n    this.statusCode = null\n    this.statusText = ''\n    this.bytesRead = 0\n    this.contentLength = ''\n    this.keepAlive = ''\n    this.connection = ''\n\n    assert(this.headers.length % 2 === 0)\n    this.headers = []\n    this.headersSize = 0\n\n    if (statusCode < 200) {\n      return\n    }\n\n    /* istanbul ignore next: should be handled by llhttp? */\n    if (request.method !== 'HEAD' && contentLength && bytesRead !== parseInt(contentLength, 10)) {\n      util.destroy(socket, new ResponseContentLengthMismatchError())\n      return -1\n    }\n\n    request.onComplete(headers)\n\n    client[kQueue][client[kRunningIdx]++] = null\n\n    if (socket[kWriting]) {\n      assert.strictEqual(client[kRunning], 0)\n      // Response completed before request.\n      util.destroy(socket, new InformationalError('reset'))\n      return constants.ERROR.PAUSED\n    } else if (!shouldKeepAlive) {\n      util.destroy(socket, new InformationalError('reset'))\n      return constants.ERROR.PAUSED\n    } else if (socket[kReset] && client[kRunning] === 0) {\n      // Destroy socket once all requests have completed.\n      // The request at the tail of the pipeline is the one\n      // that requested reset and no further requests should\n      // have been queued since then.\n      util.destroy(socket, new InformationalError('reset'))\n      return constants.ERROR.PAUSED\n    } else if (client[kPipelining] === 1) {\n      // We must wait a full event loop cycle to reuse this socket to make sure\n      // that non-spec compliant servers are not closing the connection even if they\n      // said they won't.\n      setImmediate(resume, client)\n    } else {\n      resume(client)\n    }\n  }\n}\n\nfunction onParserTimeout (parser) {\n  const { socket, timeoutType, client } = parser\n\n  /* istanbul ignore else */\n  if (timeoutType === TIMEOUT_HEADERS) {\n    if (!socket[kWriting] || socket.writableNeedDrain || client[kRunning] > 1) {\n      assert(!parser.paused, 'cannot be paused while waiting for headers')\n      util.destroy(socket, new HeadersTimeoutError())\n    }\n  } else if (timeoutType === TIMEOUT_BODY) {\n    if (!parser.paused) {\n      util.destroy(socket, new BodyTimeoutError())\n    }\n  } else if (timeoutType === TIMEOUT_IDLE) {\n    assert(client[kRunning] === 0 && client[kKeepAliveTimeoutValue])\n    util.destroy(socket, new InformationalError('socket idle timeout'))\n  }\n}\n\nfunction onSocketReadable () {\n  const { [kParser]: parser } = this\n  if (parser) {\n    parser.readMore()\n  }\n}\n\nfunction onSocketError (err) {\n  const { [kClient]: client, [kParser]: parser } = this\n\n  assert(err.code !== 'ERR_TLS_CERT_ALTNAME_INVALID')\n\n  if (client[kHTTPConnVersion] !== 'h2') {\n    // On Mac OS, we get an ECONNRESET even if there is a full body to be forwarded\n    // to the user.\n    if (err.code === 'ECONNRESET' && parser.statusCode && !parser.shouldKeepAlive) {\n      // We treat all incoming data so for as a valid response.\n      parser.onMessageComplete()\n      return\n    }\n  }\n\n  this[kError] = err\n\n  onError(this[kClient], err)\n}\n\nfunction onError (client, err) {\n  if (\n    client[kRunning] === 0 &&\n    err.code !== 'UND_ERR_INFO' &&\n    err.code !== 'UND_ERR_SOCKET'\n  ) {\n    // Error is not caused by running request and not a recoverable\n    // socket error.\n\n    assert(client[kPendingIdx] === client[kRunningIdx])\n\n    const requests = client[kQueue].splice(client[kRunningIdx])\n    for (let i = 0; i < requests.length; i++) {\n      const request = requests[i]\n      errorRequest(client, request, err)\n    }\n    assert(client[kSize] === 0)\n  }\n}\n\nfunction onSocketEnd () {\n  const { [kParser]: parser, [kClient]: client } = this\n\n  if (client[kHTTPConnVersion] !== 'h2') {\n    if (parser.statusCode && !parser.shouldKeepAlive) {\n      // We treat all incoming data so far as a valid response.\n      parser.onMessageComplete()\n      return\n    }\n  }\n\n  util.destroy(this, new SocketError('other side closed', util.getSocketInfo(this)))\n}\n\nfunction onSocketClose () {\n  const { [kClient]: client, [kParser]: parser } = this\n\n  if (client[kHTTPConnVersion] === 'h1' && parser) {\n    if (!this[kError] && parser.statusCode && !parser.shouldKeepAlive) {\n      // We treat all incoming data so far as a valid response.\n      parser.onMessageComplete()\n    }\n\n    this[kParser].destroy()\n    this[kParser] = null\n  }\n\n  const err = this[kError] || new SocketError('closed', util.getSocketInfo(this))\n\n  client[kSocket] = null\n\n  if (client.destroyed) {\n    assert(client[kPending] === 0)\n\n    // Fail entire queue.\n    const requests = client[kQueue].splice(client[kRunningIdx])\n    for (let i = 0; i < requests.length; i++) {\n      const request = requests[i]\n      errorRequest(client, request, err)\n    }\n  } else if (client[kRunning] > 0 && err.code !== 'UND_ERR_INFO') {\n    // Fail head of pipeline.\n    const request = client[kQueue][client[kRunningIdx]]\n    client[kQueue][client[kRunningIdx]++] = null\n\n    errorRequest(client, request, err)\n  }\n\n  client[kPendingIdx] = client[kRunningIdx]\n\n  assert(client[kRunning] === 0)\n\n  client.emit('disconnect', client[kUrl], [client], err)\n\n  resume(client)\n}\n\nasync function connect (client) {\n  assert(!client[kConnecting])\n  assert(!client[kSocket])\n\n  let { host, hostname, protocol, port } = client[kUrl]\n\n  // Resolve ipv6\n  if (hostname[0] === '[') {\n    const idx = hostname.indexOf(']')\n\n    assert(idx !== -1)\n    const ip = hostname.substring(1, idx)\n\n    assert(net.isIP(ip))\n    hostname = ip\n  }\n\n  client[kConnecting] = true\n\n  if (channels.beforeConnect.hasSubscribers) {\n    channels.beforeConnect.publish({\n      connectParams: {\n        host,\n        hostname,\n        protocol,\n        port,\n        servername: client[kServerName],\n        localAddress: client[kLocalAddress]\n      },\n      connector: client[kConnector]\n    })\n  }\n\n  try {\n    const socket = await new Promise((resolve, reject) => {\n      client[kConnector]({\n        host,\n        hostname,\n        protocol,\n        port,\n        servername: client[kServerName],\n        localAddress: client[kLocalAddress]\n      }, (err, socket) => {\n        if (err) {\n          reject(err)\n        } else {\n          resolve(socket)\n        }\n      })\n    })\n\n    if (client.destroyed) {\n      util.destroy(socket.on('error', () => {}), new ClientDestroyedError())\n      return\n    }\n\n    client[kConnecting] = false\n\n    assert(socket)\n\n    const isH2 = socket.alpnProtocol === 'h2'\n    if (isH2) {\n      if (!h2ExperimentalWarned) {\n        h2ExperimentalWarned = true\n        process.emitWarning('H2 support is experimental, expect them to change at any time.', {\n          code: 'UNDICI-H2'\n        })\n      }\n\n      const session = http2.connect(client[kUrl], {\n        createConnection: () => socket,\n        peerMaxConcurrentStreams: client[kHTTP2SessionState].maxConcurrentStreams\n      })\n\n      client[kHTTPConnVersion] = 'h2'\n      session[kClient] = client\n      session[kSocket] = socket\n      session.on('error', onHttp2SessionError)\n      session.on('frameError', onHttp2FrameError)\n      session.on('end', onHttp2SessionEnd)\n      session.on('goaway', onHTTP2GoAway)\n      session.on('close', onSocketClose)\n      session.unref()\n\n      client[kHTTP2Session] = session\n      socket[kHTTP2Session] = session\n    } else {\n      if (!llhttpInstance) {\n        llhttpInstance = await llhttpPromise\n        llhttpPromise = null\n      }\n\n      socket[kNoRef] = false\n      socket[kWriting] = false\n      socket[kReset] = false\n      socket[kBlocking] = false\n      socket[kParser] = new Parser(client, socket, llhttpInstance)\n    }\n\n    socket[kCounter] = 0\n    socket[kMaxRequests] = client[kMaxRequests]\n    socket[kClient] = client\n    socket[kError] = null\n\n    socket\n      .on('error', onSocketError)\n      .on('readable', onSocketReadable)\n      .on('end', onSocketEnd)\n      .on('close', onSocketClose)\n\n    client[kSocket] = socket\n\n    if (channels.connected.hasSubscribers) {\n      channels.connected.publish({\n        connectParams: {\n          host,\n          hostname,\n          protocol,\n          port,\n          servername: client[kServerName],\n          localAddress: client[kLocalAddress]\n        },\n        connector: client[kConnector],\n        socket\n      })\n    }\n    client.emit('connect', client[kUrl], [client])\n  } catch (err) {\n    if (client.destroyed) {\n      return\n    }\n\n    client[kConnecting] = false\n\n    if (channels.connectError.hasSubscribers) {\n      channels.connectError.publish({\n        connectParams: {\n          host,\n          hostname,\n          protocol,\n          port,\n          servername: client[kServerName],\n          localAddress: client[kLocalAddress]\n        },\n        connector: client[kConnector],\n        error: err\n      })\n    }\n\n    if (err.code === 'ERR_TLS_CERT_ALTNAME_INVALID') {\n      assert(client[kRunning] === 0)\n      while (client[kPending] > 0 && client[kQueue][client[kPendingIdx]].servername === client[kServerName]) {\n        const request = client[kQueue][client[kPendingIdx]++]\n        errorRequest(client, request, err)\n      }\n    } else {\n      onError(client, err)\n    }\n\n    client.emit('connectionError', client[kUrl], [client], err)\n  }\n\n  resume(client)\n}\n\nfunction emitDrain (client) {\n  client[kNeedDrain] = 0\n  client.emit('drain', client[kUrl], [client])\n}\n\nfunction resume (client, sync) {\n  if (client[kResuming] === 2) {\n    return\n  }\n\n  client[kResuming] = 2\n\n  _resume(client, sync)\n  client[kResuming] = 0\n\n  if (client[kRunningIdx] > 256) {\n    client[kQueue].splice(0, client[kRunningIdx])\n    client[kPendingIdx] -= client[kRunningIdx]\n    client[kRunningIdx] = 0\n  }\n}\n\nfunction _resume (client, sync) {\n  while (true) {\n    if (client.destroyed) {\n      assert(client[kPending] === 0)\n      return\n    }\n\n    if (client[kClosedResolve] && !client[kSize]) {\n      client[kClosedResolve]()\n      client[kClosedResolve] = null\n      return\n    }\n\n    const socket = client[kSocket]\n\n    if (socket && !socket.destroyed && socket.alpnProtocol !== 'h2') {\n      if (client[kSize] === 0) {\n        if (!socket[kNoRef] && socket.unref) {\n          socket.unref()\n          socket[kNoRef] = true\n        }\n      } else if (socket[kNoRef] && socket.ref) {\n        socket.ref()\n        socket[kNoRef] = false\n      }\n\n      if (client[kSize] === 0) {\n        if (socket[kParser].timeoutType !== TIMEOUT_IDLE) {\n          socket[kParser].setTimeout(client[kKeepAliveTimeoutValue], TIMEOUT_IDLE)\n        }\n      } else if (client[kRunning] > 0 && socket[kParser].statusCode < 200) {\n        if (socket[kParser].timeoutType !== TIMEOUT_HEADERS) {\n          const request = client[kQueue][client[kRunningIdx]]\n          const headersTimeout = request.headersTimeout != null\n            ? request.headersTimeout\n            : client[kHeadersTimeout]\n          socket[kParser].setTimeout(headersTimeout, TIMEOUT_HEADERS)\n        }\n      }\n    }\n\n    if (client[kBusy]) {\n      client[kNeedDrain] = 2\n    } else if (client[kNeedDrain] === 2) {\n      if (sync) {\n        client[kNeedDrain] = 1\n        process.nextTick(emitDrain, client)\n      } else {\n        emitDrain(client)\n      }\n      continue\n    }\n\n    if (client[kPending] === 0) {\n      return\n    }\n\n    if (client[kRunning] >= (client[kPipelining] || 1)) {\n      return\n    }\n\n    const request = client[kQueue][client[kPendingIdx]]\n\n    if (client[kUrl].protocol === 'https:' && client[kServerName] !== request.servername) {\n      if (client[kRunning] > 0) {\n        return\n      }\n\n      client[kServerName] = request.servername\n\n      if (socket && socket.servername !== request.servername) {\n        util.destroy(socket, new InformationalError('servername changed'))\n        return\n      }\n    }\n\n    if (client[kConnecting]) {\n      return\n    }\n\n    if (!socket && !client[kHTTP2Session]) {\n      connect(client)\n      return\n    }\n\n    if (socket.destroyed || socket[kWriting] || socket[kReset] || socket[kBlocking]) {\n      return\n    }\n\n    if (client[kRunning] > 0 && !request.idempotent) {\n      // Non-idempotent request cannot be retried.\n      // Ensure that no other requests are inflight and\n      // could cause failure.\n      return\n    }\n\n    if (client[kRunning] > 0 && (request.upgrade || request.method === 'CONNECT')) {\n      // Don't dispatch an upgrade until all preceding requests have completed.\n      // A misbehaving server might upgrade the connection before all pipelined\n      // request has completed.\n      return\n    }\n\n    if (client[kRunning] > 0 && util.bodyLength(request.body) !== 0 &&\n      (util.isStream(request.body) || util.isAsyncIterable(request.body))) {\n      // Request with stream or iterator body can error while other requests\n      // are inflight and indirectly error those as well.\n      // Ensure this doesn't happen by waiting for inflight\n      // to complete before dispatching.\n\n      // Request with stream or iterator body cannot be retried.\n      // Ensure that no other requests are inflight and\n      // could cause failure.\n      return\n    }\n\n    if (!request.aborted && write(client, request)) {\n      client[kPendingIdx]++\n    } else {\n      client[kQueue].splice(client[kPendingIdx], 1)\n    }\n  }\n}\n\n// https://www.rfc-editor.org/rfc/rfc7230#section-3.3.2\nfunction shouldSendContentLength (method) {\n  return method !== 'GET' && method !== 'HEAD' && method !== 'OPTIONS' && method !== 'TRACE' && method !== 'CONNECT'\n}\n\nfunction write (client, request) {\n  if (client[kHTTPConnVersion] === 'h2') {\n    writeH2(client, client[kHTTP2Session], request)\n    return\n  }\n\n  const { body, method, path, host, upgrade, headers, blocking, reset } = request\n\n  // https://tools.ietf.org/html/rfc7231#section-4.3.1\n  // https://tools.ietf.org/html/rfc7231#section-4.3.2\n  // https://tools.ietf.org/html/rfc7231#section-4.3.5\n\n  // Sending a payload body on a request that does not\n  // expect it can cause undefined behavior on some\n  // servers and corrupt connection state. Do not\n  // re-use the connection for further requests.\n\n  const expectsPayload = (\n    method === 'PUT' ||\n    method === 'POST' ||\n    method === 'PATCH'\n  )\n\n  if (body && typeof body.read === 'function') {\n    // Try to read EOF in order to get length.\n    body.read(0)\n  }\n\n  const bodyLength = util.bodyLength(body)\n\n  let contentLength = bodyLength\n\n  if (contentLength === null) {\n    contentLength = request.contentLength\n  }\n\n  if (contentLength === 0 && !expectsPayload) {\n    // https://tools.ietf.org/html/rfc7230#section-3.3.2\n    // A user agent SHOULD NOT send a Content-Length header field when\n    // the request message does not contain a payload body and the method\n    // semantics do not anticipate such a body.\n\n    contentLength = null\n  }\n\n  // https://github.com/nodejs/undici/issues/2046\n  // A user agent may send a Content-Length header with 0 value, this should be allowed.\n  if (shouldSendContentLength(method) && contentLength > 0 && request.contentLength !== null && request.contentLength !== contentLength) {\n    if (client[kStrictContentLength]) {\n      errorRequest(client, request, new RequestContentLengthMismatchError())\n      return false\n    }\n\n    process.emitWarning(new RequestContentLengthMismatchError())\n  }\n\n  const socket = client[kSocket]\n\n  try {\n    request.onConnect((err) => {\n      if (request.aborted || request.completed) {\n        return\n      }\n\n      errorRequest(client, request, err || new RequestAbortedError())\n\n      util.destroy(socket, new InformationalError('aborted'))\n    })\n  } catch (err) {\n    errorRequest(client, request, err)\n  }\n\n  if (request.aborted) {\n    return false\n  }\n\n  if (method === 'HEAD') {\n    // https://github.com/mcollina/undici/issues/258\n    // Close after a HEAD request to interop with misbehaving servers\n    // that may send a body in the response.\n\n    socket[kReset] = true\n  }\n\n  if (upgrade || method === 'CONNECT') {\n    // On CONNECT or upgrade, block pipeline from dispatching further\n    // requests on this connection.\n\n    socket[kReset] = true\n  }\n\n  if (reset != null) {\n    socket[kReset] = reset\n  }\n\n  if (client[kMaxRequests] && socket[kCounter]++ >= client[kMaxRequests]) {\n    socket[kReset] = true\n  }\n\n  if (blocking) {\n    socket[kBlocking] = true\n  }\n\n  let header = `${method} ${path} HTTP/1.1\\r\\n`\n\n  if (typeof host === 'string') {\n    header += `host: ${host}\\r\\n`\n  } else {\n    header += client[kHostHeader]\n  }\n\n  if (upgrade) {\n    header += `connection: upgrade\\r\\nupgrade: ${upgrade}\\r\\n`\n  } else if (client[kPipelining] && !socket[kReset]) {\n    header += 'connection: keep-alive\\r\\n'\n  } else {\n    header += 'connection: close\\r\\n'\n  }\n\n  if (headers) {\n    header += headers\n  }\n\n  if (channels.sendHeaders.hasSubscribers) {\n    channels.sendHeaders.publish({ request, headers: header, socket })\n  }\n\n  /* istanbul ignore else: assertion */\n  if (!body || bodyLength === 0) {\n    if (contentLength === 0) {\n      socket.write(`${header}content-length: 0\\r\\n\\r\\n`, 'latin1')\n    } else {\n      assert(contentLength === null, 'no body must not have content length')\n      socket.write(`${header}\\r\\n`, 'latin1')\n    }\n    request.onRequestSent()\n  } else if (util.isBuffer(body)) {\n    assert(contentLength === body.byteLength, 'buffer body must have content length')\n\n    socket.cork()\n    socket.write(`${header}content-length: ${contentLength}\\r\\n\\r\\n`, 'latin1')\n    socket.write(body)\n    socket.uncork()\n    request.onBodySent(body)\n    request.onRequestSent()\n    if (!expectsPayload) {\n      socket[kReset] = true\n    }\n  } else if (util.isBlobLike(body)) {\n    if (typeof body.stream === 'function') {\n      writeIterable({ body: body.stream(), client, request, socket, contentLength, header, expectsPayload })\n    } else {\n      writeBlob({ body, client, request, socket, contentLength, header, expectsPayload })\n    }\n  } else if (util.isStream(body)) {\n    writeStream({ body, client, request, socket, contentLength, header, expectsPayload })\n  } else if (util.isIterable(body)) {\n    writeIterable({ body, client, request, socket, contentLength, header, expectsPayload })\n  } else {\n    assert(false)\n  }\n\n  return true\n}\n\nfunction writeH2 (client, session, request) {\n  const { body, method, path, host, upgrade, expectContinue, signal, headers: reqHeaders } = request\n\n  let headers\n  if (typeof reqHeaders === 'string') headers = Request[kHTTP2CopyHeaders](reqHeaders.trim())\n  else headers = reqHeaders\n\n  if (upgrade) {\n    errorRequest(client, request, new Error('Upgrade not supported for H2'))\n    return false\n  }\n\n  try {\n    // TODO(HTTP/2): Should we call onConnect immediately or on stream ready event?\n    request.onConnect((err) => {\n      if (request.aborted || request.completed) {\n        return\n      }\n\n      errorRequest(client, request, err || new RequestAbortedError())\n    })\n  } catch (err) {\n    errorRequest(client, request, err)\n  }\n\n  if (request.aborted) {\n    return false\n  }\n\n  /** @type {import('node:http2').ClientHttp2Stream} */\n  let stream\n  const h2State = client[kHTTP2SessionState]\n\n  headers[HTTP2_HEADER_AUTHORITY] = host || client[kHost]\n  headers[HTTP2_HEADER_METHOD] = method\n\n  if (method === 'CONNECT') {\n    session.ref()\n    // we are already connected, streams are pending, first request\n    // will create a new stream. We trigger a request to create the stream and wait until\n    // `ready` event is triggered\n    // We disabled endStream to allow the user to write to the stream\n    stream = session.request(headers, { endStream: false, signal })\n\n    if (stream.id && !stream.pending) {\n      request.onUpgrade(null, null, stream)\n      ++h2State.openStreams\n    } else {\n      stream.once('ready', () => {\n        request.onUpgrade(null, null, stream)\n        ++h2State.openStreams\n      })\n    }\n\n    stream.once('close', () => {\n      h2State.openStreams -= 1\n      // TODO(HTTP/2): unref only if current streams count is 0\n      if (h2State.openStreams === 0) session.unref()\n    })\n\n    return true\n  }\n\n  // https://tools.ietf.org/html/rfc7540#section-8.3\n  // :path and :scheme headers must be omited when sending CONNECT\n\n  headers[HTTP2_HEADER_PATH] = path\n  headers[HTTP2_HEADER_SCHEME] = 'https'\n\n  // https://tools.ietf.org/html/rfc7231#section-4.3.1\n  // https://tools.ietf.org/html/rfc7231#section-4.3.2\n  // https://tools.ietf.org/html/rfc7231#section-4.3.5\n\n  // Sending a payload body on a request that does not\n  // expect it can cause undefined behavior on some\n  // servers and corrupt connection state. Do not\n  // re-use the connection for further requests.\n\n  const expectsPayload = (\n    method === 'PUT' ||\n    method === 'POST' ||\n    method === 'PATCH'\n  )\n\n  if (body && typeof body.read === 'function') {\n    // Try to read EOF in order to get length.\n    body.read(0)\n  }\n\n  let contentLength = util.bodyLength(body)\n\n  if (contentLength == null) {\n    contentLength = request.contentLength\n  }\n\n  if (contentLength === 0 || !expectsPayload) {\n    // https://tools.ietf.org/html/rfc7230#section-3.3.2\n    // A user agent SHOULD NOT send a Content-Length header field when\n    // the request message does not contain a payload body and the method\n    // semantics do not anticipate such a body.\n\n    contentLength = null\n  }\n\n  // https://github.com/nodejs/undici/issues/2046\n  // A user agent may send a Content-Length header with 0 value, this should be allowed.\n  if (shouldSendContentLength(method) && contentLength > 0 && request.contentLength != null && request.contentLength !== contentLength) {\n    if (client[kStrictContentLength]) {\n      errorRequest(client, request, new RequestContentLengthMismatchError())\n      return false\n    }\n\n    process.emitWarning(new RequestContentLengthMismatchError())\n  }\n\n  if (contentLength != null) {\n    assert(body, 'no body must not have content length')\n    headers[HTTP2_HEADER_CONTENT_LENGTH] = `${contentLength}`\n  }\n\n  session.ref()\n\n  const shouldEndStream = method === 'GET' || method === 'HEAD'\n  if (expectContinue) {\n    headers[HTTP2_HEADER_EXPECT] = '100-continue'\n    stream = session.request(headers, { endStream: shouldEndStream, signal })\n\n    stream.once('continue', writeBodyH2)\n  } else {\n    stream = session.request(headers, {\n      endStream: shouldEndStream,\n      signal\n    })\n    writeBodyH2()\n  }\n\n  // Increment counter as we have new several streams open\n  ++h2State.openStreams\n\n  stream.once('response', headers => {\n    const { [HTTP2_HEADER_STATUS]: statusCode, ...realHeaders } = headers\n\n    if (request.onHeaders(Number(statusCode), realHeaders, stream.resume.bind(stream), '') === false) {\n      stream.pause()\n    }\n  })\n\n  stream.once('end', () => {\n    request.onComplete([])\n  })\n\n  stream.on('data', (chunk) => {\n    if (request.onData(chunk) === false) {\n      stream.pause()\n    }\n  })\n\n  stream.once('close', () => {\n    h2State.openStreams -= 1\n    // TODO(HTTP/2): unref only if current streams count is 0\n    if (h2State.openStreams === 0) {\n      session.unref()\n    }\n  })\n\n  stream.once('error', function (err) {\n    if (client[kHTTP2Session] && !client[kHTTP2Session].destroyed && !this.closed && !this.destroyed) {\n      h2State.streams -= 1\n      util.destroy(stream, err)\n    }\n  })\n\n  stream.once('frameError', (type, code) => {\n    const err = new InformationalError(`HTTP/2: \"frameError\" received - type ${type}, code ${code}`)\n    errorRequest(client, request, err)\n\n    if (client[kHTTP2Session] && !client[kHTTP2Session].destroyed && !this.closed && !this.destroyed) {\n      h2State.streams -= 1\n      util.destroy(stream, err)\n    }\n  })\n\n  // stream.on('aborted', () => {\n  //   // TODO(HTTP/2): Support aborted\n  // })\n\n  // stream.on('timeout', () => {\n  //   // TODO(HTTP/2): Support timeout\n  // })\n\n  // stream.on('push', headers => {\n  //   // TODO(HTTP/2): Suppor push\n  // })\n\n  // stream.on('trailers', headers => {\n  //   // TODO(HTTP/2): Support trailers\n  // })\n\n  return true\n\n  function writeBodyH2 () {\n    /* istanbul ignore else: assertion */\n    if (!body) {\n      request.onRequestSent()\n    } else if (util.isBuffer(body)) {\n      assert(contentLength === body.byteLength, 'buffer body must have content length')\n      stream.cork()\n      stream.write(body)\n      stream.uncork()\n      stream.end()\n      request.onBodySent(body)\n      request.onRequestSent()\n    } else if (util.isBlobLike(body)) {\n      if (typeof body.stream === 'function') {\n        writeIterable({\n          client,\n          request,\n          contentLength,\n          h2stream: stream,\n          expectsPayload,\n          body: body.stream(),\n          socket: client[kSocket],\n          header: ''\n        })\n      } else {\n        writeBlob({\n          body,\n          client,\n          request,\n          contentLength,\n          expectsPayload,\n          h2stream: stream,\n          header: '',\n          socket: client[kSocket]\n        })\n      }\n    } else if (util.isStream(body)) {\n      writeStream({\n        body,\n        client,\n        request,\n        contentLength,\n        expectsPayload,\n        socket: client[kSocket],\n        h2stream: stream,\n        header: ''\n      })\n    } else if (util.isIterable(body)) {\n      writeIterable({\n        body,\n        client,\n        request,\n        contentLength,\n        expectsPayload,\n        header: '',\n        h2stream: stream,\n        socket: client[kSocket]\n      })\n    } else {\n      assert(false)\n    }\n  }\n}\n\nfunction writeStream ({ h2stream, body, client, request, socket, contentLength, header, expectsPayload }) {\n  assert(contentLength !== 0 || client[kRunning] === 0, 'stream body cannot be pipelined')\n\n  if (client[kHTTPConnVersion] === 'h2') {\n    // For HTTP/2, is enough to pipe the stream\n    const pipe = pipeline(\n      body,\n      h2stream,\n      (err) => {\n        if (err) {\n          util.destroy(body, err)\n          util.destroy(h2stream, err)\n        } else {\n          request.onRequestSent()\n        }\n      }\n    )\n\n    pipe.on('data', onPipeData)\n    pipe.once('end', () => {\n      pipe.removeListener('data', onPipeData)\n      util.destroy(pipe)\n    })\n\n    function onPipeData (chunk) {\n      request.onBodySent(chunk)\n    }\n\n    return\n  }\n\n  let finished = false\n\n  const writer = new AsyncWriter({ socket, request, contentLength, client, expectsPayload, header })\n\n  const onData = function (chunk) {\n    if (finished) {\n      return\n    }\n\n    try {\n      if (!writer.write(chunk) && this.pause) {\n        this.pause()\n      }\n    } catch (err) {\n      util.destroy(this, err)\n    }\n  }\n  const onDrain = function () {\n    if (finished) {\n      return\n    }\n\n    if (body.resume) {\n      body.resume()\n    }\n  }\n  const onAbort = function () {\n    if (finished) {\n      return\n    }\n    const err = new RequestAbortedError()\n    queueMicrotask(() => onFinished(err))\n  }\n  const onFinished = function (err) {\n    if (finished) {\n      return\n    }\n\n    finished = true\n\n    assert(socket.destroyed || (socket[kWriting] && client[kRunning] <= 1))\n\n    socket\n      .off('drain', onDrain)\n      .off('error', onFinished)\n\n    body\n      .removeListener('data', onData)\n      .removeListener('end', onFinished)\n      .removeListener('error', onFinished)\n      .removeListener('close', onAbort)\n\n    if (!err) {\n      try {\n        writer.end()\n      } catch (er) {\n        err = er\n      }\n    }\n\n    writer.destroy(err)\n\n    if (err && (err.code !== 'UND_ERR_INFO' || err.message !== 'reset')) {\n      util.destroy(body, err)\n    } else {\n      util.destroy(body)\n    }\n  }\n\n  body\n    .on('data', onData)\n    .on('end', onFinished)\n    .on('error', onFinished)\n    .on('close', onAbort)\n\n  if (body.resume) {\n    body.resume()\n  }\n\n  socket\n    .on('drain', onDrain)\n    .on('error', onFinished)\n}\n\nasync function writeBlob ({ h2stream, body, client, request, socket, contentLength, header, expectsPayload }) {\n  assert(contentLength === body.size, 'blob body must have content length')\n\n  const isH2 = client[kHTTPConnVersion] === 'h2'\n  try {\n    if (contentLength != null && contentLength !== body.size) {\n      throw new RequestContentLengthMismatchError()\n    }\n\n    const buffer = Buffer.from(await body.arrayBuffer())\n\n    if (isH2) {\n      h2stream.cork()\n      h2stream.write(buffer)\n      h2stream.uncork()\n    } else {\n      socket.cork()\n      socket.write(`${header}content-length: ${contentLength}\\r\\n\\r\\n`, 'latin1')\n      socket.write(buffer)\n      socket.uncork()\n    }\n\n    request.onBodySent(buffer)\n    request.onRequestSent()\n\n    if (!expectsPayload) {\n      socket[kReset] = true\n    }\n\n    resume(client)\n  } catch (err) {\n    util.destroy(isH2 ? h2stream : socket, err)\n  }\n}\n\nasync function writeIterable ({ h2stream, body, client, request, socket, contentLength, header, expectsPayload }) {\n  assert(contentLength !== 0 || client[kRunning] === 0, 'iterator body cannot be pipelined')\n\n  let callback = null\n  function onDrain () {\n    if (callback) {\n      const cb = callback\n      callback = null\n      cb()\n    }\n  }\n\n  const waitForDrain = () => new Promise((resolve, reject) => {\n    assert(callback === null)\n\n    if (socket[kError]) {\n      reject(socket[kError])\n    } else {\n      callback = resolve\n    }\n  })\n\n  if (client[kHTTPConnVersion] === 'h2') {\n    h2stream\n      .on('close', onDrain)\n      .on('drain', onDrain)\n\n    try {\n      // It's up to the user to somehow abort the async iterable.\n      for await (const chunk of body) {\n        if (socket[kError]) {\n          throw socket[kError]\n        }\n\n        const res = h2stream.write(chunk)\n        request.onBodySent(chunk)\n        if (!res) {\n          await waitForDrain()\n        }\n      }\n    } catch (err) {\n      h2stream.destroy(err)\n    } finally {\n      request.onRequestSent()\n      h2stream.end()\n      h2stream\n        .off('close', onDrain)\n        .off('drain', onDrain)\n    }\n\n    return\n  }\n\n  socket\n    .on('close', onDrain)\n    .on('drain', onDrain)\n\n  const writer = new AsyncWriter({ socket, request, contentLength, client, expectsPayload, header })\n  try {\n    // It's up to the user to somehow abort the async iterable.\n    for await (const chunk of body) {\n      if (socket[kError]) {\n        throw socket[kError]\n      }\n\n      if (!writer.write(chunk)) {\n        await waitForDrain()\n      }\n    }\n\n    writer.end()\n  } catch (err) {\n    writer.destroy(err)\n  } finally {\n    socket\n      .off('close', onDrain)\n      .off('drain', onDrain)\n  }\n}\n\nclass AsyncWriter {\n  constructor ({ socket, request, contentLength, client, expectsPayload, header }) {\n    this.socket = socket\n    this.request = request\n    this.contentLength = contentLength\n    this.client = client\n    this.bytesWritten = 0\n    this.expectsPayload = expectsPayload\n    this.header = header\n\n    socket[kWriting] = true\n  }\n\n  write (chunk) {\n    const { socket, request, contentLength, client, bytesWritten, expectsPayload, header } = this\n\n    if (socket[kError]) {\n      throw socket[kError]\n    }\n\n    if (socket.destroyed) {\n      return false\n    }\n\n    const len = Buffer.byteLength(chunk)\n    if (!len) {\n      return true\n    }\n\n    // We should defer writing chunks.\n    if (contentLength !== null && bytesWritten + len > contentLength) {\n      if (client[kStrictContentLength]) {\n        throw new RequestContentLengthMismatchError()\n      }\n\n      process.emitWarning(new RequestContentLengthMismatchError())\n    }\n\n    socket.cork()\n\n    if (bytesWritten === 0) {\n      if (!expectsPayload) {\n        socket[kReset] = true\n      }\n\n      if (contentLength === null) {\n        socket.write(`${header}transfer-encoding: chunked\\r\\n`, 'latin1')\n      } else {\n        socket.write(`${header}content-length: ${contentLength}\\r\\n\\r\\n`, 'latin1')\n      }\n    }\n\n    if (contentLength === null) {\n      socket.write(`\\r\\n${len.toString(16)}\\r\\n`, 'latin1')\n    }\n\n    this.bytesWritten += len\n\n    const ret = socket.write(chunk)\n\n    socket.uncork()\n\n    request.onBodySent(chunk)\n\n    if (!ret) {\n      if (socket[kParser].timeout && socket[kParser].timeoutType === TIMEOUT_HEADERS) {\n        // istanbul ignore else: only for jest\n        if (socket[kParser].timeout.refresh) {\n          socket[kParser].timeout.refresh()\n        }\n      }\n    }\n\n    return ret\n  }\n\n  end () {\n    const { socket, contentLength, client, bytesWritten, expectsPayload, header, request } = this\n    request.onRequestSent()\n\n    socket[kWriting] = false\n\n    if (socket[kError]) {\n      throw socket[kError]\n    }\n\n    if (socket.destroyed) {\n      return\n    }\n\n    if (bytesWritten === 0) {\n      if (expectsPayload) {\n        // https://tools.ietf.org/html/rfc7230#section-3.3.2\n        // A user agent SHOULD send a Content-Length in a request message when\n        // no Transfer-Encoding is sent and the request method defines a meaning\n        // for an enclosed payload body.\n\n        socket.write(`${header}content-length: 0\\r\\n\\r\\n`, 'latin1')\n      } else {\n        socket.write(`${header}\\r\\n`, 'latin1')\n      }\n    } else if (contentLength === null) {\n      socket.write('\\r\\n0\\r\\n\\r\\n', 'latin1')\n    }\n\n    if (contentLength !== null && bytesWritten !== contentLength) {\n      if (client[kStrictContentLength]) {\n        throw new RequestContentLengthMismatchError()\n      } else {\n        process.emitWarning(new RequestContentLengthMismatchError())\n      }\n    }\n\n    if (socket[kParser].timeout && socket[kParser].timeoutType === TIMEOUT_HEADERS) {\n      // istanbul ignore else: only for jest\n      if (socket[kParser].timeout.refresh) {\n        socket[kParser].timeout.refresh()\n      }\n    }\n\n    resume(client)\n  }\n\n  destroy (err) {\n    const { socket, client } = this\n\n    socket[kWriting] = false\n\n    if (err) {\n      assert(client[kRunning] <= 1, 'pipeline should only contain this request')\n      util.destroy(socket, err)\n    }\n  }\n}\n\nfunction errorRequest (client, request, err) {\n  try {\n    request.onError(err)\n    assert(request.aborted)\n  } catch (err) {\n    client.emit('error', err)\n  }\n}\n\nmodule.exports = Client\n","'use strict'\n\n/* istanbul ignore file: only for Node 12 */\n\nconst { kConnected, kSize } = require('../core/symbols')\n\nclass CompatWeakRef {\n  constructor (value) {\n    this.value = value\n  }\n\n  deref () {\n    return this.value[kConnected] === 0 && this.value[kSize] === 0\n      ? undefined\n      : this.value\n  }\n}\n\nclass CompatFinalizer {\n  constructor (finalizer) {\n    this.finalizer = finalizer\n  }\n\n  register (dispatcher, key) {\n    if (dispatcher.on) {\n      dispatcher.on('disconnect', () => {\n        if (dispatcher[kConnected] === 0 && dispatcher[kSize] === 0) {\n          this.finalizer(key)\n        }\n      })\n    }\n  }\n}\n\nmodule.exports = function () {\n  // FIXME: remove workaround when the Node bug is fixed\n  // https://github.com/nodejs/node/issues/49344#issuecomment-1741776308\n  if (process.env.NODE_V8_COVERAGE) {\n    return {\n      WeakRef: CompatWeakRef,\n      FinalizationRegistry: CompatFinalizer\n    }\n  }\n  return {\n    WeakRef: global.WeakRef || CompatWeakRef,\n    FinalizationRegistry: global.FinalizationRegistry || CompatFinalizer\n  }\n}\n","'use strict'\n\n// https://wicg.github.io/cookie-store/#cookie-maximum-attribute-value-size\nconst maxAttributeValueSize = 1024\n\n// https://wicg.github.io/cookie-store/#cookie-maximum-name-value-pair-size\nconst maxNameValuePairSize = 4096\n\nmodule.exports = {\n  maxAttributeValueSize,\n  maxNameValuePairSize\n}\n","'use strict'\n\nconst { parseSetCookie } = require('./parse')\nconst { stringify, getHeadersList } = require('./util')\nconst { webidl } = require('../fetch/webidl')\nconst { Headers } = require('../fetch/headers')\n\n/**\n * @typedef {Object} Cookie\n * @property {string} name\n * @property {string} value\n * @property {Date|number|undefined} expires\n * @property {number|undefined} maxAge\n * @property {string|undefined} domain\n * @property {string|undefined} path\n * @property {boolean|undefined} secure\n * @property {boolean|undefined} httpOnly\n * @property {'Strict'|'Lax'|'None'} sameSite\n * @property {string[]} unparsed\n */\n\n/**\n * @param {Headers} headers\n * @returns {Record<string, string>}\n */\nfunction getCookies (headers) {\n  webidl.argumentLengthCheck(arguments, 1, { header: 'getCookies' })\n\n  webidl.brandCheck(headers, Headers, { strict: false })\n\n  const cookie = headers.get('cookie')\n  const out = {}\n\n  if (!cookie) {\n    return out\n  }\n\n  for (const piece of cookie.split(';')) {\n    const [name, ...value] = piece.split('=')\n\n    out[name.trim()] = value.join('=')\n  }\n\n  return out\n}\n\n/**\n * @param {Headers} headers\n * @param {string} name\n * @param {{ path?: string, domain?: string }|undefined} attributes\n * @returns {void}\n */\nfunction deleteCookie (headers, name, attributes) {\n  webidl.argumentLengthCheck(arguments, 2, { header: 'deleteCookie' })\n\n  webidl.brandCheck(headers, Headers, { strict: false })\n\n  name = webidl.converters.DOMString(name)\n  attributes = webidl.converters.DeleteCookieAttributes(attributes)\n\n  // Matches behavior of\n  // https://github.com/denoland/deno_std/blob/63827b16330b82489a04614027c33b7904e08be5/http/cookie.ts#L278\n  setCookie(headers, {\n    name,\n    value: '',\n    expires: new Date(0),\n    ...attributes\n  })\n}\n\n/**\n * @param {Headers} headers\n * @returns {Cookie[]}\n */\nfunction getSetCookies (headers) {\n  webidl.argumentLengthCheck(arguments, 1, { header: 'getSetCookies' })\n\n  webidl.brandCheck(headers, Headers, { strict: false })\n\n  const cookies = getHeadersList(headers).cookies\n\n  if (!cookies) {\n    return []\n  }\n\n  // In older versions of undici, cookies is a list of name:value.\n  return cookies.map((pair) => parseSetCookie(Array.isArray(pair) ? pair[1] : pair))\n}\n\n/**\n * @param {Headers} headers\n * @param {Cookie} cookie\n * @returns {void}\n */\nfunction setCookie (headers, cookie) {\n  webidl.argumentLengthCheck(arguments, 2, { header: 'setCookie' })\n\n  webidl.brandCheck(headers, Headers, { strict: false })\n\n  cookie = webidl.converters.Cookie(cookie)\n\n  const str = stringify(cookie)\n\n  if (str) {\n    headers.append('Set-Cookie', stringify(cookie))\n  }\n}\n\nwebidl.converters.DeleteCookieAttributes = webidl.dictionaryConverter([\n  {\n    converter: webidl.nullableConverter(webidl.converters.DOMString),\n    key: 'path',\n    defaultValue: null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.DOMString),\n    key: 'domain',\n    defaultValue: null\n  }\n])\n\nwebidl.converters.Cookie = webidl.dictionaryConverter([\n  {\n    converter: webidl.converters.DOMString,\n    key: 'name'\n  },\n  {\n    converter: webidl.converters.DOMString,\n    key: 'value'\n  },\n  {\n    converter: webidl.nullableConverter((value) => {\n      if (typeof value === 'number') {\n        return webidl.converters['unsigned long long'](value)\n      }\n\n      return new Date(value)\n    }),\n    key: 'expires',\n    defaultValue: null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters['long long']),\n    key: 'maxAge',\n    defaultValue: null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.DOMString),\n    key: 'domain',\n    defaultValue: null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.DOMString),\n    key: 'path',\n    defaultValue: null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.boolean),\n    key: 'secure',\n    defaultValue: null\n  },\n  {\n    converter: webidl.nullableConverter(webidl.converters.boolean),\n    key: 'httpOnly',\n    defaultValue: null\n  },\n  {\n    converter: webidl.converters.USVString,\n    key: 'sameSite',\n    allowedValues: ['Strict', 'Lax', 'None']\n  },\n  {\n    converter: webidl.sequenceConverter(webidl.converters.DOMString),\n    key: 'unparsed',\n    defaultValue: []\n  }\n])\n\nmodule.exports = {\n  getCookies,\n  deleteCookie,\n  getSetCookies,\n  setCookie\n}\n","'use strict'\n\nconst { maxNameValuePairSize, maxAttributeValueSize } = require('./constants')\nconst { isCTLExcludingHtab } = require('./util')\nconst { collectASequenceOfCodePointsFast } = require('../fetch/dataURL')\nconst assert = require('assert')\n\n/**\n * @description Parses the field-value attributes of a set-cookie header string.\n * @see https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4\n * @param {string} header\n * @returns if the header is invalid, null will be returned\n */\nfunction parseSetCookie (header) {\n  // 1. If the set-cookie-string contains a %x00-08 / %x0A-1F / %x7F\n  //    character (CTL characters excluding HTAB): Abort these steps and\n  //    ignore the set-cookie-string entirely.\n  if (isCTLExcludingHtab(header)) {\n    return null\n  }\n\n  let nameValuePair = ''\n  let unparsedAttributes = ''\n  let name = ''\n  let value = ''\n\n  // 2. If the set-cookie-string contains a %x3B (\";\") character:\n  if (header.includes(';')) {\n    // 1. The name-value-pair string consists of the characters up to,\n    //    but not including, the first %x3B (\";\"), and the unparsed-\n    //    attributes consist of the remainder of the set-cookie-string\n    //    (including the %x3B (\";\") in question).\n    const position = { position: 0 }\n\n    nameValuePair = collectASequenceOfCodePointsFast(';', header, position)\n    unparsedAttributes = header.slice(position.position)\n  } else {\n    // Otherwise:\n\n    // 1. The name-value-pair string consists of all the characters\n    //    contained in the set-cookie-string, and the unparsed-\n    //    attributes is the empty string.\n    nameValuePair = header\n  }\n\n  // 3. If the name-value-pair string lacks a %x3D (\"=\") character, then\n  //    the name string is empty, and the value string is the value of\n  //    name-value-pair.\n  if (!nameValuePair.includes('=')) {\n    value = nameValuePair\n  } else {\n    //    Otherwise, the name string consists of the characters up to, but\n    //    not including, the first %x3D (\"=\") character, and the (possibly\n    //    empty) value string consists of the characters after the first\n    //    %x3D (\"=\") character.\n    const position = { position: 0 }\n    name = collectASequenceOfCodePointsFast(\n      '=',\n      nameValuePair,\n      position\n    )\n    value = nameValuePair.slice(position.position + 1)\n  }\n\n  // 4. Remove any leading or trailing WSP characters from the name\n  //    string and the value string.\n  name = name.trim()\n  value = value.trim()\n\n  // 5. If the sum of the lengths of the name string and the value string\n  //    is more than 4096 octets, abort these steps and ignore the set-\n  //    cookie-string entirely.\n  if (name.length + value.length > maxNameValuePairSize) {\n    return null\n  }\n\n  // 6. The cookie-name is the name string, and the cookie-value is the\n  //    value string.\n  return {\n    name, value, ...parseUnparsedAttributes(unparsedAttributes)\n  }\n}\n\n/**\n * Parses the remaining attributes of a set-cookie header\n * @see https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4\n * @param {string} unparsedAttributes\n * @param {[Object.<string, unknown>]={}} cookieAttributeList\n */\nfunction parseUnparsedAttributes (unparsedAttributes, cookieAttributeList = {}) {\n  // 1. If the unparsed-attributes string is empty, skip the rest of\n  //    these steps.\n  if (unparsedAttributes.length === 0) {\n    return cookieAttributeList\n  }\n\n  // 2. Discard the first character of the unparsed-attributes (which\n  //    will be a %x3B (\";\") character).\n  assert(unparsedAttributes[0] === ';')\n  unparsedAttributes = unparsedAttributes.slice(1)\n\n  let cookieAv = ''\n\n  // 3. If the remaining unparsed-attributes contains a %x3B (\";\")\n  //    character:\n  if (unparsedAttributes.includes(';')) {\n    // 1. Consume the characters of the unparsed-attributes up to, but\n    //    not including, the first %x3B (\";\") character.\n    cookieAv = collectASequenceOfCodePointsFast(\n      ';',\n      unparsedAttributes,\n      { position: 0 }\n    )\n    unparsedAttributes = unparsedAttributes.slice(cookieAv.length)\n  } else {\n    // Otherwise:\n\n    // 1. Consume the remainder of the unparsed-attributes.\n    cookieAv = unparsedAttributes\n    unparsedAttributes = ''\n  }\n\n  // Let the cookie-av string be the characters consumed in this step.\n\n  let attributeName = ''\n  let attributeValue = ''\n\n  // 4. If the cookie-av string contains a %x3D (\"=\") character:\n  if (cookieAv.includes('=')) {\n    // 1. The (possibly empty) attribute-name string consists of the\n    //    characters up to, but not including, the first %x3D (\"=\")\n    //    character, and the (possibly empty) attribute-value string\n    //    consists of the characters after the first %x3D (\"=\")\n    //    character.\n    const position = { position: 0 }\n\n    attributeName = collectASequenceOfCodePointsFast(\n      '=',\n      cookieAv,\n      position\n    )\n    attributeValue = cookieAv.slice(position.position + 1)\n  } else {\n    // Otherwise:\n\n    // 1. The attribute-name string consists of the entire cookie-av\n    //    string, and the attribute-value string is empty.\n    attributeName = cookieAv\n  }\n\n  // 5. Remove any leading or trailing WSP characters from the attribute-\n  //    name string and the attribute-value string.\n  attributeName = attributeName.trim()\n  attributeValue = attributeValue.trim()\n\n  // 6. If the attribute-value is longer than 1024 octets, ignore the\n  //    cookie-av string and return to Step 1 of this algorithm.\n  if (attributeValue.length > maxAttributeValueSize) {\n    return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)\n  }\n\n  // 7. Process the attribute-name and attribute-value according to the\n  //    requirements in the following subsections.  (Notice that\n  //    attributes with unrecognized attribute-names are ignored.)\n  const attributeNameLowercase = attributeName.toLowerCase()\n\n  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.1\n  // If the attribute-name case-insensitively matches the string\n  // \"Expires\", the user agent MUST process the cookie-av as follows.\n  if (attributeNameLowercase === 'expires') {\n    // 1. Let the expiry-time be the result of parsing the attribute-value\n    //    as cookie-date (see Section 5.1.1).\n    const expiryTime = new Date(attributeValue)\n\n    // 2. If the attribute-value failed to parse as a cookie date, ignore\n    //    the cookie-av.\n\n    cookieAttributeList.expires = expiryTime\n  } else if (attributeNameLowercase === 'max-age') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.2\n    // If the attribute-name case-insensitively matches the string \"Max-\n    // Age\", the user agent MUST process the cookie-av as follows.\n\n    // 1. If the first character of the attribute-value is not a DIGIT or a\n    //    \"-\" character, ignore the cookie-av.\n    const charCode = attributeValue.charCodeAt(0)\n\n    if ((charCode < 48 || charCode > 57) && attributeValue[0] !== '-') {\n      return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)\n    }\n\n    // 2. If the remainder of attribute-value contains a non-DIGIT\n    //    character, ignore the cookie-av.\n    if (!/^\\d+$/.test(attributeValue)) {\n      return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)\n    }\n\n    // 3. Let delta-seconds be the attribute-value converted to an integer.\n    const deltaSeconds = Number(attributeValue)\n\n    // 4. Let cookie-age-limit be the maximum age of the cookie (which\n    //    SHOULD be 400 days or less, see Section 4.1.2.2).\n\n    // 5. Set delta-seconds to the smaller of its present value and cookie-\n    //    age-limit.\n    // deltaSeconds = Math.min(deltaSeconds * 1000, maxExpiresMs)\n\n    // 6. If delta-seconds is less than or equal to zero (0), let expiry-\n    //    time be the earliest representable date and time.  Otherwise, let\n    //    the expiry-time be the current date and time plus delta-seconds\n    //    seconds.\n    // const expiryTime = deltaSeconds <= 0 ? Date.now() : Date.now() + deltaSeconds\n\n    // 7. Append an attribute to the cookie-attribute-list with an\n    //    attribute-name of Max-Age and an attribute-value of expiry-time.\n    cookieAttributeList.maxAge = deltaSeconds\n  } else if (attributeNameLowercase === 'domain') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.3\n    // If the attribute-name case-insensitively matches the string \"Domain\",\n    // the user agent MUST process the cookie-av as follows.\n\n    // 1. Let cookie-domain be the attribute-value.\n    let cookieDomain = attributeValue\n\n    // 2. If cookie-domain starts with %x2E (\".\"), let cookie-domain be\n    //    cookie-domain without its leading %x2E (\".\").\n    if (cookieDomain[0] === '.') {\n      cookieDomain = cookieDomain.slice(1)\n    }\n\n    // 3. Convert the cookie-domain to lower case.\n    cookieDomain = cookieDomain.toLowerCase()\n\n    // 4. Append an attribute to the cookie-attribute-list with an\n    //    attribute-name of Domain and an attribute-value of cookie-domain.\n    cookieAttributeList.domain = cookieDomain\n  } else if (attributeNameLowercase === 'path') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.4\n    // If the attribute-name case-insensitively matches the string \"Path\",\n    // the user agent MUST process the cookie-av as follows.\n\n    // 1. If the attribute-value is empty or if the first character of the\n    //    attribute-value is not %x2F (\"/\"):\n    let cookiePath = ''\n    if (attributeValue.length === 0 || attributeValue[0] !== '/') {\n      // 1. Let cookie-path be the default-path.\n      cookiePath = '/'\n    } else {\n      // Otherwise:\n\n      // 1. Let cookie-path be the attribute-value.\n      cookiePath = attributeValue\n    }\n\n    // 2. Append an attribute to the cookie-attribute-list with an\n    //    attribute-name of Path and an attribute-value of cookie-path.\n    cookieAttributeList.path = cookiePath\n  } else if (attributeNameLowercase === 'secure') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.5\n    // If the attribute-name case-insensitively matches the string \"Secure\",\n    // the user agent MUST append an attribute to the cookie-attribute-list\n    // with an attribute-name of Secure and an empty attribute-value.\n\n    cookieAttributeList.secure = true\n  } else if (attributeNameLowercase === 'httponly') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.6\n    // If the attribute-name case-insensitively matches the string\n    // \"HttpOnly\", the user agent MUST append an attribute to the cookie-\n    // attribute-list with an attribute-name of HttpOnly and an empty\n    // attribute-value.\n\n    cookieAttributeList.httpOnly = true\n  } else if (attributeNameLowercase === 'samesite') {\n    // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-rfc6265bis#section-5.4.7\n    // If the attribute-name case-insensitively matches the string\n    // \"SameSite\", the user agent MUST process the cookie-av as follows:\n\n    // 1. Let enforcement be \"Default\".\n    let enforcement = 'Default'\n\n    const attributeValueLowercase = attributeValue.toLowerCase()\n    // 2. If cookie-av's attribute-value is a case-insensitive match for\n    //    \"None\", set enforcement to \"None\".\n    if (attributeValueLowercase.includes('none')) {\n      enforcement = 'None'\n    }\n\n    // 3. If cookie-av's attribute-value is a case-insensitive match for\n    //    \"Strict\", set enforcement to \"Strict\".\n    if (attributeValueLowercase.includes('strict')) {\n      enforcement = 'Strict'\n    }\n\n    // 4. If cookie-av's attribute-value is a case-insensitive match for\n    //    \"Lax\", set enforcement to \"Lax\".\n    if (attributeValueLowercase.includes('lax')) {\n      enforcement = 'Lax'\n    }\n\n    // 5. Append an attribute to the cookie-attribute-list with an\n    //    attribute-name of \"SameSite\" and an attribute-value of\n    //    enforcement.\n    cookieAttributeList.sameSite = enforcement\n  } else {\n    cookieAttributeList.unparsed ??= []\n\n    cookieAttributeList.unparsed.push(`${attributeName}=${attributeValue}`)\n  }\n\n  // 8. Return to Step 1 of this algorithm.\n  return parseUnparsedAttributes(unparsedAttributes, cookieAttributeList)\n}\n\nmodule.exports = {\n  parseSetCookie,\n  parseUnparsedAttributes\n}\n","'use strict'\n\nconst assert = require('assert')\nconst { kHeadersList } = require('../core/symbols')\n\nfunction isCTLExcludingHtab (value) {\n  if (value.length === 0) {\n    return false\n  }\n\n  for (const char of value) {\n    const code = char.charCodeAt(0)\n\n    if (\n      (code >= 0x00 || code <= 0x08) ||\n      (code >= 0x0A || code <= 0x1F) ||\n      code === 0x7F\n    ) {\n      return false\n    }\n  }\n}\n\n/**\n CHAR           = <any US-ASCII character (octets 0 - 127)>\n token          = 1*<any CHAR except CTLs or separators>\n separators     = \"(\" | \")\" | \"<\" | \">\" | \"@\"\n                | \",\" | \";\" | \":\" | \"\\\" | <\">\n                | \"/\" | \"[\" | \"]\" | \"?\" | \"=\"\n                | \"{\" | \"}\" | SP | HT\n * @param {string} name\n */\nfunction validateCookieName (name) {\n  for (const char of name) {\n    const code = char.charCodeAt(0)\n\n    if (\n      (code <= 0x20 || code > 0x7F) ||\n      char === '(' ||\n      char === ')' ||\n      char === '>' ||\n      char === '<' ||\n      char === '@' ||\n      char === ',' ||\n      char === ';' ||\n      char === ':' ||\n      char === '\\\\' ||\n      char === '\"' ||\n      char === '/' ||\n      char === '[' ||\n      char === ']' ||\n      char === '?' ||\n      char === '=' ||\n      char === '{' ||\n      char === '}'\n    ) {\n      throw new Error('Invalid cookie name')\n    }\n  }\n}\n\n/**\n cookie-value      = *cookie-octet / ( DQUOTE *cookie-octet DQUOTE )\n cookie-octet      = %x21 / %x23-2B / %x2D-3A / %x3C-5B / %x5D-7E\n                       ; US-ASCII characters excluding CTLs,\n                       ; whitespace DQUOTE, comma, semicolon,\n                       ; and backslash\n * @param {string} value\n */\nfunction validateCookieValue (value) {\n  for (const char of value) {\n    const code = char.charCodeAt(0)\n\n    if (\n      code < 0x21 || // exclude CTLs (0-31)\n      code === 0x22 ||\n      code === 0x2C ||\n      code === 0x3B ||\n      code === 0x5C ||\n      code > 0x7E // non-ascii\n    ) {\n      throw new Error('Invalid header value')\n    }\n  }\n}\n\n/**\n * path-value        = <any CHAR except CTLs or \";\">\n * @param {string} path\n */\nfunction validateCookiePath (path) {\n  for (const char of path) {\n    const code = char.charCodeAt(0)\n\n    if (code < 0x21 || char === ';') {\n      throw new Error('Invalid cookie path')\n    }\n  }\n}\n\n/**\n * I have no idea why these values aren't allowed to be honest,\n * but Deno tests these. - Khafra\n * @param {string} domain\n */\nfunction validateCookieDomain (domain) {\n  if (\n    domain.startsWith('-') ||\n    domain.endsWith('.') ||\n    domain.endsWith('-')\n  ) {\n    throw new Error('Invalid cookie domain')\n  }\n}\n\n/**\n * @see https://www.rfc-editor.org/rfc/rfc7231#section-7.1.1.1\n * @param {number|Date} date\n  IMF-fixdate  = day-name \",\" SP date1 SP time-of-day SP GMT\n  ; fixed length/zone/capitalization subset of the format\n  ; see Section 3.3 of [RFC5322]\n\n  day-name     = %x4D.6F.6E ; \"Mon\", case-sensitive\n              / %x54.75.65 ; \"Tue\", case-sensitive\n              / %x57.65.64 ; \"Wed\", case-sensitive\n              / %x54.68.75 ; \"Thu\", case-sensitive\n              / %x46.72.69 ; \"Fri\", case-sensitive\n              / %x53.61.74 ; \"Sat\", case-sensitive\n              / %x53.75.6E ; \"Sun\", case-sensitive\n  date1        = day SP month SP year\n                  ; e.g., 02 Jun 1982\n\n  day          = 2DIGIT\n  month        = %x4A.61.6E ; \"Jan\", case-sensitive\n              / %x46.65.62 ; \"Feb\", case-sensitive\n              / %x4D.61.72 ; \"Mar\", case-sensitive\n              / %x41.70.72 ; \"Apr\", case-sensitive\n              / %x4D.61.79 ; \"May\", case-sensitive\n              / %x4A.75.6E ; \"Jun\", case-sensitive\n              / %x4A.75.6C ; \"Jul\", case-sensitive\n              / %x41.75.67 ; \"Aug\", case-sensitive\n              / %x53.65.70 ; \"Sep\", case-sensitive\n              / %x4F.63.74 ; \"Oct\", case-sensitive\n              / %x4E.6F.76 ; \"Nov\", case-sensitive\n              / %x44.65.63 ; \"Dec\", case-sensitive\n  year         = 4DIGIT\n\n  GMT          = %x47.4D.54 ; \"GMT\", case-sensitive\n\n  time-of-day  = hour \":\" minute \":\" second\n              ; 00:00:00 - 23:59:60 (leap second)\n\n  hour         = 2DIGIT\n  minute       = 2DIGIT\n  second       = 2DIGIT\n */\nfunction toIMFDate (date) {\n  if (typeof date === 'number') {\n    date = new Date(date)\n  }\n\n  const days = [\n    'Sun', 'Mon', 'Tue', 'Wed',\n    'Thu', 'Fri', 'Sat'\n  ]\n\n  const months = [\n    'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n    'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'\n  ]\n\n  const dayName = days[date.getUTCDay()]\n  const day = date.getUTCDate().toString().padStart(2, '0')\n  const month = months[date.getUTCMonth()]\n  const year = date.getUTCFullYear()\n  const hour = date.getUTCHours().toString().padStart(2, '0')\n  const minute = date.getUTCMinutes().toString().padStart(2, '0')\n  const second = date.getUTCSeconds().toString().padStart(2, '0')\n\n  return `${dayName}, ${day} ${month} ${year} ${hour}:${minute}:${second} GMT`\n}\n\n/**\n max-age-av        = \"Max-Age=\" non-zero-digit *DIGIT\n                       ; In practice, both expires-av and max-age-av\n                       ; are limited to dates representable by the\n                       ; user agent.\n * @param {number} maxAge\n */\nfunction validateCookieMaxAge (maxAge) {\n  if (maxAge < 0) {\n    throw new Error('Invalid cookie max-age')\n  }\n}\n\n/**\n * @see https://www.rfc-editor.org/rfc/rfc6265#section-4.1.1\n * @param {import('./index').Cookie} cookie\n */\nfunction stringify (cookie) {\n  if (cookie.name.length === 0) {\n    return null\n  }\n\n  validateCookieName(cookie.name)\n  validateCookieValue(cookie.value)\n\n  const out = [`${cookie.name}=${cookie.value}`]\n\n  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-cookie-prefixes-00#section-3.1\n  // https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-cookie-prefixes-00#section-3.2\n  if (cookie.name.startsWith('__Secure-')) {\n    cookie.secure = true\n  }\n\n  if (cookie.name.startsWith('__Host-')) {\n    cookie.secure = true\n    cookie.domain = null\n    cookie.path = '/'\n  }\n\n  if (cookie.secure) {\n    out.push('Secure')\n  }\n\n  if (cookie.httpOnly) {\n    out.push('HttpOnly')\n  }\n\n  if (typeof cookie.maxAge === 'number') {\n    validateCookieMaxAge(cookie.maxAge)\n    out.push(`Max-Age=${cookie.maxAge}`)\n  }\n\n  if (cookie.domain) {\n    validateCookieDomain(cookie.domain)\n    out.push(`Domain=${cookie.domain}`)\n  }\n\n  if (cookie.path) {\n    validateCookiePath(cookie.path)\n    out.push(`Path=${cookie.path}`)\n  }\n\n  if (cookie.expires && cookie.expires.toString() !== 'Invalid Date') {\n    out.push(`Expires=${toIMFDate(cookie.expires)}`)\n  }\n\n  if (cookie.sameSite) {\n    out.push(`SameSite=${cookie.sameSite}`)\n  }\n\n  for (const part of cookie.unparsed) {\n    if (!part.includes('=')) {\n      throw new Error('Invalid unparsed')\n    }\n\n    const [key, ...value] = part.split('=')\n\n    out.push(`${key.trim()}=${value.join('=')}`)\n  }\n\n  return out.join('; ')\n}\n\nlet kHeadersListNode\n\nfunction getHeadersList (headers) {\n  if (headers[kHeadersList]) {\n    return headers[kHeadersList]\n  }\n\n  if (!kHeadersListNode) {\n    kHeadersListNode = Object.getOwnPropertySymbols(headers).find(\n      (symbol) => symbol.description === 'headers list'\n    )\n\n    assert(kHeadersListNode, 'Headers cannot be parsed')\n  }\n\n  const headersList = headers[kHeadersListNode]\n  assert(headersList)\n\n  return headersList\n}\n\nmodule.exports = {\n  isCTLExcludingHtab,\n  stringify,\n  getHeadersList\n}\n","'use strict'\n\nconst net = require('net')\nconst assert = require('assert')\nconst util = require('./util')\nconst { InvalidArgumentError, ConnectTimeoutError } = require('./errors')\n\nlet tls // include tls conditionally since it is not always available\n\n// TODO: session re-use does not wait for the first\n// connection to resolve the session and might therefore\n// resolve the same servername multiple times even when\n// re-use is enabled.\n\nlet SessionCache\n// FIXME: remove workaround when the Node bug is fixed\n// https://github.com/nodejs/node/issues/49344#issuecomment-1741776308\nif (global.FinalizationRegistry && !process.env.NODE_V8_COVERAGE) {\n  SessionCache = class WeakSessionCache {\n    constructor (maxCachedSessions) {\n      this._maxCachedSessions = maxCachedSessions\n      this._sessionCache = new Map()\n      this._sessionRegistry = new global.FinalizationRegistry((key) => {\n        if (this._sessionCache.size < this._maxCachedSessions) {\n          return\n        }\n\n        const ref = this._sessionCache.get(key)\n        if (ref !== undefined && ref.deref() === undefined) {\n          this._sessionCache.delete(key)\n        }\n      })\n    }\n\n    get (sessionKey) {\n      const ref = this._sessionCache.get(sessionKey)\n      return ref ? ref.deref() : null\n    }\n\n    set (sessionKey, session) {\n      if (this._maxCachedSessions === 0) {\n        return\n      }\n\n      this._sessionCache.set(sessionKey, new WeakRef(session))\n      this._sessionRegistry.register(session, sessionKey)\n    }\n  }\n} else {\n  SessionCache = class SimpleSessionCache {\n    constructor (maxCachedSessions) {\n      this._maxCachedSessions = maxCachedSessions\n      this._sessionCache = new Map()\n    }\n\n    get (sessionKey) {\n      return this._sessionCache.get(sessionKey)\n    }\n\n    set (sessionKey, session) {\n      if (this._maxCachedSessions === 0) {\n        return\n      }\n\n      if (this._sessionCache.size >= this._maxCachedSessions) {\n        // remove the oldest session\n        const { value: oldestKey } = this._sessionCache.keys().next()\n        this._sessionCache.delete(oldestKey)\n      }\n\n      this._sessionCache.set(sessionKey, session)\n    }\n  }\n}\n\nfunction buildConnector ({ allowH2, maxCachedSessions, socketPath, timeout, ...opts }) {\n  if (maxCachedSessions != null && (!Number.isInteger(maxCachedSessions) || maxCachedSessions < 0)) {\n    throw new InvalidArgumentError('maxCachedSessions must be a positive integer or zero')\n  }\n\n  const options = { path: socketPath, ...opts }\n  const sessionCache = new SessionCache(maxCachedSessions == null ? 100 : maxCachedSessions)\n  timeout = timeout == null ? 10e3 : timeout\n  allowH2 = allowH2 != null ? allowH2 : false\n  return function connect ({ hostname, host, protocol, port, servername, localAddress, httpSocket }, callback) {\n    let socket\n    if (protocol === 'https:') {\n      if (!tls) {\n        tls = require('tls')\n      }\n      servername = servername || options.servername || util.getServerName(host) || null\n\n      const sessionKey = servername || hostname\n      const session = sessionCache.get(sessionKey) || null\n\n      assert(sessionKey)\n\n      socket = tls.connect({\n        highWaterMark: 16384, // TLS in node can't have bigger HWM anyway...\n        ...options,\n        servername,\n        session,\n        localAddress,\n        // TODO(HTTP/2): Add support for h2c\n        ALPNProtocols: allowH2 ? ['http/1.1', 'h2'] : ['http/1.1'],\n        socket: httpSocket, // upgrade socket connection\n        port: port || 443,\n        host: hostname\n      })\n\n      socket\n        .on('session', function (session) {\n          // TODO (fix): Can a session become invalid once established? Don't think so?\n          sessionCache.set(sessionKey, session)\n        })\n    } else {\n      assert(!httpSocket, 'httpSocket can only be sent on TLS update')\n      socket = net.connect({\n        highWaterMark: 64 * 1024, // Same as nodejs fs streams.\n        ...options,\n        localAddress,\n        port: port || 80,\n        host: hostname\n      })\n    }\n\n    // Set TCP keep alive options on the socket here instead of in connect() for the case of assigning the socket\n    if (options.keepAlive == null || options.keepAlive) {\n      const keepAliveInitialDelay = options.keepAliveInitialDelay === undefined ? 60e3 : options.keepAliveInitialDelay\n      socket.setKeepAlive(true, keepAliveInitialDelay)\n    }\n\n    const cancelTimeout = setupTimeout(() => onConnectTimeout(socket), timeout)\n\n    socket\n      .setNoDelay(true)\n      .once(protocol === 'https:' ? 'secureConnect' : 'connect', function () {\n        cancelTimeout()\n\n        if (callback) {\n          const cb = callback\n          callback = null\n          cb(null, this)\n        }\n      })\n      .on('error', function (err) {\n        cancelTimeout()\n\n        if (callback) {\n          const cb = callback\n          callback = null\n          cb(err)\n        }\n      })\n\n    return socket\n  }\n}\n\nfunction setupTimeout (onConnectTimeout, timeout) {\n  if (!timeout) {\n    return () => {}\n  }\n\n  let s1 = null\n  let s2 = null\n  const timeoutId = setTimeout(() => {\n    // setImmediate is added to make sure that we priotorise socket error events over timeouts\n    s1 = setImmediate(() => {\n      if (process.platform === 'win32') {\n        // Windows needs an extra setImmediate probably due to implementation differences in the socket logic\n        s2 = setImmediate(() => onConnectTimeout())\n      } else {\n        onConnectTimeout()\n      }\n    })\n  }, timeout)\n  return () => {\n    clearTimeout(timeoutId)\n    clearImmediate(s1)\n    clearImmediate(s2)\n  }\n}\n\nfunction onConnectTimeout (socket) {\n  util.destroy(socket, new ConnectTimeoutError())\n}\n\nmodule.exports = buildConnector\n","'use strict'\n\n/** @type {Record<string, string | undefined>} */\nconst headerNameLowerCasedRecord = {}\n\n// https://developer.mozilla.org/docs/Web/HTTP/Headers\nconst wellknownHeaderNames = [\n  'Accept',\n  'Accept-Encoding',\n  'Accept-Language',\n  'Accept-Ranges',\n  'Access-Control-Allow-Credentials',\n  'Access-Control-Allow-Headers',\n  'Access-Control-Allow-Methods',\n  'Access-Control-Allow-Origin',\n  'Access-Control-Expose-Headers',\n  'Access-Control-Max-Age',\n  'Access-Control-Request-Headers',\n  'Access-Control-Request-Method',\n  'Age',\n  'Allow',\n  'Alt-Svc',\n  'Alt-Used',\n  'Authorization',\n  'Cache-Control',\n  'Clear-Site-Data',\n  'Connection',\n  'Content-Disposition',\n  'Content-Encoding',\n  'Content-Language',\n  'Content-Length',\n  'Content-Location',\n  'Content-Range',\n  'Content-Security-Policy',\n  'Content-Security-Policy-Report-Only',\n  'Content-Type',\n  'Cookie',\n  'Cross-Origin-Embedder-Policy',\n  'Cross-Origin-Opener-Policy',\n  'Cross-Origin-Resource-Policy',\n  'Date',\n  'Device-Memory',\n  'Downlink',\n  'ECT',\n  'ETag',\n  'Expect',\n  'Expect-CT',\n  'Expires',\n  'Forwarded',\n  'From',\n  'Host',\n  'If-Match',\n  'If-Modified-Since',\n  'If-None-Match',\n  'If-Range',\n  'If-Unmodified-Since',\n  'Keep-Alive',\n  'Last-Modified',\n  'Link',\n  'Location',\n  'Max-Forwards',\n  'Origin',\n  'Permissions-Policy',\n  'Pragma',\n  'Proxy-Authenticate',\n  'Proxy-Authorization',\n  'RTT',\n  'Range',\n  'Referer',\n  'Referrer-Policy',\n  'Refresh',\n  'Retry-After',\n  'Sec-WebSocket-Accept',\n  'Sec-WebSocket-Extensions',\n  'Sec-WebSocket-Key',\n  'Sec-WebSocket-Protocol',\n  'Sec-WebSocket-Version',\n  'Server',\n  'Server-Timing',\n  'Service-Worker-Allowed',\n  'Service-Worker-Navigation-Preload',\n  'Set-Cookie',\n  'SourceMap',\n  'Strict-Transport-Security',\n  'Supports-Loading-Mode',\n  'TE',\n  'Timing-Allow-Origin',\n  'Trailer',\n  'Transfer-Encoding',\n  'Upgrade',\n  'Upgrade-Insecure-Requests',\n  'User-Agent',\n  'Vary',\n  'Via',\n  'WWW-Authenticate',\n  'X-Content-Type-Options',\n  'X-DNS-Prefetch-Control',\n  'X-Frame-Options',\n  'X-Permitted-Cross-Domain-Policies',\n  'X-Powered-By',\n  'X-Requested-With',\n  'X-XSS-Protection'\n]\n\nfor (let i = 0; i < wellknownHeaderNames.length; ++i) {\n  const key = wellknownHeaderNames[i]\n  const lowerCasedKey = key.toLowerCase()\n  headerNameLowerCasedRecord[key] = headerNameLowerCasedRecord[lowerCasedKey] =\n    lowerCasedKey\n}\n\n// Note: object prototypes should not be able to be referenced. e.g. `Object#hasOwnProperty`.\nObject.setPrototypeOf(headerNameLowerCasedRecord, null)\n\nmodule.exports = {\n  wellknownHeaderNames,\n  headerNameLowerCasedRecord\n}\n","'use strict'\n\nclass UndiciError extends Error {\n  constructor (message) {\n    super(message)\n    this.name = 'UndiciError'\n    this.code = 'UND_ERR'\n  }\n}\n\nclass ConnectTimeoutError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, ConnectTimeoutError)\n    this.name = 'ConnectTimeoutError'\n    this.message = message || 'Connect Timeout Error'\n    this.code = 'UND_ERR_CONNECT_TIMEOUT'\n  }\n}\n\nclass HeadersTimeoutError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, HeadersTimeoutError)\n    this.name = 'HeadersTimeoutError'\n    this.message = message || 'Headers Timeout Error'\n    this.code = 'UND_ERR_HEADERS_TIMEOUT'\n  }\n}\n\nclass HeadersOverflowError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, HeadersOverflowError)\n    this.name = 'HeadersOverflowError'\n    this.message = message || 'Headers Overflow Error'\n    this.code = 'UND_ERR_HEADERS_OVERFLOW'\n  }\n}\n\nclass BodyTimeoutError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, BodyTimeoutError)\n    this.name = 'BodyTimeoutError'\n    this.message = message || 'Body Timeout Error'\n    this.code = 'UND_ERR_BODY_TIMEOUT'\n  }\n}\n\nclass ResponseStatusCodeError extends UndiciError {\n  constructor (message, statusCode, headers, body) {\n    super(message)\n    Error.captureStackTrace(this, ResponseStatusCodeError)\n    this.name = 'ResponseStatusCodeError'\n    this.message = message || 'Response Status Code Error'\n    this.code = 'UND_ERR_RESPONSE_STATUS_CODE'\n    this.body = body\n    this.status = statusCode\n    this.statusCode = statusCode\n    this.headers = headers\n  }\n}\n\nclass InvalidArgumentError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, InvalidArgumentError)\n    this.name = 'InvalidArgumentError'\n    this.message = message || 'Invalid Argument Error'\n    this.code = 'UND_ERR_INVALID_ARG'\n  }\n}\n\nclass InvalidReturnValueError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, InvalidReturnValueError)\n    this.name = 'InvalidReturnValueError'\n    this.message = message || 'Invalid Return Value Error'\n    this.code = 'UND_ERR_INVALID_RETURN_VALUE'\n  }\n}\n\nclass RequestAbortedError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, RequestAbortedError)\n    this.name = 'AbortError'\n    this.message = message || 'Request aborted'\n    this.code = 'UND_ERR_ABORTED'\n  }\n}\n\nclass InformationalError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, InformationalError)\n    this.name = 'InformationalError'\n    this.message = message || 'Request information'\n    this.code = 'UND_ERR_INFO'\n  }\n}\n\nclass RequestContentLengthMismatchError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, RequestContentLengthMismatchError)\n    this.name = 'RequestContentLengthMismatchError'\n    this.message = message || 'Request body length does not match content-length header'\n    this.code = 'UND_ERR_REQ_CONTENT_LENGTH_MISMATCH'\n  }\n}\n\nclass ResponseContentLengthMismatchError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, ResponseContentLengthMismatchError)\n    this.name = 'ResponseContentLengthMismatchError'\n    this.message = message || 'Response body length does not match content-length header'\n    this.code = 'UND_ERR_RES_CONTENT_LENGTH_MISMATCH'\n  }\n}\n\nclass ClientDestroyedError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, ClientDestroyedError)\n    this.name = 'ClientDestroyedError'\n    this.message = message || 'The client is destroyed'\n    this.code = 'UND_ERR_DESTROYED'\n  }\n}\n\nclass ClientClosedError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, ClientClosedError)\n    this.name = 'ClientClosedError'\n    this.message = message || 'The client is closed'\n    this.code = 'UND_ERR_CLOSED'\n  }\n}\n\nclass SocketError extends UndiciError {\n  constructor (message, socket) {\n    super(message)\n    Error.captureStackTrace(this, SocketError)\n    this.name = 'SocketError'\n    this.message = message || 'Socket error'\n    this.code = 'UND_ERR_SOCKET'\n    this.socket = socket\n  }\n}\n\nclass NotSupportedError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, NotSupportedError)\n    this.name = 'NotSupportedError'\n    this.message = message || 'Not supported error'\n    this.code = 'UND_ERR_NOT_SUPPORTED'\n  }\n}\n\nclass BalancedPoolMissingUpstreamError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, NotSupportedError)\n    this.name = 'MissingUpstreamError'\n    this.message = message || 'No upstream has been added to the BalancedPool'\n    this.code = 'UND_ERR_BPL_MISSING_UPSTREAM'\n  }\n}\n\nclass HTTPParserError extends Error {\n  constructor (message, code, data) {\n    super(message)\n    Error.captureStackTrace(this, HTTPParserError)\n    this.name = 'HTTPParserError'\n    this.code = code ? `HPE_${code}` : undefined\n    this.data = data ? data.toString() : undefined\n  }\n}\n\nclass ResponseExceededMaxSizeError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, ResponseExceededMaxSizeError)\n    this.name = 'ResponseExceededMaxSizeError'\n    this.message = message || 'Response content exceeded max size'\n    this.code = 'UND_ERR_RES_EXCEEDED_MAX_SIZE'\n  }\n}\n\nclass RequestRetryError extends UndiciError {\n  constructor (message, code, { headers, data }) {\n    super(message)\n    Error.captureStackTrace(this, RequestRetryError)\n    this.name = 'RequestRetryError'\n    this.message = message || 'Request retry error'\n    this.code = 'UND_ERR_REQ_RETRY'\n    this.statusCode = code\n    this.data = data\n    this.headers = headers\n  }\n}\n\nmodule.exports = {\n  HTTPParserError,\n  UndiciError,\n  HeadersTimeoutError,\n  HeadersOverflowError,\n  BodyTimeoutError,\n  RequestContentLengthMismatchError,\n  ConnectTimeoutError,\n  ResponseStatusCodeError,\n  InvalidArgumentError,\n  InvalidReturnValueError,\n  RequestAbortedError,\n  ClientDestroyedError,\n  ClientClosedError,\n  InformationalError,\n  SocketError,\n  NotSupportedError,\n  ResponseContentLengthMismatchError,\n  BalancedPoolMissingUpstreamError,\n  ResponseExceededMaxSizeError,\n  RequestRetryError\n}\n","'use strict'\n\nconst {\n  InvalidArgumentError,\n  NotSupportedError\n} = require('./errors')\nconst assert = require('assert')\nconst { kHTTP2BuildRequest, kHTTP2CopyHeaders, kHTTP1BuildRequest } = require('./symbols')\nconst util = require('./util')\n\n// tokenRegExp and headerCharRegex have been lifted from\n// https://github.com/nodejs/node/blob/main/lib/_http_common.js\n\n/**\n * Verifies that the given val is a valid HTTP token\n * per the rules defined in RFC 7230\n * See https://tools.ietf.org/html/rfc7230#section-3.2.6\n */\nconst tokenRegExp = /^[\\^_`a-zA-Z\\-0-9!#$%&'*+.|~]+$/\n\n/**\n * Matches if val contains an invalid field-vchar\n *  field-value    = *( field-content / obs-fold )\n *  field-content  = field-vchar [ 1*( SP / HTAB ) field-vchar ]\n *  field-vchar    = VCHAR / obs-text\n */\nconst headerCharRegex = /[^\\t\\x20-\\x7e\\x80-\\xff]/\n\n// Verifies that a given path is valid does not contain control chars \\x00 to \\x20\nconst invalidPathRegex = /[^\\u0021-\\u00ff]/\n\nconst kHandler = Symbol('handler')\n\nconst channels = {}\n\nlet extractBody\n\ntry {\n  const diagnosticsChannel = require('diagnostics_channel')\n  channels.create = diagnosticsChannel.channel('undici:request:create')\n  channels.bodySent = diagnosticsChannel.channel('undici:request:bodySent')\n  channels.headers = diagnosticsChannel.channel('undici:request:headers')\n  channels.trailers = diagnosticsChannel.channel('undici:request:trailers')\n  channels.error = diagnosticsChannel.channel('undici:request:error')\n} catch {\n  channels.create = { hasSubscribers: false }\n  channels.bodySent = { hasSubscribers: false }\n  channels.headers = { hasSubscribers: false }\n  channels.trailers = { hasSubscribers: false }\n  channels.error = { hasSubscribers: false }\n}\n\nclass Request {\n  constructor (origin, {\n    path,\n    method,\n    body,\n    headers,\n    query,\n    idempotent,\n    blocking,\n    upgrade,\n    headersTimeout,\n    bodyTimeout,\n    reset,\n    throwOnError,\n    expectContinue\n  }, handler) {\n    if (typeof path !== 'string') {\n      throw new InvalidArgumentError('path must be a string')\n    } else if (\n      path[0] !== '/' &&\n      !(path.startsWith('http://') || path.startsWith('https://')) &&\n      method !== 'CONNECT'\n    ) {\n      throw new InvalidArgumentError('path must be an absolute URL or start with a slash')\n    } else if (invalidPathRegex.exec(path) !== null) {\n      throw new InvalidArgumentError('invalid request path')\n    }\n\n    if (typeof method !== 'string') {\n      throw new InvalidArgumentError('method must be a string')\n    } else if (tokenRegExp.exec(method) === null) {\n      throw new InvalidArgumentError('invalid request method')\n    }\n\n    if (upgrade && typeof upgrade !== 'string') {\n      throw new InvalidArgumentError('upgrade must be a string')\n    }\n\n    if (headersTimeout != null && (!Number.isFinite(headersTimeout) || headersTimeout < 0)) {\n      throw new InvalidArgumentError('invalid headersTimeout')\n    }\n\n    if (bodyTimeout != null && (!Number.isFinite(bodyTimeout) || bodyTimeout < 0)) {\n      throw new InvalidArgumentError('invalid bodyTimeout')\n    }\n\n    if (reset != null && typeof reset !== 'boolean') {\n      throw new InvalidArgumentError('invalid reset')\n    }\n\n    if (expectContinue != null && typeof expectContinue !== 'boolean') {\n      throw new InvalidArgumentError('invalid expectContinue')\n    }\n\n    this.headersTimeout = headersTimeout\n\n    this.bodyTimeout = bodyTimeout\n\n    this.throwOnError = throwOnError === true\n\n    this.method = method\n\n    this.abort = null\n\n    if (body == null) {\n      this.body = null\n    } else if (util.isStream(body)) {\n      this.body = body\n\n      const rState = this.body._readableState\n      if (!rState || !rState.autoDestroy) {\n        this.endHandler = function autoDestroy () {\n          util.destroy(this)\n        }\n        this.body.on('end', this.endHandler)\n      }\n\n      this.errorHandler = err => {\n        if (this.abort) {\n          this.abort(err)\n        } else {\n          this.error = err\n        }\n      }\n      this.body.on('error', this.errorHandler)\n    } else if (util.isBuffer(body)) {\n      this.body = body.byteLength ? body : null\n    } else if (ArrayBuffer.isView(body)) {\n      this.body = body.buffer.byteLength ? Buffer.from(body.buffer, body.byteOffset, body.byteLength) : null\n    } else if (body instanceof ArrayBuffer) {\n      this.body = body.byteLength ? Buffer.from(body) : null\n    } else if (typeof body === 'string') {\n      this.body = body.length ? Buffer.from(body) : null\n    } else if (util.isFormDataLike(body) || util.isIterable(body) || util.isBlobLike(body)) {\n      this.body = body\n    } else {\n      throw new InvalidArgumentError('body must be a string, a Buffer, a Readable stream, an iterable, or an async iterable')\n    }\n\n    this.completed = false\n\n    this.aborted = false\n\n    this.upgrade = upgrade || null\n\n    this.path = query ? util.buildURL(path, query) : path\n\n    this.origin = origin\n\n    this.idempotent = idempotent == null\n      ? method === 'HEAD' || method === 'GET'\n      : idempotent\n\n    this.blocking = blocking == null ? false : blocking\n\n    this.reset = reset == null ? null : reset\n\n    this.host = null\n\n    this.contentLength = null\n\n    this.contentType = null\n\n    this.headers = ''\n\n    // Only for H2\n    this.expectContinue = expectContinue != null ? expectContinue : false\n\n    if (Array.isArray(headers)) {\n      if (headers.length % 2 !== 0) {\n        throw new InvalidArgumentError('headers array must be even')\n      }\n      for (let i = 0; i < headers.length; i += 2) {\n        processHeader(this, headers[i], headers[i + 1])\n      }\n    } else if (headers && typeof headers === 'object') {\n      const keys = Object.keys(headers)\n      for (let i = 0; i < keys.length; i++) {\n        const key = keys[i]\n        processHeader(this, key, headers[key])\n      }\n    } else if (headers != null) {\n      throw new InvalidArgumentError('headers must be an object or an array')\n    }\n\n    if (util.isFormDataLike(this.body)) {\n      if (util.nodeMajor < 16 || (util.nodeMajor === 16 && util.nodeMinor < 8)) {\n        throw new InvalidArgumentError('Form-Data bodies are only supported in node v16.8 and newer.')\n      }\n\n      if (!extractBody) {\n        extractBody = require('../fetch/body.js').extractBody\n      }\n\n      const [bodyStream, contentType] = extractBody(body)\n      if (this.contentType == null) {\n        this.contentType = contentType\n        this.headers += `content-type: ${contentType}\\r\\n`\n      }\n      this.body = bodyStream.stream\n      this.contentLength = bodyStream.length\n    } else if (util.isBlobLike(body) && this.contentType == null && body.type) {\n      this.contentType = body.type\n      this.headers += `content-type: ${body.type}\\r\\n`\n    }\n\n    util.validateHandler(handler, method, upgrade)\n\n    this.servername = util.getServerName(this.host)\n\n    this[kHandler] = handler\n\n    if (channels.create.hasSubscribers) {\n      channels.create.publish({ request: this })\n    }\n  }\n\n  onBodySent (chunk) {\n    if (this[kHandler].onBodySent) {\n      try {\n        return this[kHandler].onBodySent(chunk)\n      } catch (err) {\n        this.abort(err)\n      }\n    }\n  }\n\n  onRequestSent () {\n    if (channels.bodySent.hasSubscribers) {\n      channels.bodySent.publish({ request: this })\n    }\n\n    if (this[kHandler].onRequestSent) {\n      try {\n        return this[kHandler].onRequestSent()\n      } catch (err) {\n        this.abort(err)\n      }\n    }\n  }\n\n  onConnect (abort) {\n    assert(!this.aborted)\n    assert(!this.completed)\n\n    if (this.error) {\n      abort(this.error)\n    } else {\n      this.abort = abort\n      return this[kHandler].onConnect(abort)\n    }\n  }\n\n  onHeaders (statusCode, headers, resume, statusText) {\n    assert(!this.aborted)\n    assert(!this.completed)\n\n    if (channels.headers.hasSubscribers) {\n      channels.headers.publish({ request: this, response: { statusCode, headers, statusText } })\n    }\n\n    try {\n      return this[kHandler].onHeaders(statusCode, headers, resume, statusText)\n    } catch (err) {\n      this.abort(err)\n    }\n  }\n\n  onData (chunk) {\n    assert(!this.aborted)\n    assert(!this.completed)\n\n    try {\n      return this[kHandler].onData(chunk)\n    } catch (err) {\n      this.abort(err)\n      return false\n    }\n  }\n\n  onUpgrade (statusCode, headers, socket) {\n    assert(!this.aborted)\n    assert(!this.completed)\n\n    return this[kHandler].onUpgrade(statusCode, headers, socket)\n  }\n\n  onComplete (trailers) {\n    this.onFinally()\n\n    assert(!this.aborted)\n\n    this.completed = true\n    if (channels.trailers.hasSubscribers) {\n      channels.trailers.publish({ request: this, trailers })\n    }\n\n    try {\n      return this[kHandler].onComplete(trailers)\n    } catch (err) {\n      // TODO (fix): This might be a bad idea?\n      this.onError(err)\n    }\n  }\n\n  onError (error) {\n    this.onFinally()\n\n    if (channels.error.hasSubscribers) {\n      channels.error.publish({ request: this, error })\n    }\n\n    if (this.aborted) {\n      return\n    }\n    this.aborted = true\n\n    return this[kHandler].onError(error)\n  }\n\n  onFinally () {\n    if (this.errorHandler) {\n      this.body.off('error', this.errorHandler)\n      this.errorHandler = null\n    }\n\n    if (this.endHandler) {\n      this.body.off('end', this.endHandler)\n      this.endHandler = null\n    }\n  }\n\n  // TODO: adjust to support H2\n  addHeader (key, value) {\n    processHeader(this, key, value)\n    return this\n  }\n\n  static [kHTTP1BuildRequest] (origin, opts, handler) {\n    // TODO: Migrate header parsing here, to make Requests\n    // HTTP agnostic\n    return new Request(origin, opts, handler)\n  }\n\n  static [kHTTP2BuildRequest] (origin, opts, handler) {\n    const headers = opts.headers\n    opts = { ...opts, headers: null }\n\n    const request = new Request(origin, opts, handler)\n\n    request.headers = {}\n\n    if (Array.isArray(headers)) {\n      if (headers.length % 2 !== 0) {\n        throw new InvalidArgumentError('headers array must be even')\n      }\n      for (let i = 0; i < headers.length; i += 2) {\n        processHeader(request, headers[i], headers[i + 1], true)\n      }\n    } else if (headers && typeof headers === 'object') {\n      const keys = Object.keys(headers)\n      for (let i = 0; i < keys.length; i++) {\n        const key = keys[i]\n        processHeader(request, key, headers[key], true)\n      }\n    } else if (headers != null) {\n      throw new InvalidArgumentError('headers must be an object or an array')\n    }\n\n    return request\n  }\n\n  static [kHTTP2CopyHeaders] (raw) {\n    const rawHeaders = raw.split('\\r\\n')\n    const headers = {}\n\n    for (const header of rawHeaders) {\n      const [key, value] = header.split(': ')\n\n      if (value == null || value.length === 0) continue\n\n      if (headers[key]) headers[key] += `,${value}`\n      else headers[key] = value\n    }\n\n    return headers\n  }\n}\n\nfunction processHeaderValue (key, val, skipAppend) {\n  if (val && typeof val === 'object') {\n    throw new InvalidArgumentError(`invalid ${key} header`)\n  }\n\n  val = val != null ? `${val}` : ''\n\n  if (headerCharRegex.exec(val) !== null) {\n    throw new InvalidArgumentError(`invalid ${key} header`)\n  }\n\n  return skipAppend ? val : `${key}: ${val}\\r\\n`\n}\n\nfunction processHeader (request, key, val, skipAppend = false) {\n  if (val && (typeof val === 'object' && !Array.isArray(val))) {\n    throw new InvalidArgumentError(`invalid ${key} header`)\n  } else if (val === undefined) {\n    return\n  }\n\n  if (\n    request.host === null &&\n    key.length === 4 &&\n    key.toLowerCase() === 'host'\n  ) {\n    if (headerCharRegex.exec(val) !== null) {\n      throw new InvalidArgumentError(`invalid ${key} header`)\n    }\n    // Consumed by Client\n    request.host = val\n  } else if (\n    request.contentLength === null &&\n    key.length === 14 &&\n    key.toLowerCase() === 'content-length'\n  ) {\n    request.contentLength = parseInt(val, 10)\n    if (!Number.isFinite(request.contentLength)) {\n      throw new InvalidArgumentError('invalid content-length header')\n    }\n  } else if (\n    request.contentType === null &&\n    key.length === 12 &&\n    key.toLowerCase() === 'content-type'\n  ) {\n    request.contentType = val\n    if (skipAppend) request.headers[key] = processHeaderValue(key, val, skipAppend)\n    else request.headers += processHeaderValue(key, val)\n  } else if (\n    key.length === 17 &&\n    key.toLowerCase() === 'transfer-encoding'\n  ) {\n    throw new InvalidArgumentError('invalid transfer-encoding header')\n  } else if (\n    key.length === 10 &&\n    key.toLowerCase() === 'connection'\n  ) {\n    const value = typeof val === 'string' ? val.toLowerCase() : null\n    if (value !== 'close' && value !== 'keep-alive') {\n      throw new InvalidArgumentError('invalid connection header')\n    } else if (value === 'close') {\n      request.reset = true\n    }\n  } else if (\n    key.length === 10 &&\n    key.toLowerCase() === 'keep-alive'\n  ) {\n    throw new InvalidArgumentError('invalid keep-alive header')\n  } else if (\n    key.length === 7 &&\n    key.toLowerCase() === 'upgrade'\n  ) {\n    throw new InvalidArgumentError('invalid upgrade header')\n  } else if (\n    key.length === 6 &&\n    key.toLowerCase() === 'expect'\n  ) {\n    throw new NotSupportedError('expect header not supported')\n  } else if (tokenRegExp.exec(key) === null) {\n    throw new InvalidArgumentError('invalid header key')\n  } else {\n    if (Array.isArray(val)) {\n      for (let i = 0; i < val.length; i++) {\n        if (skipAppend) {\n          if (request.headers[key]) request.headers[key] += `,${processHeaderValue(key, val[i], skipAppend)}`\n          else request.headers[key] = processHeaderValue(key, val[i], skipAppend)\n        } else {\n          request.headers += processHeaderValue(key, val[i])\n        }\n      }\n    } else {\n      if (skipAppend) request.headers[key] = processHeaderValue(key, val, skipAppend)\n      else request.headers += processHeaderValue(key, val)\n    }\n  }\n}\n\nmodule.exports = Request\n","module.exports = {\n  kClose: Symbol('close'),\n  kDestroy: Symbol('destroy'),\n  kDispatch: Symbol('dispatch'),\n  kUrl: Symbol('url'),\n  kWriting: Symbol('writing'),\n  kResuming: Symbol('resuming'),\n  kQueue: Symbol('queue'),\n  kConnect: Symbol('connect'),\n  kConnecting: Symbol('connecting'),\n  kHeadersList: Symbol('headers list'),\n  kKeepAliveDefaultTimeout: Symbol('default keep alive timeout'),\n  kKeepAliveMaxTimeout: Symbol('max keep alive timeout'),\n  kKeepAliveTimeoutThreshold: Symbol('keep alive timeout threshold'),\n  kKeepAliveTimeoutValue: Symbol('keep alive timeout'),\n  kKeepAlive: Symbol('keep alive'),\n  kHeadersTimeout: Symbol('headers timeout'),\n  kBodyTimeout: Symbol('body timeout'),\n  kServerName: Symbol('server name'),\n  kLocalAddress: Symbol('local address'),\n  kHost: Symbol('host'),\n  kNoRef: Symbol('no ref'),\n  kBodyUsed: Symbol('used'),\n  kRunning: Symbol('running'),\n  kBlocking: Symbol('blocking'),\n  kPending: Symbol('pending'),\n  kSize: Symbol('size'),\n  kBusy: Symbol('busy'),\n  kQueued: Symbol('queued'),\n  kFree: Symbol('free'),\n  kConnected: Symbol('connected'),\n  kClosed: Symbol('closed'),\n  kNeedDrain: Symbol('need drain'),\n  kReset: Symbol('reset'),\n  kDestroyed: Symbol.for('nodejs.stream.destroyed'),\n  kMaxHeadersSize: Symbol('max headers size'),\n  kRunningIdx: Symbol('running index'),\n  kPendingIdx: Symbol('pending index'),\n  kError: Symbol('error'),\n  kClients: Symbol('clients'),\n  kClient: Symbol('client'),\n  kParser: Symbol('parser'),\n  kOnDestroyed: Symbol('destroy callbacks'),\n  kPipelining: Symbol('pipelining'),\n  kSocket: Symbol('socket'),\n  kHostHeader: Symbol('host header'),\n  kConnector: Symbol('connector'),\n  kStrictContentLength: Symbol('strict content length'),\n  kMaxRedirections: Symbol('maxRedirections'),\n  kMaxRequests: Symbol('maxRequestsPerClient'),\n  kProxy: Symbol('proxy agent options'),\n  kCounter: Symbol('socket request counter'),\n  kInterceptors: Symbol('dispatch interceptors'),\n  kMaxResponseSize: Symbol('max response size'),\n  kHTTP2Session: Symbol('http2Session'),\n  kHTTP2SessionState: Symbol('http2Session state'),\n  kHTTP2BuildRequest: Symbol('http2 build request'),\n  kHTTP1BuildRequest: Symbol('http1 build request'),\n  kHTTP2CopyHeaders: Symbol('http2 copy headers'),\n  kHTTPConnVersion: Symbol('http connection version'),\n  kRetryHandlerDefaultRetry: Symbol('retry agent default retry'),\n  kConstruct: Symbol('constructable')\n}\n","'use strict'\n\nconst assert = require('assert')\nconst { kDestroyed, kBodyUsed } = require('./symbols')\nconst { IncomingMessage } = require('http')\nconst stream = require('stream')\nconst net = require('net')\nconst { InvalidArgumentError } = require('./errors')\nconst { Blob } = require('buffer')\nconst nodeUtil = require('util')\nconst { stringify } = require('querystring')\nconst { headerNameLowerCasedRecord } = require('./constants')\n\nconst [nodeMajor, nodeMinor] = process.versions.node.split('.').map(v => Number(v))\n\nfunction nop () {}\n\nfunction isStream (obj) {\n  return obj && typeof obj === 'object' && typeof obj.pipe === 'function' && typeof obj.on === 'function'\n}\n\n// based on https://github.com/node-fetch/fetch-blob/blob/8ab587d34080de94140b54f07168451e7d0b655e/index.js#L229-L241 (MIT License)\nfunction isBlobLike (object) {\n  return (Blob && object instanceof Blob) || (\n    object &&\n    typeof object === 'object' &&\n    (typeof object.stream === 'function' ||\n      typeof object.arrayBuffer === 'function') &&\n    /^(Blob|File)$/.test(object[Symbol.toStringTag])\n  )\n}\n\nfunction buildURL (url, queryParams) {\n  if (url.includes('?') || url.includes('#')) {\n    throw new Error('Query params cannot be passed when url already contains \"?\" or \"#\".')\n  }\n\n  const stringified = stringify(queryParams)\n\n  if (stringified) {\n    url += '?' + stringified\n  }\n\n  return url\n}\n\nfunction parseURL (url) {\n  if (typeof url === 'string') {\n    url = new URL(url)\n\n    if (!/^https?:/.test(url.origin || url.protocol)) {\n      throw new InvalidArgumentError('Invalid URL protocol: the URL must start with `http:` or `https:`.')\n    }\n\n    return url\n  }\n\n  if (!url || typeof url !== 'object') {\n    throw new InvalidArgumentError('Invalid URL: The URL argument must be a non-null object.')\n  }\n\n  if (!/^https?:/.test(url.origin || url.protocol)) {\n    throw new InvalidArgumentError('Invalid URL protocol: the URL must start with `http:` or `https:`.')\n  }\n\n  if (!(url instanceof URL)) {\n    if (url.port != null && url.port !== '' && !Number.isFinite(parseInt(url.port))) {\n      throw new InvalidArgumentError('Invalid URL: port must be a valid integer or a string representation of an integer.')\n    }\n\n    if (url.path != null && typeof url.path !== 'string') {\n      throw new InvalidArgumentError('Invalid URL path: the path must be a string or null/undefined.')\n    }\n\n    if (url.pathname != null && typeof url.pathname !== 'string') {\n      throw new InvalidArgumentError('Invalid URL pathname: the pathname must be a string or null/undefined.')\n    }\n\n    if (url.hostname != null && typeof url.hostname !== 'string') {\n      throw new InvalidArgumentError('Invalid URL hostname: the hostname must be a string or null/undefined.')\n    }\n\n    if (url.origin != null && typeof url.origin !== 'string') {\n      throw new InvalidArgumentError('Invalid URL origin: the origin must be a string or null/undefined.')\n    }\n\n    const port = url.port != null\n      ? url.port\n      : (url.protocol === 'https:' ? 443 : 80)\n    let origin = url.origin != null\n      ? url.origin\n      : `${url.protocol}//${url.hostname}:${port}`\n    let path = url.path != null\n      ? url.path\n      : `${url.pathname || ''}${url.search || ''}`\n\n    if (origin.endsWith('/')) {\n      origin = origin.substring(0, origin.length - 1)\n    }\n\n    if (path && !path.startsWith('/')) {\n      path = `/${path}`\n    }\n    // new URL(path, origin) is unsafe when `path` contains an absolute URL\n    // From https://developer.mozilla.org/en-US/docs/Web/API/URL/URL:\n    // If first parameter is a relative URL, second param is required, and will be used as the base URL.\n    // If first parameter is an absolute URL, a given second param will be ignored.\n    url = new URL(origin + path)\n  }\n\n  return url\n}\n\nfunction parseOrigin (url) {\n  url = parseURL(url)\n\n  if (url.pathname !== '/' || url.search || url.hash) {\n    throw new InvalidArgumentError('invalid url')\n  }\n\n  return url\n}\n\nfunction getHostname (host) {\n  if (host[0] === '[') {\n    const idx = host.indexOf(']')\n\n    assert(idx !== -1)\n    return host.substring(1, idx)\n  }\n\n  const idx = host.indexOf(':')\n  if (idx === -1) return host\n\n  return host.substring(0, idx)\n}\n\n// IP addresses are not valid server names per RFC6066\n// > Currently, the only server names supported are DNS hostnames\nfunction getServerName (host) {\n  if (!host) {\n    return null\n  }\n\n  assert.strictEqual(typeof host, 'string')\n\n  const servername = getHostname(host)\n  if (net.isIP(servername)) {\n    return ''\n  }\n\n  return servername\n}\n\nfunction deepClone (obj) {\n  return JSON.parse(JSON.stringify(obj))\n}\n\nfunction isAsyncIterable (obj) {\n  return !!(obj != null && typeof obj[Symbol.asyncIterator] === 'function')\n}\n\nfunction isIterable (obj) {\n  return !!(obj != null && (typeof obj[Symbol.iterator] === 'function' || typeof obj[Symbol.asyncIterator] === 'function'))\n}\n\nfunction bodyLength (body) {\n  if (body == null) {\n    return 0\n  } else if (isStream(body)) {\n    const state = body._readableState\n    return state && state.objectMode === false && state.ended === true && Number.isFinite(state.length)\n      ? state.length\n      : null\n  } else if (isBlobLike(body)) {\n    return body.size != null ? body.size : null\n  } else if (isBuffer(body)) {\n    return body.byteLength\n  }\n\n  return null\n}\n\nfunction isDestroyed (stream) {\n  return !stream || !!(stream.destroyed || stream[kDestroyed])\n}\n\nfunction isReadableAborted (stream) {\n  const state = stream && stream._readableState\n  return isDestroyed(stream) && state && !state.endEmitted\n}\n\nfunction destroy (stream, err) {\n  if (stream == null || !isStream(stream) || isDestroyed(stream)) {\n    return\n  }\n\n  if (typeof stream.destroy === 'function') {\n    if (Object.getPrototypeOf(stream).constructor === IncomingMessage) {\n      // See: https://github.com/nodejs/node/pull/38505/files\n      stream.socket = null\n    }\n\n    stream.destroy(err)\n  } else if (err) {\n    process.nextTick((stream, err) => {\n      stream.emit('error', err)\n    }, stream, err)\n  }\n\n  if (stream.destroyed !== true) {\n    stream[kDestroyed] = true\n  }\n}\n\nconst KEEPALIVE_TIMEOUT_EXPR = /timeout=(\\d+)/\nfunction parseKeepAliveTimeout (val) {\n  const m = val.toString().match(KEEPALIVE_TIMEOUT_EXPR)\n  return m ? parseInt(m[1], 10) * 1000 : null\n}\n\n/**\n * Retrieves a header name and returns its lowercase value.\n * @param {string | Buffer} value Header name\n * @returns {string}\n */\nfunction headerNameToString (value) {\n  return headerNameLowerCasedRecord[value] || value.toLowerCase()\n}\n\nfunction parseHeaders (headers, obj = {}) {\n  // For H2 support\n  if (!Array.isArray(headers)) return headers\n\n  for (let i = 0; i < headers.length; i += 2) {\n    const key = headers[i].toString().toLowerCase()\n    let val = obj[key]\n\n    if (!val) {\n      if (Array.isArray(headers[i + 1])) {\n        obj[key] = headers[i + 1].map(x => x.toString('utf8'))\n      } else {\n        obj[key] = headers[i + 1].toString('utf8')\n      }\n    } else {\n      if (!Array.isArray(val)) {\n        val = [val]\n        obj[key] = val\n      }\n      val.push(headers[i + 1].toString('utf8'))\n    }\n  }\n\n  // See https://github.com/nodejs/node/pull/46528\n  if ('content-length' in obj && 'content-disposition' in obj) {\n    obj['content-disposition'] = Buffer.from(obj['content-disposition']).toString('latin1')\n  }\n\n  return obj\n}\n\nfunction parseRawHeaders (headers) {\n  const ret = []\n  let hasContentLength = false\n  let contentDispositionIdx = -1\n\n  for (let n = 0; n < headers.length; n += 2) {\n    const key = headers[n + 0].toString()\n    const val = headers[n + 1].toString('utf8')\n\n    if (key.length === 14 && (key === 'content-length' || key.toLowerCase() === 'content-length')) {\n      ret.push(key, val)\n      hasContentLength = true\n    } else if (key.length === 19 && (key === 'content-disposition' || key.toLowerCase() === 'content-disposition')) {\n      contentDispositionIdx = ret.push(key, val) - 1\n    } else {\n      ret.push(key, val)\n    }\n  }\n\n  // See https://github.com/nodejs/node/pull/46528\n  if (hasContentLength && contentDispositionIdx !== -1) {\n    ret[contentDispositionIdx] = Buffer.from(ret[contentDispositionIdx]).toString('latin1')\n  }\n\n  return ret\n}\n\nfunction isBuffer (buffer) {\n  // See, https://github.com/mcollina/undici/pull/319\n  return buffer instanceof Uint8Array || Buffer.isBuffer(buffer)\n}\n\nfunction validateHandler (handler, method, upgrade) {\n  if (!handler || typeof handler !== 'object') {\n    throw new InvalidArgumentError('handler must be an object')\n  }\n\n  if (typeof handler.onConnect !== 'function') {\n    throw new InvalidArgumentError('invalid onConnect method')\n  }\n\n  if (typeof handler.onError !== 'function') {\n    throw new InvalidArgumentError('invalid onError method')\n  }\n\n  if (typeof handler.onBodySent !== 'function' && handler.onBodySent !== undefined) {\n    throw new InvalidArgumentError('invalid onBodySent method')\n  }\n\n  if (upgrade || method === 'CONNECT') {\n    if (typeof handler.onUpgrade !== 'function') {\n      throw new InvalidArgumentError('invalid onUpgrade method')\n    }\n  } else {\n    if (typeof handler.onHeaders !== 'function') {\n      throw new InvalidArgumentError('invalid onHeaders method')\n    }\n\n    if (typeof handler.onData !== 'function') {\n      throw new InvalidArgumentError('invalid onData method')\n    }\n\n    if (typeof handler.onComplete !== 'function') {\n      throw new InvalidArgumentError('invalid onComplete method')\n    }\n  }\n}\n\n// A body is disturbed if it has been read from and it cannot\n// be re-used without losing state or data.\nfunction isDisturbed (body) {\n  return !!(body && (\n    stream.isDisturbed\n      ? stream.isDisturbed(body) || body[kBodyUsed] // TODO (fix): Why is body[kBodyUsed] needed?\n      : body[kBodyUsed] ||\n        body.readableDidRead ||\n        (body._readableState && body._readableState.dataEmitted) ||\n        isReadableAborted(body)\n  ))\n}\n\nfunction isErrored (body) {\n  return !!(body && (\n    stream.isErrored\n      ? stream.isErrored(body)\n      : /state: 'errored'/.test(nodeUtil.inspect(body)\n      )))\n}\n\nfunction isReadable (body) {\n  return !!(body && (\n    stream.isReadable\n      ? stream.isReadable(body)\n      : /state: 'readable'/.test(nodeUtil.inspect(body)\n      )))\n}\n\nfunction getSocketInfo (socket) {\n  return {\n    localAddress: socket.localAddress,\n    localPort: socket.localPort,\n    remoteAddress: socket.remoteAddress,\n    remotePort: socket.remotePort,\n    remoteFamily: socket.remoteFamily,\n    timeout: socket.timeout,\n    bytesWritten: socket.bytesWritten,\n    bytesRead: socket.bytesRead\n  }\n}\n\nasync function * convertIterableToBuffer (iterable) {\n  for await (const chunk of iterable) {\n    yield Buffer.isBuffer(chunk) ? chunk : Buffer.from(chunk)\n  }\n}\n\nlet ReadableStream\nfunction ReadableStreamFrom (iterable) {\n  if (!ReadableStream) {\n    ReadableStream = require('stream/web').ReadableStream\n  }\n\n  if (ReadableStream.from) {\n    return ReadableStream.from(convertIterableToBuffer(iterable))\n  }\n\n  let iterator\n  return new ReadableStream(\n    {\n      async start () {\n        iterator = iterable[Symbol.asyncIterator]()\n      },\n      async pull (controller) {\n        const { done, value } = await iterator.next()\n        if (done) {\n          queueMicrotask(() => {\n            controller.close()\n          })\n        } else {\n          const buf = Buffer.isBuffer(value) ? value : Buffer.from(value)\n          controller.enqueue(new Uint8Array(buf))\n        }\n        return controller.desiredSize > 0\n      },\n      async cancel (reason) {\n        await iterator.return()\n      }\n    },\n    0\n  )\n}\n\n// The chunk should be a FormData instance and contains\n// all the required methods.\nfunction isFormDataLike (object) {\n  return (\n    object &&\n    typeof object === 'object' &&\n    typeof object.append === 'function' &&\n    typeof object.delete === 'function' &&\n    typeof object.get === 'function' &&\n    typeof object.getAll === 'function' &&\n    typeof object.has === 'function' &&\n    typeof object.set === 'function' &&\n    object[Symbol.toStringTag] === 'FormData'\n  )\n}\n\nfunction throwIfAborted (signal) {\n  if (!signal) { return }\n  if (typeof signal.throwIfAborted === 'function') {\n    signal.throwIfAborted()\n  } else {\n    if (signal.aborted) {\n      // DOMException not available < v17.0.0\n      const err = new Error('The operation was aborted')\n      err.name = 'AbortError'\n      throw err\n    }\n  }\n}\n\nfunction addAbortListener (signal, listener) {\n  if ('addEventListener' in signal) {\n    signal.addEventListener('abort', listener, { once: true })\n    return () => signal.removeEventListener('abort', listener)\n  }\n  signal.addListener('abort', listener)\n  return () => signal.removeListener('abort', listener)\n}\n\nconst hasToWellFormed = !!String.prototype.toWellFormed\n\n/**\n * @param {string} val\n */\nfunction toUSVString (val) {\n  if (hasToWellFormed) {\n    return `${val}`.toWellFormed()\n  } else if (nodeUtil.toUSVString) {\n    return nodeUtil.toUSVString(val)\n  }\n\n  return `${val}`\n}\n\n// Parsed accordingly to RFC 9110\n// https://www.rfc-editor.org/rfc/rfc9110#field.content-range\nfunction parseRangeHeader (range) {\n  if (range == null || range === '') return { start: 0, end: null, size: null }\n\n  const m = range ? range.match(/^bytes (\\d+)-(\\d+)\\/(\\d+)?$/) : null\n  return m\n    ? {\n        start: parseInt(m[1]),\n        end: m[2] ? parseInt(m[2]) : null,\n        size: m[3] ? parseInt(m[3]) : null\n      }\n    : null\n}\n\nconst kEnumerableProperty = Object.create(null)\nkEnumerableProperty.enumerable = true\n\nmodule.exports = {\n  kEnumerableProperty,\n  nop,\n  isDisturbed,\n  isErrored,\n  isReadable,\n  toUSVString,\n  isReadableAborted,\n  isBlobLike,\n  parseOrigin,\n  parseURL,\n  getServerName,\n  isStream,\n  isIterable,\n  isAsyncIterable,\n  isDestroyed,\n  headerNameToString,\n  parseRawHeaders,\n  parseHeaders,\n  parseKeepAliveTimeout,\n  destroy,\n  bodyLength,\n  deepClone,\n  ReadableStreamFrom,\n  isBuffer,\n  validateHandler,\n  getSocketInfo,\n  isFormDataLike,\n  buildURL,\n  throwIfAborted,\n  addAbortListener,\n  parseRangeHeader,\n  nodeMajor,\n  nodeMinor,\n  nodeHasAutoSelectFamily: nodeMajor > 18 || (nodeMajor === 18 && nodeMinor >= 13),\n  safeHTTPMethods: ['GET', 'HEAD', 'OPTIONS', 'TRACE']\n}\n","'use strict'\n\nconst Dispatcher = require('./dispatcher')\nconst {\n  ClientDestroyedError,\n  ClientClosedError,\n  InvalidArgumentError\n} = require('./core/errors')\nconst { kDestroy, kClose, kDispatch, kInterceptors } = require('./core/symbols')\n\nconst kDestroyed = Symbol('destroyed')\nconst kClosed = Symbol('closed')\nconst kOnDestroyed = Symbol('onDestroyed')\nconst kOnClosed = Symbol('onClosed')\nconst kInterceptedDispatch = Symbol('Intercepted Dispatch')\n\nclass DispatcherBase extends Dispatcher {\n  constructor () {\n    super()\n\n    this[kDestroyed] = false\n    this[kOnDestroyed] = null\n    this[kClosed] = false\n    this[kOnClosed] = []\n  }\n\n  get destroyed () {\n    return this[kDestroyed]\n  }\n\n  get closed () {\n    return this[kClosed]\n  }\n\n  get interceptors () {\n    return this[kInterceptors]\n  }\n\n  set interceptors (newInterceptors) {\n    if (newInterceptors) {\n      for (let i = newInterceptors.length - 1; i >= 0; i--) {\n        const interceptor = this[kInterceptors][i]\n        if (typeof interceptor !== 'function') {\n          throw new InvalidArgumentError('interceptor must be an function')\n        }\n      }\n    }\n\n    this[kInterceptors] = newInterceptors\n  }\n\n  close (callback) {\n    if (callback === undefined) {\n      return new Promise((resolve, reject) => {\n        this.close((err, data) => {\n          return err ? reject(err) : resolve(data)\n        })\n      })\n    }\n\n    if (typeof callback !== 'function') {\n      throw new InvalidArgumentError('invalid callback')\n    }\n\n    if (this[kDestroyed]) {\n      queueMicrotask(() => callback(new ClientDestroyedError(), null))\n      return\n    }\n\n    if (this[kClosed]) {\n      if (this[kOnClosed]) {\n        this[kOnClosed].push(callback)\n      } else {\n        queueMicrotask(() => callback(null, null))\n      }\n      return\n    }\n\n    this[kClosed] = true\n    this[kOnClosed].push(callback)\n\n    const onClosed = () => {\n      const callbacks = this[kOnClosed]\n      this[kOnClosed] = null\n      for (let i = 0; i < callbacks.length; i++) {\n        callbacks[i](null, null)\n      }\n    }\n\n    // Should not error.\n    this[kClose]()\n      .then(() => this.destroy())\n      .then(() => {\n        queueMicrotask(onClosed)\n      })\n  }\n\n  destroy (err, callback) {\n    if (typeof err === 'function') {\n      callback = err\n      err = null\n    }\n\n    if (callback === undefined) {\n      return new Promise((resolve, reject) => {\n        this.destroy(err, (err, data) => {\n          return err ? /* istanbul ignore next: should never error */ reject(err) : resolve(data)\n        })\n      })\n    }\n\n    if (typeof callback !== 'function') {\n      throw new InvalidArgumentError('invalid callback')\n    }\n\n    if (this[kDestroyed]) {\n      if (this[kOnDestroyed]) {\n        this[kOnDestroyed].push(callback)\n      } else {\n        queueMicrotask(() => callback(null, null))\n      }\n      return\n    }\n\n    if (!err) {\n      err = new ClientDestroyedError()\n    }\n\n    this[kDestroyed] = true\n    this[kOnDestroyed] = this[kOnDestroyed] || []\n    this[kOnDestroyed].push(callback)\n\n    const onDestroyed = () => {\n      const callbacks = this[kOnDestroyed]\n      this[kOnDestroyed] = null\n      for (let i = 0; i < callbacks.length; i++) {\n        callbacks[i](null, null)\n      }\n    }\n\n    // Should not error.\n    this[kDestroy](err).then(() => {\n      queueMicrotask(onDestroyed)\n    })\n  }\n\n  [kInterceptedDispatch] (opts, handler) {\n    if (!this[kInterceptors] || this[kInterceptors].length === 0) {\n      this[kInterceptedDispatch] = this[kDispatch]\n      return this[kDispatch](opts, handler)\n    }\n\n    let dispatch = this[kDispatch].bind(this)\n    for (let i = this[kInterceptors].length - 1; i >= 0; i--) {\n      dispatch = this[kInterceptors][i](dispatch)\n    }\n    this[kInterceptedDispatch] = dispatch\n    return dispatch(opts, handler)\n  }\n\n  dispatch (opts, handler) {\n    if (!handler || typeof handler !== 'object') {\n      throw new InvalidArgumentError('handler must be an object')\n    }\n\n    try {\n      if (!opts || typeof opts !== 'object') {\n        throw new InvalidArgumentError('opts must be an object.')\n      }\n\n      if (this[kDestroyed] || this[kOnDestroyed]) {\n        throw new ClientDestroyedError()\n      }\n\n      if (this[kClosed]) {\n        throw new ClientClosedError()\n      }\n\n      return this[kInterceptedDispatch](opts, handler)\n    } catch (err) {\n      if (typeof handler.onError !== 'function') {\n        throw new InvalidArgumentError('invalid onError method')\n      }\n\n      handler.onError(err)\n\n      return false\n    }\n  }\n}\n\nmodule.exports = DispatcherBase\n","'use strict'\n\nconst EventEmitter = require('events')\n\nclass Dispatcher extends EventEmitter {\n  dispatch () {\n    throw new Error('not implemented')\n  }\n\n  close () {\n    throw new Error('not implemented')\n  }\n\n  destroy () {\n    throw new Error('not implemented')\n  }\n}\n\nmodule.exports = Dispatcher\n","'use strict'\n\nconst Busboy = require('@fastify/busboy')\nconst util = require('../core/util')\nconst {\n  ReadableStreamFrom,\n  isBlobLike,\n  isReadableStreamLike,\n  readableStreamClose,\n  createDeferredPromise,\n  fullyReadBody\n} = require('./util')\nconst { FormData } = require('./formdata')\nconst { kState } = require('./symbols')\nconst { webidl } = require('./webidl')\nconst { DOMException, structuredClone } = require('./constants')\nconst { Blob, File: NativeFile } = require('buffer')\nconst { kBodyUsed } = require('../core/symbols')\nconst assert = require('assert')\nconst { isErrored } = require('../core/util')\nconst { isUint8Array, isArrayBuffer } = require('util/types')\nconst { File: UndiciFile } = require('./file')\nconst { parseMIMEType, serializeAMimeType } = require('./dataURL')\n\nlet ReadableStream = globalThis.ReadableStream\n\n/** @type {globalThis['File']} */\nconst File = NativeFile ?? UndiciFile\nconst textEncoder = new TextEncoder()\nconst textDecoder = new TextDecoder()\n\n// https://fetch.spec.whatwg.org/#concept-bodyinit-extract\nfunction extractBody (object, keepalive = false) {\n  if (!ReadableStream) {\n    ReadableStream = require('stream/web').ReadableStream\n  }\n\n  // 1. Let stream be null.\n  let stream = null\n\n  // 2. If object is a ReadableStream object, then set stream to object.\n  if (object instanceof ReadableStream) {\n    stream = object\n  } else if (isBlobLike(object)) {\n    // 3. Otherwise, if object is a Blob object, set stream to the\n    //    result of running objects get stream.\n    stream = object.stream()\n  } else {\n    // 4. Otherwise, set stream to a new ReadableStream object, and set\n    //    up stream.\n    stream = new ReadableStream({\n      async pull (controller) {\n        controller.enqueue(\n          typeof source === 'string' ? textEncoder.encode(source) : source\n        )\n        queueMicrotask(() => readableStreamClose(controller))\n      },\n      start () {},\n      type: undefined\n    })\n  }\n\n  // 5. Assert: stream is a ReadableStream object.\n  assert(isReadableStreamLike(stream))\n\n  // 6. Let action be null.\n  let action = null\n\n  // 7. Let source be null.\n  let source = null\n\n  // 8. Let length be null.\n  let length = null\n\n  // 9. Let type be null.\n  let type = null\n\n  // 10. Switch on object:\n  if (typeof object === 'string') {\n    // Set source to the UTF-8 encoding of object.\n    // Note: setting source to a Uint8Array here breaks some mocking assumptions.\n    source = object\n\n    // Set type to `text/plain;charset=UTF-8`.\n    type = 'text/plain;charset=UTF-8'\n  } else if (object instanceof URLSearchParams) {\n    // URLSearchParams\n\n    // spec says to run application/x-www-form-urlencoded on body.list\n    // this is implemented in Node.js as apart of an URLSearchParams instance toString method\n    // See: https://github.com/nodejs/node/blob/e46c680bf2b211bbd52cf959ca17ee98c7f657f5/lib/internal/url.js#L490\n    // and https://github.com/nodejs/node/blob/e46c680bf2b211bbd52cf959ca17ee98c7f657f5/lib/internal/url.js#L1100\n\n    // Set source to the result of running the application/x-www-form-urlencoded serializer with objects list.\n    source = object.toString()\n\n    // Set type to `application/x-www-form-urlencoded;charset=UTF-8`.\n    type = 'application/x-www-form-urlencoded;charset=UTF-8'\n  } else if (isArrayBuffer(object)) {\n    // BufferSource/ArrayBuffer\n\n    // Set source to a copy of the bytes held by object.\n    source = new Uint8Array(object.slice())\n  } else if (ArrayBuffer.isView(object)) {\n    // BufferSource/ArrayBufferView\n\n    // Set source to a copy of the bytes held by object.\n    source = new Uint8Array(object.buffer.slice(object.byteOffset, object.byteOffset + object.byteLength))\n  } else if (util.isFormDataLike(object)) {\n    const boundary = `----formdata-undici-0${`${Math.floor(Math.random() * 1e11)}`.padStart(11, '0')}`\n    const prefix = `--${boundary}\\r\\nContent-Disposition: form-data`\n\n    /*! formdata-polyfill. MIT License. Jimmy Wrting <https://jimmy.warting.se/opensource> */\n    const escape = (str) =>\n      str.replace(/\\n/g, '%0A').replace(/\\r/g, '%0D').replace(/\"/g, '%22')\n    const normalizeLinefeeds = (value) => value.replace(/\\r?\\n|\\r/g, '\\r\\n')\n\n    // Set action to this step: run the multipart/form-data\n    // encoding algorithm, with objects entry list and UTF-8.\n    // - This ensures that the body is immutable and can't be changed afterwords\n    // - That the content-length is calculated in advance.\n    // - And that all parts are pre-encoded and ready to be sent.\n\n    const blobParts = []\n    const rn = new Uint8Array([13, 10]) // '\\r\\n'\n    length = 0\n    let hasUnknownSizeValue = false\n\n    for (const [name, value] of object) {\n      if (typeof value === 'string') {\n        const chunk = textEncoder.encode(prefix +\n          `; name=\"${escape(normalizeLinefeeds(name))}\"` +\n          `\\r\\n\\r\\n${normalizeLinefeeds(value)}\\r\\n`)\n        blobParts.push(chunk)\n        length += chunk.byteLength\n      } else {\n        const chunk = textEncoder.encode(`${prefix}; name=\"${escape(normalizeLinefeeds(name))}\"` +\n          (value.name ? `; filename=\"${escape(value.name)}\"` : '') + '\\r\\n' +\n          `Content-Type: ${\n            value.type || 'application/octet-stream'\n          }\\r\\n\\r\\n`)\n        blobParts.push(chunk, value, rn)\n        if (typeof value.size === 'number') {\n          length += chunk.byteLength + value.size + rn.byteLength\n        } else {\n          hasUnknownSizeValue = true\n        }\n      }\n    }\n\n    const chunk = textEncoder.encode(`--${boundary}--`)\n    blobParts.push(chunk)\n    length += chunk.byteLength\n    if (hasUnknownSizeValue) {\n      length = null\n    }\n\n    // Set source to object.\n    source = object\n\n    action = async function * () {\n      for (const part of blobParts) {\n        if (part.stream) {\n          yield * part.stream()\n        } else {\n          yield part\n        }\n      }\n    }\n\n    // Set type to `multipart/form-data; boundary=`,\n    // followed by the multipart/form-data boundary string generated\n    // by the multipart/form-data encoding algorithm.\n    type = 'multipart/form-data; boundary=' + boundary\n  } else if (isBlobLike(object)) {\n    // Blob\n\n    // Set source to object.\n    source = object\n\n    // Set length to objects size.\n    length = object.size\n\n    // If objects type attribute is not the empty byte sequence, set\n    // type to its value.\n    if (object.type) {\n      type = object.type\n    }\n  } else if (typeof object[Symbol.asyncIterator] === 'function') {\n    // If keepalive is true, then throw a TypeError.\n    if (keepalive) {\n      throw new TypeError('keepalive')\n    }\n\n    // If object is disturbed or locked, then throw a TypeError.\n    if (util.isDisturbed(object) || object.locked) {\n      throw new TypeError(\n        'Response body object should not be disturbed or locked'\n      )\n    }\n\n    stream =\n      object instanceof ReadableStream ? object : ReadableStreamFrom(object)\n  }\n\n  // 11. If source is a byte sequence, then set action to a\n  // step that returns source and length to sources length.\n  if (typeof source === 'string' || util.isBuffer(source)) {\n    length = Buffer.byteLength(source)\n  }\n\n  // 12. If action is non-null, then run these steps in in parallel:\n  if (action != null) {\n    // Run action.\n    let iterator\n    stream = new ReadableStream({\n      async start () {\n        iterator = action(object)[Symbol.asyncIterator]()\n      },\n      async pull (controller) {\n        const { value, done } = await iterator.next()\n        if (done) {\n          // When running action is done, close stream.\n          queueMicrotask(() => {\n            controller.close()\n          })\n        } else {\n          // Whenever one or more bytes are available and stream is not errored,\n          // enqueue a Uint8Array wrapping an ArrayBuffer containing the available\n          // bytes into stream.\n          if (!isErrored(stream)) {\n            controller.enqueue(new Uint8Array(value))\n          }\n        }\n        return controller.desiredSize > 0\n      },\n      async cancel (reason) {\n        await iterator.return()\n      },\n      type: undefined\n    })\n  }\n\n  // 13. Let body be a body whose stream is stream, source is source,\n  // and length is length.\n  const body = { stream, source, length }\n\n  // 14. Return (body, type).\n  return [body, type]\n}\n\n// https://fetch.spec.whatwg.org/#bodyinit-safely-extract\nfunction safelyExtractBody (object, keepalive = false) {\n  if (!ReadableStream) {\n    // istanbul ignore next\n    ReadableStream = require('stream/web').ReadableStream\n  }\n\n  // To safely extract a body and a `Content-Type` value from\n  // a byte sequence or BodyInit object object, run these steps:\n\n  // 1. If object is a ReadableStream object, then:\n  if (object instanceof ReadableStream) {\n    // Assert: object is neither disturbed nor locked.\n    // istanbul ignore next\n    assert(!util.isDisturbed(object), 'The body has already been consumed.')\n    // istanbul ignore next\n    assert(!object.locked, 'The stream is locked.')\n  }\n\n  // 2. Return the results of extracting object.\n  return extractBody(object, keepalive)\n}\n\nfunction cloneBody (body) {\n  // To clone a body body, run these steps:\n\n  // https://fetch.spec.whatwg.org/#concept-body-clone\n\n  // 1. Let  out1, out2  be the result of teeing bodys stream.\n  const [out1, out2] = body.stream.tee()\n  const out2Clone = structuredClone(out2, { transfer: [out2] })\n  // This, for whatever reasons, unrefs out2Clone which allows\n  // the process to exit by itself.\n  const [, finalClone] = out2Clone.tee()\n\n  // 2. Set bodys stream to out1.\n  body.stream = out1\n\n  // 3. Return a body whose stream is out2 and other members are copied from body.\n  return {\n    stream: finalClone,\n    length: body.length,\n    source: body.source\n  }\n}\n\nasync function * consumeBody (body) {\n  if (body) {\n    if (isUint8Array(body)) {\n      yield body\n    } else {\n      const stream = body.stream\n\n      if (util.isDisturbed(stream)) {\n        throw new TypeError('The body has already been consumed.')\n      }\n\n      if (stream.locked) {\n        throw new TypeError('The stream is locked.')\n      }\n\n      // Compat.\n      stream[kBodyUsed] = true\n\n      yield * stream\n    }\n  }\n}\n\nfunction throwIfAborted (state) {\n  if (state.aborted) {\n    throw new DOMException('The operation was aborted.', 'AbortError')\n  }\n}\n\nfunction bodyMixinMethods (instance) {\n  const methods = {\n    blob () {\n      // The blob() method steps are to return the result of\n      // running consume body with this and the following step\n      // given a byte sequence bytes: return a Blob whose\n      // contents are bytes and whose type attribute is thiss\n      // MIME type.\n      return specConsumeBody(this, (bytes) => {\n        let mimeType = bodyMimeType(this)\n\n        if (mimeType === 'failure') {\n          mimeType = ''\n        } else if (mimeType) {\n          mimeType = serializeAMimeType(mimeType)\n        }\n\n        // Return a Blob whose contents are bytes and type attribute\n        // is mimeType.\n        return new Blob([bytes], { type: mimeType })\n      }, instance)\n    },\n\n    arrayBuffer () {\n      // The arrayBuffer() method steps are to return the result\n      // of running consume body with this and the following step\n      // given a byte sequence bytes: return a new ArrayBuffer\n      // whose contents are bytes.\n      return specConsumeBody(this, (bytes) => {\n        return new Uint8Array(bytes).buffer\n      }, instance)\n    },\n\n    text () {\n      // The text() method steps are to return the result of running\n      // consume body with this and UTF-8 decode.\n      return specConsumeBody(this, utf8DecodeBytes, instance)\n    },\n\n    json () {\n      // The json() method steps are to return the result of running\n      // consume body with this and parse JSON from bytes.\n      return specConsumeBody(this, parseJSONFromBytes, instance)\n    },\n\n    async formData () {\n      webidl.brandCheck(this, instance)\n\n      throwIfAborted(this[kState])\n\n      const contentType = this.headers.get('Content-Type')\n\n      // If mimeTypes essence is \"multipart/form-data\", then:\n      if (/multipart\\/form-data/.test(contentType)) {\n        const headers = {}\n        for (const [key, value] of this.headers) headers[key.toLowerCase()] = value\n\n        const responseFormData = new FormData()\n\n        let busboy\n\n        try {\n          busboy = new Busboy({\n            headers,\n            preservePath: true\n          })\n        } catch (err) {\n          throw new DOMException(`${err}`, 'AbortError')\n        }\n\n        busboy.on('field', (name, value) => {\n          responseFormData.append(name, value)\n        })\n        busboy.on('file', (name, value, filename, encoding, mimeType) => {\n          const chunks = []\n\n          if (encoding === 'base64' || encoding.toLowerCase() === 'base64') {\n            let base64chunk = ''\n\n            value.on('data', (chunk) => {\n              base64chunk += chunk.toString().replace(/[\\r\\n]/gm, '')\n\n              const end = base64chunk.length - base64chunk.length % 4\n              chunks.push(Buffer.from(base64chunk.slice(0, end), 'base64'))\n\n              base64chunk = base64chunk.slice(end)\n            })\n            value.on('end', () => {\n              chunks.push(Buffer.from(base64chunk, 'base64'))\n              responseFormData.append(name, new File(chunks, filename, { type: mimeType }))\n            })\n          } else {\n            value.on('data', (chunk) => {\n              chunks.push(chunk)\n            })\n            value.on('end', () => {\n              responseFormData.append(name, new File(chunks, filename, { type: mimeType }))\n            })\n          }\n        })\n\n        const busboyResolve = new Promise((resolve, reject) => {\n          busboy.on('finish', resolve)\n          busboy.on('error', (err) => reject(new TypeError(err)))\n        })\n\n        if (this.body !== null) for await (const chunk of consumeBody(this[kState].body)) busboy.write(chunk)\n        busboy.end()\n        await busboyResolve\n\n        return responseFormData\n      } else if (/application\\/x-www-form-urlencoded/.test(contentType)) {\n        // Otherwise, if mimeTypes essence is \"application/x-www-form-urlencoded\", then:\n\n        // 1. Let entries be the result of parsing bytes.\n        let entries\n        try {\n          let text = ''\n          // application/x-www-form-urlencoded parser will keep the BOM.\n          // https://url.spec.whatwg.org/#concept-urlencoded-parser\n          // Note that streaming decoder is stateful and cannot be reused\n          const streamingDecoder = new TextDecoder('utf-8', { ignoreBOM: true })\n\n          for await (const chunk of consumeBody(this[kState].body)) {\n            if (!isUint8Array(chunk)) {\n              throw new TypeError('Expected Uint8Array chunk')\n            }\n            text += streamingDecoder.decode(chunk, { stream: true })\n          }\n          text += streamingDecoder.decode()\n          entries = new URLSearchParams(text)\n        } catch (err) {\n          // istanbul ignore next: Unclear when new URLSearchParams can fail on a string.\n          // 2. If entries is failure, then throw a TypeError.\n          throw Object.assign(new TypeError(), { cause: err })\n        }\n\n        // 3. Return a new FormData object whose entries are entries.\n        const formData = new FormData()\n        for (const [name, value] of entries) {\n          formData.append(name, value)\n        }\n        return formData\n      } else {\n        // Wait a tick before checking if the request has been aborted.\n        // Otherwise, a TypeError can be thrown when an AbortError should.\n        await Promise.resolve()\n\n        throwIfAborted(this[kState])\n\n        // Otherwise, throw a TypeError.\n        throw webidl.errors.exception({\n          header: `${instance.name}.formData`,\n          message: 'Could not parse content as FormData.'\n        })\n      }\n    }\n  }\n\n  return methods\n}\n\nfunction mixinBody (prototype) {\n  Object.assign(prototype.prototype, bodyMixinMethods(prototype))\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-body-consume-body\n * @param {Response|Request} object\n * @param {(value: unknown) => unknown} convertBytesToJSValue\n * @param {Response|Request} instance\n */\nasync function specConsumeBody (object, convertBytesToJSValue, instance) {\n  webidl.brandCheck(object, instance)\n\n  throwIfAborted(object[kState])\n\n  // 1. If object is unusable, then return a promise rejected\n  //    with a TypeError.\n  if (bodyUnusable(object[kState].body)) {\n    throw new TypeError('Body is unusable')\n  }\n\n  // 2. Let promise be a new promise.\n  const promise = createDeferredPromise()\n\n  // 3. Let errorSteps given error be to reject promise with error.\n  const errorSteps = (error) => promise.reject(error)\n\n  // 4. Let successSteps given a byte sequence data be to resolve\n  //    promise with the result of running convertBytesToJSValue\n  //    with data. If that threw an exception, then run errorSteps\n  //    with that exception.\n  const successSteps = (data) => {\n    try {\n      promise.resolve(convertBytesToJSValue(data))\n    } catch (e) {\n      errorSteps(e)\n    }\n  }\n\n  // 5. If objects body is null, then run successSteps with an\n  //    empty byte sequence.\n  if (object[kState].body == null) {\n    successSteps(new Uint8Array())\n    return promise.promise\n  }\n\n  // 6. Otherwise, fully read objects body given successSteps,\n  //    errorSteps, and objects relevant global object.\n  await fullyReadBody(object[kState].body, successSteps, errorSteps)\n\n  // 7. Return promise.\n  return promise.promise\n}\n\n// https://fetch.spec.whatwg.org/#body-unusable\nfunction bodyUnusable (body) {\n  // An object including the Body interface mixin is\n  // said to be unusable if its body is non-null and\n  // its bodys stream is disturbed or locked.\n  return body != null && (body.stream.locked || util.isDisturbed(body.stream))\n}\n\n/**\n * @see https://encoding.spec.whatwg.org/#utf-8-decode\n * @param {Buffer} buffer\n */\nfunction utf8DecodeBytes (buffer) {\n  if (buffer.length === 0) {\n    return ''\n  }\n\n  // 1. Let buffer be the result of peeking three bytes from\n  //    ioQueue, converted to a byte sequence.\n\n  // 2. If buffer is 0xEF 0xBB 0xBF, then read three\n  //    bytes from ioQueue. (Do nothing with those bytes.)\n  if (buffer[0] === 0xEF && buffer[1] === 0xBB && buffer[2] === 0xBF) {\n    buffer = buffer.subarray(3)\n  }\n\n  // 3. Process a queue with an instance of UTF-8s\n  //    decoder, ioQueue, output, and \"replacement\".\n  const output = textDecoder.decode(buffer)\n\n  // 4. Return output.\n  return output\n}\n\n/**\n * @see https://infra.spec.whatwg.org/#parse-json-bytes-to-a-javascript-value\n * @param {Uint8Array} bytes\n */\nfunction parseJSONFromBytes (bytes) {\n  return JSON.parse(utf8DecodeBytes(bytes))\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-body-mime-type\n * @param {import('./response').Response|import('./request').Request} object\n */\nfunction bodyMimeType (object) {\n  const { headersList } = object[kState]\n  const contentType = headersList.get('content-type')\n\n  if (contentType === null) {\n    return 'failure'\n  }\n\n  return parseMIMEType(contentType)\n}\n\nmodule.exports = {\n  extractBody,\n  safelyExtractBody,\n  cloneBody,\n  mixinBody\n}\n","'use strict'\n\nconst { MessageChannel, receiveMessageOnPort } = require('worker_threads')\n\nconst corsSafeListedMethods = ['GET', 'HEAD', 'POST']\nconst corsSafeListedMethodsSet = new Set(corsSafeListedMethods)\n\nconst nullBodyStatus = [101, 204, 205, 304]\n\nconst redirectStatus = [301, 302, 303, 307, 308]\nconst redirectStatusSet = new Set(redirectStatus)\n\n// https://fetch.spec.whatwg.org/#block-bad-port\nconst badPorts = [\n  '1', '7', '9', '11', '13', '15', '17', '19', '20', '21', '22', '23', '25', '37', '42', '43', '53', '69', '77', '79',\n  '87', '95', '101', '102', '103', '104', '109', '110', '111', '113', '115', '117', '119', '123', '135', '137',\n  '139', '143', '161', '179', '389', '427', '465', '512', '513', '514', '515', '526', '530', '531', '532',\n  '540', '548', '554', '556', '563', '587', '601', '636', '989', '990', '993', '995', '1719', '1720', '1723',\n  '2049', '3659', '4045', '5060', '5061', '6000', '6566', '6665', '6666', '6667', '6668', '6669', '6697',\n  '10080'\n]\n\nconst badPortsSet = new Set(badPorts)\n\n// https://w3c.github.io/webappsec-referrer-policy/#referrer-policies\nconst referrerPolicy = [\n  '',\n  'no-referrer',\n  'no-referrer-when-downgrade',\n  'same-origin',\n  'origin',\n  'strict-origin',\n  'origin-when-cross-origin',\n  'strict-origin-when-cross-origin',\n  'unsafe-url'\n]\nconst referrerPolicySet = new Set(referrerPolicy)\n\nconst requestRedirect = ['follow', 'manual', 'error']\n\nconst safeMethods = ['GET', 'HEAD', 'OPTIONS', 'TRACE']\nconst safeMethodsSet = new Set(safeMethods)\n\nconst requestMode = ['navigate', 'same-origin', 'no-cors', 'cors']\n\nconst requestCredentials = ['omit', 'same-origin', 'include']\n\nconst requestCache = [\n  'default',\n  'no-store',\n  'reload',\n  'no-cache',\n  'force-cache',\n  'only-if-cached'\n]\n\n// https://fetch.spec.whatwg.org/#request-body-header-name\nconst requestBodyHeader = [\n  'content-encoding',\n  'content-language',\n  'content-location',\n  'content-type',\n  // See https://github.com/nodejs/undici/issues/2021\n  // 'Content-Length' is a forbidden header name, which is typically\n  // removed in the Headers implementation. However, undici doesn't\n  // filter out headers, so we add it here.\n  'content-length'\n]\n\n// https://fetch.spec.whatwg.org/#enumdef-requestduplex\nconst requestDuplex = [\n  'half'\n]\n\n// http://fetch.spec.whatwg.org/#forbidden-method\nconst forbiddenMethods = ['CONNECT', 'TRACE', 'TRACK']\nconst forbiddenMethodsSet = new Set(forbiddenMethods)\n\nconst subresource = [\n  'audio',\n  'audioworklet',\n  'font',\n  'image',\n  'manifest',\n  'paintworklet',\n  'script',\n  'style',\n  'track',\n  'video',\n  'xslt',\n  ''\n]\nconst subresourceSet = new Set(subresource)\n\n/** @type {globalThis['DOMException']} */\nconst DOMException = globalThis.DOMException ?? (() => {\n  // DOMException was only made a global in Node v17.0.0,\n  // but fetch supports >= v16.8.\n  try {\n    atob('~')\n  } catch (err) {\n    return Object.getPrototypeOf(err).constructor\n  }\n})()\n\nlet channel\n\n/** @type {globalThis['structuredClone']} */\nconst structuredClone =\n  globalThis.structuredClone ??\n  // https://github.com/nodejs/node/blob/b27ae24dcc4251bad726d9d84baf678d1f707fed/lib/internal/structured_clone.js\n  // structuredClone was added in v17.0.0, but fetch supports v16.8\n  function structuredClone (value, options = undefined) {\n    if (arguments.length === 0) {\n      throw new TypeError('missing argument')\n    }\n\n    if (!channel) {\n      channel = new MessageChannel()\n    }\n    channel.port1.unref()\n    channel.port2.unref()\n    channel.port1.postMessage(value, options?.transfer)\n    return receiveMessageOnPort(channel.port2).message\n  }\n\nmodule.exports = {\n  DOMException,\n  structuredClone,\n  subresource,\n  forbiddenMethods,\n  requestBodyHeader,\n  referrerPolicy,\n  requestRedirect,\n  requestMode,\n  requestCredentials,\n  requestCache,\n  redirectStatus,\n  corsSafeListedMethods,\n  nullBodyStatus,\n  safeMethods,\n  badPorts,\n  requestDuplex,\n  subresourceSet,\n  badPortsSet,\n  redirectStatusSet,\n  corsSafeListedMethodsSet,\n  safeMethodsSet,\n  forbiddenMethodsSet,\n  referrerPolicySet\n}\n","const assert = require('assert')\nconst { atob } = require('buffer')\nconst { isomorphicDecode } = require('./util')\n\nconst encoder = new TextEncoder()\n\n/**\n * @see https://mimesniff.spec.whatwg.org/#http-token-code-point\n */\nconst HTTP_TOKEN_CODEPOINTS = /^[!#$%&'*+-.^_|~A-Za-z0-9]+$/\nconst HTTP_WHITESPACE_REGEX = /(\\u000A|\\u000D|\\u0009|\\u0020)/ // eslint-disable-line\n/**\n * @see https://mimesniff.spec.whatwg.org/#http-quoted-string-token-code-point\n */\nconst HTTP_QUOTED_STRING_TOKENS = /[\\u0009|\\u0020-\\u007E|\\u0080-\\u00FF]/ // eslint-disable-line\n\n// https://fetch.spec.whatwg.org/#data-url-processor\n/** @param {URL} dataURL */\nfunction dataURLProcessor (dataURL) {\n  // 1. Assert: dataURLs scheme is \"data\".\n  assert(dataURL.protocol === 'data:')\n\n  // 2. Let input be the result of running the URL\n  // serializer on dataURL with exclude fragment\n  // set to true.\n  let input = URLSerializer(dataURL, true)\n\n  // 3. Remove the leading \"data:\" string from input.\n  input = input.slice(5)\n\n  // 4. Let position point at the start of input.\n  const position = { position: 0 }\n\n  // 5. Let mimeType be the result of collecting a\n  // sequence of code points that are not equal\n  // to U+002C (,), given position.\n  let mimeType = collectASequenceOfCodePointsFast(\n    ',',\n    input,\n    position\n  )\n\n  // 6. Strip leading and trailing ASCII whitespace\n  // from mimeType.\n  // Undici implementation note: we need to store the\n  // length because if the mimetype has spaces removed,\n  // the wrong amount will be sliced from the input in\n  // step #9\n  const mimeTypeLength = mimeType.length\n  mimeType = removeASCIIWhitespace(mimeType, true, true)\n\n  // 7. If position is past the end of input, then\n  // return failure\n  if (position.position >= input.length) {\n    return 'failure'\n  }\n\n  // 8. Advance position by 1.\n  position.position++\n\n  // 9. Let encodedBody be the remainder of input.\n  const encodedBody = input.slice(mimeTypeLength + 1)\n\n  // 10. Let body be the percent-decoding of encodedBody.\n  let body = stringPercentDecode(encodedBody)\n\n  // 11. If mimeType ends with U+003B (;), followed by\n  // zero or more U+0020 SPACE, followed by an ASCII\n  // case-insensitive match for \"base64\", then:\n  if (/;(\\u0020){0,}base64$/i.test(mimeType)) {\n    // 1. Let stringBody be the isomorphic decode of body.\n    const stringBody = isomorphicDecode(body)\n\n    // 2. Set body to the forgiving-base64 decode of\n    // stringBody.\n    body = forgivingBase64(stringBody)\n\n    // 3. If body is failure, then return failure.\n    if (body === 'failure') {\n      return 'failure'\n    }\n\n    // 4. Remove the last 6 code points from mimeType.\n    mimeType = mimeType.slice(0, -6)\n\n    // 5. Remove trailing U+0020 SPACE code points from mimeType,\n    // if any.\n    mimeType = mimeType.replace(/(\\u0020)+$/, '')\n\n    // 6. Remove the last U+003B (;) code point from mimeType.\n    mimeType = mimeType.slice(0, -1)\n  }\n\n  // 12. If mimeType starts with U+003B (;), then prepend\n  // \"text/plain\" to mimeType.\n  if (mimeType.startsWith(';')) {\n    mimeType = 'text/plain' + mimeType\n  }\n\n  // 13. Let mimeTypeRecord be the result of parsing\n  // mimeType.\n  let mimeTypeRecord = parseMIMEType(mimeType)\n\n  // 14. If mimeTypeRecord is failure, then set\n  // mimeTypeRecord to text/plain;charset=US-ASCII.\n  if (mimeTypeRecord === 'failure') {\n    mimeTypeRecord = parseMIMEType('text/plain;charset=US-ASCII')\n  }\n\n  // 15. Return a new data: URL struct whose MIME\n  // type is mimeTypeRecord and body is body.\n  // https://fetch.spec.whatwg.org/#data-url-struct\n  return { mimeType: mimeTypeRecord, body }\n}\n\n// https://url.spec.whatwg.org/#concept-url-serializer\n/**\n * @param {URL} url\n * @param {boolean} excludeFragment\n */\nfunction URLSerializer (url, excludeFragment = false) {\n  if (!excludeFragment) {\n    return url.href\n  }\n\n  const href = url.href\n  const hashLength = url.hash.length\n\n  return hashLength === 0 ? href : href.substring(0, href.length - hashLength)\n}\n\n// https://infra.spec.whatwg.org/#collect-a-sequence-of-code-points\n/**\n * @param {(char: string) => boolean} condition\n * @param {string} input\n * @param {{ position: number }} position\n */\nfunction collectASequenceOfCodePoints (condition, input, position) {\n  // 1. Let result be the empty string.\n  let result = ''\n\n  // 2. While position doesnt point past the end of input and the\n  // code point at position within input meets the condition condition:\n  while (position.position < input.length && condition(input[position.position])) {\n    // 1. Append that code point to the end of result.\n    result += input[position.position]\n\n    // 2. Advance position by 1.\n    position.position++\n  }\n\n  // 3. Return result.\n  return result\n}\n\n/**\n * A faster collectASequenceOfCodePoints that only works when comparing a single character.\n * @param {string} char\n * @param {string} input\n * @param {{ position: number }} position\n */\nfunction collectASequenceOfCodePointsFast (char, input, position) {\n  const idx = input.indexOf(char, position.position)\n  const start = position.position\n\n  if (idx === -1) {\n    position.position = input.length\n    return input.slice(start)\n  }\n\n  position.position = idx\n  return input.slice(start, position.position)\n}\n\n// https://url.spec.whatwg.org/#string-percent-decode\n/** @param {string} input */\nfunction stringPercentDecode (input) {\n  // 1. Let bytes be the UTF-8 encoding of input.\n  const bytes = encoder.encode(input)\n\n  // 2. Return the percent-decoding of bytes.\n  return percentDecode(bytes)\n}\n\n// https://url.spec.whatwg.org/#percent-decode\n/** @param {Uint8Array} input */\nfunction percentDecode (input) {\n  // 1. Let output be an empty byte sequence.\n  /** @type {number[]} */\n  const output = []\n\n  // 2. For each byte byte in input:\n  for (let i = 0; i < input.length; i++) {\n    const byte = input[i]\n\n    // 1. If byte is not 0x25 (%), then append byte to output.\n    if (byte !== 0x25) {\n      output.push(byte)\n\n    // 2. Otherwise, if byte is 0x25 (%) and the next two bytes\n    // after byte in input are not in the ranges\n    // 0x30 (0) to 0x39 (9), 0x41 (A) to 0x46 (F),\n    // and 0x61 (a) to 0x66 (f), all inclusive, append byte\n    // to output.\n    } else if (\n      byte === 0x25 &&\n      !/^[0-9A-Fa-f]{2}$/i.test(String.fromCharCode(input[i + 1], input[i + 2]))\n    ) {\n      output.push(0x25)\n\n    // 3. Otherwise:\n    } else {\n      // 1. Let bytePoint be the two bytes after byte in input,\n      // decoded, and then interpreted as hexadecimal number.\n      const nextTwoBytes = String.fromCharCode(input[i + 1], input[i + 2])\n      const bytePoint = Number.parseInt(nextTwoBytes, 16)\n\n      // 2. Append a byte whose value is bytePoint to output.\n      output.push(bytePoint)\n\n      // 3. Skip the next two bytes in input.\n      i += 2\n    }\n  }\n\n  // 3. Return output.\n  return Uint8Array.from(output)\n}\n\n// https://mimesniff.spec.whatwg.org/#parse-a-mime-type\n/** @param {string} input */\nfunction parseMIMEType (input) {\n  // 1. Remove any leading and trailing HTTP whitespace\n  // from input.\n  input = removeHTTPWhitespace(input, true, true)\n\n  // 2. Let position be a position variable for input,\n  // initially pointing at the start of input.\n  const position = { position: 0 }\n\n  // 3. Let type be the result of collecting a sequence\n  // of code points that are not U+002F (/) from\n  // input, given position.\n  const type = collectASequenceOfCodePointsFast(\n    '/',\n    input,\n    position\n  )\n\n  // 4. If type is the empty string or does not solely\n  // contain HTTP token code points, then return failure.\n  // https://mimesniff.spec.whatwg.org/#http-token-code-point\n  if (type.length === 0 || !HTTP_TOKEN_CODEPOINTS.test(type)) {\n    return 'failure'\n  }\n\n  // 5. If position is past the end of input, then return\n  // failure\n  if (position.position > input.length) {\n    return 'failure'\n  }\n\n  // 6. Advance position by 1. (This skips past U+002F (/).)\n  position.position++\n\n  // 7. Let subtype be the result of collecting a sequence of\n  // code points that are not U+003B (;) from input, given\n  // position.\n  let subtype = collectASequenceOfCodePointsFast(\n    ';',\n    input,\n    position\n  )\n\n  // 8. Remove any trailing HTTP whitespace from subtype.\n  subtype = removeHTTPWhitespace(subtype, false, true)\n\n  // 9. If subtype is the empty string or does not solely\n  // contain HTTP token code points, then return failure.\n  if (subtype.length === 0 || !HTTP_TOKEN_CODEPOINTS.test(subtype)) {\n    return 'failure'\n  }\n\n  const typeLowercase = type.toLowerCase()\n  const subtypeLowercase = subtype.toLowerCase()\n\n  // 10. Let mimeType be a new MIME type record whose type\n  // is type, in ASCII lowercase, and subtype is subtype,\n  // in ASCII lowercase.\n  // https://mimesniff.spec.whatwg.org/#mime-type\n  const mimeType = {\n    type: typeLowercase,\n    subtype: subtypeLowercase,\n    /** @type {Map<string, string>} */\n    parameters: new Map(),\n    // https://mimesniff.spec.whatwg.org/#mime-type-essence\n    essence: `${typeLowercase}/${subtypeLowercase}`\n  }\n\n  // 11. While position is not past the end of input:\n  while (position.position < input.length) {\n    // 1. Advance position by 1. (This skips past U+003B (;).)\n    position.position++\n\n    // 2. Collect a sequence of code points that are HTTP\n    // whitespace from input given position.\n    collectASequenceOfCodePoints(\n      // https://fetch.spec.whatwg.org/#http-whitespace\n      char => HTTP_WHITESPACE_REGEX.test(char),\n      input,\n      position\n    )\n\n    // 3. Let parameterName be the result of collecting a\n    // sequence of code points that are not U+003B (;)\n    // or U+003D (=) from input, given position.\n    let parameterName = collectASequenceOfCodePoints(\n      (char) => char !== ';' && char !== '=',\n      input,\n      position\n    )\n\n    // 4. Set parameterName to parameterName, in ASCII\n    // lowercase.\n    parameterName = parameterName.toLowerCase()\n\n    // 5. If position is not past the end of input, then:\n    if (position.position < input.length) {\n      // 1. If the code point at position within input is\n      // U+003B (;), then continue.\n      if (input[position.position] === ';') {\n        continue\n      }\n\n      // 2. Advance position by 1. (This skips past U+003D (=).)\n      position.position++\n    }\n\n    // 6. If position is past the end of input, then break.\n    if (position.position > input.length) {\n      break\n    }\n\n    // 7. Let parameterValue be null.\n    let parameterValue = null\n\n    // 8. If the code point at position within input is\n    // U+0022 (\"), then:\n    if (input[position.position] === '\"') {\n      // 1. Set parameterValue to the result of collecting\n      // an HTTP quoted string from input, given position\n      // and the extract-value flag.\n      parameterValue = collectAnHTTPQuotedString(input, position, true)\n\n      // 2. Collect a sequence of code points that are not\n      // U+003B (;) from input, given position.\n      collectASequenceOfCodePointsFast(\n        ';',\n        input,\n        position\n      )\n\n    // 9. Otherwise:\n    } else {\n      // 1. Set parameterValue to the result of collecting\n      // a sequence of code points that are not U+003B (;)\n      // from input, given position.\n      parameterValue = collectASequenceOfCodePointsFast(\n        ';',\n        input,\n        position\n      )\n\n      // 2. Remove any trailing HTTP whitespace from parameterValue.\n      parameterValue = removeHTTPWhitespace(parameterValue, false, true)\n\n      // 3. If parameterValue is the empty string, then continue.\n      if (parameterValue.length === 0) {\n        continue\n      }\n    }\n\n    // 10. If all of the following are true\n    // - parameterName is not the empty string\n    // - parameterName solely contains HTTP token code points\n    // - parameterValue solely contains HTTP quoted-string token code points\n    // - mimeTypes parameters[parameterName] does not exist\n    // then set mimeTypes parameters[parameterName] to parameterValue.\n    if (\n      parameterName.length !== 0 &&\n      HTTP_TOKEN_CODEPOINTS.test(parameterName) &&\n      (parameterValue.length === 0 || HTTP_QUOTED_STRING_TOKENS.test(parameterValue)) &&\n      !mimeType.parameters.has(parameterName)\n    ) {\n      mimeType.parameters.set(parameterName, parameterValue)\n    }\n  }\n\n  // 12. Return mimeType.\n  return mimeType\n}\n\n// https://infra.spec.whatwg.org/#forgiving-base64-decode\n/** @param {string} data */\nfunction forgivingBase64 (data) {\n  // 1. Remove all ASCII whitespace from data.\n  data = data.replace(/[\\u0009\\u000A\\u000C\\u000D\\u0020]/g, '')  // eslint-disable-line\n\n  // 2. If datas code point length divides by 4 leaving\n  // no remainder, then:\n  if (data.length % 4 === 0) {\n    // 1. If data ends with one or two U+003D (=) code points,\n    // then remove them from data.\n    data = data.replace(/=?=$/, '')\n  }\n\n  // 3. If datas code point length divides by 4 leaving\n  // a remainder of 1, then return failure.\n  if (data.length % 4 === 1) {\n    return 'failure'\n  }\n\n  // 4. If data contains a code point that is not one of\n  //  U+002B (+)\n  //  U+002F (/)\n  //  ASCII alphanumeric\n  // then return failure.\n  if (/[^+/0-9A-Za-z]/.test(data)) {\n    return 'failure'\n  }\n\n  const binary = atob(data)\n  const bytes = new Uint8Array(binary.length)\n\n  for (let byte = 0; byte < binary.length; byte++) {\n    bytes[byte] = binary.charCodeAt(byte)\n  }\n\n  return bytes\n}\n\n// https://fetch.spec.whatwg.org/#collect-an-http-quoted-string\n// tests: https://fetch.spec.whatwg.org/#example-http-quoted-string\n/**\n * @param {string} input\n * @param {{ position: number }} position\n * @param {boolean?} extractValue\n */\nfunction collectAnHTTPQuotedString (input, position, extractValue) {\n  // 1. Let positionStart be position.\n  const positionStart = position.position\n\n  // 2. Let value be the empty string.\n  let value = ''\n\n  // 3. Assert: the code point at position within input\n  // is U+0022 (\").\n  assert(input[position.position] === '\"')\n\n  // 4. Advance position by 1.\n  position.position++\n\n  // 5. While true:\n  while (true) {\n    // 1. Append the result of collecting a sequence of code points\n    // that are not U+0022 (\") or U+005C (\\) from input, given\n    // position, to value.\n    value += collectASequenceOfCodePoints(\n      (char) => char !== '\"' && char !== '\\\\',\n      input,\n      position\n    )\n\n    // 2. If position is past the end of input, then break.\n    if (position.position >= input.length) {\n      break\n    }\n\n    // 3. Let quoteOrBackslash be the code point at position within\n    // input.\n    const quoteOrBackslash = input[position.position]\n\n    // 4. Advance position by 1.\n    position.position++\n\n    // 5. If quoteOrBackslash is U+005C (\\), then:\n    if (quoteOrBackslash === '\\\\') {\n      // 1. If position is past the end of input, then append\n      // U+005C (\\) to value and break.\n      if (position.position >= input.length) {\n        value += '\\\\'\n        break\n      }\n\n      // 2. Append the code point at position within input to value.\n      value += input[position.position]\n\n      // 3. Advance position by 1.\n      position.position++\n\n    // 6. Otherwise:\n    } else {\n      // 1. Assert: quoteOrBackslash is U+0022 (\").\n      assert(quoteOrBackslash === '\"')\n\n      // 2. Break.\n      break\n    }\n  }\n\n  // 6. If the extract-value flag is set, then return value.\n  if (extractValue) {\n    return value\n  }\n\n  // 7. Return the code points from positionStart to position,\n  // inclusive, within input.\n  return input.slice(positionStart, position.position)\n}\n\n/**\n * @see https://mimesniff.spec.whatwg.org/#serialize-a-mime-type\n */\nfunction serializeAMimeType (mimeType) {\n  assert(mimeType !== 'failure')\n  const { parameters, essence } = mimeType\n\n  // 1. Let serialization be the concatenation of mimeTypes\n  //    type, U+002F (/), and mimeTypes subtype.\n  let serialization = essence\n\n  // 2. For each name  value of mimeTypes parameters:\n  for (let [name, value] of parameters.entries()) {\n    // 1. Append U+003B (;) to serialization.\n    serialization += ';'\n\n    // 2. Append name to serialization.\n    serialization += name\n\n    // 3. Append U+003D (=) to serialization.\n    serialization += '='\n\n    // 4. If value does not solely contain HTTP token code\n    //    points or value is the empty string, then:\n    if (!HTTP_TOKEN_CODEPOINTS.test(value)) {\n      // 1. Precede each occurence of U+0022 (\") or\n      //    U+005C (\\) in value with U+005C (\\).\n      value = value.replace(/(\\\\|\")/g, '\\\\$1')\n\n      // 2. Prepend U+0022 (\") to value.\n      value = '\"' + value\n\n      // 3. Append U+0022 (\") to value.\n      value += '\"'\n    }\n\n    // 5. Append value to serialization.\n    serialization += value\n  }\n\n  // 3. Return serialization.\n  return serialization\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#http-whitespace\n * @param {string} char\n */\nfunction isHTTPWhiteSpace (char) {\n  return char === '\\r' || char === '\\n' || char === '\\t' || char === ' '\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#http-whitespace\n * @param {string} str\n */\nfunction removeHTTPWhitespace (str, leading = true, trailing = true) {\n  let lead = 0\n  let trail = str.length - 1\n\n  if (leading) {\n    for (; lead < str.length && isHTTPWhiteSpace(str[lead]); lead++);\n  }\n\n  if (trailing) {\n    for (; trail > 0 && isHTTPWhiteSpace(str[trail]); trail--);\n  }\n\n  return str.slice(lead, trail + 1)\n}\n\n/**\n * @see https://infra.spec.whatwg.org/#ascii-whitespace\n * @param {string} char\n */\nfunction isASCIIWhitespace (char) {\n  return char === '\\r' || char === '\\n' || char === '\\t' || char === '\\f' || char === ' '\n}\n\n/**\n * @see https://infra.spec.whatwg.org/#strip-leading-and-trailing-ascii-whitespace\n */\nfunction removeASCIIWhitespace (str, leading = true, trailing = true) {\n  let lead = 0\n  let trail = str.length - 1\n\n  if (leading) {\n    for (; lead < str.length && isASCIIWhitespace(str[lead]); lead++);\n  }\n\n  if (trailing) {\n    for (; trail > 0 && isASCIIWhitespace(str[trail]); trail--);\n  }\n\n  return str.slice(lead, trail + 1)\n}\n\nmodule.exports = {\n  dataURLProcessor,\n  URLSerializer,\n  collectASequenceOfCodePoints,\n  collectASequenceOfCodePointsFast,\n  stringPercentDecode,\n  parseMIMEType,\n  collectAnHTTPQuotedString,\n  serializeAMimeType\n}\n","'use strict'\n\nconst { Blob, File: NativeFile } = require('buffer')\nconst { types } = require('util')\nconst { kState } = require('./symbols')\nconst { isBlobLike } = require('./util')\nconst { webidl } = require('./webidl')\nconst { parseMIMEType, serializeAMimeType } = require('./dataURL')\nconst { kEnumerableProperty } = require('../core/util')\nconst encoder = new TextEncoder()\n\nclass File extends Blob {\n  constructor (fileBits, fileName, options = {}) {\n    // The File constructor is invoked with two or three parameters, depending\n    // on whether the optional dictionary parameter is used. When the File()\n    // constructor is invoked, user agents must run the following steps:\n    webidl.argumentLengthCheck(arguments, 2, { header: 'File constructor' })\n\n    fileBits = webidl.converters['sequence<BlobPart>'](fileBits)\n    fileName = webidl.converters.USVString(fileName)\n    options = webidl.converters.FilePropertyBag(options)\n\n    // 1. Let bytes be the result of processing blob parts given fileBits and\n    // options.\n    // Note: Blob handles this for us\n\n    // 2. Let n be the fileName argument to the constructor.\n    const n = fileName\n\n    // 3. Process FilePropertyBag dictionary argument by running the following\n    // substeps:\n\n    //    1. If the type member is provided and is not the empty string, let t\n    //    be set to the type dictionary member. If t contains any characters\n    //    outside the range U+0020 to U+007E, then set t to the empty string\n    //    and return from these substeps.\n    //    2. Convert every character in t to ASCII lowercase.\n    let t = options.type\n    let d\n\n    // eslint-disable-next-line no-labels\n    substep: {\n      if (t) {\n        t = parseMIMEType(t)\n\n        if (t === 'failure') {\n          t = ''\n          // eslint-disable-next-line no-labels\n          break substep\n        }\n\n        t = serializeAMimeType(t).toLowerCase()\n      }\n\n      //    3. If the lastModified member is provided, let d be set to the\n      //    lastModified dictionary member. If it is not provided, set d to the\n      //    current date and time represented as the number of milliseconds since\n      //    the Unix Epoch (which is the equivalent of Date.now() [ECMA-262]).\n      d = options.lastModified\n    }\n\n    // 4. Return a new File object F such that:\n    // F refers to the bytes byte sequence.\n    // F.size is set to the number of total bytes in bytes.\n    // F.name is set to n.\n    // F.type is set to t.\n    // F.lastModified is set to d.\n\n    super(processBlobParts(fileBits, options), { type: t })\n    this[kState] = {\n      name: n,\n      lastModified: d,\n      type: t\n    }\n  }\n\n  get name () {\n    webidl.brandCheck(this, File)\n\n    return this[kState].name\n  }\n\n  get lastModified () {\n    webidl.brandCheck(this, File)\n\n    return this[kState].lastModified\n  }\n\n  get type () {\n    webidl.brandCheck(this, File)\n\n    return this[kState].type\n  }\n}\n\nclass FileLike {\n  constructor (blobLike, fileName, options = {}) {\n    // TODO: argument idl type check\n\n    // The File constructor is invoked with two or three parameters, depending\n    // on whether the optional dictionary parameter is used. When the File()\n    // constructor is invoked, user agents must run the following steps:\n\n    // 1. Let bytes be the result of processing blob parts given fileBits and\n    // options.\n\n    // 2. Let n be the fileName argument to the constructor.\n    const n = fileName\n\n    // 3. Process FilePropertyBag dictionary argument by running the following\n    // substeps:\n\n    //    1. If the type member is provided and is not the empty string, let t\n    //    be set to the type dictionary member. If t contains any characters\n    //    outside the range U+0020 to U+007E, then set t to the empty string\n    //    and return from these substeps.\n    //    TODO\n    const t = options.type\n\n    //    2. Convert every character in t to ASCII lowercase.\n    //    TODO\n\n    //    3. If the lastModified member is provided, let d be set to the\n    //    lastModified dictionary member. If it is not provided, set d to the\n    //    current date and time represented as the number of milliseconds since\n    //    the Unix Epoch (which is the equivalent of Date.now() [ECMA-262]).\n    const d = options.lastModified ?? Date.now()\n\n    // 4. Return a new File object F such that:\n    // F refers to the bytes byte sequence.\n    // F.size is set to the number of total bytes in bytes.\n    // F.name is set to n.\n    // F.type is set to t.\n    // F.lastModified is set to d.\n\n    this[kState] = {\n      blobLike,\n      name: n,\n      type: t,\n      lastModified: d\n    }\n  }\n\n  stream (...args) {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.stream(...args)\n  }\n\n  arrayBuffer (...args) {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.arrayBuffer(...args)\n  }\n\n  slice (...args) {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.slice(...args)\n  }\n\n  text (...args) {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.text(...args)\n  }\n\n  get size () {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.size\n  }\n\n  get type () {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].blobLike.type\n  }\n\n  get name () {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].name\n  }\n\n  get lastModified () {\n    webidl.brandCheck(this, FileLike)\n\n    return this[kState].lastModified\n  }\n\n  get [Symbol.toStringTag] () {\n    return 'File'\n  }\n}\n\nObject.defineProperties(File.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'File',\n    configurable: true\n  },\n  name: kEnumerableProperty,\n  lastModified: kEnumerableProperty\n})\n\nwebidl.converters.Blob = webidl.interfaceConverter(Blob)\n\nwebidl.converters.BlobPart = function (V, opts) {\n  if (webidl.util.Type(V) === 'Object') {\n    if (isBlobLike(V)) {\n      return webidl.converters.Blob(V, { strict: false })\n    }\n\n    if (\n      ArrayBuffer.isView(V) ||\n      types.isAnyArrayBuffer(V)\n    ) {\n      return webidl.converters.BufferSource(V, opts)\n    }\n  }\n\n  return webidl.converters.USVString(V, opts)\n}\n\nwebidl.converters['sequence<BlobPart>'] = webidl.sequenceConverter(\n  webidl.converters.BlobPart\n)\n\n// https://www.w3.org/TR/FileAPI/#dfn-FilePropertyBag\nwebidl.converters.FilePropertyBag = webidl.dictionaryConverter([\n  {\n    key: 'lastModified',\n    converter: webidl.converters['long long'],\n    get defaultValue () {\n      return Date.now()\n    }\n  },\n  {\n    key: 'type',\n    converter: webidl.converters.DOMString,\n    defaultValue: ''\n  },\n  {\n    key: 'endings',\n    converter: (value) => {\n      value = webidl.converters.DOMString(value)\n      value = value.toLowerCase()\n\n      if (value !== 'native') {\n        value = 'transparent'\n      }\n\n      return value\n    },\n    defaultValue: 'transparent'\n  }\n])\n\n/**\n * @see https://www.w3.org/TR/FileAPI/#process-blob-parts\n * @param {(NodeJS.TypedArray|Blob|string)[]} parts\n * @param {{ type: string, endings: string }} options\n */\nfunction processBlobParts (parts, options) {\n  // 1. Let bytes be an empty sequence of bytes.\n  /** @type {NodeJS.TypedArray[]} */\n  const bytes = []\n\n  // 2. For each element in parts:\n  for (const element of parts) {\n    // 1. If element is a USVString, run the following substeps:\n    if (typeof element === 'string') {\n      // 1. Let s be element.\n      let s = element\n\n      // 2. If the endings member of options is \"native\", set s\n      //    to the result of converting line endings to native\n      //    of element.\n      if (options.endings === 'native') {\n        s = convertLineEndingsNative(s)\n      }\n\n      // 3. Append the result of UTF-8 encoding s to bytes.\n      bytes.push(encoder.encode(s))\n    } else if (\n      types.isAnyArrayBuffer(element) ||\n      types.isTypedArray(element)\n    ) {\n      // 2. If element is a BufferSource, get a copy of the\n      //    bytes held by the buffer source, and append those\n      //    bytes to bytes.\n      if (!element.buffer) { // ArrayBuffer\n        bytes.push(new Uint8Array(element))\n      } else {\n        bytes.push(\n          new Uint8Array(element.buffer, element.byteOffset, element.byteLength)\n        )\n      }\n    } else if (isBlobLike(element)) {\n      // 3. If element is a Blob, append the bytes it represents\n      //    to bytes.\n      bytes.push(element)\n    }\n  }\n\n  // 3. Return bytes.\n  return bytes\n}\n\n/**\n * @see https://www.w3.org/TR/FileAPI/#convert-line-endings-to-native\n * @param {string} s\n */\nfunction convertLineEndingsNative (s) {\n  // 1. Let native line ending be be the code point U+000A LF.\n  let nativeLineEnding = '\\n'\n\n  // 2. If the underlying platforms conventions are to\n  //    represent newlines as a carriage return and line feed\n  //    sequence, set native line ending to the code point\n  //    U+000D CR followed by the code point U+000A LF.\n  if (process.platform === 'win32') {\n    nativeLineEnding = '\\r\\n'\n  }\n\n  return s.replace(/\\r?\\n/g, nativeLineEnding)\n}\n\n// If this function is moved to ./util.js, some tools (such as\n// rollup) will warn about circular dependencies. See:\n// https://github.com/nodejs/undici/issues/1629\nfunction isFileLike (object) {\n  return (\n    (NativeFile && object instanceof NativeFile) ||\n    object instanceof File || (\n      object &&\n      (typeof object.stream === 'function' ||\n      typeof object.arrayBuffer === 'function') &&\n      object[Symbol.toStringTag] === 'File'\n    )\n  )\n}\n\nmodule.exports = { File, FileLike, isFileLike }\n","'use strict'\n\nconst { isBlobLike, toUSVString, makeIterator } = require('./util')\nconst { kState } = require('./symbols')\nconst { File: UndiciFile, FileLike, isFileLike } = require('./file')\nconst { webidl } = require('./webidl')\nconst { Blob, File: NativeFile } = require('buffer')\n\n/** @type {globalThis['File']} */\nconst File = NativeFile ?? UndiciFile\n\n// https://xhr.spec.whatwg.org/#formdata\nclass FormData {\n  constructor (form) {\n    if (form !== undefined) {\n      throw webidl.errors.conversionFailed({\n        prefix: 'FormData constructor',\n        argument: 'Argument 1',\n        types: ['undefined']\n      })\n    }\n\n    this[kState] = []\n  }\n\n  append (name, value, filename = undefined) {\n    webidl.brandCheck(this, FormData)\n\n    webidl.argumentLengthCheck(arguments, 2, { header: 'FormData.append' })\n\n    if (arguments.length === 3 && !isBlobLike(value)) {\n      throw new TypeError(\n        \"Failed to execute 'append' on 'FormData': parameter 2 is not of type 'Blob'\"\n      )\n    }\n\n    // 1. Let value be value if given; otherwise blobValue.\n\n    name = webidl.converters.USVString(name)\n    value = isBlobLike(value)\n      ? webidl.converters.Blob(value, { strict: false })\n      : webidl.converters.USVString(value)\n    filename = arguments.length === 3\n      ? webidl.converters.USVString(filename)\n      : undefined\n\n    // 2. Let entry be the result of creating an entry with\n    // name, value, and filename if given.\n    const entry = makeEntry(name, value, filename)\n\n    // 3. Append entry to thiss entry list.\n    this[kState].push(entry)\n  }\n\n  delete (name) {\n    webidl.brandCheck(this, FormData)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.delete' })\n\n    name = webidl.converters.USVString(name)\n\n    // The delete(name) method steps are to remove all entries whose name\n    // is name from thiss entry list.\n    this[kState] = this[kState].filter(entry => entry.name !== name)\n  }\n\n  get (name) {\n    webidl.brandCheck(this, FormData)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.get' })\n\n    name = webidl.converters.USVString(name)\n\n    // 1. If there is no entry whose name is name in thiss entry list,\n    // then return null.\n    const idx = this[kState].findIndex((entry) => entry.name === name)\n    if (idx === -1) {\n      return null\n    }\n\n    // 2. Return the value of the first entry whose name is name from\n    // thiss entry list.\n    return this[kState][idx].value\n  }\n\n  getAll (name) {\n    webidl.brandCheck(this, FormData)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.getAll' })\n\n    name = webidl.converters.USVString(name)\n\n    // 1. If there is no entry whose name is name in thiss entry list,\n    // then return the empty list.\n    // 2. Return the values of all entries whose name is name, in order,\n    // from thiss entry list.\n    return this[kState]\n      .filter((entry) => entry.name === name)\n      .map((entry) => entry.value)\n  }\n\n  has (name) {\n    webidl.brandCheck(this, FormData)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.has' })\n\n    name = webidl.converters.USVString(name)\n\n    // The has(name) method steps are to return true if there is an entry\n    // whose name is name in thiss entry list; otherwise false.\n    return this[kState].findIndex((entry) => entry.name === name) !== -1\n  }\n\n  set (name, value, filename = undefined) {\n    webidl.brandCheck(this, FormData)\n\n    webidl.argumentLengthCheck(arguments, 2, { header: 'FormData.set' })\n\n    if (arguments.length === 3 && !isBlobLike(value)) {\n      throw new TypeError(\n        \"Failed to execute 'set' on 'FormData': parameter 2 is not of type 'Blob'\"\n      )\n    }\n\n    // The set(name, value) and set(name, blobValue, filename) method steps\n    // are:\n\n    // 1. Let value be value if given; otherwise blobValue.\n\n    name = webidl.converters.USVString(name)\n    value = isBlobLike(value)\n      ? webidl.converters.Blob(value, { strict: false })\n      : webidl.converters.USVString(value)\n    filename = arguments.length === 3\n      ? toUSVString(filename)\n      : undefined\n\n    // 2. Let entry be the result of creating an entry with name, value, and\n    // filename if given.\n    const entry = makeEntry(name, value, filename)\n\n    // 3. If there are entries in thiss entry list whose name is name, then\n    // replace the first such entry with entry and remove the others.\n    const idx = this[kState].findIndex((entry) => entry.name === name)\n    if (idx !== -1) {\n      this[kState] = [\n        ...this[kState].slice(0, idx),\n        entry,\n        ...this[kState].slice(idx + 1).filter((entry) => entry.name !== name)\n      ]\n    } else {\n      // 4. Otherwise, append entry to thiss entry list.\n      this[kState].push(entry)\n    }\n  }\n\n  entries () {\n    webidl.brandCheck(this, FormData)\n\n    return makeIterator(\n      () => this[kState].map(pair => [pair.name, pair.value]),\n      'FormData',\n      'key+value'\n    )\n  }\n\n  keys () {\n    webidl.brandCheck(this, FormData)\n\n    return makeIterator(\n      () => this[kState].map(pair => [pair.name, pair.value]),\n      'FormData',\n      'key'\n    )\n  }\n\n  values () {\n    webidl.brandCheck(this, FormData)\n\n    return makeIterator(\n      () => this[kState].map(pair => [pair.name, pair.value]),\n      'FormData',\n      'value'\n    )\n  }\n\n  /**\n   * @param {(value: string, key: string, self: FormData) => void} callbackFn\n   * @param {unknown} thisArg\n   */\n  forEach (callbackFn, thisArg = globalThis) {\n    webidl.brandCheck(this, FormData)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FormData.forEach' })\n\n    if (typeof callbackFn !== 'function') {\n      throw new TypeError(\n        \"Failed to execute 'forEach' on 'FormData': parameter 1 is not of type 'Function'.\"\n      )\n    }\n\n    for (const [key, value] of this) {\n      callbackFn.apply(thisArg, [value, key, this])\n    }\n  }\n}\n\nFormData.prototype[Symbol.iterator] = FormData.prototype.entries\n\nObject.defineProperties(FormData.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'FormData',\n    configurable: true\n  }\n})\n\n/**\n * @see https://html.spec.whatwg.org/multipage/form-control-infrastructure.html#create-an-entry\n * @param {string} name\n * @param {string|Blob} value\n * @param {?string} filename\n * @returns\n */\nfunction makeEntry (name, value, filename) {\n  // 1. Set name to the result of converting name into a scalar value string.\n  // \"To convert a string into a scalar value string, replace any surrogates\n  //  with U+FFFD.\"\n  // see: https://nodejs.org/dist/latest-v18.x/docs/api/buffer.html#buftostringencoding-start-end\n  name = Buffer.from(name).toString('utf8')\n\n  // 2. If value is a string, then set value to the result of converting\n  //    value into a scalar value string.\n  if (typeof value === 'string') {\n    value = Buffer.from(value).toString('utf8')\n  } else {\n    // 3. Otherwise:\n\n    // 1. If value is not a File object, then set value to a new File object,\n    //    representing the same bytes, whose name attribute value is \"blob\"\n    if (!isFileLike(value)) {\n      value = value instanceof Blob\n        ? new File([value], 'blob', { type: value.type })\n        : new FileLike(value, 'blob', { type: value.type })\n    }\n\n    // 2. If filename is given, then set value to a new File object,\n    //    representing the same bytes, whose name attribute is filename.\n    if (filename !== undefined) {\n      /** @type {FilePropertyBag} */\n      const options = {\n        type: value.type,\n        lastModified: value.lastModified\n      }\n\n      value = (NativeFile && value instanceof NativeFile) || value instanceof UndiciFile\n        ? new File([value], filename, options)\n        : new FileLike(value, filename, options)\n    }\n  }\n\n  // 4. Return an entry whose name is name and whose value is value.\n  return { name, value }\n}\n\nmodule.exports = { FormData }\n","'use strict'\n\n// In case of breaking changes, increase the version\n// number to avoid conflicts.\nconst globalOrigin = Symbol.for('undici.globalOrigin.1')\n\nfunction getGlobalOrigin () {\n  return globalThis[globalOrigin]\n}\n\nfunction setGlobalOrigin (newOrigin) {\n  if (newOrigin === undefined) {\n    Object.defineProperty(globalThis, globalOrigin, {\n      value: undefined,\n      writable: true,\n      enumerable: false,\n      configurable: false\n    })\n\n    return\n  }\n\n  const parsedURL = new URL(newOrigin)\n\n  if (parsedURL.protocol !== 'http:' && parsedURL.protocol !== 'https:') {\n    throw new TypeError(`Only http & https urls are allowed, received ${parsedURL.protocol}`)\n  }\n\n  Object.defineProperty(globalThis, globalOrigin, {\n    value: parsedURL,\n    writable: true,\n    enumerable: false,\n    configurable: false\n  })\n}\n\nmodule.exports = {\n  getGlobalOrigin,\n  setGlobalOrigin\n}\n","// https://github.com/Ethan-Arrowood/undici-fetch\n\n'use strict'\n\nconst { kHeadersList, kConstruct } = require('../core/symbols')\nconst { kGuard } = require('./symbols')\nconst { kEnumerableProperty } = require('../core/util')\nconst {\n  makeIterator,\n  isValidHeaderName,\n  isValidHeaderValue\n} = require('./util')\nconst { webidl } = require('./webidl')\nconst assert = require('assert')\n\nconst kHeadersMap = Symbol('headers map')\nconst kHeadersSortedMap = Symbol('headers map sorted')\n\n/**\n * @param {number} code\n */\nfunction isHTTPWhiteSpaceCharCode (code) {\n  return code === 0x00a || code === 0x00d || code === 0x009 || code === 0x020\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-header-value-normalize\n * @param {string} potentialValue\n */\nfunction headerValueNormalize (potentialValue) {\n  //  To normalize a byte sequence potentialValue, remove\n  //  any leading and trailing HTTP whitespace bytes from\n  //  potentialValue.\n  let i = 0; let j = potentialValue.length\n\n  while (j > i && isHTTPWhiteSpaceCharCode(potentialValue.charCodeAt(j - 1))) --j\n  while (j > i && isHTTPWhiteSpaceCharCode(potentialValue.charCodeAt(i))) ++i\n\n  return i === 0 && j === potentialValue.length ? potentialValue : potentialValue.substring(i, j)\n}\n\nfunction fill (headers, object) {\n  // To fill a Headers object headers with a given object object, run these steps:\n\n  // 1. If object is a sequence, then for each header in object:\n  // Note: webidl conversion to array has already been done.\n  if (Array.isArray(object)) {\n    for (let i = 0; i < object.length; ++i) {\n      const header = object[i]\n      // 1. If header does not contain exactly two items, then throw a TypeError.\n      if (header.length !== 2) {\n        throw webidl.errors.exception({\n          header: 'Headers constructor',\n          message: `expected name/value pair to be length 2, found ${header.length}.`\n        })\n      }\n\n      // 2. Append (headers first item, headers second item) to headers.\n      appendHeader(headers, header[0], header[1])\n    }\n  } else if (typeof object === 'object' && object !== null) {\n    // Note: null should throw\n\n    // 2. Otherwise, object is a record, then for each key  value in object,\n    //    append (key, value) to headers\n    const keys = Object.keys(object)\n    for (let i = 0; i < keys.length; ++i) {\n      appendHeader(headers, keys[i], object[keys[i]])\n    }\n  } else {\n    throw webidl.errors.conversionFailed({\n      prefix: 'Headers constructor',\n      argument: 'Argument 1',\n      types: ['sequence<sequence<ByteString>>', 'record<ByteString, ByteString>']\n    })\n  }\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-headers-append\n */\nfunction appendHeader (headers, name, value) {\n  // 1. Normalize value.\n  value = headerValueNormalize(value)\n\n  // 2. If name is not a header name or value is not a\n  //    header value, then throw a TypeError.\n  if (!isValidHeaderName(name)) {\n    throw webidl.errors.invalidArgument({\n      prefix: 'Headers.append',\n      value: name,\n      type: 'header name'\n    })\n  } else if (!isValidHeaderValue(value)) {\n    throw webidl.errors.invalidArgument({\n      prefix: 'Headers.append',\n      value,\n      type: 'header value'\n    })\n  }\n\n  // 3. If headerss guard is \"immutable\", then throw a TypeError.\n  // 4. Otherwise, if headerss guard is \"request\" and name is a\n  //    forbidden header name, return.\n  // Note: undici does not implement forbidden header names\n  if (headers[kGuard] === 'immutable') {\n    throw new TypeError('immutable')\n  } else if (headers[kGuard] === 'request-no-cors') {\n    // 5. Otherwise, if headerss guard is \"request-no-cors\":\n    // TODO\n  }\n\n  // 6. Otherwise, if headerss guard is \"response\" and name is a\n  //    forbidden response-header name, return.\n\n  // 7. Append (name, value) to headerss header list.\n  return headers[kHeadersList].append(name, value)\n\n  // 8. If headerss guard is \"request-no-cors\", then remove\n  //    privileged no-CORS request headers from headers\n}\n\nclass HeadersList {\n  /** @type {[string, string][]|null} */\n  cookies = null\n\n  constructor (init) {\n    if (init instanceof HeadersList) {\n      this[kHeadersMap] = new Map(init[kHeadersMap])\n      this[kHeadersSortedMap] = init[kHeadersSortedMap]\n      this.cookies = init.cookies === null ? null : [...init.cookies]\n    } else {\n      this[kHeadersMap] = new Map(init)\n      this[kHeadersSortedMap] = null\n    }\n  }\n\n  // https://fetch.spec.whatwg.org/#header-list-contains\n  contains (name) {\n    // A header list list contains a header name name if list\n    // contains a header whose name is a byte-case-insensitive\n    // match for name.\n    name = name.toLowerCase()\n\n    return this[kHeadersMap].has(name)\n  }\n\n  clear () {\n    this[kHeadersMap].clear()\n    this[kHeadersSortedMap] = null\n    this.cookies = null\n  }\n\n  // https://fetch.spec.whatwg.org/#concept-header-list-append\n  append (name, value) {\n    this[kHeadersSortedMap] = null\n\n    // 1. If list contains name, then set name to the first such\n    //    headers name.\n    const lowercaseName = name.toLowerCase()\n    const exists = this[kHeadersMap].get(lowercaseName)\n\n    // 2. Append (name, value) to list.\n    if (exists) {\n      const delimiter = lowercaseName === 'cookie' ? '; ' : ', '\n      this[kHeadersMap].set(lowercaseName, {\n        name: exists.name,\n        value: `${exists.value}${delimiter}${value}`\n      })\n    } else {\n      this[kHeadersMap].set(lowercaseName, { name, value })\n    }\n\n    if (lowercaseName === 'set-cookie') {\n      this.cookies ??= []\n      this.cookies.push(value)\n    }\n  }\n\n  // https://fetch.spec.whatwg.org/#concept-header-list-set\n  set (name, value) {\n    this[kHeadersSortedMap] = null\n    const lowercaseName = name.toLowerCase()\n\n    if (lowercaseName === 'set-cookie') {\n      this.cookies = [value]\n    }\n\n    // 1. If list contains name, then set the value of\n    //    the first such header to value and remove the\n    //    others.\n    // 2. Otherwise, append header (name, value) to list.\n    this[kHeadersMap].set(lowercaseName, { name, value })\n  }\n\n  // https://fetch.spec.whatwg.org/#concept-header-list-delete\n  delete (name) {\n    this[kHeadersSortedMap] = null\n\n    name = name.toLowerCase()\n\n    if (name === 'set-cookie') {\n      this.cookies = null\n    }\n\n    this[kHeadersMap].delete(name)\n  }\n\n  // https://fetch.spec.whatwg.org/#concept-header-list-get\n  get (name) {\n    const value = this[kHeadersMap].get(name.toLowerCase())\n\n    // 1. If list does not contain name, then return null.\n    // 2. Return the values of all headers in list whose name\n    //    is a byte-case-insensitive match for name,\n    //    separated from each other by 0x2C 0x20, in order.\n    return value === undefined ? null : value.value\n  }\n\n  * [Symbol.iterator] () {\n    // use the lowercased name\n    for (const [name, { value }] of this[kHeadersMap]) {\n      yield [name, value]\n    }\n  }\n\n  get entries () {\n    const headers = {}\n\n    if (this[kHeadersMap].size) {\n      for (const { name, value } of this[kHeadersMap].values()) {\n        headers[name] = value\n      }\n    }\n\n    return headers\n  }\n}\n\n// https://fetch.spec.whatwg.org/#headers-class\nclass Headers {\n  constructor (init = undefined) {\n    if (init === kConstruct) {\n      return\n    }\n    this[kHeadersList] = new HeadersList()\n\n    // The new Headers(init) constructor steps are:\n\n    // 1. Set thiss guard to \"none\".\n    this[kGuard] = 'none'\n\n    // 2. If init is given, then fill this with init.\n    if (init !== undefined) {\n      init = webidl.converters.HeadersInit(init)\n      fill(this, init)\n    }\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-append\n  append (name, value) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 2, { header: 'Headers.append' })\n\n    name = webidl.converters.ByteString(name)\n    value = webidl.converters.ByteString(value)\n\n    return appendHeader(this, name, value)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-delete\n  delete (name) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Headers.delete' })\n\n    name = webidl.converters.ByteString(name)\n\n    // 1. If name is not a header name, then throw a TypeError.\n    if (!isValidHeaderName(name)) {\n      throw webidl.errors.invalidArgument({\n        prefix: 'Headers.delete',\n        value: name,\n        type: 'header name'\n      })\n    }\n\n    // 2. If thiss guard is \"immutable\", then throw a TypeError.\n    // 3. Otherwise, if thiss guard is \"request\" and name is a\n    //    forbidden header name, return.\n    // 4. Otherwise, if thiss guard is \"request-no-cors\", name\n    //    is not a no-CORS-safelisted request-header name, and\n    //    name is not a privileged no-CORS request-header name,\n    //    return.\n    // 5. Otherwise, if thiss guard is \"response\" and name is\n    //    a forbidden response-header name, return.\n    // Note: undici does not implement forbidden header names\n    if (this[kGuard] === 'immutable') {\n      throw new TypeError('immutable')\n    } else if (this[kGuard] === 'request-no-cors') {\n      // TODO\n    }\n\n    // 6. If thiss header list does not contain name, then\n    //    return.\n    if (!this[kHeadersList].contains(name)) {\n      return\n    }\n\n    // 7. Delete name from thiss header list.\n    // 8. If thiss guard is \"request-no-cors\", then remove\n    //    privileged no-CORS request headers from this.\n    this[kHeadersList].delete(name)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-get\n  get (name) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Headers.get' })\n\n    name = webidl.converters.ByteString(name)\n\n    // 1. If name is not a header name, then throw a TypeError.\n    if (!isValidHeaderName(name)) {\n      throw webidl.errors.invalidArgument({\n        prefix: 'Headers.get',\n        value: name,\n        type: 'header name'\n      })\n    }\n\n    // 2. Return the result of getting name from thiss header\n    //    list.\n    return this[kHeadersList].get(name)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-has\n  has (name) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Headers.has' })\n\n    name = webidl.converters.ByteString(name)\n\n    // 1. If name is not a header name, then throw a TypeError.\n    if (!isValidHeaderName(name)) {\n      throw webidl.errors.invalidArgument({\n        prefix: 'Headers.has',\n        value: name,\n        type: 'header name'\n      })\n    }\n\n    // 2. Return true if thiss header list contains name;\n    //    otherwise false.\n    return this[kHeadersList].contains(name)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-set\n  set (name, value) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 2, { header: 'Headers.set' })\n\n    name = webidl.converters.ByteString(name)\n    value = webidl.converters.ByteString(value)\n\n    // 1. Normalize value.\n    value = headerValueNormalize(value)\n\n    // 2. If name is not a header name or value is not a\n    //    header value, then throw a TypeError.\n    if (!isValidHeaderName(name)) {\n      throw webidl.errors.invalidArgument({\n        prefix: 'Headers.set',\n        value: name,\n        type: 'header name'\n      })\n    } else if (!isValidHeaderValue(value)) {\n      throw webidl.errors.invalidArgument({\n        prefix: 'Headers.set',\n        value,\n        type: 'header value'\n      })\n    }\n\n    // 3. If thiss guard is \"immutable\", then throw a TypeError.\n    // 4. Otherwise, if thiss guard is \"request\" and name is a\n    //    forbidden header name, return.\n    // 5. Otherwise, if thiss guard is \"request-no-cors\" and\n    //    name/value is not a no-CORS-safelisted request-header,\n    //    return.\n    // 6. Otherwise, if thiss guard is \"response\" and name is a\n    //    forbidden response-header name, return.\n    // Note: undici does not implement forbidden header names\n    if (this[kGuard] === 'immutable') {\n      throw new TypeError('immutable')\n    } else if (this[kGuard] === 'request-no-cors') {\n      // TODO\n    }\n\n    // 7. Set (name, value) in thiss header list.\n    // 8. If thiss guard is \"request-no-cors\", then remove\n    //    privileged no-CORS request headers from this\n    this[kHeadersList].set(name, value)\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-headers-getsetcookie\n  getSetCookie () {\n    webidl.brandCheck(this, Headers)\n\n    // 1. If thiss header list does not contain `Set-Cookie`, then return  .\n    // 2. Return the values of all headers in thiss header list whose name is\n    //    a byte-case-insensitive match for `Set-Cookie`, in order.\n\n    const list = this[kHeadersList].cookies\n\n    if (list) {\n      return [...list]\n    }\n\n    return []\n  }\n\n  // https://fetch.spec.whatwg.org/#concept-header-list-sort-and-combine\n  get [kHeadersSortedMap] () {\n    if (this[kHeadersList][kHeadersSortedMap]) {\n      return this[kHeadersList][kHeadersSortedMap]\n    }\n\n    // 1. Let headers be an empty list of headers with the key being the name\n    //    and value the value.\n    const headers = []\n\n    // 2. Let names be the result of convert header names to a sorted-lowercase\n    //    set with all the names of the headers in list.\n    const names = [...this[kHeadersList]].sort((a, b) => a[0] < b[0] ? -1 : 1)\n    const cookies = this[kHeadersList].cookies\n\n    // 3. For each name of names:\n    for (let i = 0; i < names.length; ++i) {\n      const [name, value] = names[i]\n      // 1. If name is `set-cookie`, then:\n      if (name === 'set-cookie') {\n        // 1. Let values be a list of all values of headers in list whose name\n        //    is a byte-case-insensitive match for name, in order.\n\n        // 2. For each value of values:\n        // 1. Append (name, value) to headers.\n        for (let j = 0; j < cookies.length; ++j) {\n          headers.push([name, cookies[j]])\n        }\n      } else {\n        // 2. Otherwise:\n\n        // 1. Let value be the result of getting name from list.\n\n        // 2. Assert: value is non-null.\n        assert(value !== null)\n\n        // 3. Append (name, value) to headers.\n        headers.push([name, value])\n      }\n    }\n\n    this[kHeadersList][kHeadersSortedMap] = headers\n\n    // 4. Return headers.\n    return headers\n  }\n\n  keys () {\n    webidl.brandCheck(this, Headers)\n\n    if (this[kGuard] === 'immutable') {\n      const value = this[kHeadersSortedMap]\n      return makeIterator(() => value, 'Headers',\n        'key')\n    }\n\n    return makeIterator(\n      () => [...this[kHeadersSortedMap].values()],\n      'Headers',\n      'key'\n    )\n  }\n\n  values () {\n    webidl.brandCheck(this, Headers)\n\n    if (this[kGuard] === 'immutable') {\n      const value = this[kHeadersSortedMap]\n      return makeIterator(() => value, 'Headers',\n        'value')\n    }\n\n    return makeIterator(\n      () => [...this[kHeadersSortedMap].values()],\n      'Headers',\n      'value'\n    )\n  }\n\n  entries () {\n    webidl.brandCheck(this, Headers)\n\n    if (this[kGuard] === 'immutable') {\n      const value = this[kHeadersSortedMap]\n      return makeIterator(() => value, 'Headers',\n        'key+value')\n    }\n\n    return makeIterator(\n      () => [...this[kHeadersSortedMap].values()],\n      'Headers',\n      'key+value'\n    )\n  }\n\n  /**\n   * @param {(value: string, key: string, self: Headers) => void} callbackFn\n   * @param {unknown} thisArg\n   */\n  forEach (callbackFn, thisArg = globalThis) {\n    webidl.brandCheck(this, Headers)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Headers.forEach' })\n\n    if (typeof callbackFn !== 'function') {\n      throw new TypeError(\n        \"Failed to execute 'forEach' on 'Headers': parameter 1 is not of type 'Function'.\"\n      )\n    }\n\n    for (const [key, value] of this) {\n      callbackFn.apply(thisArg, [value, key, this])\n    }\n  }\n\n  [Symbol.for('nodejs.util.inspect.custom')] () {\n    webidl.brandCheck(this, Headers)\n\n    return this[kHeadersList]\n  }\n}\n\nHeaders.prototype[Symbol.iterator] = Headers.prototype.entries\n\nObject.defineProperties(Headers.prototype, {\n  append: kEnumerableProperty,\n  delete: kEnumerableProperty,\n  get: kEnumerableProperty,\n  has: kEnumerableProperty,\n  set: kEnumerableProperty,\n  getSetCookie: kEnumerableProperty,\n  keys: kEnumerableProperty,\n  values: kEnumerableProperty,\n  entries: kEnumerableProperty,\n  forEach: kEnumerableProperty,\n  [Symbol.iterator]: { enumerable: false },\n  [Symbol.toStringTag]: {\n    value: 'Headers',\n    configurable: true\n  }\n})\n\nwebidl.converters.HeadersInit = function (V) {\n  if (webidl.util.Type(V) === 'Object') {\n    if (V[Symbol.iterator]) {\n      return webidl.converters['sequence<sequence<ByteString>>'](V)\n    }\n\n    return webidl.converters['record<ByteString, ByteString>'](V)\n  }\n\n  throw webidl.errors.conversionFailed({\n    prefix: 'Headers constructor',\n    argument: 'Argument 1',\n    types: ['sequence<sequence<ByteString>>', 'record<ByteString, ByteString>']\n  })\n}\n\nmodule.exports = {\n  fill,\n  Headers,\n  HeadersList\n}\n","// https://github.com/Ethan-Arrowood/undici-fetch\n\n'use strict'\n\nconst {\n  Response,\n  makeNetworkError,\n  makeAppropriateNetworkError,\n  filterResponse,\n  makeResponse\n} = require('./response')\nconst { Headers } = require('./headers')\nconst { Request, makeRequest } = require('./request')\nconst zlib = require('zlib')\nconst {\n  bytesMatch,\n  makePolicyContainer,\n  clonePolicyContainer,\n  requestBadPort,\n  TAOCheck,\n  appendRequestOriginHeader,\n  responseLocationURL,\n  requestCurrentURL,\n  setRequestReferrerPolicyOnRedirect,\n  tryUpgradeRequestToAPotentiallyTrustworthyURL,\n  createOpaqueTimingInfo,\n  appendFetchMetadata,\n  corsCheck,\n  crossOriginResourcePolicyCheck,\n  determineRequestsReferrer,\n  coarsenedSharedCurrentTime,\n  createDeferredPromise,\n  isBlobLike,\n  sameOrigin,\n  isCancelled,\n  isAborted,\n  isErrorLike,\n  fullyReadBody,\n  readableStreamClose,\n  isomorphicEncode,\n  urlIsLocal,\n  urlIsHttpHttpsScheme,\n  urlHasHttpsScheme\n} = require('./util')\nconst { kState, kHeaders, kGuard, kRealm } = require('./symbols')\nconst assert = require('assert')\nconst { safelyExtractBody } = require('./body')\nconst {\n  redirectStatusSet,\n  nullBodyStatus,\n  safeMethodsSet,\n  requestBodyHeader,\n  subresourceSet,\n  DOMException\n} = require('./constants')\nconst { kHeadersList } = require('../core/symbols')\nconst EE = require('events')\nconst { Readable, pipeline } = require('stream')\nconst { addAbortListener, isErrored, isReadable, nodeMajor, nodeMinor } = require('../core/util')\nconst { dataURLProcessor, serializeAMimeType } = require('./dataURL')\nconst { TransformStream } = require('stream/web')\nconst { getGlobalDispatcher } = require('../global')\nconst { webidl } = require('./webidl')\nconst { STATUS_CODES } = require('http')\nconst GET_OR_HEAD = ['GET', 'HEAD']\n\n/** @type {import('buffer').resolveObjectURL} */\nlet resolveObjectURL\nlet ReadableStream = globalThis.ReadableStream\n\nclass Fetch extends EE {\n  constructor (dispatcher) {\n    super()\n\n    this.dispatcher = dispatcher\n    this.connection = null\n    this.dump = false\n    this.state = 'ongoing'\n    // 2 terminated listeners get added per request,\n    // but only 1 gets removed. If there are 20 redirects,\n    // 21 listeners will be added.\n    // See https://github.com/nodejs/undici/issues/1711\n    // TODO (fix): Find and fix root cause for leaked listener.\n    this.setMaxListeners(21)\n  }\n\n  terminate (reason) {\n    if (this.state !== 'ongoing') {\n      return\n    }\n\n    this.state = 'terminated'\n    this.connection?.destroy(reason)\n    this.emit('terminated', reason)\n  }\n\n  // https://fetch.spec.whatwg.org/#fetch-controller-abort\n  abort (error) {\n    if (this.state !== 'ongoing') {\n      return\n    }\n\n    // 1. Set controllers state to \"aborted\".\n    this.state = 'aborted'\n\n    // 2. Let fallbackError be an \"AbortError\" DOMException.\n    // 3. Set error to fallbackError if it is not given.\n    if (!error) {\n      error = new DOMException('The operation was aborted.', 'AbortError')\n    }\n\n    // 4. Let serializedError be StructuredSerialize(error).\n    //    If that threw an exception, catch it, and let\n    //    serializedError be StructuredSerialize(fallbackError).\n\n    // 5. Set controllers serialized abort reason to serializedError.\n    this.serializedAbortReason = error\n\n    this.connection?.destroy(error)\n    this.emit('terminated', error)\n  }\n}\n\n// https://fetch.spec.whatwg.org/#fetch-method\nfunction fetch (input, init = {}) {\n  webidl.argumentLengthCheck(arguments, 1, { header: 'globalThis.fetch' })\n\n  // 1. Let p be a new promise.\n  const p = createDeferredPromise()\n\n  // 2. Let requestObject be the result of invoking the initial value of\n  // Request as constructor with input and init as arguments. If this throws\n  // an exception, reject p with it and return p.\n  let requestObject\n\n  try {\n    requestObject = new Request(input, init)\n  } catch (e) {\n    p.reject(e)\n    return p.promise\n  }\n\n  // 3. Let request be requestObjects request.\n  const request = requestObject[kState]\n\n  // 4. If requestObjects signals aborted flag is set, then:\n  if (requestObject.signal.aborted) {\n    // 1. Abort the fetch() call with p, request, null, and\n    //    requestObjects signals abort reason.\n    abortFetch(p, request, null, requestObject.signal.reason)\n\n    // 2. Return p.\n    return p.promise\n  }\n\n  // 5. Let globalObject be requests clients global object.\n  const globalObject = request.client.globalObject\n\n  // 6. If globalObject is a ServiceWorkerGlobalScope object, then set\n  // requests service-workers mode to \"none\".\n  if (globalObject?.constructor?.name === 'ServiceWorkerGlobalScope') {\n    request.serviceWorkers = 'none'\n  }\n\n  // 7. Let responseObject be null.\n  let responseObject = null\n\n  // 8. Let relevantRealm be thiss relevant Realm.\n  const relevantRealm = null\n\n  // 9. Let locallyAborted be false.\n  let locallyAborted = false\n\n  // 10. Let controller be null.\n  let controller = null\n\n  // 11. Add the following abort steps to requestObjects signal:\n  addAbortListener(\n    requestObject.signal,\n    () => {\n      // 1. Set locallyAborted to true.\n      locallyAborted = true\n\n      // 2. Assert: controller is non-null.\n      assert(controller != null)\n\n      // 3. Abort controller with requestObjects signals abort reason.\n      controller.abort(requestObject.signal.reason)\n\n      // 4. Abort the fetch() call with p, request, responseObject,\n      //    and requestObjects signals abort reason.\n      abortFetch(p, request, responseObject, requestObject.signal.reason)\n    }\n  )\n\n  // 12. Let handleFetchDone given response response be to finalize and\n  // report timing with response, globalObject, and \"fetch\".\n  const handleFetchDone = (response) =>\n    finalizeAndReportTiming(response, 'fetch')\n\n  // 13. Set controller to the result of calling fetch given request,\n  // with processResponseEndOfBody set to handleFetchDone, and processResponse\n  // given response being these substeps:\n\n  const processResponse = (response) => {\n    // 1. If locallyAborted is true, terminate these substeps.\n    if (locallyAborted) {\n      return Promise.resolve()\n    }\n\n    // 2. If responses aborted flag is set, then:\n    if (response.aborted) {\n      // 1. Let deserializedError be the result of deserialize a serialized\n      //    abort reason given controllers serialized abort reason and\n      //    relevantRealm.\n\n      // 2. Abort the fetch() call with p, request, responseObject, and\n      //    deserializedError.\n\n      abortFetch(p, request, responseObject, controller.serializedAbortReason)\n      return Promise.resolve()\n    }\n\n    // 3. If response is a network error, then reject p with a TypeError\n    // and terminate these substeps.\n    if (response.type === 'error') {\n      p.reject(\n        Object.assign(new TypeError('fetch failed'), { cause: response.error })\n      )\n      return Promise.resolve()\n    }\n\n    // 4. Set responseObject to the result of creating a Response object,\n    // given response, \"immutable\", and relevantRealm.\n    responseObject = new Response()\n    responseObject[kState] = response\n    responseObject[kRealm] = relevantRealm\n    responseObject[kHeaders][kHeadersList] = response.headersList\n    responseObject[kHeaders][kGuard] = 'immutable'\n    responseObject[kHeaders][kRealm] = relevantRealm\n\n    // 5. Resolve p with responseObject.\n    p.resolve(responseObject)\n  }\n\n  controller = fetching({\n    request,\n    processResponseEndOfBody: handleFetchDone,\n    processResponse,\n    dispatcher: init.dispatcher ?? getGlobalDispatcher() // undici\n  })\n\n  // 14. Return p.\n  return p.promise\n}\n\n// https://fetch.spec.whatwg.org/#finalize-and-report-timing\nfunction finalizeAndReportTiming (response, initiatorType = 'other') {\n  // 1. If response is an aborted network error, then return.\n  if (response.type === 'error' && response.aborted) {\n    return\n  }\n\n  // 2. If responses URL list is null or empty, then return.\n  if (!response.urlList?.length) {\n    return\n  }\n\n  // 3. Let originalURL be responses URL list[0].\n  const originalURL = response.urlList[0]\n\n  // 4. Let timingInfo be responses timing info.\n  let timingInfo = response.timingInfo\n\n  // 5. Let cacheState be responses cache state.\n  let cacheState = response.cacheState\n\n  // 6. If originalURLs scheme is not an HTTP(S) scheme, then return.\n  if (!urlIsHttpHttpsScheme(originalURL)) {\n    return\n  }\n\n  // 7. If timingInfo is null, then return.\n  if (timingInfo === null) {\n    return\n  }\n\n  // 8. If responses timing allow passed flag is not set, then:\n  if (!response.timingAllowPassed) {\n    //  1. Set timingInfo to a the result of creating an opaque timing info for timingInfo.\n    timingInfo = createOpaqueTimingInfo({\n      startTime: timingInfo.startTime\n    })\n\n    //  2. Set cacheState to the empty string.\n    cacheState = ''\n  }\n\n  // 9. Set timingInfos end time to the coarsened shared current time\n  // given globals relevant settings objects cross-origin isolated\n  // capability.\n  // TODO: given globals relevant settings objects cross-origin isolated\n  // capability?\n  timingInfo.endTime = coarsenedSharedCurrentTime()\n\n  // 10. Set responses timing info to timingInfo.\n  response.timingInfo = timingInfo\n\n  // 11. Mark resource timing for timingInfo, originalURL, initiatorType,\n  // global, and cacheState.\n  markResourceTiming(\n    timingInfo,\n    originalURL,\n    initiatorType,\n    globalThis,\n    cacheState\n  )\n}\n\n// https://w3c.github.io/resource-timing/#dfn-mark-resource-timing\nfunction markResourceTiming (timingInfo, originalURL, initiatorType, globalThis, cacheState) {\n  if (nodeMajor > 18 || (nodeMajor === 18 && nodeMinor >= 2)) {\n    performance.markResourceTiming(timingInfo, originalURL.href, initiatorType, globalThis, cacheState)\n  }\n}\n\n// https://fetch.spec.whatwg.org/#abort-fetch\nfunction abortFetch (p, request, responseObject, error) {\n  // Note: AbortSignal.reason was added in node v17.2.0\n  // which would give us an undefined error to reject with.\n  // Remove this once node v16 is no longer supported.\n  if (!error) {\n    error = new DOMException('The operation was aborted.', 'AbortError')\n  }\n\n  // 1. Reject promise with error.\n  p.reject(error)\n\n  // 2. If requests body is not null and is readable, then cancel requests\n  // body with error.\n  if (request.body != null && isReadable(request.body?.stream)) {\n    request.body.stream.cancel(error).catch((err) => {\n      if (err.code === 'ERR_INVALID_STATE') {\n        // Node bug?\n        return\n      }\n      throw err\n    })\n  }\n\n  // 3. If responseObject is null, then return.\n  if (responseObject == null) {\n    return\n  }\n\n  // 4. Let response be responseObjects response.\n  const response = responseObject[kState]\n\n  // 5. If responses body is not null and is readable, then error responses\n  // body with error.\n  if (response.body != null && isReadable(response.body?.stream)) {\n    response.body.stream.cancel(error).catch((err) => {\n      if (err.code === 'ERR_INVALID_STATE') {\n        // Node bug?\n        return\n      }\n      throw err\n    })\n  }\n}\n\n// https://fetch.spec.whatwg.org/#fetching\nfunction fetching ({\n  request,\n  processRequestBodyChunkLength,\n  processRequestEndOfBody,\n  processResponse,\n  processResponseEndOfBody,\n  processResponseConsumeBody,\n  useParallelQueue = false,\n  dispatcher // undici\n}) {\n  // 1. Let taskDestination be null.\n  let taskDestination = null\n\n  // 2. Let crossOriginIsolatedCapability be false.\n  let crossOriginIsolatedCapability = false\n\n  // 3. If requests client is non-null, then:\n  if (request.client != null) {\n    // 1. Set taskDestination to requests clients global object.\n    taskDestination = request.client.globalObject\n\n    // 2. Set crossOriginIsolatedCapability to requests clients cross-origin\n    // isolated capability.\n    crossOriginIsolatedCapability =\n      request.client.crossOriginIsolatedCapability\n  }\n\n  // 4. If useParallelQueue is true, then set taskDestination to the result of\n  // starting a new parallel queue.\n  // TODO\n\n  // 5. Let timingInfo be a new fetch timing info whose start time and\n  // post-redirect start time are the coarsened shared current time given\n  // crossOriginIsolatedCapability.\n  const currenTime = coarsenedSharedCurrentTime(crossOriginIsolatedCapability)\n  const timingInfo = createOpaqueTimingInfo({\n    startTime: currenTime\n  })\n\n  // 6. Let fetchParams be a new fetch params whose\n  // request is request,\n  // timing info is timingInfo,\n  // process request body chunk length is processRequestBodyChunkLength,\n  // process request end-of-body is processRequestEndOfBody,\n  // process response is processResponse,\n  // process response consume body is processResponseConsumeBody,\n  // process response end-of-body is processResponseEndOfBody,\n  // task destination is taskDestination,\n  // and cross-origin isolated capability is crossOriginIsolatedCapability.\n  const fetchParams = {\n    controller: new Fetch(dispatcher),\n    request,\n    timingInfo,\n    processRequestBodyChunkLength,\n    processRequestEndOfBody,\n    processResponse,\n    processResponseConsumeBody,\n    processResponseEndOfBody,\n    taskDestination,\n    crossOriginIsolatedCapability\n  }\n\n  // 7. If requests body is a byte sequence, then set requests body to\n  //    requests body as a body.\n  // NOTE: Since fetching is only called from fetch, body should already be\n  // extracted.\n  assert(!request.body || request.body.stream)\n\n  // 8. If requests window is \"client\", then set requests window to requests\n  // client, if requests clients global object is a Window object; otherwise\n  // \"no-window\".\n  if (request.window === 'client') {\n    // TODO: What if request.client is null?\n    request.window =\n      request.client?.globalObject?.constructor?.name === 'Window'\n        ? request.client\n        : 'no-window'\n  }\n\n  // 9. If requests origin is \"client\", then set requests origin to requests\n  // clients origin.\n  if (request.origin === 'client') {\n    // TODO: What if request.client is null?\n    request.origin = request.client?.origin\n  }\n\n  // 10. If all of the following conditions are true:\n  // TODO\n\n  // 11. If requests policy container is \"client\", then:\n  if (request.policyContainer === 'client') {\n    // 1. If requests client is non-null, then set requests policy\n    // container to a clone of requests clients policy container. [HTML]\n    if (request.client != null) {\n      request.policyContainer = clonePolicyContainer(\n        request.client.policyContainer\n      )\n    } else {\n      // 2. Otherwise, set requests policy container to a new policy\n      // container.\n      request.policyContainer = makePolicyContainer()\n    }\n  }\n\n  // 12. If requests header list does not contain `Accept`, then:\n  if (!request.headersList.contains('accept')) {\n    // 1. Let value be `*/*`.\n    const value = '*/*'\n\n    // 2. A user agent should set value to the first matching statement, if\n    // any, switching on requests destination:\n    // \"document\"\n    // \"frame\"\n    // \"iframe\"\n    // `text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8`\n    // \"image\"\n    // `image/png,image/svg+xml,image/*;q=0.8,*/*;q=0.5`\n    // \"style\"\n    // `text/css,*/*;q=0.1`\n    // TODO\n\n    // 3. Append `Accept`/value to requests header list.\n    request.headersList.append('accept', value)\n  }\n\n  // 13. If requests header list does not contain `Accept-Language`, then\n  // user agents should append `Accept-Language`/an appropriate value to\n  // requests header list.\n  if (!request.headersList.contains('accept-language')) {\n    request.headersList.append('accept-language', '*')\n  }\n\n  // 14. If requests priority is null, then use requests initiator and\n  // destination appropriately in setting requests priority to a\n  // user-agent-defined object.\n  if (request.priority === null) {\n    // TODO\n  }\n\n  // 15. If request is a subresource request, then:\n  if (subresourceSet.has(request.destination)) {\n    // TODO\n  }\n\n  // 16. Run main fetch given fetchParams.\n  mainFetch(fetchParams)\n    .catch(err => {\n      fetchParams.controller.terminate(err)\n    })\n\n  // 17. Return fetchParam's controller\n  return fetchParams.controller\n}\n\n// https://fetch.spec.whatwg.org/#concept-main-fetch\nasync function mainFetch (fetchParams, recursive = false) {\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let response be null.\n  let response = null\n\n  // 3. If requests local-URLs-only flag is set and requests current URL is\n  // not local, then set response to a network error.\n  if (request.localURLsOnly && !urlIsLocal(requestCurrentURL(request))) {\n    response = makeNetworkError('local URLs only')\n  }\n\n  // 4. Run report Content Security Policy violations for request.\n  // TODO\n\n  // 5. Upgrade request to a potentially trustworthy URL, if appropriate.\n  tryUpgradeRequestToAPotentiallyTrustworthyURL(request)\n\n  // 6. If should request be blocked due to a bad port, should fetching request\n  // be blocked as mixed content, or should request be blocked by Content\n  // Security Policy returns blocked, then set response to a network error.\n  if (requestBadPort(request) === 'blocked') {\n    response = makeNetworkError('bad port')\n  }\n  // TODO: should fetching request be blocked as mixed content?\n  // TODO: should request be blocked by Content Security Policy?\n\n  // 7. If requests referrer policy is the empty string, then set requests\n  // referrer policy to requests policy containers referrer policy.\n  if (request.referrerPolicy === '') {\n    request.referrerPolicy = request.policyContainer.referrerPolicy\n  }\n\n  // 8. If requests referrer is not \"no-referrer\", then set requests\n  // referrer to the result of invoking determine requests referrer.\n  if (request.referrer !== 'no-referrer') {\n    request.referrer = determineRequestsReferrer(request)\n  }\n\n  // 9. Set requests current URLs scheme to \"https\" if all of the following\n  // conditions are true:\n  // - requests current URLs scheme is \"http\"\n  // - requests current URLs host is a domain\n  // - Matching requests current URLs host per Known HSTS Host Domain Name\n  //   Matching results in either a superdomain match with an asserted\n  //   includeSubDomains directive or a congruent match (with or without an\n  //   asserted includeSubDomains directive). [HSTS]\n  // TODO\n\n  // 10. If recursive is false, then run the remaining steps in parallel.\n  // TODO\n\n  // 11. If response is null, then set response to the result of running\n  // the steps corresponding to the first matching statement:\n  if (response === null) {\n    response = await (async () => {\n      const currentURL = requestCurrentURL(request)\n\n      if (\n        // - requests current URLs origin is same origin with requests origin,\n        //   and requests response tainting is \"basic\"\n        (sameOrigin(currentURL, request.url) && request.responseTainting === 'basic') ||\n        // requests current URLs scheme is \"data\"\n        (currentURL.protocol === 'data:') ||\n        // - requests mode is \"navigate\" or \"websocket\"\n        (request.mode === 'navigate' || request.mode === 'websocket')\n      ) {\n        // 1. Set requests response tainting to \"basic\".\n        request.responseTainting = 'basic'\n\n        // 2. Return the result of running scheme fetch given fetchParams.\n        return await schemeFetch(fetchParams)\n      }\n\n      // requests mode is \"same-origin\"\n      if (request.mode === 'same-origin') {\n        // 1. Return a network error.\n        return makeNetworkError('request mode cannot be \"same-origin\"')\n      }\n\n      // requests mode is \"no-cors\"\n      if (request.mode === 'no-cors') {\n        // 1. If requests redirect mode is not \"follow\", then return a network\n        // error.\n        if (request.redirect !== 'follow') {\n          return makeNetworkError(\n            'redirect mode cannot be \"follow\" for \"no-cors\" request'\n          )\n        }\n\n        // 2. Set requests response tainting to \"opaque\".\n        request.responseTainting = 'opaque'\n\n        // 3. Return the result of running scheme fetch given fetchParams.\n        return await schemeFetch(fetchParams)\n      }\n\n      // requests current URLs scheme is not an HTTP(S) scheme\n      if (!urlIsHttpHttpsScheme(requestCurrentURL(request))) {\n        // Return a network error.\n        return makeNetworkError('URL scheme must be a HTTP(S) scheme')\n      }\n\n      // - requests use-CORS-preflight flag is set\n      // - requests unsafe-request flag is set and either requests method is\n      //   not a CORS-safelisted method or CORS-unsafe request-header names with\n      //   requests header list is not empty\n      //    1. Set requests response tainting to \"cors\".\n      //    2. Let corsWithPreflightResponse be the result of running HTTP fetch\n      //    given fetchParams and true.\n      //    3. If corsWithPreflightResponse is a network error, then clear cache\n      //    entries using request.\n      //    4. Return corsWithPreflightResponse.\n      // TODO\n\n      // Otherwise\n      //    1. Set requests response tainting to \"cors\".\n      request.responseTainting = 'cors'\n\n      //    2. Return the result of running HTTP fetch given fetchParams.\n      return await httpFetch(fetchParams)\n    })()\n  }\n\n  // 12. If recursive is true, then return response.\n  if (recursive) {\n    return response\n  }\n\n  // 13. If response is not a network error and response is not a filtered\n  // response, then:\n  if (response.status !== 0 && !response.internalResponse) {\n    // If requests response tainting is \"cors\", then:\n    if (request.responseTainting === 'cors') {\n      // 1. Let headerNames be the result of extracting header list values\n      // given `Access-Control-Expose-Headers` and responses header list.\n      // TODO\n      // 2. If requests credentials mode is not \"include\" and headerNames\n      // contains `*`, then set responses CORS-exposed header-name list to\n      // all unique header names in responses header list.\n      // TODO\n      // 3. Otherwise, if headerNames is not null or failure, then set\n      // responses CORS-exposed header-name list to headerNames.\n      // TODO\n    }\n\n    // Set response to the following filtered response with response as its\n    // internal response, depending on requests response tainting:\n    if (request.responseTainting === 'basic') {\n      response = filterResponse(response, 'basic')\n    } else if (request.responseTainting === 'cors') {\n      response = filterResponse(response, 'cors')\n    } else if (request.responseTainting === 'opaque') {\n      response = filterResponse(response, 'opaque')\n    } else {\n      assert(false)\n    }\n  }\n\n  // 14. Let internalResponse be response, if response is a network error,\n  // and responses internal response otherwise.\n  let internalResponse =\n    response.status === 0 ? response : response.internalResponse\n\n  // 15. If internalResponses URL list is empty, then set it to a clone of\n  // requests URL list.\n  if (internalResponse.urlList.length === 0) {\n    internalResponse.urlList.push(...request.urlList)\n  }\n\n  // 16. If requests timing allow failed flag is unset, then set\n  // internalResponses timing allow passed flag.\n  if (!request.timingAllowFailed) {\n    response.timingAllowPassed = true\n  }\n\n  // 17. If response is not a network error and any of the following returns\n  // blocked\n  // - should internalResponse to request be blocked as mixed content\n  // - should internalResponse to request be blocked by Content Security Policy\n  // - should internalResponse to request be blocked due to its MIME type\n  // - should internalResponse to request be blocked due to nosniff\n  // TODO\n\n  // 18. If responses type is \"opaque\", internalResponses status is 206,\n  // internalResponses range-requested flag is set, and requests header\n  // list does not contain `Range`, then set response and internalResponse\n  // to a network error.\n  if (\n    response.type === 'opaque' &&\n    internalResponse.status === 206 &&\n    internalResponse.rangeRequested &&\n    !request.headers.contains('range')\n  ) {\n    response = internalResponse = makeNetworkError()\n  }\n\n  // 19. If response is not a network error and either requests method is\n  // `HEAD` or `CONNECT`, or internalResponses status is a null body status,\n  // set internalResponses body to null and disregard any enqueuing toward\n  // it (if any).\n  if (\n    response.status !== 0 &&\n    (request.method === 'HEAD' ||\n      request.method === 'CONNECT' ||\n      nullBodyStatus.includes(internalResponse.status))\n  ) {\n    internalResponse.body = null\n    fetchParams.controller.dump = true\n  }\n\n  // 20. If requests integrity metadata is not the empty string, then:\n  if (request.integrity) {\n    // 1. Let processBodyError be this step: run fetch finale given fetchParams\n    // and a network error.\n    const processBodyError = (reason) =>\n      fetchFinale(fetchParams, makeNetworkError(reason))\n\n    // 2. If requests response tainting is \"opaque\", or responses body is null,\n    // then run processBodyError and abort these steps.\n    if (request.responseTainting === 'opaque' || response.body == null) {\n      processBodyError(response.error)\n      return\n    }\n\n    // 3. Let processBody given bytes be these steps:\n    const processBody = (bytes) => {\n      // 1. If bytes do not match requests integrity metadata,\n      // then run processBodyError and abort these steps. [SRI]\n      if (!bytesMatch(bytes, request.integrity)) {\n        processBodyError('integrity mismatch')\n        return\n      }\n\n      // 2. Set responses body to bytes as a body.\n      response.body = safelyExtractBody(bytes)[0]\n\n      // 3. Run fetch finale given fetchParams and response.\n      fetchFinale(fetchParams, response)\n    }\n\n    // 4. Fully read responses body given processBody and processBodyError.\n    await fullyReadBody(response.body, processBody, processBodyError)\n  } else {\n    // 21. Otherwise, run fetch finale given fetchParams and response.\n    fetchFinale(fetchParams, response)\n  }\n}\n\n// https://fetch.spec.whatwg.org/#concept-scheme-fetch\n// given a fetch params fetchParams\nfunction schemeFetch (fetchParams) {\n  // Note: since the connection is destroyed on redirect, which sets fetchParams to a\n  // cancelled state, we do not want this condition to trigger *unless* there have been\n  // no redirects. See https://github.com/nodejs/undici/issues/1776\n  // 1. If fetchParams is canceled, then return the appropriate network error for fetchParams.\n  if (isCancelled(fetchParams) && fetchParams.request.redirectCount === 0) {\n    return Promise.resolve(makeAppropriateNetworkError(fetchParams))\n  }\n\n  // 2. Let request be fetchParamss request.\n  const { request } = fetchParams\n\n  const { protocol: scheme } = requestCurrentURL(request)\n\n  // 3. Switch on requests current URLs scheme and run the associated steps:\n  switch (scheme) {\n    case 'about:': {\n      // If requests current URLs path is the string \"blank\", then return a new response\n      // whose status message is `OK`, header list is  (`Content-Type`, `text/html;charset=utf-8`) ,\n      // and body is the empty byte sequence as a body.\n\n      // Otherwise, return a network error.\n      return Promise.resolve(makeNetworkError('about scheme is not supported'))\n    }\n    case 'blob:': {\n      if (!resolveObjectURL) {\n        resolveObjectURL = require('buffer').resolveObjectURL\n      }\n\n      // 1. Let blobURLEntry be requests current URLs blob URL entry.\n      const blobURLEntry = requestCurrentURL(request)\n\n      // https://github.com/web-platform-tests/wpt/blob/7b0ebaccc62b566a1965396e5be7bb2bc06f841f/FileAPI/url/resources/fetch-tests.js#L52-L56\n      // Buffer.resolveObjectURL does not ignore URL queries.\n      if (blobURLEntry.search.length !== 0) {\n        return Promise.resolve(makeNetworkError('NetworkError when attempting to fetch resource.'))\n      }\n\n      const blobURLEntryObject = resolveObjectURL(blobURLEntry.toString())\n\n      // 2. If requests method is not `GET`, blobURLEntry is null, or blobURLEntrys\n      //    object is not a Blob object, then return a network error.\n      if (request.method !== 'GET' || !isBlobLike(blobURLEntryObject)) {\n        return Promise.resolve(makeNetworkError('invalid method'))\n      }\n\n      // 3. Let bodyWithType be the result of safely extracting blobURLEntrys object.\n      const bodyWithType = safelyExtractBody(blobURLEntryObject)\n\n      // 4. Let body be bodyWithTypes body.\n      const body = bodyWithType[0]\n\n      // 5. Let length be bodys length, serialized and isomorphic encoded.\n      const length = isomorphicEncode(`${body.length}`)\n\n      // 6. Let type be bodyWithTypes type if it is non-null; otherwise the empty byte sequence.\n      const type = bodyWithType[1] ?? ''\n\n      // 7. Return a new response whose status message is `OK`, header list is\n      //     (`Content-Length`, length), (`Content-Type`, type) , and body is body.\n      const response = makeResponse({\n        statusText: 'OK',\n        headersList: [\n          ['content-length', { name: 'Content-Length', value: length }],\n          ['content-type', { name: 'Content-Type', value: type }]\n        ]\n      })\n\n      response.body = body\n\n      return Promise.resolve(response)\n    }\n    case 'data:': {\n      // 1. Let dataURLStruct be the result of running the\n      //    data: URL processor on requests current URL.\n      const currentURL = requestCurrentURL(request)\n      const dataURLStruct = dataURLProcessor(currentURL)\n\n      // 2. If dataURLStruct is failure, then return a\n      //    network error.\n      if (dataURLStruct === 'failure') {\n        return Promise.resolve(makeNetworkError('failed to fetch the data URL'))\n      }\n\n      // 3. Let mimeType be dataURLStructs MIME type, serialized.\n      const mimeType = serializeAMimeType(dataURLStruct.mimeType)\n\n      // 4. Return a response whose status message is `OK`,\n      //    header list is  (`Content-Type`, mimeType) ,\n      //    and body is dataURLStructs body as a body.\n      return Promise.resolve(makeResponse({\n        statusText: 'OK',\n        headersList: [\n          ['content-type', { name: 'Content-Type', value: mimeType }]\n        ],\n        body: safelyExtractBody(dataURLStruct.body)[0]\n      }))\n    }\n    case 'file:': {\n      // For now, unfortunate as it is, file URLs are left as an exercise for the reader.\n      // When in doubt, return a network error.\n      return Promise.resolve(makeNetworkError('not implemented... yet...'))\n    }\n    case 'http:':\n    case 'https:': {\n      // Return the result of running HTTP fetch given fetchParams.\n\n      return httpFetch(fetchParams)\n        .catch((err) => makeNetworkError(err))\n    }\n    default: {\n      return Promise.resolve(makeNetworkError('unknown scheme'))\n    }\n  }\n}\n\n// https://fetch.spec.whatwg.org/#finalize-response\nfunction finalizeResponse (fetchParams, response) {\n  // 1. Set fetchParamss requests done flag.\n  fetchParams.request.done = true\n\n  // 2, If fetchParamss process response done is not null, then queue a fetch\n  // task to run fetchParamss process response done given response, with\n  // fetchParamss task destination.\n  if (fetchParams.processResponseDone != null) {\n    queueMicrotask(() => fetchParams.processResponseDone(response))\n  }\n}\n\n// https://fetch.spec.whatwg.org/#fetch-finale\nfunction fetchFinale (fetchParams, response) {\n  // 1. If response is a network error, then:\n  if (response.type === 'error') {\n    // 1. Set responses URL list to  fetchParamss requests URL list[0] .\n    response.urlList = [fetchParams.request.urlList[0]]\n\n    // 2. Set responses timing info to the result of creating an opaque timing\n    // info for fetchParamss timing info.\n    response.timingInfo = createOpaqueTimingInfo({\n      startTime: fetchParams.timingInfo.startTime\n    })\n  }\n\n  // 2. Let processResponseEndOfBody be the following steps:\n  const processResponseEndOfBody = () => {\n    // 1. Set fetchParamss requests done flag.\n    fetchParams.request.done = true\n\n    // If fetchParamss process response end-of-body is not null,\n    // then queue a fetch task to run fetchParamss process response\n    // end-of-body given response with fetchParamss task destination.\n    if (fetchParams.processResponseEndOfBody != null) {\n      queueMicrotask(() => fetchParams.processResponseEndOfBody(response))\n    }\n  }\n\n  // 3. If fetchParamss process response is non-null, then queue a fetch task\n  // to run fetchParamss process response given response, with fetchParamss\n  // task destination.\n  if (fetchParams.processResponse != null) {\n    queueMicrotask(() => fetchParams.processResponse(response))\n  }\n\n  // 4. If responses body is null, then run processResponseEndOfBody.\n  if (response.body == null) {\n    processResponseEndOfBody()\n  } else {\n  // 5. Otherwise:\n\n    // 1. Let transformStream be a new a TransformStream.\n\n    // 2. Let identityTransformAlgorithm be an algorithm which, given chunk,\n    // enqueues chunk in transformStream.\n    const identityTransformAlgorithm = (chunk, controller) => {\n      controller.enqueue(chunk)\n    }\n\n    // 3. Set up transformStream with transformAlgorithm set to identityTransformAlgorithm\n    // and flushAlgorithm set to processResponseEndOfBody.\n    const transformStream = new TransformStream({\n      start () {},\n      transform: identityTransformAlgorithm,\n      flush: processResponseEndOfBody\n    }, {\n      size () {\n        return 1\n      }\n    }, {\n      size () {\n        return 1\n      }\n    })\n\n    // 4. Set responses body to the result of piping responses body through transformStream.\n    response.body = { stream: response.body.stream.pipeThrough(transformStream) }\n  }\n\n  // 6. If fetchParamss process response consume body is non-null, then:\n  if (fetchParams.processResponseConsumeBody != null) {\n    // 1. Let processBody given nullOrBytes be this step: run fetchParamss\n    // process response consume body given response and nullOrBytes.\n    const processBody = (nullOrBytes) => fetchParams.processResponseConsumeBody(response, nullOrBytes)\n\n    // 2. Let processBodyError be this step: run fetchParamss process\n    // response consume body given response and failure.\n    const processBodyError = (failure) => fetchParams.processResponseConsumeBody(response, failure)\n\n    // 3. If responses body is null, then queue a fetch task to run processBody\n    // given null, with fetchParamss task destination.\n    if (response.body == null) {\n      queueMicrotask(() => processBody(null))\n    } else {\n      // 4. Otherwise, fully read responses body given processBody, processBodyError,\n      // and fetchParamss task destination.\n      return fullyReadBody(response.body, processBody, processBodyError)\n    }\n    return Promise.resolve()\n  }\n}\n\n// https://fetch.spec.whatwg.org/#http-fetch\nasync function httpFetch (fetchParams) {\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let response be null.\n  let response = null\n\n  // 3. Let actualResponse be null.\n  let actualResponse = null\n\n  // 4. Let timingInfo be fetchParamss timing info.\n  const timingInfo = fetchParams.timingInfo\n\n  // 5. If requests service-workers mode is \"all\", then:\n  if (request.serviceWorkers === 'all') {\n    // TODO\n  }\n\n  // 6. If response is null, then:\n  if (response === null) {\n    // 1. If makeCORSPreflight is true and one of these conditions is true:\n    // TODO\n\n    // 2. If requests redirect mode is \"follow\", then set requests\n    // service-workers mode to \"none\".\n    if (request.redirect === 'follow') {\n      request.serviceWorkers = 'none'\n    }\n\n    // 3. Set response and actualResponse to the result of running\n    // HTTP-network-or-cache fetch given fetchParams.\n    actualResponse = response = await httpNetworkOrCacheFetch(fetchParams)\n\n    // 4. If requests response tainting is \"cors\" and a CORS check\n    // for request and response returns failure, then return a network error.\n    if (\n      request.responseTainting === 'cors' &&\n      corsCheck(request, response) === 'failure'\n    ) {\n      return makeNetworkError('cors failure')\n    }\n\n    // 5. If the TAO check for request and response returns failure, then set\n    // requests timing allow failed flag.\n    if (TAOCheck(request, response) === 'failure') {\n      request.timingAllowFailed = true\n    }\n  }\n\n  // 7. If either requests response tainting or responses type\n  // is \"opaque\", and the cross-origin resource policy check with\n  // requests origin, requests client, requests destination,\n  // and actualResponse returns blocked, then return a network error.\n  if (\n    (request.responseTainting === 'opaque' || response.type === 'opaque') &&\n    crossOriginResourcePolicyCheck(\n      request.origin,\n      request.client,\n      request.destination,\n      actualResponse\n    ) === 'blocked'\n  ) {\n    return makeNetworkError('blocked')\n  }\n\n  // 8. If actualResponses status is a redirect status, then:\n  if (redirectStatusSet.has(actualResponse.status)) {\n    // 1. If actualResponses status is not 303, requests body is not null,\n    // and the connection uses HTTP/2, then user agents may, and are even\n    // encouraged to, transmit an RST_STREAM frame.\n    // See, https://github.com/whatwg/fetch/issues/1288\n    if (request.redirect !== 'manual') {\n      fetchParams.controller.connection.destroy()\n    }\n\n    // 2. Switch on requests redirect mode:\n    if (request.redirect === 'error') {\n      // Set response to a network error.\n      response = makeNetworkError('unexpected redirect')\n    } else if (request.redirect === 'manual') {\n      // Set response to an opaque-redirect filtered response whose internal\n      // response is actualResponse.\n      // NOTE(spec): On the web this would return an `opaqueredirect` response,\n      // but that doesn't make sense server side.\n      // See https://github.com/nodejs/undici/issues/1193.\n      response = actualResponse\n    } else if (request.redirect === 'follow') {\n      // Set response to the result of running HTTP-redirect fetch given\n      // fetchParams and response.\n      response = await httpRedirectFetch(fetchParams, response)\n    } else {\n      assert(false)\n    }\n  }\n\n  // 9. Set responses timing info to timingInfo.\n  response.timingInfo = timingInfo\n\n  // 10. Return response.\n  return response\n}\n\n// https://fetch.spec.whatwg.org/#http-redirect-fetch\nfunction httpRedirectFetch (fetchParams, response) {\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let actualResponse be response, if response is not a filtered response,\n  // and responses internal response otherwise.\n  const actualResponse = response.internalResponse\n    ? response.internalResponse\n    : response\n\n  // 3. Let locationURL be actualResponses location URL given requests current\n  // URLs fragment.\n  let locationURL\n\n  try {\n    locationURL = responseLocationURL(\n      actualResponse,\n      requestCurrentURL(request).hash\n    )\n\n    // 4. If locationURL is null, then return response.\n    if (locationURL == null) {\n      return response\n    }\n  } catch (err) {\n    // 5. If locationURL is failure, then return a network error.\n    return Promise.resolve(makeNetworkError(err))\n  }\n\n  // 6. If locationURLs scheme is not an HTTP(S) scheme, then return a network\n  // error.\n  if (!urlIsHttpHttpsScheme(locationURL)) {\n    return Promise.resolve(makeNetworkError('URL scheme must be a HTTP(S) scheme'))\n  }\n\n  // 7. If requests redirect count is 20, then return a network error.\n  if (request.redirectCount === 20) {\n    return Promise.resolve(makeNetworkError('redirect count exceeded'))\n  }\n\n  // 8. Increase requests redirect count by 1.\n  request.redirectCount += 1\n\n  // 9. If requests mode is \"cors\", locationURL includes credentials, and\n  // requests origin is not same origin with locationURLs origin, then return\n  //  a network error.\n  if (\n    request.mode === 'cors' &&\n    (locationURL.username || locationURL.password) &&\n    !sameOrigin(request, locationURL)\n  ) {\n    return Promise.resolve(makeNetworkError('cross origin not allowed for request mode \"cors\"'))\n  }\n\n  // 10. If requests response tainting is \"cors\" and locationURL includes\n  // credentials, then return a network error.\n  if (\n    request.responseTainting === 'cors' &&\n    (locationURL.username || locationURL.password)\n  ) {\n    return Promise.resolve(makeNetworkError(\n      'URL cannot contain credentials for request mode \"cors\"'\n    ))\n  }\n\n  // 11. If actualResponses status is not 303, requests body is non-null,\n  // and requests bodys source is null, then return a network error.\n  if (\n    actualResponse.status !== 303 &&\n    request.body != null &&\n    request.body.source == null\n  ) {\n    return Promise.resolve(makeNetworkError())\n  }\n\n  // 12. If one of the following is true\n  // - actualResponses status is 301 or 302 and requests method is `POST`\n  // - actualResponses status is 303 and requests method is not `GET` or `HEAD`\n  if (\n    ([301, 302].includes(actualResponse.status) && request.method === 'POST') ||\n    (actualResponse.status === 303 &&\n      !GET_OR_HEAD.includes(request.method))\n  ) {\n    // then:\n    // 1. Set requests method to `GET` and requests body to null.\n    request.method = 'GET'\n    request.body = null\n\n    // 2. For each headerName of request-body-header name, delete headerName from\n    // requests header list.\n    for (const headerName of requestBodyHeader) {\n      request.headersList.delete(headerName)\n    }\n  }\n\n  // 13. If requests current URLs origin is not same origin with locationURLs\n  //     origin, then for each headerName of CORS non-wildcard request-header name,\n  //     delete headerName from requests header list.\n  if (!sameOrigin(requestCurrentURL(request), locationURL)) {\n    // https://fetch.spec.whatwg.org/#cors-non-wildcard-request-header-name\n    request.headersList.delete('authorization')\n\n    // https://fetch.spec.whatwg.org/#authentication-entries\n    request.headersList.delete('proxy-authorization', true)\n\n    // \"Cookie\" and \"Host\" are forbidden request-headers, which undici doesn't implement.\n    request.headersList.delete('cookie')\n    request.headersList.delete('host')\n  }\n\n  // 14. If requests body is non-null, then set requests body to the first return\n  // value of safely extracting requests bodys source.\n  if (request.body != null) {\n    assert(request.body.source != null)\n    request.body = safelyExtractBody(request.body.source)[0]\n  }\n\n  // 15. Let timingInfo be fetchParamss timing info.\n  const timingInfo = fetchParams.timingInfo\n\n  // 16. Set timingInfos redirect end time and post-redirect start time to the\n  // coarsened shared current time given fetchParamss cross-origin isolated\n  // capability.\n  timingInfo.redirectEndTime = timingInfo.postRedirectStartTime =\n    coarsenedSharedCurrentTime(fetchParams.crossOriginIsolatedCapability)\n\n  // 17. If timingInfos redirect start time is 0, then set timingInfos\n  //  redirect start time to timingInfos start time.\n  if (timingInfo.redirectStartTime === 0) {\n    timingInfo.redirectStartTime = timingInfo.startTime\n  }\n\n  // 18. Append locationURL to requests URL list.\n  request.urlList.push(locationURL)\n\n  // 19. Invoke set requests referrer policy on redirect on request and\n  // actualResponse.\n  setRequestReferrerPolicyOnRedirect(request, actualResponse)\n\n  // 20. Return the result of running main fetch given fetchParams and true.\n  return mainFetch(fetchParams, true)\n}\n\n// https://fetch.spec.whatwg.org/#http-network-or-cache-fetch\nasync function httpNetworkOrCacheFetch (\n  fetchParams,\n  isAuthenticationFetch = false,\n  isNewConnectionFetch = false\n) {\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let httpFetchParams be null.\n  let httpFetchParams = null\n\n  // 3. Let httpRequest be null.\n  let httpRequest = null\n\n  // 4. Let response be null.\n  let response = null\n\n  // 5. Let storedResponse be null.\n  // TODO: cache\n\n  // 6. Let httpCache be null.\n  const httpCache = null\n\n  // 7. Let the revalidatingFlag be unset.\n  const revalidatingFlag = false\n\n  // 8. Run these steps, but abort when the ongoing fetch is terminated:\n\n  //    1. If requests window is \"no-window\" and requests redirect mode is\n  //    \"error\", then set httpFetchParams to fetchParams and httpRequest to\n  //    request.\n  if (request.window === 'no-window' && request.redirect === 'error') {\n    httpFetchParams = fetchParams\n    httpRequest = request\n  } else {\n    // Otherwise:\n\n    // 1. Set httpRequest to a clone of request.\n    httpRequest = makeRequest(request)\n\n    // 2. Set httpFetchParams to a copy of fetchParams.\n    httpFetchParams = { ...fetchParams }\n\n    // 3. Set httpFetchParamss request to httpRequest.\n    httpFetchParams.request = httpRequest\n  }\n\n  //    3. Let includeCredentials be true if one of\n  const includeCredentials =\n    request.credentials === 'include' ||\n    (request.credentials === 'same-origin' &&\n      request.responseTainting === 'basic')\n\n  //    4. Let contentLength be httpRequests bodys length, if httpRequests\n  //    body is non-null; otherwise null.\n  const contentLength = httpRequest.body ? httpRequest.body.length : null\n\n  //    5. Let contentLengthHeaderValue be null.\n  let contentLengthHeaderValue = null\n\n  //    6. If httpRequests body is null and httpRequests method is `POST` or\n  //    `PUT`, then set contentLengthHeaderValue to `0`.\n  if (\n    httpRequest.body == null &&\n    ['POST', 'PUT'].includes(httpRequest.method)\n  ) {\n    contentLengthHeaderValue = '0'\n  }\n\n  //    7. If contentLength is non-null, then set contentLengthHeaderValue to\n  //    contentLength, serialized and isomorphic encoded.\n  if (contentLength != null) {\n    contentLengthHeaderValue = isomorphicEncode(`${contentLength}`)\n  }\n\n  //    8. If contentLengthHeaderValue is non-null, then append\n  //    `Content-Length`/contentLengthHeaderValue to httpRequests header\n  //    list.\n  if (contentLengthHeaderValue != null) {\n    httpRequest.headersList.append('content-length', contentLengthHeaderValue)\n  }\n\n  //    9. If contentLengthHeaderValue is non-null, then append (`Content-Length`,\n  //    contentLengthHeaderValue) to httpRequests header list.\n\n  //    10. If contentLength is non-null and httpRequests keepalive is true,\n  //    then:\n  if (contentLength != null && httpRequest.keepalive) {\n    // NOTE: keepalive is a noop outside of browser context.\n  }\n\n  //    11. If httpRequests referrer is a URL, then append\n  //    `Referer`/httpRequests referrer, serialized and isomorphic encoded,\n  //     to httpRequests header list.\n  if (httpRequest.referrer instanceof URL) {\n    httpRequest.headersList.append('referer', isomorphicEncode(httpRequest.referrer.href))\n  }\n\n  //    12. Append a request `Origin` header for httpRequest.\n  appendRequestOriginHeader(httpRequest)\n\n  //    13. Append the Fetch metadata headers for httpRequest. [FETCH-METADATA]\n  appendFetchMetadata(httpRequest)\n\n  //    14. If httpRequests header list does not contain `User-Agent`, then\n  //    user agents should append `User-Agent`/default `User-Agent` value to\n  //    httpRequests header list.\n  if (!httpRequest.headersList.contains('user-agent')) {\n    httpRequest.headersList.append('user-agent', typeof esbuildDetection === 'undefined' ? 'undici' : 'node')\n  }\n\n  //    15. If httpRequests cache mode is \"default\" and httpRequests header\n  //    list contains `If-Modified-Since`, `If-None-Match`,\n  //    `If-Unmodified-Since`, `If-Match`, or `If-Range`, then set\n  //    httpRequests cache mode to \"no-store\".\n  if (\n    httpRequest.cache === 'default' &&\n    (httpRequest.headersList.contains('if-modified-since') ||\n      httpRequest.headersList.contains('if-none-match') ||\n      httpRequest.headersList.contains('if-unmodified-since') ||\n      httpRequest.headersList.contains('if-match') ||\n      httpRequest.headersList.contains('if-range'))\n  ) {\n    httpRequest.cache = 'no-store'\n  }\n\n  //    16. If httpRequests cache mode is \"no-cache\", httpRequests prevent\n  //    no-cache cache-control header modification flag is unset, and\n  //    httpRequests header list does not contain `Cache-Control`, then append\n  //    `Cache-Control`/`max-age=0` to httpRequests header list.\n  if (\n    httpRequest.cache === 'no-cache' &&\n    !httpRequest.preventNoCacheCacheControlHeaderModification &&\n    !httpRequest.headersList.contains('cache-control')\n  ) {\n    httpRequest.headersList.append('cache-control', 'max-age=0')\n  }\n\n  //    17. If httpRequests cache mode is \"no-store\" or \"reload\", then:\n  if (httpRequest.cache === 'no-store' || httpRequest.cache === 'reload') {\n    // 1. If httpRequests header list does not contain `Pragma`, then append\n    // `Pragma`/`no-cache` to httpRequests header list.\n    if (!httpRequest.headersList.contains('pragma')) {\n      httpRequest.headersList.append('pragma', 'no-cache')\n    }\n\n    // 2. If httpRequests header list does not contain `Cache-Control`,\n    // then append `Cache-Control`/`no-cache` to httpRequests header list.\n    if (!httpRequest.headersList.contains('cache-control')) {\n      httpRequest.headersList.append('cache-control', 'no-cache')\n    }\n  }\n\n  //    18. If httpRequests header list contains `Range`, then append\n  //    `Accept-Encoding`/`identity` to httpRequests header list.\n  if (httpRequest.headersList.contains('range')) {\n    httpRequest.headersList.append('accept-encoding', 'identity')\n  }\n\n  //    19. Modify httpRequests header list per HTTP. Do not append a given\n  //    header if httpRequests header list contains that headers name.\n  //    TODO: https://github.com/whatwg/fetch/issues/1285#issuecomment-896560129\n  if (!httpRequest.headersList.contains('accept-encoding')) {\n    if (urlHasHttpsScheme(requestCurrentURL(httpRequest))) {\n      httpRequest.headersList.append('accept-encoding', 'br, gzip, deflate')\n    } else {\n      httpRequest.headersList.append('accept-encoding', 'gzip, deflate')\n    }\n  }\n\n  httpRequest.headersList.delete('host')\n\n  //    20. If includeCredentials is true, then:\n  if (includeCredentials) {\n    // 1. If the user agent is not configured to block cookies for httpRequest\n    // (see section 7 of [COOKIES]), then:\n    // TODO: credentials\n    // 2. If httpRequests header list does not contain `Authorization`, then:\n    // TODO: credentials\n  }\n\n  //    21. If theres a proxy-authentication entry, use it as appropriate.\n  //    TODO: proxy-authentication\n\n  //    22. Set httpCache to the result of determining the HTTP cache\n  //    partition, given httpRequest.\n  //    TODO: cache\n\n  //    23. If httpCache is null, then set httpRequests cache mode to\n  //    \"no-store\".\n  if (httpCache == null) {\n    httpRequest.cache = 'no-store'\n  }\n\n  //    24. If httpRequests cache mode is neither \"no-store\" nor \"reload\",\n  //    then:\n  if (httpRequest.mode !== 'no-store' && httpRequest.mode !== 'reload') {\n    // TODO: cache\n  }\n\n  // 9. If aborted, then return the appropriate network error for fetchParams.\n  // TODO\n\n  // 10. If response is null, then:\n  if (response == null) {\n    // 1. If httpRequests cache mode is \"only-if-cached\", then return a\n    // network error.\n    if (httpRequest.mode === 'only-if-cached') {\n      return makeNetworkError('only if cached')\n    }\n\n    // 2. Let forwardResponse be the result of running HTTP-network fetch\n    // given httpFetchParams, includeCredentials, and isNewConnectionFetch.\n    const forwardResponse = await httpNetworkFetch(\n      httpFetchParams,\n      includeCredentials,\n      isNewConnectionFetch\n    )\n\n    // 3. If httpRequests method is unsafe and forwardResponses status is\n    // in the range 200 to 399, inclusive, invalidate appropriate stored\n    // responses in httpCache, as per the \"Invalidation\" chapter of HTTP\n    // Caching, and set storedResponse to null. [HTTP-CACHING]\n    if (\n      !safeMethodsSet.has(httpRequest.method) &&\n      forwardResponse.status >= 200 &&\n      forwardResponse.status <= 399\n    ) {\n      // TODO: cache\n    }\n\n    // 4. If the revalidatingFlag is set and forwardResponses status is 304,\n    // then:\n    if (revalidatingFlag && forwardResponse.status === 304) {\n      // TODO: cache\n    }\n\n    // 5. If response is null, then:\n    if (response == null) {\n      // 1. Set response to forwardResponse.\n      response = forwardResponse\n\n      // 2. Store httpRequest and forwardResponse in httpCache, as per the\n      // \"Storing Responses in Caches\" chapter of HTTP Caching. [HTTP-CACHING]\n      // TODO: cache\n    }\n  }\n\n  // 11. Set responses URL list to a clone of httpRequests URL list.\n  response.urlList = [...httpRequest.urlList]\n\n  // 12. If httpRequests header list contains `Range`, then set responses\n  // range-requested flag.\n  if (httpRequest.headersList.contains('range')) {\n    response.rangeRequested = true\n  }\n\n  // 13. Set responses request-includes-credentials to includeCredentials.\n  response.requestIncludesCredentials = includeCredentials\n\n  // 14. If responses status is 401, httpRequests response tainting is not\n  // \"cors\", includeCredentials is true, and requests window is an environment\n  // settings object, then:\n  // TODO\n\n  // 15. If responses status is 407, then:\n  if (response.status === 407) {\n    // 1. If requests window is \"no-window\", then return a network error.\n    if (request.window === 'no-window') {\n      return makeNetworkError()\n    }\n\n    // 2. ???\n\n    // 3. If fetchParams is canceled, then return the appropriate network error for fetchParams.\n    if (isCancelled(fetchParams)) {\n      return makeAppropriateNetworkError(fetchParams)\n    }\n\n    // 4. Prompt the end user as appropriate in requests window and store\n    // the result as a proxy-authentication entry. [HTTP-AUTH]\n    // TODO: Invoke some kind of callback?\n\n    // 5. Set response to the result of running HTTP-network-or-cache fetch given\n    // fetchParams.\n    // TODO\n    return makeNetworkError('proxy authentication required')\n  }\n\n  // 16. If all of the following are true\n  if (\n    // responses status is 421\n    response.status === 421 &&\n    // isNewConnectionFetch is false\n    !isNewConnectionFetch &&\n    // requests body is null, or requests body is non-null and requests bodys source is non-null\n    (request.body == null || request.body.source != null)\n  ) {\n    // then:\n\n    // 1. If fetchParams is canceled, then return the appropriate network error for fetchParams.\n    if (isCancelled(fetchParams)) {\n      return makeAppropriateNetworkError(fetchParams)\n    }\n\n    // 2. Set response to the result of running HTTP-network-or-cache\n    // fetch given fetchParams, isAuthenticationFetch, and true.\n\n    // TODO (spec): The spec doesn't specify this but we need to cancel\n    // the active response before we can start a new one.\n    // https://github.com/whatwg/fetch/issues/1293\n    fetchParams.controller.connection.destroy()\n\n    response = await httpNetworkOrCacheFetch(\n      fetchParams,\n      isAuthenticationFetch,\n      true\n    )\n  }\n\n  // 17. If isAuthenticationFetch is true, then create an authentication entry\n  if (isAuthenticationFetch) {\n    // TODO\n  }\n\n  // 18. Return response.\n  return response\n}\n\n// https://fetch.spec.whatwg.org/#http-network-fetch\nasync function httpNetworkFetch (\n  fetchParams,\n  includeCredentials = false,\n  forceNewConnection = false\n) {\n  assert(!fetchParams.controller.connection || fetchParams.controller.connection.destroyed)\n\n  fetchParams.controller.connection = {\n    abort: null,\n    destroyed: false,\n    destroy (err) {\n      if (!this.destroyed) {\n        this.destroyed = true\n        this.abort?.(err ?? new DOMException('The operation was aborted.', 'AbortError'))\n      }\n    }\n  }\n\n  // 1. Let request be fetchParamss request.\n  const request = fetchParams.request\n\n  // 2. Let response be null.\n  let response = null\n\n  // 3. Let timingInfo be fetchParamss timing info.\n  const timingInfo = fetchParams.timingInfo\n\n  // 4. Let httpCache be the result of determining the HTTP cache partition,\n  // given request.\n  // TODO: cache\n  const httpCache = null\n\n  // 5. If httpCache is null, then set requests cache mode to \"no-store\".\n  if (httpCache == null) {\n    request.cache = 'no-store'\n  }\n\n  // 6. Let networkPartitionKey be the result of determining the network\n  // partition key given request.\n  // TODO\n\n  // 7. Let newConnection be \"yes\" if forceNewConnection is true; otherwise\n  // \"no\".\n  const newConnection = forceNewConnection ? 'yes' : 'no' // eslint-disable-line no-unused-vars\n\n  // 8. Switch on requests mode:\n  if (request.mode === 'websocket') {\n    // Let connection be the result of obtaining a WebSocket connection,\n    // given requests current URL.\n    // TODO\n  } else {\n    // Let connection be the result of obtaining a connection, given\n    // networkPartitionKey, requests current URLs origin,\n    // includeCredentials, and forceNewConnection.\n    // TODO\n  }\n\n  // 9. Run these steps, but abort when the ongoing fetch is terminated:\n\n  //    1. If connection is failure, then return a network error.\n\n  //    2. Set timingInfos final connection timing info to the result of\n  //    calling clamp and coarsen connection timing info with connections\n  //    timing info, timingInfos post-redirect start time, and fetchParamss\n  //    cross-origin isolated capability.\n\n  //    3. If connection is not an HTTP/2 connection, requests body is non-null,\n  //    and requests bodys source is null, then append (`Transfer-Encoding`,\n  //    `chunked`) to requests header list.\n\n  //    4. Set timingInfos final network-request start time to the coarsened\n  //    shared current time given fetchParamss cross-origin isolated\n  //    capability.\n\n  //    5. Set response to the result of making an HTTP request over connection\n  //    using request with the following caveats:\n\n  //        - Follow the relevant requirements from HTTP. [HTTP] [HTTP-SEMANTICS]\n  //        [HTTP-COND] [HTTP-CACHING] [HTTP-AUTH]\n\n  //        - If requests body is non-null, and requests bodys source is null,\n  //        then the user agent may have a buffer of up to 64 kibibytes and store\n  //        a part of requests body in that buffer. If the user agent reads from\n  //        requests body beyond that buffers size and the user agent needs to\n  //        resend request, then instead return a network error.\n\n  //        - Set timingInfos final network-response start time to the coarsened\n  //        shared current time given fetchParamss cross-origin isolated capability,\n  //        immediately after the user agents HTTP parser receives the first byte\n  //        of the response (e.g., frame header bytes for HTTP/2 or response status\n  //        line for HTTP/1.x).\n\n  //        - Wait until all the headers are transmitted.\n\n  //        - Any responses whose status is in the range 100 to 199, inclusive,\n  //        and is not 101, are to be ignored, except for the purposes of setting\n  //        timingInfos final network-response start time above.\n\n  //    - If requests header list contains `Transfer-Encoding`/`chunked` and\n  //    response is transferred via HTTP/1.0 or older, then return a network\n  //    error.\n\n  //    - If the HTTP request results in a TLS client certificate dialog, then:\n\n  //        1. If requests window is an environment settings object, make the\n  //        dialog available in requests window.\n\n  //        2. Otherwise, return a network error.\n\n  // To transmit requests body body, run these steps:\n  let requestBody = null\n  // 1. If body is null and fetchParamss process request end-of-body is\n  // non-null, then queue a fetch task given fetchParamss process request\n  // end-of-body and fetchParamss task destination.\n  if (request.body == null && fetchParams.processRequestEndOfBody) {\n    queueMicrotask(() => fetchParams.processRequestEndOfBody())\n  } else if (request.body != null) {\n    // 2. Otherwise, if body is non-null:\n\n    //    1. Let processBodyChunk given bytes be these steps:\n    const processBodyChunk = async function * (bytes) {\n      // 1. If the ongoing fetch is terminated, then abort these steps.\n      if (isCancelled(fetchParams)) {\n        return\n      }\n\n      // 2. Run this step in parallel: transmit bytes.\n      yield bytes\n\n      // 3. If fetchParamss process request body is non-null, then run\n      // fetchParamss process request body given bytess length.\n      fetchParams.processRequestBodyChunkLength?.(bytes.byteLength)\n    }\n\n    // 2. Let processEndOfBody be these steps:\n    const processEndOfBody = () => {\n      // 1. If fetchParams is canceled, then abort these steps.\n      if (isCancelled(fetchParams)) {\n        return\n      }\n\n      // 2. If fetchParamss process request end-of-body is non-null,\n      // then run fetchParamss process request end-of-body.\n      if (fetchParams.processRequestEndOfBody) {\n        fetchParams.processRequestEndOfBody()\n      }\n    }\n\n    // 3. Let processBodyError given e be these steps:\n    const processBodyError = (e) => {\n      // 1. If fetchParams is canceled, then abort these steps.\n      if (isCancelled(fetchParams)) {\n        return\n      }\n\n      // 2. If e is an \"AbortError\" DOMException, then abort fetchParamss controller.\n      if (e.name === 'AbortError') {\n        fetchParams.controller.abort()\n      } else {\n        fetchParams.controller.terminate(e)\n      }\n    }\n\n    // 4. Incrementally read requests body given processBodyChunk, processEndOfBody,\n    // processBodyError, and fetchParamss task destination.\n    requestBody = (async function * () {\n      try {\n        for await (const bytes of request.body.stream) {\n          yield * processBodyChunk(bytes)\n        }\n        processEndOfBody()\n      } catch (err) {\n        processBodyError(err)\n      }\n    })()\n  }\n\n  try {\n    // socket is only provided for websockets\n    const { body, status, statusText, headersList, socket } = await dispatch({ body: requestBody })\n\n    if (socket) {\n      response = makeResponse({ status, statusText, headersList, socket })\n    } else {\n      const iterator = body[Symbol.asyncIterator]()\n      fetchParams.controller.next = () => iterator.next()\n\n      response = makeResponse({ status, statusText, headersList })\n    }\n  } catch (err) {\n    // 10. If aborted, then:\n    if (err.name === 'AbortError') {\n      // 1. If connection uses HTTP/2, then transmit an RST_STREAM frame.\n      fetchParams.controller.connection.destroy()\n\n      // 2. Return the appropriate network error for fetchParams.\n      return makeAppropriateNetworkError(fetchParams, err)\n    }\n\n    return makeNetworkError(err)\n  }\n\n  // 11. Let pullAlgorithm be an action that resumes the ongoing fetch\n  // if it is suspended.\n  const pullAlgorithm = () => {\n    fetchParams.controller.resume()\n  }\n\n  // 12. Let cancelAlgorithm be an algorithm that aborts fetchParamss\n  // controller with reason, given reason.\n  const cancelAlgorithm = (reason) => {\n    fetchParams.controller.abort(reason)\n  }\n\n  // 13. Let highWaterMark be a non-negative, non-NaN number, chosen by\n  // the user agent.\n  // TODO\n\n  // 14. Let sizeAlgorithm be an algorithm that accepts a chunk object\n  // and returns a non-negative, non-NaN, non-infinite number, chosen by the user agent.\n  // TODO\n\n  // 15. Let stream be a new ReadableStream.\n  // 16. Set up stream with pullAlgorithm set to pullAlgorithm,\n  // cancelAlgorithm set to cancelAlgorithm, highWaterMark set to\n  // highWaterMark, and sizeAlgorithm set to sizeAlgorithm.\n  if (!ReadableStream) {\n    ReadableStream = require('stream/web').ReadableStream\n  }\n\n  const stream = new ReadableStream(\n    {\n      async start (controller) {\n        fetchParams.controller.controller = controller\n      },\n      async pull (controller) {\n        await pullAlgorithm(controller)\n      },\n      async cancel (reason) {\n        await cancelAlgorithm(reason)\n      }\n    },\n    {\n      highWaterMark: 0,\n      size () {\n        return 1\n      }\n    }\n  )\n\n  // 17. Run these steps, but abort when the ongoing fetch is terminated:\n\n  //    1. Set responses body to a new body whose stream is stream.\n  response.body = { stream }\n\n  //    2. If response is not a network error and requests cache mode is\n  //    not \"no-store\", then update response in httpCache for request.\n  //    TODO\n\n  //    3. If includeCredentials is true and the user agent is not configured\n  //    to block cookies for request (see section 7 of [COOKIES]), then run the\n  //    \"set-cookie-string\" parsing algorithm (see section 5.2 of [COOKIES]) on\n  //    the value of each header whose name is a byte-case-insensitive match for\n  //    `Set-Cookie` in responses header list, if any, and requests current URL.\n  //    TODO\n\n  // 18. If aborted, then:\n  // TODO\n\n  // 19. Run these steps in parallel:\n\n  //    1. Run these steps, but abort when fetchParams is canceled:\n  fetchParams.controller.on('terminated', onAborted)\n  fetchParams.controller.resume = async () => {\n    // 1. While true\n    while (true) {\n      // 1-3. See onData...\n\n      // 4. Set bytes to the result of handling content codings given\n      // codings and bytes.\n      let bytes\n      let isFailure\n      try {\n        const { done, value } = await fetchParams.controller.next()\n\n        if (isAborted(fetchParams)) {\n          break\n        }\n\n        bytes = done ? undefined : value\n      } catch (err) {\n        if (fetchParams.controller.ended && !timingInfo.encodedBodySize) {\n          // zlib doesn't like empty streams.\n          bytes = undefined\n        } else {\n          bytes = err\n\n          // err may be propagated from the result of calling readablestream.cancel,\n          // which might not be an error. https://github.com/nodejs/undici/issues/2009\n          isFailure = true\n        }\n      }\n\n      if (bytes === undefined) {\n        // 2. Otherwise, if the bytes transmission for responses message\n        // body is done normally and stream is readable, then close\n        // stream, finalize response for fetchParams and response, and\n        // abort these in-parallel steps.\n        readableStreamClose(fetchParams.controller.controller)\n\n        finalizeResponse(fetchParams, response)\n\n        return\n      }\n\n      // 5. Increase timingInfos decoded body size by bytess length.\n      timingInfo.decodedBodySize += bytes?.byteLength ?? 0\n\n      // 6. If bytes is failure, then terminate fetchParamss controller.\n      if (isFailure) {\n        fetchParams.controller.terminate(bytes)\n        return\n      }\n\n      // 7. Enqueue a Uint8Array wrapping an ArrayBuffer containing bytes\n      // into stream.\n      fetchParams.controller.controller.enqueue(new Uint8Array(bytes))\n\n      // 8. If stream is errored, then terminate the ongoing fetch.\n      if (isErrored(stream)) {\n        fetchParams.controller.terminate()\n        return\n      }\n\n      // 9. If stream doesnt need more data ask the user agent to suspend\n      // the ongoing fetch.\n      if (!fetchParams.controller.controller.desiredSize) {\n        return\n      }\n    }\n  }\n\n  //    2. If aborted, then:\n  function onAborted (reason) {\n    // 2. If fetchParams is aborted, then:\n    if (isAborted(fetchParams)) {\n      // 1. Set responses aborted flag.\n      response.aborted = true\n\n      // 2. If stream is readable, then error stream with the result of\n      //    deserialize a serialized abort reason given fetchParamss\n      //    controllers serialized abort reason and an\n      //    implementation-defined realm.\n      if (isReadable(stream)) {\n        fetchParams.controller.controller.error(\n          fetchParams.controller.serializedAbortReason\n        )\n      }\n    } else {\n      // 3. Otherwise, if stream is readable, error stream with a TypeError.\n      if (isReadable(stream)) {\n        fetchParams.controller.controller.error(new TypeError('terminated', {\n          cause: isErrorLike(reason) ? reason : undefined\n        }))\n      }\n    }\n\n    // 4. If connection uses HTTP/2, then transmit an RST_STREAM frame.\n    // 5. Otherwise, the user agent should close connection unless it would be bad for performance to do so.\n    fetchParams.controller.connection.destroy()\n  }\n\n  // 20. Return response.\n  return response\n\n  async function dispatch ({ body }) {\n    const url = requestCurrentURL(request)\n    /** @type {import('../..').Agent} */\n    const agent = fetchParams.controller.dispatcher\n\n    return new Promise((resolve, reject) => agent.dispatch(\n      {\n        path: url.pathname + url.search,\n        origin: url.origin,\n        method: request.method,\n        body: fetchParams.controller.dispatcher.isMockActive ? request.body && (request.body.source || request.body.stream) : body,\n        headers: request.headersList.entries,\n        maxRedirections: 0,\n        upgrade: request.mode === 'websocket' ? 'websocket' : undefined\n      },\n      {\n        body: null,\n        abort: null,\n\n        onConnect (abort) {\n          // TODO (fix): Do we need connection here?\n          const { connection } = fetchParams.controller\n\n          if (connection.destroyed) {\n            abort(new DOMException('The operation was aborted.', 'AbortError'))\n          } else {\n            fetchParams.controller.on('terminated', abort)\n            this.abort = connection.abort = abort\n          }\n        },\n\n        onHeaders (status, headersList, resume, statusText) {\n          if (status < 200) {\n            return\n          }\n\n          let codings = []\n          let location = ''\n\n          const headers = new Headers()\n\n          // For H2, the headers are a plain JS object\n          // We distinguish between them and iterate accordingly\n          if (Array.isArray(headersList)) {\n            for (let n = 0; n < headersList.length; n += 2) {\n              const key = headersList[n + 0].toString('latin1')\n              const val = headersList[n + 1].toString('latin1')\n              if (key.toLowerCase() === 'content-encoding') {\n                // https://www.rfc-editor.org/rfc/rfc7231#section-3.1.2.1\n                // \"All content-coding values are case-insensitive...\"\n                codings = val.toLowerCase().split(',').map((x) => x.trim())\n              } else if (key.toLowerCase() === 'location') {\n                location = val\n              }\n\n              headers[kHeadersList].append(key, val)\n            }\n          } else {\n            const keys = Object.keys(headersList)\n            for (const key of keys) {\n              const val = headersList[key]\n              if (key.toLowerCase() === 'content-encoding') {\n                // https://www.rfc-editor.org/rfc/rfc7231#section-3.1.2.1\n                // \"All content-coding values are case-insensitive...\"\n                codings = val.toLowerCase().split(',').map((x) => x.trim()).reverse()\n              } else if (key.toLowerCase() === 'location') {\n                location = val\n              }\n\n              headers[kHeadersList].append(key, val)\n            }\n          }\n\n          this.body = new Readable({ read: resume })\n\n          const decoders = []\n\n          const willFollow = request.redirect === 'follow' &&\n            location &&\n            redirectStatusSet.has(status)\n\n          // https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding\n          if (request.method !== 'HEAD' && request.method !== 'CONNECT' && !nullBodyStatus.includes(status) && !willFollow) {\n            for (const coding of codings) {\n              // https://www.rfc-editor.org/rfc/rfc9112.html#section-7.2\n              if (coding === 'x-gzip' || coding === 'gzip') {\n                decoders.push(zlib.createGunzip({\n                  // Be less strict when decoding compressed responses, since sometimes\n                  // servers send slightly invalid responses that are still accepted\n                  // by common browsers.\n                  // Always using Z_SYNC_FLUSH is what cURL does.\n                  flush: zlib.constants.Z_SYNC_FLUSH,\n                  finishFlush: zlib.constants.Z_SYNC_FLUSH\n                }))\n              } else if (coding === 'deflate') {\n                decoders.push(zlib.createInflate())\n              } else if (coding === 'br') {\n                decoders.push(zlib.createBrotliDecompress())\n              } else {\n                decoders.length = 0\n                break\n              }\n            }\n          }\n\n          resolve({\n            status,\n            statusText,\n            headersList: headers[kHeadersList],\n            body: decoders.length\n              ? pipeline(this.body, ...decoders, () => { })\n              : this.body.on('error', () => {})\n          })\n\n          return true\n        },\n\n        onData (chunk) {\n          if (fetchParams.controller.dump) {\n            return\n          }\n\n          // 1. If one or more bytes have been transmitted from responses\n          // message body, then:\n\n          //  1. Let bytes be the transmitted bytes.\n          const bytes = chunk\n\n          //  2. Let codings be the result of extracting header list values\n          //  given `Content-Encoding` and responses header list.\n          //  See pullAlgorithm.\n\n          //  3. Increase timingInfos encoded body size by bytess length.\n          timingInfo.encodedBodySize += bytes.byteLength\n\n          //  4. See pullAlgorithm...\n\n          return this.body.push(bytes)\n        },\n\n        onComplete () {\n          if (this.abort) {\n            fetchParams.controller.off('terminated', this.abort)\n          }\n\n          fetchParams.controller.ended = true\n\n          this.body.push(null)\n        },\n\n        onError (error) {\n          if (this.abort) {\n            fetchParams.controller.off('terminated', this.abort)\n          }\n\n          this.body?.destroy(error)\n\n          fetchParams.controller.terminate(error)\n\n          reject(error)\n        },\n\n        onUpgrade (status, headersList, socket) {\n          if (status !== 101) {\n            return\n          }\n\n          const headers = new Headers()\n\n          for (let n = 0; n < headersList.length; n += 2) {\n            const key = headersList[n + 0].toString('latin1')\n            const val = headersList[n + 1].toString('latin1')\n\n            headers[kHeadersList].append(key, val)\n          }\n\n          resolve({\n            status,\n            statusText: STATUS_CODES[status],\n            headersList: headers[kHeadersList],\n            socket\n          })\n\n          return true\n        }\n      }\n    ))\n  }\n}\n\nmodule.exports = {\n  fetch,\n  Fetch,\n  fetching,\n  finalizeAndReportTiming\n}\n","/* globals AbortController */\n\n'use strict'\n\nconst { extractBody, mixinBody, cloneBody } = require('./body')\nconst { Headers, fill: fillHeaders, HeadersList } = require('./headers')\nconst { FinalizationRegistry } = require('../compat/dispatcher-weakref')()\nconst util = require('../core/util')\nconst {\n  isValidHTTPToken,\n  sameOrigin,\n  normalizeMethod,\n  makePolicyContainer,\n  normalizeMethodRecord\n} = require('./util')\nconst {\n  forbiddenMethodsSet,\n  corsSafeListedMethodsSet,\n  referrerPolicy,\n  requestRedirect,\n  requestMode,\n  requestCredentials,\n  requestCache,\n  requestDuplex\n} = require('./constants')\nconst { kEnumerableProperty } = util\nconst { kHeaders, kSignal, kState, kGuard, kRealm } = require('./symbols')\nconst { webidl } = require('./webidl')\nconst { getGlobalOrigin } = require('./global')\nconst { URLSerializer } = require('./dataURL')\nconst { kHeadersList, kConstruct } = require('../core/symbols')\nconst assert = require('assert')\nconst { getMaxListeners, setMaxListeners, getEventListeners, defaultMaxListeners } = require('events')\n\nlet TransformStream = globalThis.TransformStream\n\nconst kAbortController = Symbol('abortController')\n\nconst requestFinalizer = new FinalizationRegistry(({ signal, abort }) => {\n  signal.removeEventListener('abort', abort)\n})\n\n// https://fetch.spec.whatwg.org/#request-class\nclass Request {\n  // https://fetch.spec.whatwg.org/#dom-request\n  constructor (input, init = {}) {\n    if (input === kConstruct) {\n      return\n    }\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Request constructor' })\n\n    input = webidl.converters.RequestInfo(input)\n    init = webidl.converters.RequestInit(init)\n\n    // https://html.spec.whatwg.org/multipage/webappapis.html#environment-settings-object\n    this[kRealm] = {\n      settingsObject: {\n        baseUrl: getGlobalOrigin(),\n        get origin () {\n          return this.baseUrl?.origin\n        },\n        policyContainer: makePolicyContainer()\n      }\n    }\n\n    // 1. Let request be null.\n    let request = null\n\n    // 2. Let fallbackMode be null.\n    let fallbackMode = null\n\n    // 3. Let baseURL be thiss relevant settings objects API base URL.\n    const baseUrl = this[kRealm].settingsObject.baseUrl\n\n    // 4. Let signal be null.\n    let signal = null\n\n    // 5. If input is a string, then:\n    if (typeof input === 'string') {\n      // 1. Let parsedURL be the result of parsing input with baseURL.\n      // 2. If parsedURL is failure, then throw a TypeError.\n      let parsedURL\n      try {\n        parsedURL = new URL(input, baseUrl)\n      } catch (err) {\n        throw new TypeError('Failed to parse URL from ' + input, { cause: err })\n      }\n\n      // 3. If parsedURL includes credentials, then throw a TypeError.\n      if (parsedURL.username || parsedURL.password) {\n        throw new TypeError(\n          'Request cannot be constructed from a URL that includes credentials: ' +\n            input\n        )\n      }\n\n      // 4. Set request to a new request whose URL is parsedURL.\n      request = makeRequest({ urlList: [parsedURL] })\n\n      // 5. Set fallbackMode to \"cors\".\n      fallbackMode = 'cors'\n    } else {\n      // 6. Otherwise:\n\n      // 7. Assert: input is a Request object.\n      assert(input instanceof Request)\n\n      // 8. Set request to inputs request.\n      request = input[kState]\n\n      // 9. Set signal to inputs signal.\n      signal = input[kSignal]\n    }\n\n    // 7. Let origin be thiss relevant settings objects origin.\n    const origin = this[kRealm].settingsObject.origin\n\n    // 8. Let window be \"client\".\n    let window = 'client'\n\n    // 9. If requests window is an environment settings object and its origin\n    // is same origin with origin, then set window to requests window.\n    if (\n      request.window?.constructor?.name === 'EnvironmentSettingsObject' &&\n      sameOrigin(request.window, origin)\n    ) {\n      window = request.window\n    }\n\n    // 10. If init[\"window\"] exists and is non-null, then throw a TypeError.\n    if (init.window != null) {\n      throw new TypeError(`'window' option '${window}' must be null`)\n    }\n\n    // 11. If init[\"window\"] exists, then set window to \"no-window\".\n    if ('window' in init) {\n      window = 'no-window'\n    }\n\n    // 12. Set request to a new request with the following properties:\n    request = makeRequest({\n      // URL requests URL.\n      // undici implementation note: this is set as the first item in request's urlList in makeRequest\n      // method requests method.\n      method: request.method,\n      // header list A copy of requests header list.\n      // undici implementation note: headersList is cloned in makeRequest\n      headersList: request.headersList,\n      // unsafe-request flag Set.\n      unsafeRequest: request.unsafeRequest,\n      // client Thiss relevant settings object.\n      client: this[kRealm].settingsObject,\n      // window window.\n      window,\n      // priority requests priority.\n      priority: request.priority,\n      // origin requests origin. The propagation of the origin is only significant for navigation requests\n      // being handled by a service worker. In this scenario a request can have an origin that is different\n      // from the current client.\n      origin: request.origin,\n      // referrer requests referrer.\n      referrer: request.referrer,\n      // referrer policy requests referrer policy.\n      referrerPolicy: request.referrerPolicy,\n      // mode requests mode.\n      mode: request.mode,\n      // credentials mode requests credentials mode.\n      credentials: request.credentials,\n      // cache mode requests cache mode.\n      cache: request.cache,\n      // redirect mode requests redirect mode.\n      redirect: request.redirect,\n      // integrity metadata requests integrity metadata.\n      integrity: request.integrity,\n      // keepalive requests keepalive.\n      keepalive: request.keepalive,\n      // reload-navigation flag requests reload-navigation flag.\n      reloadNavigation: request.reloadNavigation,\n      // history-navigation flag requests history-navigation flag.\n      historyNavigation: request.historyNavigation,\n      // URL list A clone of requests URL list.\n      urlList: [...request.urlList]\n    })\n\n    const initHasKey = Object.keys(init).length !== 0\n\n    // 13. If init is not empty, then:\n    if (initHasKey) {\n      // 1. If requests mode is \"navigate\", then set it to \"same-origin\".\n      if (request.mode === 'navigate') {\n        request.mode = 'same-origin'\n      }\n\n      // 2. Unset requests reload-navigation flag.\n      request.reloadNavigation = false\n\n      // 3. Unset requests history-navigation flag.\n      request.historyNavigation = false\n\n      // 4. Set requests origin to \"client\".\n      request.origin = 'client'\n\n      // 5. Set requests referrer to \"client\"\n      request.referrer = 'client'\n\n      // 6. Set requests referrer policy to the empty string.\n      request.referrerPolicy = ''\n\n      // 7. Set requests URL to requests current URL.\n      request.url = request.urlList[request.urlList.length - 1]\n\n      // 8. Set requests URL list to  requests URL .\n      request.urlList = [request.url]\n    }\n\n    // 14. If init[\"referrer\"] exists, then:\n    if (init.referrer !== undefined) {\n      // 1. Let referrer be init[\"referrer\"].\n      const referrer = init.referrer\n\n      // 2. If referrer is the empty string, then set requests referrer to \"no-referrer\".\n      if (referrer === '') {\n        request.referrer = 'no-referrer'\n      } else {\n        // 1. Let parsedReferrer be the result of parsing referrer with\n        // baseURL.\n        // 2. If parsedReferrer is failure, then throw a TypeError.\n        let parsedReferrer\n        try {\n          parsedReferrer = new URL(referrer, baseUrl)\n        } catch (err) {\n          throw new TypeError(`Referrer \"${referrer}\" is not a valid URL.`, { cause: err })\n        }\n\n        // 3. If one of the following is true\n        // - parsedReferrers scheme is \"about\" and path is the string \"client\"\n        // - parsedReferrers origin is not same origin with origin\n        // then set requests referrer to \"client\".\n        if (\n          (parsedReferrer.protocol === 'about:' && parsedReferrer.hostname === 'client') ||\n          (origin && !sameOrigin(parsedReferrer, this[kRealm].settingsObject.baseUrl))\n        ) {\n          request.referrer = 'client'\n        } else {\n          // 4. Otherwise, set requests referrer to parsedReferrer.\n          request.referrer = parsedReferrer\n        }\n      }\n    }\n\n    // 15. If init[\"referrerPolicy\"] exists, then set requests referrer policy\n    // to it.\n    if (init.referrerPolicy !== undefined) {\n      request.referrerPolicy = init.referrerPolicy\n    }\n\n    // 16. Let mode be init[\"mode\"] if it exists, and fallbackMode otherwise.\n    let mode\n    if (init.mode !== undefined) {\n      mode = init.mode\n    } else {\n      mode = fallbackMode\n    }\n\n    // 17. If mode is \"navigate\", then throw a TypeError.\n    if (mode === 'navigate') {\n      throw webidl.errors.exception({\n        header: 'Request constructor',\n        message: 'invalid request mode navigate.'\n      })\n    }\n\n    // 18. If mode is non-null, set requests mode to mode.\n    if (mode != null) {\n      request.mode = mode\n    }\n\n    // 19. If init[\"credentials\"] exists, then set requests credentials mode\n    // to it.\n    if (init.credentials !== undefined) {\n      request.credentials = init.credentials\n    }\n\n    // 18. If init[\"cache\"] exists, then set requests cache mode to it.\n    if (init.cache !== undefined) {\n      request.cache = init.cache\n    }\n\n    // 21. If requests cache mode is \"only-if-cached\" and requests mode is\n    // not \"same-origin\", then throw a TypeError.\n    if (request.cache === 'only-if-cached' && request.mode !== 'same-origin') {\n      throw new TypeError(\n        \"'only-if-cached' can be set only with 'same-origin' mode\"\n      )\n    }\n\n    // 22. If init[\"redirect\"] exists, then set requests redirect mode to it.\n    if (init.redirect !== undefined) {\n      request.redirect = init.redirect\n    }\n\n    // 23. If init[\"integrity\"] exists, then set requests integrity metadata to it.\n    if (init.integrity != null) {\n      request.integrity = String(init.integrity)\n    }\n\n    // 24. If init[\"keepalive\"] exists, then set requests keepalive to it.\n    if (init.keepalive !== undefined) {\n      request.keepalive = Boolean(init.keepalive)\n    }\n\n    // 25. If init[\"method\"] exists, then:\n    if (init.method !== undefined) {\n      // 1. Let method be init[\"method\"].\n      let method = init.method\n\n      // 2. If method is not a method or method is a forbidden method, then\n      // throw a TypeError.\n      if (!isValidHTTPToken(method)) {\n        throw new TypeError(`'${method}' is not a valid HTTP method.`)\n      }\n\n      if (forbiddenMethodsSet.has(method.toUpperCase())) {\n        throw new TypeError(`'${method}' HTTP method is unsupported.`)\n      }\n\n      // 3. Normalize method.\n      method = normalizeMethodRecord[method] ?? normalizeMethod(method)\n\n      // 4. Set requests method to method.\n      request.method = method\n    }\n\n    // 26. If init[\"signal\"] exists, then set signal to it.\n    if (init.signal !== undefined) {\n      signal = init.signal\n    }\n\n    // 27. Set thiss request to request.\n    this[kState] = request\n\n    // 28. Set thiss signal to a new AbortSignal object with thiss relevant\n    // Realm.\n    // TODO: could this be simplified with AbortSignal.any\n    // (https://dom.spec.whatwg.org/#dom-abortsignal-any)\n    const ac = new AbortController()\n    this[kSignal] = ac.signal\n    this[kSignal][kRealm] = this[kRealm]\n\n    // 29. If signal is not null, then make thiss signal follow signal.\n    if (signal != null) {\n      if (\n        !signal ||\n        typeof signal.aborted !== 'boolean' ||\n        typeof signal.addEventListener !== 'function'\n      ) {\n        throw new TypeError(\n          \"Failed to construct 'Request': member signal is not of type AbortSignal.\"\n        )\n      }\n\n      if (signal.aborted) {\n        ac.abort(signal.reason)\n      } else {\n        // Keep a strong ref to ac while request object\n        // is alive. This is needed to prevent AbortController\n        // from being prematurely garbage collected.\n        // See, https://github.com/nodejs/undici/issues/1926.\n        this[kAbortController] = ac\n\n        const acRef = new WeakRef(ac)\n        const abort = function () {\n          const ac = acRef.deref()\n          if (ac !== undefined) {\n            ac.abort(this.reason)\n          }\n        }\n\n        // Third-party AbortControllers may not work with these.\n        // See, https://github.com/nodejs/undici/pull/1910#issuecomment-1464495619.\n        try {\n          // If the max amount of listeners is equal to the default, increase it\n          // This is only available in node >= v19.9.0\n          if (typeof getMaxListeners === 'function' && getMaxListeners(signal) === defaultMaxListeners) {\n            setMaxListeners(100, signal)\n          } else if (getEventListeners(signal, 'abort').length >= defaultMaxListeners) {\n            setMaxListeners(100, signal)\n          }\n        } catch {}\n\n        util.addAbortListener(signal, abort)\n        requestFinalizer.register(ac, { signal, abort })\n      }\n    }\n\n    // 30. Set thiss headers to a new Headers object with thiss relevant\n    // Realm, whose header list is requests header list and guard is\n    // \"request\".\n    this[kHeaders] = new Headers(kConstruct)\n    this[kHeaders][kHeadersList] = request.headersList\n    this[kHeaders][kGuard] = 'request'\n    this[kHeaders][kRealm] = this[kRealm]\n\n    // 31. If thiss requests mode is \"no-cors\", then:\n    if (mode === 'no-cors') {\n      // 1. If thiss requests method is not a CORS-safelisted method,\n      // then throw a TypeError.\n      if (!corsSafeListedMethodsSet.has(request.method)) {\n        throw new TypeError(\n          `'${request.method} is unsupported in no-cors mode.`\n        )\n      }\n\n      // 2. Set thiss headerss guard to \"request-no-cors\".\n      this[kHeaders][kGuard] = 'request-no-cors'\n    }\n\n    // 32. If init is not empty, then:\n    if (initHasKey) {\n      /** @type {HeadersList} */\n      const headersList = this[kHeaders][kHeadersList]\n      // 1. Let headers be a copy of thiss headers and its associated header\n      // list.\n      // 2. If init[\"headers\"] exists, then set headers to init[\"headers\"].\n      const headers = init.headers !== undefined ? init.headers : new HeadersList(headersList)\n\n      // 3. Empty thiss headerss header list.\n      headersList.clear()\n\n      // 4. If headers is a Headers object, then for each header in its header\n      // list, append headers name/headers value to thiss headers.\n      if (headers instanceof HeadersList) {\n        for (const [key, val] of headers) {\n          headersList.append(key, val)\n        }\n        // Note: Copy the `set-cookie` meta-data.\n        headersList.cookies = headers.cookies\n      } else {\n        // 5. Otherwise, fill thiss headers with headers.\n        fillHeaders(this[kHeaders], headers)\n      }\n    }\n\n    // 33. Let inputBody be inputs requests body if input is a Request\n    // object; otherwise null.\n    const inputBody = input instanceof Request ? input[kState].body : null\n\n    // 34. If either init[\"body\"] exists and is non-null or inputBody is\n    // non-null, and requests method is `GET` or `HEAD`, then throw a\n    // TypeError.\n    if (\n      (init.body != null || inputBody != null) &&\n      (request.method === 'GET' || request.method === 'HEAD')\n    ) {\n      throw new TypeError('Request with GET/HEAD method cannot have body.')\n    }\n\n    // 35. Let initBody be null.\n    let initBody = null\n\n    // 36. If init[\"body\"] exists and is non-null, then:\n    if (init.body != null) {\n      // 1. Let Content-Type be null.\n      // 2. Set initBody and Content-Type to the result of extracting\n      // init[\"body\"], with keepalive set to requests keepalive.\n      const [extractedBody, contentType] = extractBody(\n        init.body,\n        request.keepalive\n      )\n      initBody = extractedBody\n\n      // 3, If Content-Type is non-null and thiss headerss header list does\n      // not contain `Content-Type`, then append `Content-Type`/Content-Type to\n      // thiss headers.\n      if (contentType && !this[kHeaders][kHeadersList].contains('content-type')) {\n        this[kHeaders].append('content-type', contentType)\n      }\n    }\n\n    // 37. Let inputOrInitBody be initBody if it is non-null; otherwise\n    // inputBody.\n    const inputOrInitBody = initBody ?? inputBody\n\n    // 38. If inputOrInitBody is non-null and inputOrInitBodys source is\n    // null, then:\n    if (inputOrInitBody != null && inputOrInitBody.source == null) {\n      // 1. If initBody is non-null and init[\"duplex\"] does not exist,\n      //    then throw a TypeError.\n      if (initBody != null && init.duplex == null) {\n        throw new TypeError('RequestInit: duplex option is required when sending a body.')\n      }\n\n      // 2. If thiss requests mode is neither \"same-origin\" nor \"cors\",\n      // then throw a TypeError.\n      if (request.mode !== 'same-origin' && request.mode !== 'cors') {\n        throw new TypeError(\n          'If request is made from ReadableStream, mode should be \"same-origin\" or \"cors\"'\n        )\n      }\n\n      // 3. Set thiss requests use-CORS-preflight flag.\n      request.useCORSPreflightFlag = true\n    }\n\n    // 39. Let finalBody be inputOrInitBody.\n    let finalBody = inputOrInitBody\n\n    // 40. If initBody is null and inputBody is non-null, then:\n    if (initBody == null && inputBody != null) {\n      // 1. If input is unusable, then throw a TypeError.\n      if (util.isDisturbed(inputBody.stream) || inputBody.stream.locked) {\n        throw new TypeError(\n          'Cannot construct a Request with a Request object that has already been used.'\n        )\n      }\n\n      // 2. Set finalBody to the result of creating a proxy for inputBody.\n      if (!TransformStream) {\n        TransformStream = require('stream/web').TransformStream\n      }\n\n      // https://streams.spec.whatwg.org/#readablestream-create-a-proxy\n      const identityTransform = new TransformStream()\n      inputBody.stream.pipeThrough(identityTransform)\n      finalBody = {\n        source: inputBody.source,\n        length: inputBody.length,\n        stream: identityTransform.readable\n      }\n    }\n\n    // 41. Set thiss requests body to finalBody.\n    this[kState].body = finalBody\n  }\n\n  // Returns requests HTTP method, which is \"GET\" by default.\n  get method () {\n    webidl.brandCheck(this, Request)\n\n    // The method getter steps are to return thiss requests method.\n    return this[kState].method\n  }\n\n  // Returns the URL of request as a string.\n  get url () {\n    webidl.brandCheck(this, Request)\n\n    // The url getter steps are to return thiss requests URL, serialized.\n    return URLSerializer(this[kState].url)\n  }\n\n  // Returns a Headers object consisting of the headers associated with request.\n  // Note that headers added in the network layer by the user agent will not\n  // be accounted for in this object, e.g., the \"Host\" header.\n  get headers () {\n    webidl.brandCheck(this, Request)\n\n    // The headers getter steps are to return thiss headers.\n    return this[kHeaders]\n  }\n\n  // Returns the kind of resource requested by request, e.g., \"document\"\n  // or \"script\".\n  get destination () {\n    webidl.brandCheck(this, Request)\n\n    // The destination getter are to return thiss requests destination.\n    return this[kState].destination\n  }\n\n  // Returns the referrer of request. Its value can be a same-origin URL if\n  // explicitly set in init, the empty string to indicate no referrer, and\n  // \"about:client\" when defaulting to the globals default. This is used\n  // during fetching to determine the value of the `Referer` header of the\n  // request being made.\n  get referrer () {\n    webidl.brandCheck(this, Request)\n\n    // 1. If thiss requests referrer is \"no-referrer\", then return the\n    // empty string.\n    if (this[kState].referrer === 'no-referrer') {\n      return ''\n    }\n\n    // 2. If thiss requests referrer is \"client\", then return\n    // \"about:client\".\n    if (this[kState].referrer === 'client') {\n      return 'about:client'\n    }\n\n    // Return thiss requests referrer, serialized.\n    return this[kState].referrer.toString()\n  }\n\n  // Returns the referrer policy associated with request.\n  // This is used during fetching to compute the value of the requests\n  // referrer.\n  get referrerPolicy () {\n    webidl.brandCheck(this, Request)\n\n    // The referrerPolicy getter steps are to return thiss requests referrer policy.\n    return this[kState].referrerPolicy\n  }\n\n  // Returns the mode associated with request, which is a string indicating\n  // whether the request will use CORS, or will be restricted to same-origin\n  // URLs.\n  get mode () {\n    webidl.brandCheck(this, Request)\n\n    // The mode getter steps are to return thiss requests mode.\n    return this[kState].mode\n  }\n\n  // Returns the credentials mode associated with request,\n  // which is a string indicating whether credentials will be sent with the\n  // request always, never, or only when sent to a same-origin URL.\n  get credentials () {\n    // The credentials getter steps are to return thiss requests credentials mode.\n    return this[kState].credentials\n  }\n\n  // Returns the cache mode associated with request,\n  // which is a string indicating how the request will\n  // interact with the browsers cache when fetching.\n  get cache () {\n    webidl.brandCheck(this, Request)\n\n    // The cache getter steps are to return thiss requests cache mode.\n    return this[kState].cache\n  }\n\n  // Returns the redirect mode associated with request,\n  // which is a string indicating how redirects for the\n  // request will be handled during fetching. A request\n  // will follow redirects by default.\n  get redirect () {\n    webidl.brandCheck(this, Request)\n\n    // The redirect getter steps are to return thiss requests redirect mode.\n    return this[kState].redirect\n  }\n\n  // Returns requests subresource integrity metadata, which is a\n  // cryptographic hash of the resource being fetched. Its value\n  // consists of multiple hashes separated by whitespace. [SRI]\n  get integrity () {\n    webidl.brandCheck(this, Request)\n\n    // The integrity getter steps are to return thiss requests integrity\n    // metadata.\n    return this[kState].integrity\n  }\n\n  // Returns a boolean indicating whether or not request can outlive the\n  // global in which it was created.\n  get keepalive () {\n    webidl.brandCheck(this, Request)\n\n    // The keepalive getter steps are to return thiss requests keepalive.\n    return this[kState].keepalive\n  }\n\n  // Returns a boolean indicating whether or not request is for a reload\n  // navigation.\n  get isReloadNavigation () {\n    webidl.brandCheck(this, Request)\n\n    // The isReloadNavigation getter steps are to return true if thiss\n    // requests reload-navigation flag is set; otherwise false.\n    return this[kState].reloadNavigation\n  }\n\n  // Returns a boolean indicating whether or not request is for a history\n  // navigation (a.k.a. back-foward navigation).\n  get isHistoryNavigation () {\n    webidl.brandCheck(this, Request)\n\n    // The isHistoryNavigation getter steps are to return true if thiss requests\n    // history-navigation flag is set; otherwise false.\n    return this[kState].historyNavigation\n  }\n\n  // Returns the signal associated with request, which is an AbortSignal\n  // object indicating whether or not request has been aborted, and its\n  // abort event handler.\n  get signal () {\n    webidl.brandCheck(this, Request)\n\n    // The signal getter steps are to return thiss signal.\n    return this[kSignal]\n  }\n\n  get body () {\n    webidl.brandCheck(this, Request)\n\n    return this[kState].body ? this[kState].body.stream : null\n  }\n\n  get bodyUsed () {\n    webidl.brandCheck(this, Request)\n\n    return !!this[kState].body && util.isDisturbed(this[kState].body.stream)\n  }\n\n  get duplex () {\n    webidl.brandCheck(this, Request)\n\n    return 'half'\n  }\n\n  // Returns a clone of request.\n  clone () {\n    webidl.brandCheck(this, Request)\n\n    // 1. If this is unusable, then throw a TypeError.\n    if (this.bodyUsed || this.body?.locked) {\n      throw new TypeError('unusable')\n    }\n\n    // 2. Let clonedRequest be the result of cloning thiss request.\n    const clonedRequest = cloneRequest(this[kState])\n\n    // 3. Let clonedRequestObject be the result of creating a Request object,\n    // given clonedRequest, thiss headerss guard, and thiss relevant Realm.\n    const clonedRequestObject = new Request(kConstruct)\n    clonedRequestObject[kState] = clonedRequest\n    clonedRequestObject[kRealm] = this[kRealm]\n    clonedRequestObject[kHeaders] = new Headers(kConstruct)\n    clonedRequestObject[kHeaders][kHeadersList] = clonedRequest.headersList\n    clonedRequestObject[kHeaders][kGuard] = this[kHeaders][kGuard]\n    clonedRequestObject[kHeaders][kRealm] = this[kHeaders][kRealm]\n\n    // 4. Make clonedRequestObjects signal follow thiss signal.\n    const ac = new AbortController()\n    if (this.signal.aborted) {\n      ac.abort(this.signal.reason)\n    } else {\n      util.addAbortListener(\n        this.signal,\n        () => {\n          ac.abort(this.signal.reason)\n        }\n      )\n    }\n    clonedRequestObject[kSignal] = ac.signal\n\n    // 4. Return clonedRequestObject.\n    return clonedRequestObject\n  }\n}\n\nmixinBody(Request)\n\nfunction makeRequest (init) {\n  // https://fetch.spec.whatwg.org/#requests\n  const request = {\n    method: 'GET',\n    localURLsOnly: false,\n    unsafeRequest: false,\n    body: null,\n    client: null,\n    reservedClient: null,\n    replacesClientId: '',\n    window: 'client',\n    keepalive: false,\n    serviceWorkers: 'all',\n    initiator: '',\n    destination: '',\n    priority: null,\n    origin: 'client',\n    policyContainer: 'client',\n    referrer: 'client',\n    referrerPolicy: '',\n    mode: 'no-cors',\n    useCORSPreflightFlag: false,\n    credentials: 'same-origin',\n    useCredentials: false,\n    cache: 'default',\n    redirect: 'follow',\n    integrity: '',\n    cryptoGraphicsNonceMetadata: '',\n    parserMetadata: '',\n    reloadNavigation: false,\n    historyNavigation: false,\n    userActivation: false,\n    taintedOrigin: false,\n    redirectCount: 0,\n    responseTainting: 'basic',\n    preventNoCacheCacheControlHeaderModification: false,\n    done: false,\n    timingAllowFailed: false,\n    ...init,\n    headersList: init.headersList\n      ? new HeadersList(init.headersList)\n      : new HeadersList()\n  }\n  request.url = request.urlList[0]\n  return request\n}\n\n// https://fetch.spec.whatwg.org/#concept-request-clone\nfunction cloneRequest (request) {\n  // To clone a request request, run these steps:\n\n  // 1. Let newRequest be a copy of request, except for its body.\n  const newRequest = makeRequest({ ...request, body: null })\n\n  // 2. If requests body is non-null, set newRequests body to the\n  // result of cloning requests body.\n  if (request.body != null) {\n    newRequest.body = cloneBody(request.body)\n  }\n\n  // 3. Return newRequest.\n  return newRequest\n}\n\nObject.defineProperties(Request.prototype, {\n  method: kEnumerableProperty,\n  url: kEnumerableProperty,\n  headers: kEnumerableProperty,\n  redirect: kEnumerableProperty,\n  clone: kEnumerableProperty,\n  signal: kEnumerableProperty,\n  duplex: kEnumerableProperty,\n  destination: kEnumerableProperty,\n  body: kEnumerableProperty,\n  bodyUsed: kEnumerableProperty,\n  isHistoryNavigation: kEnumerableProperty,\n  isReloadNavigation: kEnumerableProperty,\n  keepalive: kEnumerableProperty,\n  integrity: kEnumerableProperty,\n  cache: kEnumerableProperty,\n  credentials: kEnumerableProperty,\n  attribute: kEnumerableProperty,\n  referrerPolicy: kEnumerableProperty,\n  referrer: kEnumerableProperty,\n  mode: kEnumerableProperty,\n  [Symbol.toStringTag]: {\n    value: 'Request',\n    configurable: true\n  }\n})\n\nwebidl.converters.Request = webidl.interfaceConverter(\n  Request\n)\n\n// https://fetch.spec.whatwg.org/#requestinfo\nwebidl.converters.RequestInfo = function (V) {\n  if (typeof V === 'string') {\n    return webidl.converters.USVString(V)\n  }\n\n  if (V instanceof Request) {\n    return webidl.converters.Request(V)\n  }\n\n  return webidl.converters.USVString(V)\n}\n\nwebidl.converters.AbortSignal = webidl.interfaceConverter(\n  AbortSignal\n)\n\n// https://fetch.spec.whatwg.org/#requestinit\nwebidl.converters.RequestInit = webidl.dictionaryConverter([\n  {\n    key: 'method',\n    converter: webidl.converters.ByteString\n  },\n  {\n    key: 'headers',\n    converter: webidl.converters.HeadersInit\n  },\n  {\n    key: 'body',\n    converter: webidl.nullableConverter(\n      webidl.converters.BodyInit\n    )\n  },\n  {\n    key: 'referrer',\n    converter: webidl.converters.USVString\n  },\n  {\n    key: 'referrerPolicy',\n    converter: webidl.converters.DOMString,\n    // https://w3c.github.io/webappsec-referrer-policy/#referrer-policy\n    allowedValues: referrerPolicy\n  },\n  {\n    key: 'mode',\n    converter: webidl.converters.DOMString,\n    // https://fetch.spec.whatwg.org/#concept-request-mode\n    allowedValues: requestMode\n  },\n  {\n    key: 'credentials',\n    converter: webidl.converters.DOMString,\n    // https://fetch.spec.whatwg.org/#requestcredentials\n    allowedValues: requestCredentials\n  },\n  {\n    key: 'cache',\n    converter: webidl.converters.DOMString,\n    // https://fetch.spec.whatwg.org/#requestcache\n    allowedValues: requestCache\n  },\n  {\n    key: 'redirect',\n    converter: webidl.converters.DOMString,\n    // https://fetch.spec.whatwg.org/#requestredirect\n    allowedValues: requestRedirect\n  },\n  {\n    key: 'integrity',\n    converter: webidl.converters.DOMString\n  },\n  {\n    key: 'keepalive',\n    converter: webidl.converters.boolean\n  },\n  {\n    key: 'signal',\n    converter: webidl.nullableConverter(\n      (signal) => webidl.converters.AbortSignal(\n        signal,\n        { strict: false }\n      )\n    )\n  },\n  {\n    key: 'window',\n    converter: webidl.converters.any\n  },\n  {\n    key: 'duplex',\n    converter: webidl.converters.DOMString,\n    allowedValues: requestDuplex\n  }\n])\n\nmodule.exports = { Request, makeRequest }\n","'use strict'\n\nconst { Headers, HeadersList, fill } = require('./headers')\nconst { extractBody, cloneBody, mixinBody } = require('./body')\nconst util = require('../core/util')\nconst { kEnumerableProperty } = util\nconst {\n  isValidReasonPhrase,\n  isCancelled,\n  isAborted,\n  isBlobLike,\n  serializeJavascriptValueToJSONString,\n  isErrorLike,\n  isomorphicEncode\n} = require('./util')\nconst {\n  redirectStatusSet,\n  nullBodyStatus,\n  DOMException\n} = require('./constants')\nconst { kState, kHeaders, kGuard, kRealm } = require('./symbols')\nconst { webidl } = require('./webidl')\nconst { FormData } = require('./formdata')\nconst { getGlobalOrigin } = require('./global')\nconst { URLSerializer } = require('./dataURL')\nconst { kHeadersList, kConstruct } = require('../core/symbols')\nconst assert = require('assert')\nconst { types } = require('util')\n\nconst ReadableStream = globalThis.ReadableStream || require('stream/web').ReadableStream\nconst textEncoder = new TextEncoder('utf-8')\n\n// https://fetch.spec.whatwg.org/#response-class\nclass Response {\n  // Creates network error Response.\n  static error () {\n    // TODO\n    const relevantRealm = { settingsObject: {} }\n\n    // The static error() method steps are to return the result of creating a\n    // Response object, given a new network error, \"immutable\", and thiss\n    // relevant Realm.\n    const responseObject = new Response()\n    responseObject[kState] = makeNetworkError()\n    responseObject[kRealm] = relevantRealm\n    responseObject[kHeaders][kHeadersList] = responseObject[kState].headersList\n    responseObject[kHeaders][kGuard] = 'immutable'\n    responseObject[kHeaders][kRealm] = relevantRealm\n    return responseObject\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-response-json\n  static json (data, init = {}) {\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Response.json' })\n\n    if (init !== null) {\n      init = webidl.converters.ResponseInit(init)\n    }\n\n    // 1. Let bytes the result of running serialize a JavaScript value to JSON bytes on data.\n    const bytes = textEncoder.encode(\n      serializeJavascriptValueToJSONString(data)\n    )\n\n    // 2. Let body be the result of extracting bytes.\n    const body = extractBody(bytes)\n\n    // 3. Let responseObject be the result of creating a Response object, given a new response,\n    //    \"response\", and thiss relevant Realm.\n    const relevantRealm = { settingsObject: {} }\n    const responseObject = new Response()\n    responseObject[kRealm] = relevantRealm\n    responseObject[kHeaders][kGuard] = 'response'\n    responseObject[kHeaders][kRealm] = relevantRealm\n\n    // 4. Perform initialize a response given responseObject, init, and (body, \"application/json\").\n    initializeResponse(responseObject, init, { body: body[0], type: 'application/json' })\n\n    // 5. Return responseObject.\n    return responseObject\n  }\n\n  // Creates a redirect Response that redirects to url with status status.\n  static redirect (url, status = 302) {\n    const relevantRealm = { settingsObject: {} }\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'Response.redirect' })\n\n    url = webidl.converters.USVString(url)\n    status = webidl.converters['unsigned short'](status)\n\n    // 1. Let parsedURL be the result of parsing url with current settings\n    // objects API base URL.\n    // 2. If parsedURL is failure, then throw a TypeError.\n    // TODO: base-URL?\n    let parsedURL\n    try {\n      parsedURL = new URL(url, getGlobalOrigin())\n    } catch (err) {\n      throw Object.assign(new TypeError('Failed to parse URL from ' + url), {\n        cause: err\n      })\n    }\n\n    // 3. If status is not a redirect status, then throw a RangeError.\n    if (!redirectStatusSet.has(status)) {\n      throw new RangeError('Invalid status code ' + status)\n    }\n\n    // 4. Let responseObject be the result of creating a Response object,\n    // given a new response, \"immutable\", and thiss relevant Realm.\n    const responseObject = new Response()\n    responseObject[kRealm] = relevantRealm\n    responseObject[kHeaders][kGuard] = 'immutable'\n    responseObject[kHeaders][kRealm] = relevantRealm\n\n    // 5. Set responseObjects responses status to status.\n    responseObject[kState].status = status\n\n    // 6. Let value be parsedURL, serialized and isomorphic encoded.\n    const value = isomorphicEncode(URLSerializer(parsedURL))\n\n    // 7. Append `Location`/value to responseObjects responses header list.\n    responseObject[kState].headersList.append('location', value)\n\n    // 8. Return responseObject.\n    return responseObject\n  }\n\n  // https://fetch.spec.whatwg.org/#dom-response\n  constructor (body = null, init = {}) {\n    if (body !== null) {\n      body = webidl.converters.BodyInit(body)\n    }\n\n    init = webidl.converters.ResponseInit(init)\n\n    // TODO\n    this[kRealm] = { settingsObject: {} }\n\n    // 1. Set thiss response to a new response.\n    this[kState] = makeResponse({})\n\n    // 2. Set thiss headers to a new Headers object with thiss relevant\n    // Realm, whose header list is thiss responses header list and guard\n    // is \"response\".\n    this[kHeaders] = new Headers(kConstruct)\n    this[kHeaders][kGuard] = 'response'\n    this[kHeaders][kHeadersList] = this[kState].headersList\n    this[kHeaders][kRealm] = this[kRealm]\n\n    // 3. Let bodyWithType be null.\n    let bodyWithType = null\n\n    // 4. If body is non-null, then set bodyWithType to the result of extracting body.\n    if (body != null) {\n      const [extractedBody, type] = extractBody(body)\n      bodyWithType = { body: extractedBody, type }\n    }\n\n    // 5. Perform initialize a response given this, init, and bodyWithType.\n    initializeResponse(this, init, bodyWithType)\n  }\n\n  // Returns responses type, e.g., \"cors\".\n  get type () {\n    webidl.brandCheck(this, Response)\n\n    // The type getter steps are to return thiss responses type.\n    return this[kState].type\n  }\n\n  // Returns responses URL, if it has one; otherwise the empty string.\n  get url () {\n    webidl.brandCheck(this, Response)\n\n    const urlList = this[kState].urlList\n\n    // The url getter steps are to return the empty string if thiss\n    // responses URL is null; otherwise thiss responses URL,\n    // serialized with exclude fragment set to true.\n    const url = urlList[urlList.length - 1] ?? null\n\n    if (url === null) {\n      return ''\n    }\n\n    return URLSerializer(url, true)\n  }\n\n  // Returns whether response was obtained through a redirect.\n  get redirected () {\n    webidl.brandCheck(this, Response)\n\n    // The redirected getter steps are to return true if thiss responses URL\n    // list has more than one item; otherwise false.\n    return this[kState].urlList.length > 1\n  }\n\n  // Returns responses status.\n  get status () {\n    webidl.brandCheck(this, Response)\n\n    // The status getter steps are to return thiss responses status.\n    return this[kState].status\n  }\n\n  // Returns whether responses status is an ok status.\n  get ok () {\n    webidl.brandCheck(this, Response)\n\n    // The ok getter steps are to return true if thiss responses status is an\n    // ok status; otherwise false.\n    return this[kState].status >= 200 && this[kState].status <= 299\n  }\n\n  // Returns responses status message.\n  get statusText () {\n    webidl.brandCheck(this, Response)\n\n    // The statusText getter steps are to return thiss responses status\n    // message.\n    return this[kState].statusText\n  }\n\n  // Returns responses headers as Headers.\n  get headers () {\n    webidl.brandCheck(this, Response)\n\n    // The headers getter steps are to return thiss headers.\n    return this[kHeaders]\n  }\n\n  get body () {\n    webidl.brandCheck(this, Response)\n\n    return this[kState].body ? this[kState].body.stream : null\n  }\n\n  get bodyUsed () {\n    webidl.brandCheck(this, Response)\n\n    return !!this[kState].body && util.isDisturbed(this[kState].body.stream)\n  }\n\n  // Returns a clone of response.\n  clone () {\n    webidl.brandCheck(this, Response)\n\n    // 1. If this is unusable, then throw a TypeError.\n    if (this.bodyUsed || (this.body && this.body.locked)) {\n      throw webidl.errors.exception({\n        header: 'Response.clone',\n        message: 'Body has already been consumed.'\n      })\n    }\n\n    // 2. Let clonedResponse be the result of cloning thiss response.\n    const clonedResponse = cloneResponse(this[kState])\n\n    // 3. Return the result of creating a Response object, given\n    // clonedResponse, thiss headerss guard, and thiss relevant Realm.\n    const clonedResponseObject = new Response()\n    clonedResponseObject[kState] = clonedResponse\n    clonedResponseObject[kRealm] = this[kRealm]\n    clonedResponseObject[kHeaders][kHeadersList] = clonedResponse.headersList\n    clonedResponseObject[kHeaders][kGuard] = this[kHeaders][kGuard]\n    clonedResponseObject[kHeaders][kRealm] = this[kHeaders][kRealm]\n\n    return clonedResponseObject\n  }\n}\n\nmixinBody(Response)\n\nObject.defineProperties(Response.prototype, {\n  type: kEnumerableProperty,\n  url: kEnumerableProperty,\n  status: kEnumerableProperty,\n  ok: kEnumerableProperty,\n  redirected: kEnumerableProperty,\n  statusText: kEnumerableProperty,\n  headers: kEnumerableProperty,\n  clone: kEnumerableProperty,\n  body: kEnumerableProperty,\n  bodyUsed: kEnumerableProperty,\n  [Symbol.toStringTag]: {\n    value: 'Response',\n    configurable: true\n  }\n})\n\nObject.defineProperties(Response, {\n  json: kEnumerableProperty,\n  redirect: kEnumerableProperty,\n  error: kEnumerableProperty\n})\n\n// https://fetch.spec.whatwg.org/#concept-response-clone\nfunction cloneResponse (response) {\n  // To clone a response response, run these steps:\n\n  // 1. If response is a filtered response, then return a new identical\n  // filtered response whose internal response is a clone of responses\n  // internal response.\n  if (response.internalResponse) {\n    return filterResponse(\n      cloneResponse(response.internalResponse),\n      response.type\n    )\n  }\n\n  // 2. Let newResponse be a copy of response, except for its body.\n  const newResponse = makeResponse({ ...response, body: null })\n\n  // 3. If responses body is non-null, then set newResponses body to the\n  // result of cloning responses body.\n  if (response.body != null) {\n    newResponse.body = cloneBody(response.body)\n  }\n\n  // 4. Return newResponse.\n  return newResponse\n}\n\nfunction makeResponse (init) {\n  return {\n    aborted: false,\n    rangeRequested: false,\n    timingAllowPassed: false,\n    requestIncludesCredentials: false,\n    type: 'default',\n    status: 200,\n    timingInfo: null,\n    cacheState: '',\n    statusText: '',\n    ...init,\n    headersList: init.headersList\n      ? new HeadersList(init.headersList)\n      : new HeadersList(),\n    urlList: init.urlList ? [...init.urlList] : []\n  }\n}\n\nfunction makeNetworkError (reason) {\n  const isError = isErrorLike(reason)\n  return makeResponse({\n    type: 'error',\n    status: 0,\n    error: isError\n      ? reason\n      : new Error(reason ? String(reason) : reason),\n    aborted: reason && reason.name === 'AbortError'\n  })\n}\n\nfunction makeFilteredResponse (response, state) {\n  state = {\n    internalResponse: response,\n    ...state\n  }\n\n  return new Proxy(response, {\n    get (target, p) {\n      return p in state ? state[p] : target[p]\n    },\n    set (target, p, value) {\n      assert(!(p in state))\n      target[p] = value\n      return true\n    }\n  })\n}\n\n// https://fetch.spec.whatwg.org/#concept-filtered-response\nfunction filterResponse (response, type) {\n  // Set response to the following filtered response with response as its\n  // internal response, depending on requests response tainting:\n  if (type === 'basic') {\n    // A basic filtered response is a filtered response whose type is \"basic\"\n    // and header list excludes any headers in internal responses header list\n    // whose name is a forbidden response-header name.\n\n    // Note: undici does not implement forbidden response-header names\n    return makeFilteredResponse(response, {\n      type: 'basic',\n      headersList: response.headersList\n    })\n  } else if (type === 'cors') {\n    // A CORS filtered response is a filtered response whose type is \"cors\"\n    // and header list excludes any headers in internal responses header\n    // list whose name is not a CORS-safelisted response-header name, given\n    // internal responses CORS-exposed header-name list.\n\n    // Note: undici does not implement CORS-safelisted response-header names\n    return makeFilteredResponse(response, {\n      type: 'cors',\n      headersList: response.headersList\n    })\n  } else if (type === 'opaque') {\n    // An opaque filtered response is a filtered response whose type is\n    // \"opaque\", URL list is the empty list, status is 0, status message\n    // is the empty byte sequence, header list is empty, and body is null.\n\n    return makeFilteredResponse(response, {\n      type: 'opaque',\n      urlList: Object.freeze([]),\n      status: 0,\n      statusText: '',\n      body: null\n    })\n  } else if (type === 'opaqueredirect') {\n    // An opaque-redirect filtered response is a filtered response whose type\n    // is \"opaqueredirect\", status is 0, status message is the empty byte\n    // sequence, header list is empty, and body is null.\n\n    return makeFilteredResponse(response, {\n      type: 'opaqueredirect',\n      status: 0,\n      statusText: '',\n      headersList: [],\n      body: null\n    })\n  } else {\n    assert(false)\n  }\n}\n\n// https://fetch.spec.whatwg.org/#appropriate-network-error\nfunction makeAppropriateNetworkError (fetchParams, err = null) {\n  // 1. Assert: fetchParams is canceled.\n  assert(isCancelled(fetchParams))\n\n  // 2. Return an aborted network error if fetchParams is aborted;\n  // otherwise return a network error.\n  return isAborted(fetchParams)\n    ? makeNetworkError(Object.assign(new DOMException('The operation was aborted.', 'AbortError'), { cause: err }))\n    : makeNetworkError(Object.assign(new DOMException('Request was cancelled.'), { cause: err }))\n}\n\n// https://whatpr.org/fetch/1392.html#initialize-a-response\nfunction initializeResponse (response, init, body) {\n  // 1. If init[\"status\"] is not in the range 200 to 599, inclusive, then\n  //    throw a RangeError.\n  if (init.status !== null && (init.status < 200 || init.status > 599)) {\n    throw new RangeError('init[\"status\"] must be in the range of 200 to 599, inclusive.')\n  }\n\n  // 2. If init[\"statusText\"] does not match the reason-phrase token production,\n  //    then throw a TypeError.\n  if ('statusText' in init && init.statusText != null) {\n    // See, https://datatracker.ietf.org/doc/html/rfc7230#section-3.1.2:\n    //   reason-phrase  = *( HTAB / SP / VCHAR / obs-text )\n    if (!isValidReasonPhrase(String(init.statusText))) {\n      throw new TypeError('Invalid statusText')\n    }\n  }\n\n  // 3. Set responses responses status to init[\"status\"].\n  if ('status' in init && init.status != null) {\n    response[kState].status = init.status\n  }\n\n  // 4. Set responses responses status message to init[\"statusText\"].\n  if ('statusText' in init && init.statusText != null) {\n    response[kState].statusText = init.statusText\n  }\n\n  // 5. If init[\"headers\"] exists, then fill responses headers with init[\"headers\"].\n  if ('headers' in init && init.headers != null) {\n    fill(response[kHeaders], init.headers)\n  }\n\n  // 6. If body was given, then:\n  if (body) {\n    // 1. If response's status is a null body status, then throw a TypeError.\n    if (nullBodyStatus.includes(response.status)) {\n      throw webidl.errors.exception({\n        header: 'Response constructor',\n        message: 'Invalid response status code ' + response.status\n      })\n    }\n\n    // 2. Set response's body to body's body.\n    response[kState].body = body.body\n\n    // 3. If body's type is non-null and response's header list does not contain\n    //    `Content-Type`, then append (`Content-Type`, body's type) to response's header list.\n    if (body.type != null && !response[kState].headersList.contains('Content-Type')) {\n      response[kState].headersList.append('content-type', body.type)\n    }\n  }\n}\n\nwebidl.converters.ReadableStream = webidl.interfaceConverter(\n  ReadableStream\n)\n\nwebidl.converters.FormData = webidl.interfaceConverter(\n  FormData\n)\n\nwebidl.converters.URLSearchParams = webidl.interfaceConverter(\n  URLSearchParams\n)\n\n// https://fetch.spec.whatwg.org/#typedefdef-xmlhttprequestbodyinit\nwebidl.converters.XMLHttpRequestBodyInit = function (V) {\n  if (typeof V === 'string') {\n    return webidl.converters.USVString(V)\n  }\n\n  if (isBlobLike(V)) {\n    return webidl.converters.Blob(V, { strict: false })\n  }\n\n  if (types.isArrayBuffer(V) || types.isTypedArray(V) || types.isDataView(V)) {\n    return webidl.converters.BufferSource(V)\n  }\n\n  if (util.isFormDataLike(V)) {\n    return webidl.converters.FormData(V, { strict: false })\n  }\n\n  if (V instanceof URLSearchParams) {\n    return webidl.converters.URLSearchParams(V)\n  }\n\n  return webidl.converters.DOMString(V)\n}\n\n// https://fetch.spec.whatwg.org/#bodyinit\nwebidl.converters.BodyInit = function (V) {\n  if (V instanceof ReadableStream) {\n    return webidl.converters.ReadableStream(V)\n  }\n\n  // Note: the spec doesn't include async iterables,\n  // this is an undici extension.\n  if (V?.[Symbol.asyncIterator]) {\n    return V\n  }\n\n  return webidl.converters.XMLHttpRequestBodyInit(V)\n}\n\nwebidl.converters.ResponseInit = webidl.dictionaryConverter([\n  {\n    key: 'status',\n    converter: webidl.converters['unsigned short'],\n    defaultValue: 200\n  },\n  {\n    key: 'statusText',\n    converter: webidl.converters.ByteString,\n    defaultValue: ''\n  },\n  {\n    key: 'headers',\n    converter: webidl.converters.HeadersInit\n  }\n])\n\nmodule.exports = {\n  makeNetworkError,\n  makeResponse,\n  makeAppropriateNetworkError,\n  filterResponse,\n  Response,\n  cloneResponse\n}\n","'use strict'\n\nmodule.exports = {\n  kUrl: Symbol('url'),\n  kHeaders: Symbol('headers'),\n  kSignal: Symbol('signal'),\n  kState: Symbol('state'),\n  kGuard: Symbol('guard'),\n  kRealm: Symbol('realm')\n}\n","'use strict'\n\nconst { redirectStatusSet, referrerPolicySet: referrerPolicyTokens, badPortsSet } = require('./constants')\nconst { getGlobalOrigin } = require('./global')\nconst { performance } = require('perf_hooks')\nconst { isBlobLike, toUSVString, ReadableStreamFrom } = require('../core/util')\nconst assert = require('assert')\nconst { isUint8Array } = require('util/types')\n\nlet supportedHashes = []\n\n// https://nodejs.org/api/crypto.html#determining-if-crypto-support-is-unavailable\n/** @type {import('crypto')|undefined} */\nlet crypto\n\ntry {\n  crypto = require('crypto')\n  const possibleRelevantHashes = ['sha256', 'sha384', 'sha512']\n  supportedHashes = crypto.getHashes().filter((hash) => possibleRelevantHashes.includes(hash))\n/* c8 ignore next 3 */\n} catch {\n}\n\nfunction responseURL (response) {\n  // https://fetch.spec.whatwg.org/#responses\n  // A response has an associated URL. It is a pointer to the last URL\n  // in responses URL list and null if responses URL list is empty.\n  const urlList = response.urlList\n  const length = urlList.length\n  return length === 0 ? null : urlList[length - 1].toString()\n}\n\n// https://fetch.spec.whatwg.org/#concept-response-location-url\nfunction responseLocationURL (response, requestFragment) {\n  // 1. If responses status is not a redirect status, then return null.\n  if (!redirectStatusSet.has(response.status)) {\n    return null\n  }\n\n  // 2. Let location be the result of extracting header list values given\n  // `Location` and responses header list.\n  let location = response.headersList.get('location')\n\n  // 3. If location is a header value, then set location to the result of\n  //    parsing location with responses URL.\n  if (location !== null && isValidHeaderValue(location)) {\n    location = new URL(location, responseURL(response))\n  }\n\n  // 4. If location is a URL whose fragment is null, then set locations\n  // fragment to requestFragment.\n  if (location && !location.hash) {\n    location.hash = requestFragment\n  }\n\n  // 5. Return location.\n  return location\n}\n\n/** @returns {URL} */\nfunction requestCurrentURL (request) {\n  return request.urlList[request.urlList.length - 1]\n}\n\nfunction requestBadPort (request) {\n  // 1. Let url be requests current URL.\n  const url = requestCurrentURL(request)\n\n  // 2. If urls scheme is an HTTP(S) scheme and urls port is a bad port,\n  // then return blocked.\n  if (urlIsHttpHttpsScheme(url) && badPortsSet.has(url.port)) {\n    return 'blocked'\n  }\n\n  // 3. Return allowed.\n  return 'allowed'\n}\n\nfunction isErrorLike (object) {\n  return object instanceof Error || (\n    object?.constructor?.name === 'Error' ||\n    object?.constructor?.name === 'DOMException'\n  )\n}\n\n// Check whether |statusText| is a ByteString and\n// matches the Reason-Phrase token production.\n// RFC 2616: https://tools.ietf.org/html/rfc2616\n// RFC 7230: https://tools.ietf.org/html/rfc7230\n// \"reason-phrase = *( HTAB / SP / VCHAR / obs-text )\"\n// https://github.com/chromium/chromium/blob/94.0.4604.1/third_party/blink/renderer/core/fetch/response.cc#L116\nfunction isValidReasonPhrase (statusText) {\n  for (let i = 0; i < statusText.length; ++i) {\n    const c = statusText.charCodeAt(i)\n    if (\n      !(\n        (\n          c === 0x09 || // HTAB\n          (c >= 0x20 && c <= 0x7e) || // SP / VCHAR\n          (c >= 0x80 && c <= 0xff)\n        ) // obs-text\n      )\n    ) {\n      return false\n    }\n  }\n  return true\n}\n\n/**\n * @see https://tools.ietf.org/html/rfc7230#section-3.2.6\n * @param {number} c\n */\nfunction isTokenCharCode (c) {\n  switch (c) {\n    case 0x22:\n    case 0x28:\n    case 0x29:\n    case 0x2c:\n    case 0x2f:\n    case 0x3a:\n    case 0x3b:\n    case 0x3c:\n    case 0x3d:\n    case 0x3e:\n    case 0x3f:\n    case 0x40:\n    case 0x5b:\n    case 0x5c:\n    case 0x5d:\n    case 0x7b:\n    case 0x7d:\n      // DQUOTE and \"(),/:;<=>?@[\\]{}\"\n      return false\n    default:\n      // VCHAR %x21-7E\n      return c >= 0x21 && c <= 0x7e\n  }\n}\n\n/**\n * @param {string} characters\n */\nfunction isValidHTTPToken (characters) {\n  if (characters.length === 0) {\n    return false\n  }\n  for (let i = 0; i < characters.length; ++i) {\n    if (!isTokenCharCode(characters.charCodeAt(i))) {\n      return false\n    }\n  }\n  return true\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#header-name\n * @param {string} potentialValue\n */\nfunction isValidHeaderName (potentialValue) {\n  return isValidHTTPToken(potentialValue)\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#header-value\n * @param {string} potentialValue\n */\nfunction isValidHeaderValue (potentialValue) {\n  // - Has no leading or trailing HTTP tab or space bytes.\n  // - Contains no 0x00 (NUL) or HTTP newline bytes.\n  if (\n    potentialValue.startsWith('\\t') ||\n    potentialValue.startsWith(' ') ||\n    potentialValue.endsWith('\\t') ||\n    potentialValue.endsWith(' ')\n  ) {\n    return false\n  }\n\n  if (\n    potentialValue.includes('\\0') ||\n    potentialValue.includes('\\r') ||\n    potentialValue.includes('\\n')\n  ) {\n    return false\n  }\n\n  return true\n}\n\n// https://w3c.github.io/webappsec-referrer-policy/#set-requests-referrer-policy-on-redirect\nfunction setRequestReferrerPolicyOnRedirect (request, actualResponse) {\n  //  Given a request request and a response actualResponse, this algorithm\n  //  updates requests referrer policy according to the Referrer-Policy\n  //  header (if any) in actualResponse.\n\n  // 1. Let policy be the result of executing  8.1 Parse a referrer policy\n  // from a Referrer-Policy header on actualResponse.\n\n  // 8.1 Parse a referrer policy from a Referrer-Policy header\n  // 1. Let policy-tokens be the result of extracting header list values given `Referrer-Policy` and responses header list.\n  const { headersList } = actualResponse\n  // 2. Let policy be the empty string.\n  // 3. For each token in policy-tokens, if token is a referrer policy and token is not the empty string, then set policy to token.\n  // 4. Return policy.\n  const policyHeader = (headersList.get('referrer-policy') ?? '').split(',')\n\n  // Note: As the referrer-policy can contain multiple policies\n  // separated by comma, we need to loop through all of them\n  // and pick the first valid one.\n  // Ref: https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referrer-Policy#specify_a_fallback_policy\n  let policy = ''\n  if (policyHeader.length > 0) {\n    // The right-most policy takes precedence.\n    // The left-most policy is the fallback.\n    for (let i = policyHeader.length; i !== 0; i--) {\n      const token = policyHeader[i - 1].trim()\n      if (referrerPolicyTokens.has(token)) {\n        policy = token\n        break\n      }\n    }\n  }\n\n  // 2. If policy is not the empty string, then set requests referrer policy to policy.\n  if (policy !== '') {\n    request.referrerPolicy = policy\n  }\n}\n\n// https://fetch.spec.whatwg.org/#cross-origin-resource-policy-check\nfunction crossOriginResourcePolicyCheck () {\n  // TODO\n  return 'allowed'\n}\n\n// https://fetch.spec.whatwg.org/#concept-cors-check\nfunction corsCheck () {\n  // TODO\n  return 'success'\n}\n\n// https://fetch.spec.whatwg.org/#concept-tao-check\nfunction TAOCheck () {\n  // TODO\n  return 'success'\n}\n\nfunction appendFetchMetadata (httpRequest) {\n  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-dest-header\n  //  TODO\n\n  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-mode-header\n\n  //  1. Assert: rs url is a potentially trustworthy URL.\n  //  TODO\n\n  //  2. Let header be a Structured Header whose value is a token.\n  let header = null\n\n  //  3. Set headers value to rs mode.\n  header = httpRequest.mode\n\n  //  4. Set a structured field value `Sec-Fetch-Mode`/header in rs header list.\n  httpRequest.headersList.set('sec-fetch-mode', header)\n\n  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-site-header\n  //  TODO\n\n  //  https://w3c.github.io/webappsec-fetch-metadata/#sec-fetch-user-header\n  //  TODO\n}\n\n// https://fetch.spec.whatwg.org/#append-a-request-origin-header\nfunction appendRequestOriginHeader (request) {\n  // 1. Let serializedOrigin be the result of byte-serializing a request origin with request.\n  let serializedOrigin = request.origin\n\n  // 2. If requests response tainting is \"cors\" or requests mode is \"websocket\", then append (`Origin`, serializedOrigin) to requests header list.\n  if (request.responseTainting === 'cors' || request.mode === 'websocket') {\n    if (serializedOrigin) {\n      request.headersList.append('origin', serializedOrigin)\n    }\n\n  // 3. Otherwise, if requests method is neither `GET` nor `HEAD`, then:\n  } else if (request.method !== 'GET' && request.method !== 'HEAD') {\n    // 1. Switch on requests referrer policy:\n    switch (request.referrerPolicy) {\n      case 'no-referrer':\n        // Set serializedOrigin to `null`.\n        serializedOrigin = null\n        break\n      case 'no-referrer-when-downgrade':\n      case 'strict-origin':\n      case 'strict-origin-when-cross-origin':\n        // If requests origin is a tuple origin, its scheme is \"https\", and requests current URLs scheme is not \"https\", then set serializedOrigin to `null`.\n        if (request.origin && urlHasHttpsScheme(request.origin) && !urlHasHttpsScheme(requestCurrentURL(request))) {\n          serializedOrigin = null\n        }\n        break\n      case 'same-origin':\n        // If requests origin is not same origin with requests current URLs origin, then set serializedOrigin to `null`.\n        if (!sameOrigin(request, requestCurrentURL(request))) {\n          serializedOrigin = null\n        }\n        break\n      default:\n        // Do nothing.\n    }\n\n    if (serializedOrigin) {\n      // 2. Append (`Origin`, serializedOrigin) to requests header list.\n      request.headersList.append('origin', serializedOrigin)\n    }\n  }\n}\n\nfunction coarsenedSharedCurrentTime (crossOriginIsolatedCapability) {\n  // TODO\n  return performance.now()\n}\n\n// https://fetch.spec.whatwg.org/#create-an-opaque-timing-info\nfunction createOpaqueTimingInfo (timingInfo) {\n  return {\n    startTime: timingInfo.startTime ?? 0,\n    redirectStartTime: 0,\n    redirectEndTime: 0,\n    postRedirectStartTime: timingInfo.startTime ?? 0,\n    finalServiceWorkerStartTime: 0,\n    finalNetworkResponseStartTime: 0,\n    finalNetworkRequestStartTime: 0,\n    endTime: 0,\n    encodedBodySize: 0,\n    decodedBodySize: 0,\n    finalConnectionTimingInfo: null\n  }\n}\n\n// https://html.spec.whatwg.org/multipage/origin.html#policy-container\nfunction makePolicyContainer () {\n  // Note: the fetch spec doesn't make use of embedder policy or CSP list\n  return {\n    referrerPolicy: 'strict-origin-when-cross-origin'\n  }\n}\n\n// https://html.spec.whatwg.org/multipage/origin.html#clone-a-policy-container\nfunction clonePolicyContainer (policyContainer) {\n  return {\n    referrerPolicy: policyContainer.referrerPolicy\n  }\n}\n\n// https://w3c.github.io/webappsec-referrer-policy/#determine-requests-referrer\nfunction determineRequestsReferrer (request) {\n  // 1. Let policy be request's referrer policy.\n  const policy = request.referrerPolicy\n\n  // Note: policy cannot (shouldn't) be null or an empty string.\n  assert(policy)\n\n  // 2. Let environment be requests client.\n\n  let referrerSource = null\n\n  // 3. Switch on requests referrer:\n  if (request.referrer === 'client') {\n    // Note: node isn't a browser and doesn't implement document/iframes,\n    // so we bypass this step and replace it with our own.\n\n    const globalOrigin = getGlobalOrigin()\n\n    if (!globalOrigin || globalOrigin.origin === 'null') {\n      return 'no-referrer'\n    }\n\n    // note: we need to clone it as it's mutated\n    referrerSource = new URL(globalOrigin)\n  } else if (request.referrer instanceof URL) {\n    // Let referrerSource be requests referrer.\n    referrerSource = request.referrer\n  }\n\n  // 4. Let requests referrerURL be the result of stripping referrerSource for\n  //    use as a referrer.\n  let referrerURL = stripURLForReferrer(referrerSource)\n\n  // 5. Let referrerOrigin be the result of stripping referrerSource for use as\n  //    a referrer, with the origin-only flag set to true.\n  const referrerOrigin = stripURLForReferrer(referrerSource, true)\n\n  // 6. If the result of serializing referrerURL is a string whose length is\n  //    greater than 4096, set referrerURL to referrerOrigin.\n  if (referrerURL.toString().length > 4096) {\n    referrerURL = referrerOrigin\n  }\n\n  const areSameOrigin = sameOrigin(request, referrerURL)\n  const isNonPotentiallyTrustWorthy = isURLPotentiallyTrustworthy(referrerURL) &&\n    !isURLPotentiallyTrustworthy(request.url)\n\n  // 8. Execute the switch statements corresponding to the value of policy:\n  switch (policy) {\n    case 'origin': return referrerOrigin != null ? referrerOrigin : stripURLForReferrer(referrerSource, true)\n    case 'unsafe-url': return referrerURL\n    case 'same-origin':\n      return areSameOrigin ? referrerOrigin : 'no-referrer'\n    case 'origin-when-cross-origin':\n      return areSameOrigin ? referrerURL : referrerOrigin\n    case 'strict-origin-when-cross-origin': {\n      const currentURL = requestCurrentURL(request)\n\n      // 1. If the origin of referrerURL and the origin of requests current\n      //    URL are the same, then return referrerURL.\n      if (sameOrigin(referrerURL, currentURL)) {\n        return referrerURL\n      }\n\n      // 2. If referrerURL is a potentially trustworthy URL and requests\n      //    current URL is not a potentially trustworthy URL, then return no\n      //    referrer.\n      if (isURLPotentiallyTrustworthy(referrerURL) && !isURLPotentiallyTrustworthy(currentURL)) {\n        return 'no-referrer'\n      }\n\n      // 3. Return referrerOrigin.\n      return referrerOrigin\n    }\n    case 'strict-origin': // eslint-disable-line\n      /**\n         * 1. If referrerURL is a potentially trustworthy URL and\n         * requests current URL is not a potentially trustworthy URL,\n         * then return no referrer.\n         * 2. Return referrerOrigin\n        */\n    case 'no-referrer-when-downgrade': // eslint-disable-line\n      /**\n       * 1. If referrerURL is a potentially trustworthy URL and\n       * requests current URL is not a potentially trustworthy URL,\n       * then return no referrer.\n       * 2. Return referrerOrigin\n      */\n\n    default: // eslint-disable-line\n      return isNonPotentiallyTrustWorthy ? 'no-referrer' : referrerOrigin\n  }\n}\n\n/**\n * @see https://w3c.github.io/webappsec-referrer-policy/#strip-url\n * @param {URL} url\n * @param {boolean|undefined} originOnly\n */\nfunction stripURLForReferrer (url, originOnly) {\n  // 1. Assert: url is a URL.\n  assert(url instanceof URL)\n\n  // 2. If urls scheme is a local scheme, then return no referrer.\n  if (url.protocol === 'file:' || url.protocol === 'about:' || url.protocol === 'blank:') {\n    return 'no-referrer'\n  }\n\n  // 3. Set urls username to the empty string.\n  url.username = ''\n\n  // 4. Set urls password to the empty string.\n  url.password = ''\n\n  // 5. Set urls fragment to null.\n  url.hash = ''\n\n  // 6. If the origin-only flag is true, then:\n  if (originOnly) {\n    // 1. Set urls path to  the empty string .\n    url.pathname = ''\n\n    // 2. Set urls query to null.\n    url.search = ''\n  }\n\n  // 7. Return url.\n  return url\n}\n\nfunction isURLPotentiallyTrustworthy (url) {\n  if (!(url instanceof URL)) {\n    return false\n  }\n\n  // If child of about, return true\n  if (url.href === 'about:blank' || url.href === 'about:srcdoc') {\n    return true\n  }\n\n  // If scheme is data, return true\n  if (url.protocol === 'data:') return true\n\n  // If file, return true\n  if (url.protocol === 'file:') return true\n\n  return isOriginPotentiallyTrustworthy(url.origin)\n\n  function isOriginPotentiallyTrustworthy (origin) {\n    // If origin is explicitly null, return false\n    if (origin == null || origin === 'null') return false\n\n    const originAsURL = new URL(origin)\n\n    // If secure, return true\n    if (originAsURL.protocol === 'https:' || originAsURL.protocol === 'wss:') {\n      return true\n    }\n\n    // If localhost or variants, return true\n    if (/^127(?:\\.[0-9]+){0,2}\\.[0-9]+$|^\\[(?:0*:)*?:?0*1\\]$/.test(originAsURL.hostname) ||\n     (originAsURL.hostname === 'localhost' || originAsURL.hostname.includes('localhost.')) ||\n     (originAsURL.hostname.endsWith('.localhost'))) {\n      return true\n    }\n\n    // If any other, return false\n    return false\n  }\n}\n\n/**\n * @see https://w3c.github.io/webappsec-subresource-integrity/#does-response-match-metadatalist\n * @param {Uint8Array} bytes\n * @param {string} metadataList\n */\nfunction bytesMatch (bytes, metadataList) {\n  // If node is not built with OpenSSL support, we cannot check\n  // a request's integrity, so allow it by default (the spec will\n  // allow requests if an invalid hash is given, as precedence).\n  /* istanbul ignore if: only if node is built with --without-ssl */\n  if (crypto === undefined) {\n    return true\n  }\n\n  // 1. Let parsedMetadata be the result of parsing metadataList.\n  const parsedMetadata = parseMetadata(metadataList)\n\n  // 2. If parsedMetadata is no metadata, return true.\n  if (parsedMetadata === 'no metadata') {\n    return true\n  }\n\n  // 3. If response is not eligible for integrity validation, return false.\n  // TODO\n\n  // 4. If parsedMetadata is the empty set, return true.\n  if (parsedMetadata.length === 0) {\n    return true\n  }\n\n  // 5. Let metadata be the result of getting the strongest\n  //    metadata from parsedMetadata.\n  const strongest = getStrongestMetadata(parsedMetadata)\n  const metadata = filterMetadataListByAlgorithm(parsedMetadata, strongest)\n\n  // 6. For each item in metadata:\n  for (const item of metadata) {\n    // 1. Let algorithm be the alg component of item.\n    const algorithm = item.algo\n\n    // 2. Let expectedValue be the val component of item.\n    const expectedValue = item.hash\n\n    // See https://github.com/web-platform-tests/wpt/commit/e4c5cc7a5e48093220528dfdd1c4012dc3837a0e\n    // \"be liberal with padding\". This is annoying, and it's not even in the spec.\n\n    // 3. Let actualValue be the result of applying algorithm to bytes.\n    let actualValue = crypto.createHash(algorithm).update(bytes).digest('base64')\n\n    if (actualValue[actualValue.length - 1] === '=') {\n      if (actualValue[actualValue.length - 2] === '=') {\n        actualValue = actualValue.slice(0, -2)\n      } else {\n        actualValue = actualValue.slice(0, -1)\n      }\n    }\n\n    // 4. If actualValue is a case-sensitive match for expectedValue,\n    //    return true.\n    if (compareBase64Mixed(actualValue, expectedValue)) {\n      return true\n    }\n  }\n\n  // 7. Return false.\n  return false\n}\n\n// https://w3c.github.io/webappsec-subresource-integrity/#grammardef-hash-with-options\n// https://www.w3.org/TR/CSP2/#source-list-syntax\n// https://www.rfc-editor.org/rfc/rfc5234#appendix-B.1\nconst parseHashWithOptions = /(?<algo>sha256|sha384|sha512)-((?<hash>[A-Za-z0-9+/]+|[A-Za-z0-9_-]+)={0,2}(?:\\s|$)( +[!-~]*)?)?/i\n\n/**\n * @see https://w3c.github.io/webappsec-subresource-integrity/#parse-metadata\n * @param {string} metadata\n */\nfunction parseMetadata (metadata) {\n  // 1. Let result be the empty set.\n  /** @type {{ algo: string, hash: string }[]} */\n  const result = []\n\n  // 2. Let empty be equal to true.\n  let empty = true\n\n  // 3. For each token returned by splitting metadata on spaces:\n  for (const token of metadata.split(' ')) {\n    // 1. Set empty to false.\n    empty = false\n\n    // 2. Parse token as a hash-with-options.\n    const parsedToken = parseHashWithOptions.exec(token)\n\n    // 3. If token does not parse, continue to the next token.\n    if (\n      parsedToken === null ||\n      parsedToken.groups === undefined ||\n      parsedToken.groups.algo === undefined\n    ) {\n      // Note: Chromium blocks the request at this point, but Firefox\n      // gives a warning that an invalid integrity was given. The\n      // correct behavior is to ignore these, and subsequently not\n      // check the integrity of the resource.\n      continue\n    }\n\n    // 4. Let algorithm be the hash-algo component of token.\n    const algorithm = parsedToken.groups.algo.toLowerCase()\n\n    // 5. If algorithm is a hash function recognized by the user\n    //    agent, add the parsed token to result.\n    if (supportedHashes.includes(algorithm)) {\n      result.push(parsedToken.groups)\n    }\n  }\n\n  // 4. Return no metadata if empty is true, otherwise return result.\n  if (empty === true) {\n    return 'no metadata'\n  }\n\n  return result\n}\n\n/**\n * @param {{ algo: 'sha256' | 'sha384' | 'sha512' }[]} metadataList\n */\nfunction getStrongestMetadata (metadataList) {\n  // Let algorithm be the algo component of the first item in metadataList.\n  // Can be sha256\n  let algorithm = metadataList[0].algo\n  // If the algorithm is sha512, then it is the strongest\n  // and we can return immediately\n  if (algorithm[3] === '5') {\n    return algorithm\n  }\n\n  for (let i = 1; i < metadataList.length; ++i) {\n    const metadata = metadataList[i]\n    // If the algorithm is sha512, then it is the strongest\n    // and we can break the loop immediately\n    if (metadata.algo[3] === '5') {\n      algorithm = 'sha512'\n      break\n    // If the algorithm is sha384, then a potential sha256 or sha384 is ignored\n    } else if (algorithm[3] === '3') {\n      continue\n    // algorithm is sha256, check if algorithm is sha384 and if so, set it as\n    // the strongest\n    } else if (metadata.algo[3] === '3') {\n      algorithm = 'sha384'\n    }\n  }\n  return algorithm\n}\n\nfunction filterMetadataListByAlgorithm (metadataList, algorithm) {\n  if (metadataList.length === 1) {\n    return metadataList\n  }\n\n  let pos = 0\n  for (let i = 0; i < metadataList.length; ++i) {\n    if (metadataList[i].algo === algorithm) {\n      metadataList[pos++] = metadataList[i]\n    }\n  }\n\n  metadataList.length = pos\n\n  return metadataList\n}\n\n/**\n * Compares two base64 strings, allowing for base64url\n * in the second string.\n *\n* @param {string} actualValue always base64\n * @param {string} expectedValue base64 or base64url\n * @returns {boolean}\n */\nfunction compareBase64Mixed (actualValue, expectedValue) {\n  if (actualValue.length !== expectedValue.length) {\n    return false\n  }\n  for (let i = 0; i < actualValue.length; ++i) {\n    if (actualValue[i] !== expectedValue[i]) {\n      if (\n        (actualValue[i] === '+' && expectedValue[i] === '-') ||\n        (actualValue[i] === '/' && expectedValue[i] === '_')\n      ) {\n        continue\n      }\n      return false\n    }\n  }\n\n  return true\n}\n\n// https://w3c.github.io/webappsec-upgrade-insecure-requests/#upgrade-request\nfunction tryUpgradeRequestToAPotentiallyTrustworthyURL (request) {\n  // TODO\n}\n\n/**\n * @link {https://html.spec.whatwg.org/multipage/origin.html#same-origin}\n * @param {URL} A\n * @param {URL} B\n */\nfunction sameOrigin (A, B) {\n  // 1. If A and B are the same opaque origin, then return true.\n  if (A.origin === B.origin && A.origin === 'null') {\n    return true\n  }\n\n  // 2. If A and B are both tuple origins and their schemes,\n  //    hosts, and port are identical, then return true.\n  if (A.protocol === B.protocol && A.hostname === B.hostname && A.port === B.port) {\n    return true\n  }\n\n  // 3. Return false.\n  return false\n}\n\nfunction createDeferredPromise () {\n  let res\n  let rej\n  const promise = new Promise((resolve, reject) => {\n    res = resolve\n    rej = reject\n  })\n\n  return { promise, resolve: res, reject: rej }\n}\n\nfunction isAborted (fetchParams) {\n  return fetchParams.controller.state === 'aborted'\n}\n\nfunction isCancelled (fetchParams) {\n  return fetchParams.controller.state === 'aborted' ||\n    fetchParams.controller.state === 'terminated'\n}\n\nconst normalizeMethodRecord = {\n  delete: 'DELETE',\n  DELETE: 'DELETE',\n  get: 'GET',\n  GET: 'GET',\n  head: 'HEAD',\n  HEAD: 'HEAD',\n  options: 'OPTIONS',\n  OPTIONS: 'OPTIONS',\n  post: 'POST',\n  POST: 'POST',\n  put: 'PUT',\n  PUT: 'PUT'\n}\n\n// Note: object prototypes should not be able to be referenced. e.g. `Object#hasOwnProperty`.\nObject.setPrototypeOf(normalizeMethodRecord, null)\n\n/**\n * @see https://fetch.spec.whatwg.org/#concept-method-normalize\n * @param {string} method\n */\nfunction normalizeMethod (method) {\n  return normalizeMethodRecord[method.toLowerCase()] ?? method\n}\n\n// https://infra.spec.whatwg.org/#serialize-a-javascript-value-to-a-json-string\nfunction serializeJavascriptValueToJSONString (value) {\n  // 1. Let result be ? Call(%JSON.stringify%, undefined,  value ).\n  const result = JSON.stringify(value)\n\n  // 2. If result is undefined, then throw a TypeError.\n  if (result === undefined) {\n    throw new TypeError('Value is not JSON serializable')\n  }\n\n  // 3. Assert: result is a string.\n  assert(typeof result === 'string')\n\n  // 4. Return result.\n  return result\n}\n\n// https://tc39.es/ecma262/#sec-%25iteratorprototype%25-object\nconst esIteratorPrototype = Object.getPrototypeOf(Object.getPrototypeOf([][Symbol.iterator]()))\n\n/**\n * @see https://webidl.spec.whatwg.org/#dfn-iterator-prototype-object\n * @param {() => unknown[]} iterator\n * @param {string} name name of the instance\n * @param {'key'|'value'|'key+value'} kind\n */\nfunction makeIterator (iterator, name, kind) {\n  const object = {\n    index: 0,\n    kind,\n    target: iterator\n  }\n\n  const i = {\n    next () {\n      // 1. Let interface be the interface for which the iterator prototype object exists.\n\n      // 2. Let thisValue be the this value.\n\n      // 3. Let object be ? ToObject(thisValue).\n\n      // 4. If object is a platform object, then perform a security\n      //    check, passing:\n\n      // 5. If object is not a default iterator object for interface,\n      //    then throw a TypeError.\n      if (Object.getPrototypeOf(this) !== i) {\n        throw new TypeError(\n          `'next' called on an object that does not implement interface ${name} Iterator.`\n        )\n      }\n\n      // 6. Let index be objects index.\n      // 7. Let kind be objects kind.\n      // 8. Let values be objects target's value pairs to iterate over.\n      const { index, kind, target } = object\n      const values = target()\n\n      // 9. Let len be the length of values.\n      const len = values.length\n\n      // 10. If index is greater than or equal to len, then return\n      //     CreateIterResultObject(undefined, true).\n      if (index >= len) {\n        return { value: undefined, done: true }\n      }\n\n      // 11. Let pair be the entry in values at index index.\n      const pair = values[index]\n\n      // 12. Set objects index to index + 1.\n      object.index = index + 1\n\n      // 13. Return the iterator result for pair and kind.\n      return iteratorResult(pair, kind)\n    },\n    // The class string of an iterator prototype object for a given interface is the\n    // result of concatenating the identifier of the interface and the string \" Iterator\".\n    [Symbol.toStringTag]: `${name} Iterator`\n  }\n\n  // The [[Prototype]] internal slot of an iterator prototype object must be %IteratorPrototype%.\n  Object.setPrototypeOf(i, esIteratorPrototype)\n  // esIteratorPrototype needs to be the prototype of i\n  // which is the prototype of an empty object. Yes, it's confusing.\n  return Object.setPrototypeOf({}, i)\n}\n\n// https://webidl.spec.whatwg.org/#iterator-result\nfunction iteratorResult (pair, kind) {\n  let result\n\n  // 1. Let result be a value determined by the value of kind:\n  switch (kind) {\n    case 'key': {\n      // 1. Let idlKey be pairs key.\n      // 2. Let key be the result of converting idlKey to an\n      //    ECMAScript value.\n      // 3. result is key.\n      result = pair[0]\n      break\n    }\n    case 'value': {\n      // 1. Let idlValue be pairs value.\n      // 2. Let value be the result of converting idlValue to\n      //    an ECMAScript value.\n      // 3. result is value.\n      result = pair[1]\n      break\n    }\n    case 'key+value': {\n      // 1. Let idlKey be pairs key.\n      // 2. Let idlValue be pairs value.\n      // 3. Let key be the result of converting idlKey to an\n      //    ECMAScript value.\n      // 4. Let value be the result of converting idlValue to\n      //    an ECMAScript value.\n      // 5. Let array be ! ArrayCreate(2).\n      // 6. Call ! CreateDataProperty(array, \"0\", key).\n      // 7. Call ! CreateDataProperty(array, \"1\", value).\n      // 8. result is array.\n      result = pair\n      break\n    }\n  }\n\n  // 2. Return CreateIterResultObject(result, false).\n  return { value: result, done: false }\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#body-fully-read\n */\nasync function fullyReadBody (body, processBody, processBodyError) {\n  // 1. If taskDestination is null, then set taskDestination to\n  //    the result of starting a new parallel queue.\n\n  // 2. Let successSteps given a byte sequence bytes be to queue a\n  //    fetch task to run processBody given bytes, with taskDestination.\n  const successSteps = processBody\n\n  // 3. Let errorSteps be to queue a fetch task to run processBodyError,\n  //    with taskDestination.\n  const errorSteps = processBodyError\n\n  // 4. Let reader be the result of getting a reader for bodys stream.\n  //    If that threw an exception, then run errorSteps with that\n  //    exception and return.\n  let reader\n\n  try {\n    reader = body.stream.getReader()\n  } catch (e) {\n    errorSteps(e)\n    return\n  }\n\n  // 5. Read all bytes from reader, given successSteps and errorSteps.\n  try {\n    const result = await readAllBytes(reader)\n    successSteps(result)\n  } catch (e) {\n    errorSteps(e)\n  }\n}\n\n/** @type {ReadableStream} */\nlet ReadableStream = globalThis.ReadableStream\n\nfunction isReadableStreamLike (stream) {\n  if (!ReadableStream) {\n    ReadableStream = require('stream/web').ReadableStream\n  }\n\n  return stream instanceof ReadableStream || (\n    stream[Symbol.toStringTag] === 'ReadableStream' &&\n    typeof stream.tee === 'function'\n  )\n}\n\nconst MAXIMUM_ARGUMENT_LENGTH = 65535\n\n/**\n * @see https://infra.spec.whatwg.org/#isomorphic-decode\n * @param {number[]|Uint8Array} input\n */\nfunction isomorphicDecode (input) {\n  // 1. To isomorphic decode a byte sequence input, return a string whose code point\n  //    length is equal to inputs length and whose code points have the same values\n  //    as the values of inputs bytes, in the same order.\n\n  if (input.length < MAXIMUM_ARGUMENT_LENGTH) {\n    return String.fromCharCode(...input)\n  }\n\n  return input.reduce((previous, current) => previous + String.fromCharCode(current), '')\n}\n\n/**\n * @param {ReadableStreamController<Uint8Array>} controller\n */\nfunction readableStreamClose (controller) {\n  try {\n    controller.close()\n  } catch (err) {\n    // TODO: add comment explaining why this error occurs.\n    if (!err.message.includes('Controller is already closed')) {\n      throw err\n    }\n  }\n}\n\n/**\n * @see https://infra.spec.whatwg.org/#isomorphic-encode\n * @param {string} input\n */\nfunction isomorphicEncode (input) {\n  // 1. Assert: input contains no code points greater than U+00FF.\n  for (let i = 0; i < input.length; i++) {\n    assert(input.charCodeAt(i) <= 0xFF)\n  }\n\n  // 2. Return a byte sequence whose length is equal to inputs code\n  //    point length and whose bytes have the same values as the\n  //    values of inputs code points, in the same order\n  return input\n}\n\n/**\n * @see https://streams.spec.whatwg.org/#readablestreamdefaultreader-read-all-bytes\n * @see https://streams.spec.whatwg.org/#read-loop\n * @param {ReadableStreamDefaultReader} reader\n */\nasync function readAllBytes (reader) {\n  const bytes = []\n  let byteLength = 0\n\n  while (true) {\n    const { done, value: chunk } = await reader.read()\n\n    if (done) {\n      // 1. Call successSteps with bytes.\n      return Buffer.concat(bytes, byteLength)\n    }\n\n    // 1. If chunk is not a Uint8Array object, call failureSteps\n    //    with a TypeError and abort these steps.\n    if (!isUint8Array(chunk)) {\n      throw new TypeError('Received non-Uint8Array chunk')\n    }\n\n    // 2. Append the bytes represented by chunk to bytes.\n    bytes.push(chunk)\n    byteLength += chunk.length\n\n    // 3. Read-loop given reader, bytes, successSteps, and failureSteps.\n  }\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#is-local\n * @param {URL} url\n */\nfunction urlIsLocal (url) {\n  assert('protocol' in url) // ensure it's a url object\n\n  const protocol = url.protocol\n\n  return protocol === 'about:' || protocol === 'blob:' || protocol === 'data:'\n}\n\n/**\n * @param {string|URL} url\n */\nfunction urlHasHttpsScheme (url) {\n  if (typeof url === 'string') {\n    return url.startsWith('https:')\n  }\n\n  return url.protocol === 'https:'\n}\n\n/**\n * @see https://fetch.spec.whatwg.org/#http-scheme\n * @param {URL} url\n */\nfunction urlIsHttpHttpsScheme (url) {\n  assert('protocol' in url) // ensure it's a url object\n\n  const protocol = url.protocol\n\n  return protocol === 'http:' || protocol === 'https:'\n}\n\n/**\n * Fetch supports node >= 16.8.0, but Object.hasOwn was added in v16.9.0.\n */\nconst hasOwn = Object.hasOwn || ((dict, key) => Object.prototype.hasOwnProperty.call(dict, key))\n\nmodule.exports = {\n  isAborted,\n  isCancelled,\n  createDeferredPromise,\n  ReadableStreamFrom,\n  toUSVString,\n  tryUpgradeRequestToAPotentiallyTrustworthyURL,\n  coarsenedSharedCurrentTime,\n  determineRequestsReferrer,\n  makePolicyContainer,\n  clonePolicyContainer,\n  appendFetchMetadata,\n  appendRequestOriginHeader,\n  TAOCheck,\n  corsCheck,\n  crossOriginResourcePolicyCheck,\n  createOpaqueTimingInfo,\n  setRequestReferrerPolicyOnRedirect,\n  isValidHTTPToken,\n  requestBadPort,\n  requestCurrentURL,\n  responseURL,\n  responseLocationURL,\n  isBlobLike,\n  isURLPotentiallyTrustworthy,\n  isValidReasonPhrase,\n  sameOrigin,\n  normalizeMethod,\n  serializeJavascriptValueToJSONString,\n  makeIterator,\n  isValidHeaderName,\n  isValidHeaderValue,\n  hasOwn,\n  isErrorLike,\n  fullyReadBody,\n  bytesMatch,\n  isReadableStreamLike,\n  readableStreamClose,\n  isomorphicEncode,\n  isomorphicDecode,\n  urlIsLocal,\n  urlHasHttpsScheme,\n  urlIsHttpHttpsScheme,\n  readAllBytes,\n  normalizeMethodRecord,\n  parseMetadata\n}\n","'use strict'\n\nconst { types } = require('util')\nconst { hasOwn, toUSVString } = require('./util')\n\n/** @type {import('../../types/webidl').Webidl} */\nconst webidl = {}\nwebidl.converters = {}\nwebidl.util = {}\nwebidl.errors = {}\n\nwebidl.errors.exception = function (message) {\n  return new TypeError(`${message.header}: ${message.message}`)\n}\n\nwebidl.errors.conversionFailed = function (context) {\n  const plural = context.types.length === 1 ? '' : ' one of'\n  const message =\n    `${context.argument} could not be converted to` +\n    `${plural}: ${context.types.join(', ')}.`\n\n  return webidl.errors.exception({\n    header: context.prefix,\n    message\n  })\n}\n\nwebidl.errors.invalidArgument = function (context) {\n  return webidl.errors.exception({\n    header: context.prefix,\n    message: `\"${context.value}\" is an invalid ${context.type}.`\n  })\n}\n\n// https://webidl.spec.whatwg.org/#implements\nwebidl.brandCheck = function (V, I, opts = undefined) {\n  if (opts?.strict !== false && !(V instanceof I)) {\n    throw new TypeError('Illegal invocation')\n  } else {\n    return V?.[Symbol.toStringTag] === I.prototype[Symbol.toStringTag]\n  }\n}\n\nwebidl.argumentLengthCheck = function ({ length }, min, ctx) {\n  if (length < min) {\n    throw webidl.errors.exception({\n      message: `${min} argument${min !== 1 ? 's' : ''} required, ` +\n               `but${length ? ' only' : ''} ${length} found.`,\n      ...ctx\n    })\n  }\n}\n\nwebidl.illegalConstructor = function () {\n  throw webidl.errors.exception({\n    header: 'TypeError',\n    message: 'Illegal constructor'\n  })\n}\n\n// https://tc39.es/ecma262/#sec-ecmascript-data-types-and-values\nwebidl.util.Type = function (V) {\n  switch (typeof V) {\n    case 'undefined': return 'Undefined'\n    case 'boolean': return 'Boolean'\n    case 'string': return 'String'\n    case 'symbol': return 'Symbol'\n    case 'number': return 'Number'\n    case 'bigint': return 'BigInt'\n    case 'function':\n    case 'object': {\n      if (V === null) {\n        return 'Null'\n      }\n\n      return 'Object'\n    }\n  }\n}\n\n// https://webidl.spec.whatwg.org/#abstract-opdef-converttoint\nwebidl.util.ConvertToInt = function (V, bitLength, signedness, opts = {}) {\n  let upperBound\n  let lowerBound\n\n  // 1. If bitLength is 64, then:\n  if (bitLength === 64) {\n    // 1. Let upperBound be 2^53  1.\n    upperBound = Math.pow(2, 53) - 1\n\n    // 2. If signedness is \"unsigned\", then let lowerBound be 0.\n    if (signedness === 'unsigned') {\n      lowerBound = 0\n    } else {\n      // 3. Otherwise let lowerBound be 2^53 + 1.\n      lowerBound = Math.pow(-2, 53) + 1\n    }\n  } else if (signedness === 'unsigned') {\n    // 2. Otherwise, if signedness is \"unsigned\", then:\n\n    // 1. Let lowerBound be 0.\n    lowerBound = 0\n\n    // 2. Let upperBound be 2^bitLength  1.\n    upperBound = Math.pow(2, bitLength) - 1\n  } else {\n    // 3. Otherwise:\n\n    // 1. Let lowerBound be -2^bitLength  1.\n    lowerBound = Math.pow(-2, bitLength) - 1\n\n    // 2. Let upperBound be 2^bitLength  1  1.\n    upperBound = Math.pow(2, bitLength - 1) - 1\n  }\n\n  // 4. Let x be ? ToNumber(V).\n  let x = Number(V)\n\n  // 5. If x is 0, then set x to +0.\n  if (x === 0) {\n    x = 0\n  }\n\n  // 6. If the conversion is to an IDL type associated\n  //    with the [EnforceRange] extended attribute, then:\n  if (opts.enforceRange === true) {\n    // 1. If x is NaN, +, or , then throw a TypeError.\n    if (\n      Number.isNaN(x) ||\n      x === Number.POSITIVE_INFINITY ||\n      x === Number.NEGATIVE_INFINITY\n    ) {\n      throw webidl.errors.exception({\n        header: 'Integer conversion',\n        message: `Could not convert ${V} to an integer.`\n      })\n    }\n\n    // 2. Set x to IntegerPart(x).\n    x = webidl.util.IntegerPart(x)\n\n    // 3. If x < lowerBound or x > upperBound, then\n    //    throw a TypeError.\n    if (x < lowerBound || x > upperBound) {\n      throw webidl.errors.exception({\n        header: 'Integer conversion',\n        message: `Value must be between ${lowerBound}-${upperBound}, got ${x}.`\n      })\n    }\n\n    // 4. Return x.\n    return x\n  }\n\n  // 7. If x is not NaN and the conversion is to an IDL\n  //    type associated with the [Clamp] extended\n  //    attribute, then:\n  if (!Number.isNaN(x) && opts.clamp === true) {\n    // 1. Set x to min(max(x, lowerBound), upperBound).\n    x = Math.min(Math.max(x, lowerBound), upperBound)\n\n    // 2. Round x to the nearest integer, choosing the\n    //    even integer if it lies halfway between two,\n    //    and choosing +0 rather than 0.\n    if (Math.floor(x) % 2 === 0) {\n      x = Math.floor(x)\n    } else {\n      x = Math.ceil(x)\n    }\n\n    // 3. Return x.\n    return x\n  }\n\n  // 8. If x is NaN, +0, +, or , then return +0.\n  if (\n    Number.isNaN(x) ||\n    (x === 0 && Object.is(0, x)) ||\n    x === Number.POSITIVE_INFINITY ||\n    x === Number.NEGATIVE_INFINITY\n  ) {\n    return 0\n  }\n\n  // 9. Set x to IntegerPart(x).\n  x = webidl.util.IntegerPart(x)\n\n  // 10. Set x to x modulo 2^bitLength.\n  x = x % Math.pow(2, bitLength)\n\n  // 11. If signedness is \"signed\" and x  2^bitLength  1,\n  //    then return x  2^bitLength.\n  if (signedness === 'signed' && x >= Math.pow(2, bitLength) - 1) {\n    return x - Math.pow(2, bitLength)\n  }\n\n  // 12. Otherwise, return x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#abstract-opdef-integerpart\nwebidl.util.IntegerPart = function (n) {\n  // 1. Let r be floor(abs(n)).\n  const r = Math.floor(Math.abs(n))\n\n  // 2. If n < 0, then return -1  r.\n  if (n < 0) {\n    return -1 * r\n  }\n\n  // 3. Otherwise, return r.\n  return r\n}\n\n// https://webidl.spec.whatwg.org/#es-sequence\nwebidl.sequenceConverter = function (converter) {\n  return (V) => {\n    // 1. If Type(V) is not Object, throw a TypeError.\n    if (webidl.util.Type(V) !== 'Object') {\n      throw webidl.errors.exception({\n        header: 'Sequence',\n        message: `Value of type ${webidl.util.Type(V)} is not an Object.`\n      })\n    }\n\n    // 2. Let method be ? GetMethod(V, @@iterator).\n    /** @type {Generator} */\n    const method = V?.[Symbol.iterator]?.()\n    const seq = []\n\n    // 3. If method is undefined, throw a TypeError.\n    if (\n      method === undefined ||\n      typeof method.next !== 'function'\n    ) {\n      throw webidl.errors.exception({\n        header: 'Sequence',\n        message: 'Object is not an iterator.'\n      })\n    }\n\n    // https://webidl.spec.whatwg.org/#create-sequence-from-iterable\n    while (true) {\n      const { done, value } = method.next()\n\n      if (done) {\n        break\n      }\n\n      seq.push(converter(value))\n    }\n\n    return seq\n  }\n}\n\n// https://webidl.spec.whatwg.org/#es-to-record\nwebidl.recordConverter = function (keyConverter, valueConverter) {\n  return (O) => {\n    // 1. If Type(O) is not Object, throw a TypeError.\n    if (webidl.util.Type(O) !== 'Object') {\n      throw webidl.errors.exception({\n        header: 'Record',\n        message: `Value of type ${webidl.util.Type(O)} is not an Object.`\n      })\n    }\n\n    // 2. Let result be a new empty instance of record<K, V>.\n    const result = {}\n\n    if (!types.isProxy(O)) {\n      // Object.keys only returns enumerable properties\n      const keys = Object.keys(O)\n\n      for (const key of keys) {\n        // 1. Let typedKey be key converted to an IDL value of type K.\n        const typedKey = keyConverter(key)\n\n        // 2. Let value be ? Get(O, key).\n        // 3. Let typedValue be value converted to an IDL value of type V.\n        const typedValue = valueConverter(O[key])\n\n        // 4. Set result[typedKey] to typedValue.\n        result[typedKey] = typedValue\n      }\n\n      // 5. Return result.\n      return result\n    }\n\n    // 3. Let keys be ? O.[[OwnPropertyKeys]]().\n    const keys = Reflect.ownKeys(O)\n\n    // 4. For each key of keys.\n    for (const key of keys) {\n      // 1. Let desc be ? O.[[GetOwnProperty]](key).\n      const desc = Reflect.getOwnPropertyDescriptor(O, key)\n\n      // 2. If desc is not undefined and desc.[[Enumerable]] is true:\n      if (desc?.enumerable) {\n        // 1. Let typedKey be key converted to an IDL value of type K.\n        const typedKey = keyConverter(key)\n\n        // 2. Let value be ? Get(O, key).\n        // 3. Let typedValue be value converted to an IDL value of type V.\n        const typedValue = valueConverter(O[key])\n\n        // 4. Set result[typedKey] to typedValue.\n        result[typedKey] = typedValue\n      }\n    }\n\n    // 5. Return result.\n    return result\n  }\n}\n\nwebidl.interfaceConverter = function (i) {\n  return (V, opts = {}) => {\n    if (opts.strict !== false && !(V instanceof i)) {\n      throw webidl.errors.exception({\n        header: i.name,\n        message: `Expected ${V} to be an instance of ${i.name}.`\n      })\n    }\n\n    return V\n  }\n}\n\nwebidl.dictionaryConverter = function (converters) {\n  return (dictionary) => {\n    const type = webidl.util.Type(dictionary)\n    const dict = {}\n\n    if (type === 'Null' || type === 'Undefined') {\n      return dict\n    } else if (type !== 'Object') {\n      throw webidl.errors.exception({\n        header: 'Dictionary',\n        message: `Expected ${dictionary} to be one of: Null, Undefined, Object.`\n      })\n    }\n\n    for (const options of converters) {\n      const { key, defaultValue, required, converter } = options\n\n      if (required === true) {\n        if (!hasOwn(dictionary, key)) {\n          throw webidl.errors.exception({\n            header: 'Dictionary',\n            message: `Missing required key \"${key}\".`\n          })\n        }\n      }\n\n      let value = dictionary[key]\n      const hasDefault = hasOwn(options, 'defaultValue')\n\n      // Only use defaultValue if value is undefined and\n      // a defaultValue options was provided.\n      if (hasDefault && value !== null) {\n        value = value ?? defaultValue\n      }\n\n      // A key can be optional and have no default value.\n      // When this happens, do not perform a conversion,\n      // and do not assign the key a value.\n      if (required || hasDefault || value !== undefined) {\n        value = converter(value)\n\n        if (\n          options.allowedValues &&\n          !options.allowedValues.includes(value)\n        ) {\n          throw webidl.errors.exception({\n            header: 'Dictionary',\n            message: `${value} is not an accepted type. Expected one of ${options.allowedValues.join(', ')}.`\n          })\n        }\n\n        dict[key] = value\n      }\n    }\n\n    return dict\n  }\n}\n\nwebidl.nullableConverter = function (converter) {\n  return (V) => {\n    if (V === null) {\n      return V\n    }\n\n    return converter(V)\n  }\n}\n\n// https://webidl.spec.whatwg.org/#es-DOMString\nwebidl.converters.DOMString = function (V, opts = {}) {\n  // 1. If V is null and the conversion is to an IDL type\n  //    associated with the [LegacyNullToEmptyString]\n  //    extended attribute, then return the DOMString value\n  //    that represents the empty string.\n  if (V === null && opts.legacyNullToEmptyString) {\n    return ''\n  }\n\n  // 2. Let x be ? ToString(V).\n  if (typeof V === 'symbol') {\n    throw new TypeError('Could not convert argument of type symbol to string.')\n  }\n\n  // 3. Return the IDL DOMString value that represents the\n  //    same sequence of code units as the one the\n  //    ECMAScript String value x represents.\n  return String(V)\n}\n\n// https://webidl.spec.whatwg.org/#es-ByteString\nwebidl.converters.ByteString = function (V) {\n  // 1. Let x be ? ToString(V).\n  // Note: DOMString converter perform ? ToString(V)\n  const x = webidl.converters.DOMString(V)\n\n  // 2. If the value of any element of x is greater than\n  //    255, then throw a TypeError.\n  for (let index = 0; index < x.length; index++) {\n    if (x.charCodeAt(index) > 255) {\n      throw new TypeError(\n        'Cannot convert argument to a ByteString because the character at ' +\n        `index ${index} has a value of ${x.charCodeAt(index)} which is greater than 255.`\n      )\n    }\n  }\n\n  // 3. Return an IDL ByteString value whose length is the\n  //    length of x, and where the value of each element is\n  //    the value of the corresponding element of x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-USVString\nwebidl.converters.USVString = toUSVString\n\n// https://webidl.spec.whatwg.org/#es-boolean\nwebidl.converters.boolean = function (V) {\n  // 1. Let x be the result of computing ToBoolean(V).\n  const x = Boolean(V)\n\n  // 2. Return the IDL boolean value that is the one that represents\n  //    the same truth value as the ECMAScript Boolean value x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-any\nwebidl.converters.any = function (V) {\n  return V\n}\n\n// https://webidl.spec.whatwg.org/#es-long-long\nwebidl.converters['long long'] = function (V) {\n  // 1. Let x be ? ConvertToInt(V, 64, \"signed\").\n  const x = webidl.util.ConvertToInt(V, 64, 'signed')\n\n  // 2. Return the IDL long long value that represents\n  //    the same numeric value as x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-unsigned-long-long\nwebidl.converters['unsigned long long'] = function (V) {\n  // 1. Let x be ? ConvertToInt(V, 64, \"unsigned\").\n  const x = webidl.util.ConvertToInt(V, 64, 'unsigned')\n\n  // 2. Return the IDL unsigned long long value that\n  //    represents the same numeric value as x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-unsigned-long\nwebidl.converters['unsigned long'] = function (V) {\n  // 1. Let x be ? ConvertToInt(V, 32, \"unsigned\").\n  const x = webidl.util.ConvertToInt(V, 32, 'unsigned')\n\n  // 2. Return the IDL unsigned long value that\n  //    represents the same numeric value as x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#es-unsigned-short\nwebidl.converters['unsigned short'] = function (V, opts) {\n  // 1. Let x be ? ConvertToInt(V, 16, \"unsigned\").\n  const x = webidl.util.ConvertToInt(V, 16, 'unsigned', opts)\n\n  // 2. Return the IDL unsigned short value that represents\n  //    the same numeric value as x.\n  return x\n}\n\n// https://webidl.spec.whatwg.org/#idl-ArrayBuffer\nwebidl.converters.ArrayBuffer = function (V, opts = {}) {\n  // 1. If Type(V) is not Object, or V does not have an\n  //    [[ArrayBufferData]] internal slot, then throw a\n  //    TypeError.\n  // see: https://tc39.es/ecma262/#sec-properties-of-the-arraybuffer-instances\n  // see: https://tc39.es/ecma262/#sec-properties-of-the-sharedarraybuffer-instances\n  if (\n    webidl.util.Type(V) !== 'Object' ||\n    !types.isAnyArrayBuffer(V)\n  ) {\n    throw webidl.errors.conversionFailed({\n      prefix: `${V}`,\n      argument: `${V}`,\n      types: ['ArrayBuffer']\n    })\n  }\n\n  // 2. If the conversion is not to an IDL type associated\n  //    with the [AllowShared] extended attribute, and\n  //    IsSharedArrayBuffer(V) is true, then throw a\n  //    TypeError.\n  if (opts.allowShared === false && types.isSharedArrayBuffer(V)) {\n    throw webidl.errors.exception({\n      header: 'ArrayBuffer',\n      message: 'SharedArrayBuffer is not allowed.'\n    })\n  }\n\n  // 3. If the conversion is not to an IDL type associated\n  //    with the [AllowResizable] extended attribute, and\n  //    IsResizableArrayBuffer(V) is true, then throw a\n  //    TypeError.\n  // Note: resizable ArrayBuffers are currently a proposal.\n\n  // 4. Return the IDL ArrayBuffer value that is a\n  //    reference to the same object as V.\n  return V\n}\n\nwebidl.converters.TypedArray = function (V, T, opts = {}) {\n  // 1. Let T be the IDL type V is being converted to.\n\n  // 2. If Type(V) is not Object, or V does not have a\n  //    [[TypedArrayName]] internal slot with a value\n  //    equal to Ts name, then throw a TypeError.\n  if (\n    webidl.util.Type(V) !== 'Object' ||\n    !types.isTypedArray(V) ||\n    V.constructor.name !== T.name\n  ) {\n    throw webidl.errors.conversionFailed({\n      prefix: `${T.name}`,\n      argument: `${V}`,\n      types: [T.name]\n    })\n  }\n\n  // 3. If the conversion is not to an IDL type associated\n  //    with the [AllowShared] extended attribute, and\n  //    IsSharedArrayBuffer(V.[[ViewedArrayBuffer]]) is\n  //    true, then throw a TypeError.\n  if (opts.allowShared === false && types.isSharedArrayBuffer(V.buffer)) {\n    throw webidl.errors.exception({\n      header: 'ArrayBuffer',\n      message: 'SharedArrayBuffer is not allowed.'\n    })\n  }\n\n  // 4. If the conversion is not to an IDL type associated\n  //    with the [AllowResizable] extended attribute, and\n  //    IsResizableArrayBuffer(V.[[ViewedArrayBuffer]]) is\n  //    true, then throw a TypeError.\n  // Note: resizable array buffers are currently a proposal\n\n  // 5. Return the IDL value of type T that is a reference\n  //    to the same object as V.\n  return V\n}\n\nwebidl.converters.DataView = function (V, opts = {}) {\n  // 1. If Type(V) is not Object, or V does not have a\n  //    [[DataView]] internal slot, then throw a TypeError.\n  if (webidl.util.Type(V) !== 'Object' || !types.isDataView(V)) {\n    throw webidl.errors.exception({\n      header: 'DataView',\n      message: 'Object is not a DataView.'\n    })\n  }\n\n  // 2. If the conversion is not to an IDL type associated\n  //    with the [AllowShared] extended attribute, and\n  //    IsSharedArrayBuffer(V.[[ViewedArrayBuffer]]) is true,\n  //    then throw a TypeError.\n  if (opts.allowShared === false && types.isSharedArrayBuffer(V.buffer)) {\n    throw webidl.errors.exception({\n      header: 'ArrayBuffer',\n      message: 'SharedArrayBuffer is not allowed.'\n    })\n  }\n\n  // 3. If the conversion is not to an IDL type associated\n  //    with the [AllowResizable] extended attribute, and\n  //    IsResizableArrayBuffer(V.[[ViewedArrayBuffer]]) is\n  //    true, then throw a TypeError.\n  // Note: resizable ArrayBuffers are currently a proposal\n\n  // 4. Return the IDL DataView value that is a reference\n  //    to the same object as V.\n  return V\n}\n\n// https://webidl.spec.whatwg.org/#BufferSource\nwebidl.converters.BufferSource = function (V, opts = {}) {\n  if (types.isAnyArrayBuffer(V)) {\n    return webidl.converters.ArrayBuffer(V, opts)\n  }\n\n  if (types.isTypedArray(V)) {\n    return webidl.converters.TypedArray(V, V.constructor)\n  }\n\n  if (types.isDataView(V)) {\n    return webidl.converters.DataView(V, opts)\n  }\n\n  throw new TypeError(`Could not convert ${V} to a BufferSource.`)\n}\n\nwebidl.converters['sequence<ByteString>'] = webidl.sequenceConverter(\n  webidl.converters.ByteString\n)\n\nwebidl.converters['sequence<sequence<ByteString>>'] = webidl.sequenceConverter(\n  webidl.converters['sequence<ByteString>']\n)\n\nwebidl.converters['record<ByteString, ByteString>'] = webidl.recordConverter(\n  webidl.converters.ByteString,\n  webidl.converters.ByteString\n)\n\nmodule.exports = {\n  webidl\n}\n","'use strict'\n\n/**\n * @see https://encoding.spec.whatwg.org/#concept-encoding-get\n * @param {string|undefined} label\n */\nfunction getEncoding (label) {\n  if (!label) {\n    return 'failure'\n  }\n\n  // 1. Remove any leading and trailing ASCII whitespace from label.\n  // 2. If label is an ASCII case-insensitive match for any of the\n  //    labels listed in the table below, then return the\n  //    corresponding encoding; otherwise return failure.\n  switch (label.trim().toLowerCase()) {\n    case 'unicode-1-1-utf-8':\n    case 'unicode11utf8':\n    case 'unicode20utf8':\n    case 'utf-8':\n    case 'utf8':\n    case 'x-unicode20utf8':\n      return 'UTF-8'\n    case '866':\n    case 'cp866':\n    case 'csibm866':\n    case 'ibm866':\n      return 'IBM866'\n    case 'csisolatin2':\n    case 'iso-8859-2':\n    case 'iso-ir-101':\n    case 'iso8859-2':\n    case 'iso88592':\n    case 'iso_8859-2':\n    case 'iso_8859-2:1987':\n    case 'l2':\n    case 'latin2':\n      return 'ISO-8859-2'\n    case 'csisolatin3':\n    case 'iso-8859-3':\n    case 'iso-ir-109':\n    case 'iso8859-3':\n    case 'iso88593':\n    case 'iso_8859-3':\n    case 'iso_8859-3:1988':\n    case 'l3':\n    case 'latin3':\n      return 'ISO-8859-3'\n    case 'csisolatin4':\n    case 'iso-8859-4':\n    case 'iso-ir-110':\n    case 'iso8859-4':\n    case 'iso88594':\n    case 'iso_8859-4':\n    case 'iso_8859-4:1988':\n    case 'l4':\n    case 'latin4':\n      return 'ISO-8859-4'\n    case 'csisolatincyrillic':\n    case 'cyrillic':\n    case 'iso-8859-5':\n    case 'iso-ir-144':\n    case 'iso8859-5':\n    case 'iso88595':\n    case 'iso_8859-5':\n    case 'iso_8859-5:1988':\n      return 'ISO-8859-5'\n    case 'arabic':\n    case 'asmo-708':\n    case 'csiso88596e':\n    case 'csiso88596i':\n    case 'csisolatinarabic':\n    case 'ecma-114':\n    case 'iso-8859-6':\n    case 'iso-8859-6-e':\n    case 'iso-8859-6-i':\n    case 'iso-ir-127':\n    case 'iso8859-6':\n    case 'iso88596':\n    case 'iso_8859-6':\n    case 'iso_8859-6:1987':\n      return 'ISO-8859-6'\n    case 'csisolatingreek':\n    case 'ecma-118':\n    case 'elot_928':\n    case 'greek':\n    case 'greek8':\n    case 'iso-8859-7':\n    case 'iso-ir-126':\n    case 'iso8859-7':\n    case 'iso88597':\n    case 'iso_8859-7':\n    case 'iso_8859-7:1987':\n    case 'sun_eu_greek':\n      return 'ISO-8859-7'\n    case 'csiso88598e':\n    case 'csisolatinhebrew':\n    case 'hebrew':\n    case 'iso-8859-8':\n    case 'iso-8859-8-e':\n    case 'iso-ir-138':\n    case 'iso8859-8':\n    case 'iso88598':\n    case 'iso_8859-8':\n    case 'iso_8859-8:1988':\n    case 'visual':\n      return 'ISO-8859-8'\n    case 'csiso88598i':\n    case 'iso-8859-8-i':\n    case 'logical':\n      return 'ISO-8859-8-I'\n    case 'csisolatin6':\n    case 'iso-8859-10':\n    case 'iso-ir-157':\n    case 'iso8859-10':\n    case 'iso885910':\n    case 'l6':\n    case 'latin6':\n      return 'ISO-8859-10'\n    case 'iso-8859-13':\n    case 'iso8859-13':\n    case 'iso885913':\n      return 'ISO-8859-13'\n    case 'iso-8859-14':\n    case 'iso8859-14':\n    case 'iso885914':\n      return 'ISO-8859-14'\n    case 'csisolatin9':\n    case 'iso-8859-15':\n    case 'iso8859-15':\n    case 'iso885915':\n    case 'iso_8859-15':\n    case 'l9':\n      return 'ISO-8859-15'\n    case 'iso-8859-16':\n      return 'ISO-8859-16'\n    case 'cskoi8r':\n    case 'koi':\n    case 'koi8':\n    case 'koi8-r':\n    case 'koi8_r':\n      return 'KOI8-R'\n    case 'koi8-ru':\n    case 'koi8-u':\n      return 'KOI8-U'\n    case 'csmacintosh':\n    case 'mac':\n    case 'macintosh':\n    case 'x-mac-roman':\n      return 'macintosh'\n    case 'iso-8859-11':\n    case 'iso8859-11':\n    case 'iso885911':\n    case 'tis-620':\n    case 'windows-874':\n      return 'windows-874'\n    case 'cp1250':\n    case 'windows-1250':\n    case 'x-cp1250':\n      return 'windows-1250'\n    case 'cp1251':\n    case 'windows-1251':\n    case 'x-cp1251':\n      return 'windows-1251'\n    case 'ansi_x3.4-1968':\n    case 'ascii':\n    case 'cp1252':\n    case 'cp819':\n    case 'csisolatin1':\n    case 'ibm819':\n    case 'iso-8859-1':\n    case 'iso-ir-100':\n    case 'iso8859-1':\n    case 'iso88591':\n    case 'iso_8859-1':\n    case 'iso_8859-1:1987':\n    case 'l1':\n    case 'latin1':\n    case 'us-ascii':\n    case 'windows-1252':\n    case 'x-cp1252':\n      return 'windows-1252'\n    case 'cp1253':\n    case 'windows-1253':\n    case 'x-cp1253':\n      return 'windows-1253'\n    case 'cp1254':\n    case 'csisolatin5':\n    case 'iso-8859-9':\n    case 'iso-ir-148':\n    case 'iso8859-9':\n    case 'iso88599':\n    case 'iso_8859-9':\n    case 'iso_8859-9:1989':\n    case 'l5':\n    case 'latin5':\n    case 'windows-1254':\n    case 'x-cp1254':\n      return 'windows-1254'\n    case 'cp1255':\n    case 'windows-1255':\n    case 'x-cp1255':\n      return 'windows-1255'\n    case 'cp1256':\n    case 'windows-1256':\n    case 'x-cp1256':\n      return 'windows-1256'\n    case 'cp1257':\n    case 'windows-1257':\n    case 'x-cp1257':\n      return 'windows-1257'\n    case 'cp1258':\n    case 'windows-1258':\n    case 'x-cp1258':\n      return 'windows-1258'\n    case 'x-mac-cyrillic':\n    case 'x-mac-ukrainian':\n      return 'x-mac-cyrillic'\n    case 'chinese':\n    case 'csgb2312':\n    case 'csiso58gb231280':\n    case 'gb2312':\n    case 'gb_2312':\n    case 'gb_2312-80':\n    case 'gbk':\n    case 'iso-ir-58':\n    case 'x-gbk':\n      return 'GBK'\n    case 'gb18030':\n      return 'gb18030'\n    case 'big5':\n    case 'big5-hkscs':\n    case 'cn-big5':\n    case 'csbig5':\n    case 'x-x-big5':\n      return 'Big5'\n    case 'cseucpkdfmtjapanese':\n    case 'euc-jp':\n    case 'x-euc-jp':\n      return 'EUC-JP'\n    case 'csiso2022jp':\n    case 'iso-2022-jp':\n      return 'ISO-2022-JP'\n    case 'csshiftjis':\n    case 'ms932':\n    case 'ms_kanji':\n    case 'shift-jis':\n    case 'shift_jis':\n    case 'sjis':\n    case 'windows-31j':\n    case 'x-sjis':\n      return 'Shift_JIS'\n    case 'cseuckr':\n    case 'csksc56011987':\n    case 'euc-kr':\n    case 'iso-ir-149':\n    case 'korean':\n    case 'ks_c_5601-1987':\n    case 'ks_c_5601-1989':\n    case 'ksc5601':\n    case 'ksc_5601':\n    case 'windows-949':\n      return 'EUC-KR'\n    case 'csiso2022kr':\n    case 'hz-gb-2312':\n    case 'iso-2022-cn':\n    case 'iso-2022-cn-ext':\n    case 'iso-2022-kr':\n    case 'replacement':\n      return 'replacement'\n    case 'unicodefffe':\n    case 'utf-16be':\n      return 'UTF-16BE'\n    case 'csunicode':\n    case 'iso-10646-ucs-2':\n    case 'ucs-2':\n    case 'unicode':\n    case 'unicodefeff':\n    case 'utf-16':\n    case 'utf-16le':\n      return 'UTF-16LE'\n    case 'x-user-defined':\n      return 'x-user-defined'\n    default: return 'failure'\n  }\n}\n\nmodule.exports = {\n  getEncoding\n}\n","'use strict'\n\nconst {\n  staticPropertyDescriptors,\n  readOperation,\n  fireAProgressEvent\n} = require('./util')\nconst {\n  kState,\n  kError,\n  kResult,\n  kEvents,\n  kAborted\n} = require('./symbols')\nconst { webidl } = require('../fetch/webidl')\nconst { kEnumerableProperty } = require('../core/util')\n\nclass FileReader extends EventTarget {\n  constructor () {\n    super()\n\n    this[kState] = 'empty'\n    this[kResult] = null\n    this[kError] = null\n    this[kEvents] = {\n      loadend: null,\n      error: null,\n      abort: null,\n      load: null,\n      progress: null,\n      loadstart: null\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dfn-readAsArrayBuffer\n   * @param {import('buffer').Blob} blob\n   */\n  readAsArrayBuffer (blob) {\n    webidl.brandCheck(this, FileReader)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FileReader.readAsArrayBuffer' })\n\n    blob = webidl.converters.Blob(blob, { strict: false })\n\n    // The readAsArrayBuffer(blob) method, when invoked,\n    // must initiate a read operation for blob with ArrayBuffer.\n    readOperation(this, blob, 'ArrayBuffer')\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#readAsBinaryString\n   * @param {import('buffer').Blob} blob\n   */\n  readAsBinaryString (blob) {\n    webidl.brandCheck(this, FileReader)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FileReader.readAsBinaryString' })\n\n    blob = webidl.converters.Blob(blob, { strict: false })\n\n    // The readAsBinaryString(blob) method, when invoked,\n    // must initiate a read operation for blob with BinaryString.\n    readOperation(this, blob, 'BinaryString')\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#readAsDataText\n   * @param {import('buffer').Blob} blob\n   * @param {string?} encoding\n   */\n  readAsText (blob, encoding = undefined) {\n    webidl.brandCheck(this, FileReader)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FileReader.readAsText' })\n\n    blob = webidl.converters.Blob(blob, { strict: false })\n\n    if (encoding !== undefined) {\n      encoding = webidl.converters.DOMString(encoding)\n    }\n\n    // The readAsText(blob, encoding) method, when invoked,\n    // must initiate a read operation for blob with Text and encoding.\n    readOperation(this, blob, 'Text', encoding)\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dfn-readAsDataURL\n   * @param {import('buffer').Blob} blob\n   */\n  readAsDataURL (blob) {\n    webidl.brandCheck(this, FileReader)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'FileReader.readAsDataURL' })\n\n    blob = webidl.converters.Blob(blob, { strict: false })\n\n    // The readAsDataURL(blob) method, when invoked, must\n    // initiate a read operation for blob with DataURL.\n    readOperation(this, blob, 'DataURL')\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dfn-abort\n   */\n  abort () {\n    // 1. If this's state is \"empty\" or if this's state is\n    //    \"done\" set this's result to null and terminate\n    //    this algorithm.\n    if (this[kState] === 'empty' || this[kState] === 'done') {\n      this[kResult] = null\n      return\n    }\n\n    // 2. If this's state is \"loading\" set this's state to\n    //    \"done\" and set this's result to null.\n    if (this[kState] === 'loading') {\n      this[kState] = 'done'\n      this[kResult] = null\n    }\n\n    // 3. If there are any tasks from this on the file reading\n    //    task source in an affiliated task queue, then remove\n    //    those tasks from that task queue.\n    this[kAborted] = true\n\n    // 4. Terminate the algorithm for the read method being processed.\n    // TODO\n\n    // 5. Fire a progress event called abort at this.\n    fireAProgressEvent('abort', this)\n\n    // 6. If this's state is not \"loading\", fire a progress\n    //    event called loadend at this.\n    if (this[kState] !== 'loading') {\n      fireAProgressEvent('loadend', this)\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dom-filereader-readystate\n   */\n  get readyState () {\n    webidl.brandCheck(this, FileReader)\n\n    switch (this[kState]) {\n      case 'empty': return this.EMPTY\n      case 'loading': return this.LOADING\n      case 'done': return this.DONE\n    }\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dom-filereader-result\n   */\n  get result () {\n    webidl.brandCheck(this, FileReader)\n\n    // The result attributes getter, when invoked, must return\n    // this's result.\n    return this[kResult]\n  }\n\n  /**\n   * @see https://w3c.github.io/FileAPI/#dom-filereader-error\n   */\n  get error () {\n    webidl.brandCheck(this, FileReader)\n\n    // The error attributes getter, when invoked, must return\n    // this's error.\n    return this[kError]\n  }\n\n  get onloadend () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].loadend\n  }\n\n  set onloadend (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].loadend) {\n      this.removeEventListener('loadend', this[kEvents].loadend)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].loadend = fn\n      this.addEventListener('loadend', fn)\n    } else {\n      this[kEvents].loadend = null\n    }\n  }\n\n  get onerror () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].error\n  }\n\n  set onerror (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].error) {\n      this.removeEventListener('error', this[kEvents].error)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].error = fn\n      this.addEventListener('error', fn)\n    } else {\n      this[kEvents].error = null\n    }\n  }\n\n  get onloadstart () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].loadstart\n  }\n\n  set onloadstart (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].loadstart) {\n      this.removeEventListener('loadstart', this[kEvents].loadstart)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].loadstart = fn\n      this.addEventListener('loadstart', fn)\n    } else {\n      this[kEvents].loadstart = null\n    }\n  }\n\n  get onprogress () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].progress\n  }\n\n  set onprogress (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].progress) {\n      this.removeEventListener('progress', this[kEvents].progress)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].progress = fn\n      this.addEventListener('progress', fn)\n    } else {\n      this[kEvents].progress = null\n    }\n  }\n\n  get onload () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].load\n  }\n\n  set onload (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].load) {\n      this.removeEventListener('load', this[kEvents].load)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].load = fn\n      this.addEventListener('load', fn)\n    } else {\n      this[kEvents].load = null\n    }\n  }\n\n  get onabort () {\n    webidl.brandCheck(this, FileReader)\n\n    return this[kEvents].abort\n  }\n\n  set onabort (fn) {\n    webidl.brandCheck(this, FileReader)\n\n    if (this[kEvents].abort) {\n      this.removeEventListener('abort', this[kEvents].abort)\n    }\n\n    if (typeof fn === 'function') {\n      this[kEvents].abort = fn\n      this.addEventListener('abort', fn)\n    } else {\n      this[kEvents].abort = null\n    }\n  }\n}\n\n// https://w3c.github.io/FileAPI/#dom-filereader-empty\nFileReader.EMPTY = FileReader.prototype.EMPTY = 0\n// https://w3c.github.io/FileAPI/#dom-filereader-loading\nFileReader.LOADING = FileReader.prototype.LOADING = 1\n// https://w3c.github.io/FileAPI/#dom-filereader-done\nFileReader.DONE = FileReader.prototype.DONE = 2\n\nObject.defineProperties(FileReader.prototype, {\n  EMPTY: staticPropertyDescriptors,\n  LOADING: staticPropertyDescriptors,\n  DONE: staticPropertyDescriptors,\n  readAsArrayBuffer: kEnumerableProperty,\n  readAsBinaryString: kEnumerableProperty,\n  readAsText: kEnumerableProperty,\n  readAsDataURL: kEnumerableProperty,\n  abort: kEnumerableProperty,\n  readyState: kEnumerableProperty,\n  result: kEnumerableProperty,\n  error: kEnumerableProperty,\n  onloadstart: kEnumerableProperty,\n  onprogress: kEnumerableProperty,\n  onload: kEnumerableProperty,\n  onabort: kEnumerableProperty,\n  onerror: kEnumerableProperty,\n  onloadend: kEnumerableProperty,\n  [Symbol.toStringTag]: {\n    value: 'FileReader',\n    writable: false,\n    enumerable: false,\n    configurable: true\n  }\n})\n\nObject.defineProperties(FileReader, {\n  EMPTY: staticPropertyDescriptors,\n  LOADING: staticPropertyDescriptors,\n  DONE: staticPropertyDescriptors\n})\n\nmodule.exports = {\n  FileReader\n}\n","'use strict'\n\nconst { webidl } = require('../fetch/webidl')\n\nconst kState = Symbol('ProgressEvent state')\n\n/**\n * @see https://xhr.spec.whatwg.org/#progressevent\n */\nclass ProgressEvent extends Event {\n  constructor (type, eventInitDict = {}) {\n    type = webidl.converters.DOMString(type)\n    eventInitDict = webidl.converters.ProgressEventInit(eventInitDict ?? {})\n\n    super(type, eventInitDict)\n\n    this[kState] = {\n      lengthComputable: eventInitDict.lengthComputable,\n      loaded: eventInitDict.loaded,\n      total: eventInitDict.total\n    }\n  }\n\n  get lengthComputable () {\n    webidl.brandCheck(this, ProgressEvent)\n\n    return this[kState].lengthComputable\n  }\n\n  get loaded () {\n    webidl.brandCheck(this, ProgressEvent)\n\n    return this[kState].loaded\n  }\n\n  get total () {\n    webidl.brandCheck(this, ProgressEvent)\n\n    return this[kState].total\n  }\n}\n\nwebidl.converters.ProgressEventInit = webidl.dictionaryConverter([\n  {\n    key: 'lengthComputable',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'loaded',\n    converter: webidl.converters['unsigned long long'],\n    defaultValue: 0\n  },\n  {\n    key: 'total',\n    converter: webidl.converters['unsigned long long'],\n    defaultValue: 0\n  },\n  {\n    key: 'bubbles',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'cancelable',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'composed',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  }\n])\n\nmodule.exports = {\n  ProgressEvent\n}\n","'use strict'\n\nmodule.exports = {\n  kState: Symbol('FileReader state'),\n  kResult: Symbol('FileReader result'),\n  kError: Symbol('FileReader error'),\n  kLastProgressEventFired: Symbol('FileReader last progress event fired timestamp'),\n  kEvents: Symbol('FileReader events'),\n  kAborted: Symbol('FileReader aborted')\n}\n","'use strict'\n\nconst {\n  kState,\n  kError,\n  kResult,\n  kAborted,\n  kLastProgressEventFired\n} = require('./symbols')\nconst { ProgressEvent } = require('./progressevent')\nconst { getEncoding } = require('./encoding')\nconst { DOMException } = require('../fetch/constants')\nconst { serializeAMimeType, parseMIMEType } = require('../fetch/dataURL')\nconst { types } = require('util')\nconst { StringDecoder } = require('string_decoder')\nconst { btoa } = require('buffer')\n\n/** @type {PropertyDescriptor} */\nconst staticPropertyDescriptors = {\n  enumerable: true,\n  writable: false,\n  configurable: false\n}\n\n/**\n * @see https://w3c.github.io/FileAPI/#readOperation\n * @param {import('./filereader').FileReader} fr\n * @param {import('buffer').Blob} blob\n * @param {string} type\n * @param {string?} encodingName\n */\nfunction readOperation (fr, blob, type, encodingName) {\n  // 1. If frs state is \"loading\", throw an InvalidStateError\n  //    DOMException.\n  if (fr[kState] === 'loading') {\n    throw new DOMException('Invalid state', 'InvalidStateError')\n  }\n\n  // 2. Set frs state to \"loading\".\n  fr[kState] = 'loading'\n\n  // 3. Set frs result to null.\n  fr[kResult] = null\n\n  // 4. Set frs error to null.\n  fr[kError] = null\n\n  // 5. Let stream be the result of calling get stream on blob.\n  /** @type {import('stream/web').ReadableStream} */\n  const stream = blob.stream()\n\n  // 6. Let reader be the result of getting a reader from stream.\n  const reader = stream.getReader()\n\n  // 7. Let bytes be an empty byte sequence.\n  /** @type {Uint8Array[]} */\n  const bytes = []\n\n  // 8. Let chunkPromise be the result of reading a chunk from\n  //    stream with reader.\n  let chunkPromise = reader.read()\n\n  // 9. Let isFirstChunk be true.\n  let isFirstChunk = true\n\n  // 10. In parallel, while true:\n  // Note: \"In parallel\" just means non-blocking\n  // Note 2: readOperation itself cannot be async as double\n  // reading the body would then reject the promise, instead\n  // of throwing an error.\n  ;(async () => {\n    while (!fr[kAborted]) {\n      // 1. Wait for chunkPromise to be fulfilled or rejected.\n      try {\n        const { done, value } = await chunkPromise\n\n        // 2. If chunkPromise is fulfilled, and isFirstChunk is\n        //    true, queue a task to fire a progress event called\n        //    loadstart at fr.\n        if (isFirstChunk && !fr[kAborted]) {\n          queueMicrotask(() => {\n            fireAProgressEvent('loadstart', fr)\n          })\n        }\n\n        // 3. Set isFirstChunk to false.\n        isFirstChunk = false\n\n        // 4. If chunkPromise is fulfilled with an object whose\n        //    done property is false and whose value property is\n        //    a Uint8Array object, run these steps:\n        if (!done && types.isUint8Array(value)) {\n          // 1. Let bs be the byte sequence represented by the\n          //    Uint8Array object.\n\n          // 2. Append bs to bytes.\n          bytes.push(value)\n\n          // 3. If roughly 50ms have passed since these steps\n          //    were last invoked, queue a task to fire a\n          //    progress event called progress at fr.\n          if (\n            (\n              fr[kLastProgressEventFired] === undefined ||\n              Date.now() - fr[kLastProgressEventFired] >= 50\n            ) &&\n            !fr[kAborted]\n          ) {\n            fr[kLastProgressEventFired] = Date.now()\n            queueMicrotask(() => {\n              fireAProgressEvent('progress', fr)\n            })\n          }\n\n          // 4. Set chunkPromise to the result of reading a\n          //    chunk from stream with reader.\n          chunkPromise = reader.read()\n        } else if (done) {\n          // 5. Otherwise, if chunkPromise is fulfilled with an\n          //    object whose done property is true, queue a task\n          //    to run the following steps and abort this algorithm:\n          queueMicrotask(() => {\n            // 1. Set frs state to \"done\".\n            fr[kState] = 'done'\n\n            // 2. Let result be the result of package data given\n            //    bytes, type, blobs type, and encodingName.\n            try {\n              const result = packageData(bytes, type, blob.type, encodingName)\n\n              // 4. Else:\n\n              if (fr[kAborted]) {\n                return\n              }\n\n              // 1. Set frs result to result.\n              fr[kResult] = result\n\n              // 2. Fire a progress event called load at the fr.\n              fireAProgressEvent('load', fr)\n            } catch (error) {\n              // 3. If package data threw an exception error:\n\n              // 1. Set frs error to error.\n              fr[kError] = error\n\n              // 2. Fire a progress event called error at fr.\n              fireAProgressEvent('error', fr)\n            }\n\n            // 5. If frs state is not \"loading\", fire a progress\n            //    event called loadend at the fr.\n            if (fr[kState] !== 'loading') {\n              fireAProgressEvent('loadend', fr)\n            }\n          })\n\n          break\n        }\n      } catch (error) {\n        if (fr[kAborted]) {\n          return\n        }\n\n        // 6. Otherwise, if chunkPromise is rejected with an\n        //    error error, queue a task to run the following\n        //    steps and abort this algorithm:\n        queueMicrotask(() => {\n          // 1. Set frs state to \"done\".\n          fr[kState] = 'done'\n\n          // 2. Set frs error to error.\n          fr[kError] = error\n\n          // 3. Fire a progress event called error at fr.\n          fireAProgressEvent('error', fr)\n\n          // 4. If frs state is not \"loading\", fire a progress\n          //    event called loadend at fr.\n          if (fr[kState] !== 'loading') {\n            fireAProgressEvent('loadend', fr)\n          }\n        })\n\n        break\n      }\n    }\n  })()\n}\n\n/**\n * @see https://w3c.github.io/FileAPI/#fire-a-progress-event\n * @see https://dom.spec.whatwg.org/#concept-event-fire\n * @param {string} e The name of the event\n * @param {import('./filereader').FileReader} reader\n */\nfunction fireAProgressEvent (e, reader) {\n  // The progress event e does not bubble. e.bubbles must be false\n  // The progress event e is NOT cancelable. e.cancelable must be false\n  const event = new ProgressEvent(e, {\n    bubbles: false,\n    cancelable: false\n  })\n\n  reader.dispatchEvent(event)\n}\n\n/**\n * @see https://w3c.github.io/FileAPI/#blob-package-data\n * @param {Uint8Array[]} bytes\n * @param {string} type\n * @param {string?} mimeType\n * @param {string?} encodingName\n */\nfunction packageData (bytes, type, mimeType, encodingName) {\n  // 1. A Blob has an associated package data algorithm, given\n  //    bytes, a type, a optional mimeType, and a optional\n  //    encodingName, which switches on type and runs the\n  //    associated steps:\n\n  switch (type) {\n    case 'DataURL': {\n      // 1. Return bytes as a DataURL [RFC2397] subject to\n      //    the considerations below:\n      //  * Use mimeType as part of the Data URL if it is\n      //    available in keeping with the Data URL\n      //    specification [RFC2397].\n      //  * If mimeType is not available return a Data URL\n      //    without a media-type. [RFC2397].\n\n      // https://datatracker.ietf.org/doc/html/rfc2397#section-3\n      // dataurl    := \"data:\" [ mediatype ] [ \";base64\" ] \",\" data\n      // mediatype  := [ type \"/\" subtype ] *( \";\" parameter )\n      // data       := *urlchar\n      // parameter  := attribute \"=\" value\n      let dataURL = 'data:'\n\n      const parsed = parseMIMEType(mimeType || 'application/octet-stream')\n\n      if (parsed !== 'failure') {\n        dataURL += serializeAMimeType(parsed)\n      }\n\n      dataURL += ';base64,'\n\n      const decoder = new StringDecoder('latin1')\n\n      for (const chunk of bytes) {\n        dataURL += btoa(decoder.write(chunk))\n      }\n\n      dataURL += btoa(decoder.end())\n\n      return dataURL\n    }\n    case 'Text': {\n      // 1. Let encoding be failure\n      let encoding = 'failure'\n\n      // 2. If the encodingName is present, set encoding to the\n      //    result of getting an encoding from encodingName.\n      if (encodingName) {\n        encoding = getEncoding(encodingName)\n      }\n\n      // 3. If encoding is failure, and mimeType is present:\n      if (encoding === 'failure' && mimeType) {\n        // 1. Let type be the result of parse a MIME type\n        //    given mimeType.\n        const type = parseMIMEType(mimeType)\n\n        // 2. If type is not failure, set encoding to the result\n        //    of getting an encoding from types parameters[\"charset\"].\n        if (type !== 'failure') {\n          encoding = getEncoding(type.parameters.get('charset'))\n        }\n      }\n\n      // 4. If encoding is failure, then set encoding to UTF-8.\n      if (encoding === 'failure') {\n        encoding = 'UTF-8'\n      }\n\n      // 5. Decode bytes using fallback encoding encoding, and\n      //    return the result.\n      return decode(bytes, encoding)\n    }\n    case 'ArrayBuffer': {\n      // Return a new ArrayBuffer whose contents are bytes.\n      const sequence = combineByteSequences(bytes)\n\n      return sequence.buffer\n    }\n    case 'BinaryString': {\n      // Return bytes as a binary string, in which every byte\n      //  is represented by a code unit of equal value [0..255].\n      let binaryString = ''\n\n      const decoder = new StringDecoder('latin1')\n\n      for (const chunk of bytes) {\n        binaryString += decoder.write(chunk)\n      }\n\n      binaryString += decoder.end()\n\n      return binaryString\n    }\n  }\n}\n\n/**\n * @see https://encoding.spec.whatwg.org/#decode\n * @param {Uint8Array[]} ioQueue\n * @param {string} encoding\n */\nfunction decode (ioQueue, encoding) {\n  const bytes = combineByteSequences(ioQueue)\n\n  // 1. Let BOMEncoding be the result of BOM sniffing ioQueue.\n  const BOMEncoding = BOMSniffing(bytes)\n\n  let slice = 0\n\n  // 2. If BOMEncoding is non-null:\n  if (BOMEncoding !== null) {\n    // 1. Set encoding to BOMEncoding.\n    encoding = BOMEncoding\n\n    // 2. Read three bytes from ioQueue, if BOMEncoding is\n    //    UTF-8; otherwise read two bytes.\n    //    (Do nothing with those bytes.)\n    slice = BOMEncoding === 'UTF-8' ? 3 : 2\n  }\n\n  // 3. Process a queue with an instance of encodings\n  //    decoder, ioQueue, output, and \"replacement\".\n\n  // 4. Return output.\n\n  const sliced = bytes.slice(slice)\n  return new TextDecoder(encoding).decode(sliced)\n}\n\n/**\n * @see https://encoding.spec.whatwg.org/#bom-sniff\n * @param {Uint8Array} ioQueue\n */\nfunction BOMSniffing (ioQueue) {\n  // 1. Let BOM be the result of peeking 3 bytes from ioQueue,\n  //    converted to a byte sequence.\n  const [a, b, c] = ioQueue\n\n  // 2. For each of the rows in the table below, starting with\n  //    the first one and going down, if BOM starts with the\n  //    bytes given in the first column, then return the\n  //    encoding given in the cell in the second column of that\n  //    row. Otherwise, return null.\n  if (a === 0xEF && b === 0xBB && c === 0xBF) {\n    return 'UTF-8'\n  } else if (a === 0xFE && b === 0xFF) {\n    return 'UTF-16BE'\n  } else if (a === 0xFF && b === 0xFE) {\n    return 'UTF-16LE'\n  }\n\n  return null\n}\n\n/**\n * @param {Uint8Array[]} sequences\n */\nfunction combineByteSequences (sequences) {\n  const size = sequences.reduce((a, b) => {\n    return a + b.byteLength\n  }, 0)\n\n  let offset = 0\n\n  return sequences.reduce((a, b) => {\n    a.set(b, offset)\n    offset += b.byteLength\n    return a\n  }, new Uint8Array(size))\n}\n\nmodule.exports = {\n  staticPropertyDescriptors,\n  readOperation,\n  fireAProgressEvent\n}\n","'use strict'\n\n// We include a version number for the Dispatcher API. In case of breaking changes,\n// this version number must be increased to avoid conflicts.\nconst globalDispatcher = Symbol.for('undici.globalDispatcher.1')\nconst { InvalidArgumentError } = require('./core/errors')\nconst Agent = require('./agent')\n\nif (getGlobalDispatcher() === undefined) {\n  setGlobalDispatcher(new Agent())\n}\n\nfunction setGlobalDispatcher (agent) {\n  if (!agent || typeof agent.dispatch !== 'function') {\n    throw new InvalidArgumentError('Argument agent must implement Agent')\n  }\n  Object.defineProperty(globalThis, globalDispatcher, {\n    value: agent,\n    writable: true,\n    enumerable: false,\n    configurable: false\n  })\n}\n\nfunction getGlobalDispatcher () {\n  return globalThis[globalDispatcher]\n}\n\nmodule.exports = {\n  setGlobalDispatcher,\n  getGlobalDispatcher\n}\n","'use strict'\n\nmodule.exports = class DecoratorHandler {\n  constructor (handler) {\n    this.handler = handler\n  }\n\n  onConnect (...args) {\n    return this.handler.onConnect(...args)\n  }\n\n  onError (...args) {\n    return this.handler.onError(...args)\n  }\n\n  onUpgrade (...args) {\n    return this.handler.onUpgrade(...args)\n  }\n\n  onHeaders (...args) {\n    return this.handler.onHeaders(...args)\n  }\n\n  onData (...args) {\n    return this.handler.onData(...args)\n  }\n\n  onComplete (...args) {\n    return this.handler.onComplete(...args)\n  }\n\n  onBodySent (...args) {\n    return this.handler.onBodySent(...args)\n  }\n}\n","'use strict'\n\nconst util = require('../core/util')\nconst { kBodyUsed } = require('../core/symbols')\nconst assert = require('assert')\nconst { InvalidArgumentError } = require('../core/errors')\nconst EE = require('events')\n\nconst redirectableStatusCodes = [300, 301, 302, 303, 307, 308]\n\nconst kBody = Symbol('body')\n\nclass BodyAsyncIterable {\n  constructor (body) {\n    this[kBody] = body\n    this[kBodyUsed] = false\n  }\n\n  async * [Symbol.asyncIterator] () {\n    assert(!this[kBodyUsed], 'disturbed')\n    this[kBodyUsed] = true\n    yield * this[kBody]\n  }\n}\n\nclass RedirectHandler {\n  constructor (dispatch, maxRedirections, opts, handler) {\n    if (maxRedirections != null && (!Number.isInteger(maxRedirections) || maxRedirections < 0)) {\n      throw new InvalidArgumentError('maxRedirections must be a positive number')\n    }\n\n    util.validateHandler(handler, opts.method, opts.upgrade)\n\n    this.dispatch = dispatch\n    this.location = null\n    this.abort = null\n    this.opts = { ...opts, maxRedirections: 0 } // opts must be a copy\n    this.maxRedirections = maxRedirections\n    this.handler = handler\n    this.history = []\n\n    if (util.isStream(this.opts.body)) {\n      // TODO (fix): Provide some way for the user to cache the file to e.g. /tmp\n      // so that it can be dispatched again?\n      // TODO (fix): Do we need 100-expect support to provide a way to do this properly?\n      if (util.bodyLength(this.opts.body) === 0) {\n        this.opts.body\n          .on('data', function () {\n            assert(false)\n          })\n      }\n\n      if (typeof this.opts.body.readableDidRead !== 'boolean') {\n        this.opts.body[kBodyUsed] = false\n        EE.prototype.on.call(this.opts.body, 'data', function () {\n          this[kBodyUsed] = true\n        })\n      }\n    } else if (this.opts.body && typeof this.opts.body.pipeTo === 'function') {\n      // TODO (fix): We can't access ReadableStream internal state\n      // to determine whether or not it has been disturbed. This is just\n      // a workaround.\n      this.opts.body = new BodyAsyncIterable(this.opts.body)\n    } else if (\n      this.opts.body &&\n      typeof this.opts.body !== 'string' &&\n      !ArrayBuffer.isView(this.opts.body) &&\n      util.isIterable(this.opts.body)\n    ) {\n      // TODO: Should we allow re-using iterable if !this.opts.idempotent\n      // or through some other flag?\n      this.opts.body = new BodyAsyncIterable(this.opts.body)\n    }\n  }\n\n  onConnect (abort) {\n    this.abort = abort\n    this.handler.onConnect(abort, { history: this.history })\n  }\n\n  onUpgrade (statusCode, headers, socket) {\n    this.handler.onUpgrade(statusCode, headers, socket)\n  }\n\n  onError (error) {\n    this.handler.onError(error)\n  }\n\n  onHeaders (statusCode, headers, resume, statusText) {\n    this.location = this.history.length >= this.maxRedirections || util.isDisturbed(this.opts.body)\n      ? null\n      : parseLocation(statusCode, headers)\n\n    if (this.opts.origin) {\n      this.history.push(new URL(this.opts.path, this.opts.origin))\n    }\n\n    if (!this.location) {\n      return this.handler.onHeaders(statusCode, headers, resume, statusText)\n    }\n\n    const { origin, pathname, search } = util.parseURL(new URL(this.location, this.opts.origin && new URL(this.opts.path, this.opts.origin)))\n    const path = search ? `${pathname}${search}` : pathname\n\n    // Remove headers referring to the original URL.\n    // By default it is Host only, unless it's a 303 (see below), which removes also all Content-* headers.\n    // https://tools.ietf.org/html/rfc7231#section-6.4\n    this.opts.headers = cleanRequestHeaders(this.opts.headers, statusCode === 303, this.opts.origin !== origin)\n    this.opts.path = path\n    this.opts.origin = origin\n    this.opts.maxRedirections = 0\n    this.opts.query = null\n\n    // https://tools.ietf.org/html/rfc7231#section-6.4.4\n    // In case of HTTP 303, always replace method to be either HEAD or GET\n    if (statusCode === 303 && this.opts.method !== 'HEAD') {\n      this.opts.method = 'GET'\n      this.opts.body = null\n    }\n  }\n\n  onData (chunk) {\n    if (this.location) {\n      /*\n        https://tools.ietf.org/html/rfc7231#section-6.4\n\n        TLDR: undici always ignores 3xx response bodies.\n\n        Redirection is used to serve the requested resource from another URL, so it is assumes that\n        no body is generated (and thus can be ignored). Even though generating a body is not prohibited.\n\n        For status 301, 302, 303, 307 and 308 (the latter from RFC 7238), the specs mention that the body usually\n        (which means it's optional and not mandated) contain just an hyperlink to the value of\n        the Location response header, so the body can be ignored safely.\n\n        For status 300, which is \"Multiple Choices\", the spec mentions both generating a Location\n        response header AND a response body with the other possible location to follow.\n        Since the spec explicitily chooses not to specify a format for such body and leave it to\n        servers and browsers implementors, we ignore the body as there is no specified way to eventually parse it.\n      */\n    } else {\n      return this.handler.onData(chunk)\n    }\n  }\n\n  onComplete (trailers) {\n    if (this.location) {\n      /*\n        https://tools.ietf.org/html/rfc7231#section-6.4\n\n        TLDR: undici always ignores 3xx response trailers as they are not expected in case of redirections\n        and neither are useful if present.\n\n        See comment on onData method above for more detailed informations.\n      */\n\n      this.location = null\n      this.abort = null\n\n      this.dispatch(this.opts, this)\n    } else {\n      this.handler.onComplete(trailers)\n    }\n  }\n\n  onBodySent (chunk) {\n    if (this.handler.onBodySent) {\n      this.handler.onBodySent(chunk)\n    }\n  }\n}\n\nfunction parseLocation (statusCode, headers) {\n  if (redirectableStatusCodes.indexOf(statusCode) === -1) {\n    return null\n  }\n\n  for (let i = 0; i < headers.length; i += 2) {\n    if (headers[i].toString().toLowerCase() === 'location') {\n      return headers[i + 1]\n    }\n  }\n}\n\n// https://tools.ietf.org/html/rfc7231#section-6.4.4\nfunction shouldRemoveHeader (header, removeContent, unknownOrigin) {\n  if (header.length === 4) {\n    return util.headerNameToString(header) === 'host'\n  }\n  if (removeContent && util.headerNameToString(header).startsWith('content-')) {\n    return true\n  }\n  if (unknownOrigin && (header.length === 13 || header.length === 6 || header.length === 19)) {\n    const name = util.headerNameToString(header)\n    return name === 'authorization' || name === 'cookie' || name === 'proxy-authorization'\n  }\n  return false\n}\n\n// https://tools.ietf.org/html/rfc7231#section-6.4\nfunction cleanRequestHeaders (headers, removeContent, unknownOrigin) {\n  const ret = []\n  if (Array.isArray(headers)) {\n    for (let i = 0; i < headers.length; i += 2) {\n      if (!shouldRemoveHeader(headers[i], removeContent, unknownOrigin)) {\n        ret.push(headers[i], headers[i + 1])\n      }\n    }\n  } else if (headers && typeof headers === 'object') {\n    for (const key of Object.keys(headers)) {\n      if (!shouldRemoveHeader(key, removeContent, unknownOrigin)) {\n        ret.push(key, headers[key])\n      }\n    }\n  } else {\n    assert(headers == null, 'headers must be an object or an array')\n  }\n  return ret\n}\n\nmodule.exports = RedirectHandler\n","const assert = require('assert')\n\nconst { kRetryHandlerDefaultRetry } = require('../core/symbols')\nconst { RequestRetryError } = require('../core/errors')\nconst { isDisturbed, parseHeaders, parseRangeHeader } = require('../core/util')\n\nfunction calculateRetryAfterHeader (retryAfter) {\n  const current = Date.now()\n  const diff = new Date(retryAfter).getTime() - current\n\n  return diff\n}\n\nclass RetryHandler {\n  constructor (opts, handlers) {\n    const { retryOptions, ...dispatchOpts } = opts\n    const {\n      // Retry scoped\n      retry: retryFn,\n      maxRetries,\n      maxTimeout,\n      minTimeout,\n      timeoutFactor,\n      // Response scoped\n      methods,\n      errorCodes,\n      retryAfter,\n      statusCodes\n    } = retryOptions ?? {}\n\n    this.dispatch = handlers.dispatch\n    this.handler = handlers.handler\n    this.opts = dispatchOpts\n    this.abort = null\n    this.aborted = false\n    this.retryOpts = {\n      retry: retryFn ?? RetryHandler[kRetryHandlerDefaultRetry],\n      retryAfter: retryAfter ?? true,\n      maxTimeout: maxTimeout ?? 30 * 1000, // 30s,\n      timeout: minTimeout ?? 500, // .5s\n      timeoutFactor: timeoutFactor ?? 2,\n      maxRetries: maxRetries ?? 5,\n      // What errors we should retry\n      methods: methods ?? ['GET', 'HEAD', 'OPTIONS', 'PUT', 'DELETE', 'TRACE'],\n      // Indicates which errors to retry\n      statusCodes: statusCodes ?? [500, 502, 503, 504, 429],\n      // List of errors to retry\n      errorCodes: errorCodes ?? [\n        'ECONNRESET',\n        'ECONNREFUSED',\n        'ENOTFOUND',\n        'ENETDOWN',\n        'ENETUNREACH',\n        'EHOSTDOWN',\n        'EHOSTUNREACH',\n        'EPIPE'\n      ]\n    }\n\n    this.retryCount = 0\n    this.start = 0\n    this.end = null\n    this.etag = null\n    this.resume = null\n\n    // Handle possible onConnect duplication\n    this.handler.onConnect(reason => {\n      this.aborted = true\n      if (this.abort) {\n        this.abort(reason)\n      } else {\n        this.reason = reason\n      }\n    })\n  }\n\n  onRequestSent () {\n    if (this.handler.onRequestSent) {\n      this.handler.onRequestSent()\n    }\n  }\n\n  onUpgrade (statusCode, headers, socket) {\n    if (this.handler.onUpgrade) {\n      this.handler.onUpgrade(statusCode, headers, socket)\n    }\n  }\n\n  onConnect (abort) {\n    if (this.aborted) {\n      abort(this.reason)\n    } else {\n      this.abort = abort\n    }\n  }\n\n  onBodySent (chunk) {\n    if (this.handler.onBodySent) return this.handler.onBodySent(chunk)\n  }\n\n  static [kRetryHandlerDefaultRetry] (err, { state, opts }, cb) {\n    const { statusCode, code, headers } = err\n    const { method, retryOptions } = opts\n    const {\n      maxRetries,\n      timeout,\n      maxTimeout,\n      timeoutFactor,\n      statusCodes,\n      errorCodes,\n      methods\n    } = retryOptions\n    let { counter, currentTimeout } = state\n\n    currentTimeout =\n      currentTimeout != null && currentTimeout > 0 ? currentTimeout : timeout\n\n    // Any code that is not a Undici's originated and allowed to retry\n    if (\n      code &&\n      code !== 'UND_ERR_REQ_RETRY' &&\n      code !== 'UND_ERR_SOCKET' &&\n      !errorCodes.includes(code)\n    ) {\n      cb(err)\n      return\n    }\n\n    // If a set of method are provided and the current method is not in the list\n    if (Array.isArray(methods) && !methods.includes(method)) {\n      cb(err)\n      return\n    }\n\n    // If a set of status code are provided and the current status code is not in the list\n    if (\n      statusCode != null &&\n      Array.isArray(statusCodes) &&\n      !statusCodes.includes(statusCode)\n    ) {\n      cb(err)\n      return\n    }\n\n    // If we reached the max number of retries\n    if (counter > maxRetries) {\n      cb(err)\n      return\n    }\n\n    let retryAfterHeader = headers != null && headers['retry-after']\n    if (retryAfterHeader) {\n      retryAfterHeader = Number(retryAfterHeader)\n      retryAfterHeader = isNaN(retryAfterHeader)\n        ? calculateRetryAfterHeader(retryAfterHeader)\n        : retryAfterHeader * 1e3 // Retry-After is in seconds\n    }\n\n    const retryTimeout =\n      retryAfterHeader > 0\n        ? Math.min(retryAfterHeader, maxTimeout)\n        : Math.min(currentTimeout * timeoutFactor ** counter, maxTimeout)\n\n    state.currentTimeout = retryTimeout\n\n    setTimeout(() => cb(null), retryTimeout)\n  }\n\n  onHeaders (statusCode, rawHeaders, resume, statusMessage) {\n    const headers = parseHeaders(rawHeaders)\n\n    this.retryCount += 1\n\n    if (statusCode >= 300) {\n      this.abort(\n        new RequestRetryError('Request failed', statusCode, {\n          headers,\n          count: this.retryCount\n        })\n      )\n      return false\n    }\n\n    // Checkpoint for resume from where we left it\n    if (this.resume != null) {\n      this.resume = null\n\n      if (statusCode !== 206) {\n        return true\n      }\n\n      const contentRange = parseRangeHeader(headers['content-range'])\n      // If no content range\n      if (!contentRange) {\n        this.abort(\n          new RequestRetryError('Content-Range mismatch', statusCode, {\n            headers,\n            count: this.retryCount\n          })\n        )\n        return false\n      }\n\n      // Let's start with a weak etag check\n      if (this.etag != null && this.etag !== headers.etag) {\n        this.abort(\n          new RequestRetryError('ETag mismatch', statusCode, {\n            headers,\n            count: this.retryCount\n          })\n        )\n        return false\n      }\n\n      const { start, size, end = size } = contentRange\n\n      assert(this.start === start, 'content-range mismatch')\n      assert(this.end == null || this.end === end, 'content-range mismatch')\n\n      this.resume = resume\n      return true\n    }\n\n    if (this.end == null) {\n      if (statusCode === 206) {\n        // First time we receive 206\n        const range = parseRangeHeader(headers['content-range'])\n\n        if (range == null) {\n          return this.handler.onHeaders(\n            statusCode,\n            rawHeaders,\n            resume,\n            statusMessage\n          )\n        }\n\n        const { start, size, end = size } = range\n\n        assert(\n          start != null && Number.isFinite(start) && this.start !== start,\n          'content-range mismatch'\n        )\n        assert(Number.isFinite(start))\n        assert(\n          end != null && Number.isFinite(end) && this.end !== end,\n          'invalid content-length'\n        )\n\n        this.start = start\n        this.end = end\n      }\n\n      // We make our best to checkpoint the body for further range headers\n      if (this.end == null) {\n        const contentLength = headers['content-length']\n        this.end = contentLength != null ? Number(contentLength) : null\n      }\n\n      assert(Number.isFinite(this.start))\n      assert(\n        this.end == null || Number.isFinite(this.end),\n        'invalid content-length'\n      )\n\n      this.resume = resume\n      this.etag = headers.etag != null ? headers.etag : null\n\n      return this.handler.onHeaders(\n        statusCode,\n        rawHeaders,\n        resume,\n        statusMessage\n      )\n    }\n\n    const err = new RequestRetryError('Request failed', statusCode, {\n      headers,\n      count: this.retryCount\n    })\n\n    this.abort(err)\n\n    return false\n  }\n\n  onData (chunk) {\n    this.start += chunk.length\n\n    return this.handler.onData(chunk)\n  }\n\n  onComplete (rawTrailers) {\n    this.retryCount = 0\n    return this.handler.onComplete(rawTrailers)\n  }\n\n  onError (err) {\n    if (this.aborted || isDisturbed(this.opts.body)) {\n      return this.handler.onError(err)\n    }\n\n    this.retryOpts.retry(\n      err,\n      {\n        state: { counter: this.retryCount++, currentTimeout: this.retryAfter },\n        opts: { retryOptions: this.retryOpts, ...this.opts }\n      },\n      onRetry.bind(this)\n    )\n\n    function onRetry (err) {\n      if (err != null || this.aborted || isDisturbed(this.opts.body)) {\n        return this.handler.onError(err)\n      }\n\n      if (this.start !== 0) {\n        this.opts = {\n          ...this.opts,\n          headers: {\n            ...this.opts.headers,\n            range: `bytes=${this.start}-${this.end ?? ''}`\n          }\n        }\n      }\n\n      try {\n        this.dispatch(this.opts, this)\n      } catch (err) {\n        this.handler.onError(err)\n      }\n    }\n  }\n}\n\nmodule.exports = RetryHandler\n","'use strict'\n\nconst RedirectHandler = require('../handler/RedirectHandler')\n\nfunction createRedirectInterceptor ({ maxRedirections: defaultMaxRedirections }) {\n  return (dispatch) => {\n    return function Intercept (opts, handler) {\n      const { maxRedirections = defaultMaxRedirections } = opts\n\n      if (!maxRedirections) {\n        return dispatch(opts, handler)\n      }\n\n      const redirectHandler = new RedirectHandler(dispatch, maxRedirections, opts, handler)\n      opts = { ...opts, maxRedirections: 0 } // Stop sub dispatcher from also redirecting.\n      return dispatch(opts, redirectHandler)\n    }\n  }\n}\n\nmodule.exports = createRedirectInterceptor\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.SPECIAL_HEADERS = exports.HEADER_STATE = exports.MINOR = exports.MAJOR = exports.CONNECTION_TOKEN_CHARS = exports.HEADER_CHARS = exports.TOKEN = exports.STRICT_TOKEN = exports.HEX = exports.URL_CHAR = exports.STRICT_URL_CHAR = exports.USERINFO_CHARS = exports.MARK = exports.ALPHANUM = exports.NUM = exports.HEX_MAP = exports.NUM_MAP = exports.ALPHA = exports.FINISH = exports.H_METHOD_MAP = exports.METHOD_MAP = exports.METHODS_RTSP = exports.METHODS_ICE = exports.METHODS_HTTP = exports.METHODS = exports.LENIENT_FLAGS = exports.FLAGS = exports.TYPE = exports.ERROR = void 0;\nconst utils_1 = require(\"./utils\");\n// C headers\nvar ERROR;\n(function (ERROR) {\n    ERROR[ERROR[\"OK\"] = 0] = \"OK\";\n    ERROR[ERROR[\"INTERNAL\"] = 1] = \"INTERNAL\";\n    ERROR[ERROR[\"STRICT\"] = 2] = \"STRICT\";\n    ERROR[ERROR[\"LF_EXPECTED\"] = 3] = \"LF_EXPECTED\";\n    ERROR[ERROR[\"UNEXPECTED_CONTENT_LENGTH\"] = 4] = \"UNEXPECTED_CONTENT_LENGTH\";\n    ERROR[ERROR[\"CLOSED_CONNECTION\"] = 5] = \"CLOSED_CONNECTION\";\n    ERROR[ERROR[\"INVALID_METHOD\"] = 6] = \"INVALID_METHOD\";\n    ERROR[ERROR[\"INVALID_URL\"] = 7] = \"INVALID_URL\";\n    ERROR[ERROR[\"INVALID_CONSTANT\"] = 8] = \"INVALID_CONSTANT\";\n    ERROR[ERROR[\"INVALID_VERSION\"] = 9] = \"INVALID_VERSION\";\n    ERROR[ERROR[\"INVALID_HEADER_TOKEN\"] = 10] = \"INVALID_HEADER_TOKEN\";\n    ERROR[ERROR[\"INVALID_CONTENT_LENGTH\"] = 11] = \"INVALID_CONTENT_LENGTH\";\n    ERROR[ERROR[\"INVALID_CHUNK_SIZE\"] = 12] = \"INVALID_CHUNK_SIZE\";\n    ERROR[ERROR[\"INVALID_STATUS\"] = 13] = \"INVALID_STATUS\";\n    ERROR[ERROR[\"INVALID_EOF_STATE\"] = 14] = \"INVALID_EOF_STATE\";\n    ERROR[ERROR[\"INVALID_TRANSFER_ENCODING\"] = 15] = \"INVALID_TRANSFER_ENCODING\";\n    ERROR[ERROR[\"CB_MESSAGE_BEGIN\"] = 16] = \"CB_MESSAGE_BEGIN\";\n    ERROR[ERROR[\"CB_HEADERS_COMPLETE\"] = 17] = \"CB_HEADERS_COMPLETE\";\n    ERROR[ERROR[\"CB_MESSAGE_COMPLETE\"] = 18] = \"CB_MESSAGE_COMPLETE\";\n    ERROR[ERROR[\"CB_CHUNK_HEADER\"] = 19] = \"CB_CHUNK_HEADER\";\n    ERROR[ERROR[\"CB_CHUNK_COMPLETE\"] = 20] = \"CB_CHUNK_COMPLETE\";\n    ERROR[ERROR[\"PAUSED\"] = 21] = \"PAUSED\";\n    ERROR[ERROR[\"PAUSED_UPGRADE\"] = 22] = \"PAUSED_UPGRADE\";\n    ERROR[ERROR[\"PAUSED_H2_UPGRADE\"] = 23] = \"PAUSED_H2_UPGRADE\";\n    ERROR[ERROR[\"USER\"] = 24] = \"USER\";\n})(ERROR = exports.ERROR || (exports.ERROR = {}));\nvar TYPE;\n(function (TYPE) {\n    TYPE[TYPE[\"BOTH\"] = 0] = \"BOTH\";\n    TYPE[TYPE[\"REQUEST\"] = 1] = \"REQUEST\";\n    TYPE[TYPE[\"RESPONSE\"] = 2] = \"RESPONSE\";\n})(TYPE = exports.TYPE || (exports.TYPE = {}));\nvar FLAGS;\n(function (FLAGS) {\n    FLAGS[FLAGS[\"CONNECTION_KEEP_ALIVE\"] = 1] = \"CONNECTION_KEEP_ALIVE\";\n    FLAGS[FLAGS[\"CONNECTION_CLOSE\"] = 2] = \"CONNECTION_CLOSE\";\n    FLAGS[FLAGS[\"CONNECTION_UPGRADE\"] = 4] = \"CONNECTION_UPGRADE\";\n    FLAGS[FLAGS[\"CHUNKED\"] = 8] = \"CHUNKED\";\n    FLAGS[FLAGS[\"UPGRADE\"] = 16] = \"UPGRADE\";\n    FLAGS[FLAGS[\"CONTENT_LENGTH\"] = 32] = \"CONTENT_LENGTH\";\n    FLAGS[FLAGS[\"SKIPBODY\"] = 64] = \"SKIPBODY\";\n    FLAGS[FLAGS[\"TRAILING\"] = 128] = \"TRAILING\";\n    // 1 << 8 is unused\n    FLAGS[FLAGS[\"TRANSFER_ENCODING\"] = 512] = \"TRANSFER_ENCODING\";\n})(FLAGS = exports.FLAGS || (exports.FLAGS = {}));\nvar LENIENT_FLAGS;\n(function (LENIENT_FLAGS) {\n    LENIENT_FLAGS[LENIENT_FLAGS[\"HEADERS\"] = 1] = \"HEADERS\";\n    LENIENT_FLAGS[LENIENT_FLAGS[\"CHUNKED_LENGTH\"] = 2] = \"CHUNKED_LENGTH\";\n    LENIENT_FLAGS[LENIENT_FLAGS[\"KEEP_ALIVE\"] = 4] = \"KEEP_ALIVE\";\n})(LENIENT_FLAGS = exports.LENIENT_FLAGS || (exports.LENIENT_FLAGS = {}));\nvar METHODS;\n(function (METHODS) {\n    METHODS[METHODS[\"DELETE\"] = 0] = \"DELETE\";\n    METHODS[METHODS[\"GET\"] = 1] = \"GET\";\n    METHODS[METHODS[\"HEAD\"] = 2] = \"HEAD\";\n    METHODS[METHODS[\"POST\"] = 3] = \"POST\";\n    METHODS[METHODS[\"PUT\"] = 4] = \"PUT\";\n    /* pathological */\n    METHODS[METHODS[\"CONNECT\"] = 5] = \"CONNECT\";\n    METHODS[METHODS[\"OPTIONS\"] = 6] = \"OPTIONS\";\n    METHODS[METHODS[\"TRACE\"] = 7] = \"TRACE\";\n    /* WebDAV */\n    METHODS[METHODS[\"COPY\"] = 8] = \"COPY\";\n    METHODS[METHODS[\"LOCK\"] = 9] = \"LOCK\";\n    METHODS[METHODS[\"MKCOL\"] = 10] = \"MKCOL\";\n    METHODS[METHODS[\"MOVE\"] = 11] = \"MOVE\";\n    METHODS[METHODS[\"PROPFIND\"] = 12] = \"PROPFIND\";\n    METHODS[METHODS[\"PROPPATCH\"] = 13] = \"PROPPATCH\";\n    METHODS[METHODS[\"SEARCH\"] = 14] = \"SEARCH\";\n    METHODS[METHODS[\"UNLOCK\"] = 15] = \"UNLOCK\";\n    METHODS[METHODS[\"BIND\"] = 16] = \"BIND\";\n    METHODS[METHODS[\"REBIND\"] = 17] = \"REBIND\";\n    METHODS[METHODS[\"UNBIND\"] = 18] = \"UNBIND\";\n    METHODS[METHODS[\"ACL\"] = 19] = \"ACL\";\n    /* subversion */\n    METHODS[METHODS[\"REPORT\"] = 20] = \"REPORT\";\n    METHODS[METHODS[\"MKACTIVITY\"] = 21] = \"MKACTIVITY\";\n    METHODS[METHODS[\"CHECKOUT\"] = 22] = \"CHECKOUT\";\n    METHODS[METHODS[\"MERGE\"] = 23] = \"MERGE\";\n    /* upnp */\n    METHODS[METHODS[\"M-SEARCH\"] = 24] = \"M-SEARCH\";\n    METHODS[METHODS[\"NOTIFY\"] = 25] = \"NOTIFY\";\n    METHODS[METHODS[\"SUBSCRIBE\"] = 26] = \"SUBSCRIBE\";\n    METHODS[METHODS[\"UNSUBSCRIBE\"] = 27] = \"UNSUBSCRIBE\";\n    /* RFC-5789 */\n    METHODS[METHODS[\"PATCH\"] = 28] = \"PATCH\";\n    METHODS[METHODS[\"PURGE\"] = 29] = \"PURGE\";\n    /* CalDAV */\n    METHODS[METHODS[\"MKCALENDAR\"] = 30] = \"MKCALENDAR\";\n    /* RFC-2068, section 19.6.1.2 */\n    METHODS[METHODS[\"LINK\"] = 31] = \"LINK\";\n    METHODS[METHODS[\"UNLINK\"] = 32] = \"UNLINK\";\n    /* icecast */\n    METHODS[METHODS[\"SOURCE\"] = 33] = \"SOURCE\";\n    /* RFC-7540, section 11.6 */\n    METHODS[METHODS[\"PRI\"] = 34] = \"PRI\";\n    /* RFC-2326 RTSP */\n    METHODS[METHODS[\"DESCRIBE\"] = 35] = \"DESCRIBE\";\n    METHODS[METHODS[\"ANNOUNCE\"] = 36] = \"ANNOUNCE\";\n    METHODS[METHODS[\"SETUP\"] = 37] = \"SETUP\";\n    METHODS[METHODS[\"PLAY\"] = 38] = \"PLAY\";\n    METHODS[METHODS[\"PAUSE\"] = 39] = \"PAUSE\";\n    METHODS[METHODS[\"TEARDOWN\"] = 40] = \"TEARDOWN\";\n    METHODS[METHODS[\"GET_PARAMETER\"] = 41] = \"GET_PARAMETER\";\n    METHODS[METHODS[\"SET_PARAMETER\"] = 42] = \"SET_PARAMETER\";\n    METHODS[METHODS[\"REDIRECT\"] = 43] = \"REDIRECT\";\n    METHODS[METHODS[\"RECORD\"] = 44] = \"RECORD\";\n    /* RAOP */\n    METHODS[METHODS[\"FLUSH\"] = 45] = \"FLUSH\";\n})(METHODS = exports.METHODS || (exports.METHODS = {}));\nexports.METHODS_HTTP = [\n    METHODS.DELETE,\n    METHODS.GET,\n    METHODS.HEAD,\n    METHODS.POST,\n    METHODS.PUT,\n    METHODS.CONNECT,\n    METHODS.OPTIONS,\n    METHODS.TRACE,\n    METHODS.COPY,\n    METHODS.LOCK,\n    METHODS.MKCOL,\n    METHODS.MOVE,\n    METHODS.PROPFIND,\n    METHODS.PROPPATCH,\n    METHODS.SEARCH,\n    METHODS.UNLOCK,\n    METHODS.BIND,\n    METHODS.REBIND,\n    METHODS.UNBIND,\n    METHODS.ACL,\n    METHODS.REPORT,\n    METHODS.MKACTIVITY,\n    METHODS.CHECKOUT,\n    METHODS.MERGE,\n    METHODS['M-SEARCH'],\n    METHODS.NOTIFY,\n    METHODS.SUBSCRIBE,\n    METHODS.UNSUBSCRIBE,\n    METHODS.PATCH,\n    METHODS.PURGE,\n    METHODS.MKCALENDAR,\n    METHODS.LINK,\n    METHODS.UNLINK,\n    METHODS.PRI,\n    // TODO(indutny): should we allow it with HTTP?\n    METHODS.SOURCE,\n];\nexports.METHODS_ICE = [\n    METHODS.SOURCE,\n];\nexports.METHODS_RTSP = [\n    METHODS.OPTIONS,\n    METHODS.DESCRIBE,\n    METHODS.ANNOUNCE,\n    METHODS.SETUP,\n    METHODS.PLAY,\n    METHODS.PAUSE,\n    METHODS.TEARDOWN,\n    METHODS.GET_PARAMETER,\n    METHODS.SET_PARAMETER,\n    METHODS.REDIRECT,\n    METHODS.RECORD,\n    METHODS.FLUSH,\n    // For AirPlay\n    METHODS.GET,\n    METHODS.POST,\n];\nexports.METHOD_MAP = utils_1.enumToMap(METHODS);\nexports.H_METHOD_MAP = {};\nObject.keys(exports.METHOD_MAP).forEach((key) => {\n    if (/^H/.test(key)) {\n        exports.H_METHOD_MAP[key] = exports.METHOD_MAP[key];\n    }\n});\nvar FINISH;\n(function (FINISH) {\n    FINISH[FINISH[\"SAFE\"] = 0] = \"SAFE\";\n    FINISH[FINISH[\"SAFE_WITH_CB\"] = 1] = \"SAFE_WITH_CB\";\n    FINISH[FINISH[\"UNSAFE\"] = 2] = \"UNSAFE\";\n})(FINISH = exports.FINISH || (exports.FINISH = {}));\nexports.ALPHA = [];\nfor (let i = 'A'.charCodeAt(0); i <= 'Z'.charCodeAt(0); i++) {\n    // Upper case\n    exports.ALPHA.push(String.fromCharCode(i));\n    // Lower case\n    exports.ALPHA.push(String.fromCharCode(i + 0x20));\n}\nexports.NUM_MAP = {\n    0: 0, 1: 1, 2: 2, 3: 3, 4: 4,\n    5: 5, 6: 6, 7: 7, 8: 8, 9: 9,\n};\nexports.HEX_MAP = {\n    0: 0, 1: 1, 2: 2, 3: 3, 4: 4,\n    5: 5, 6: 6, 7: 7, 8: 8, 9: 9,\n    A: 0XA, B: 0XB, C: 0XC, D: 0XD, E: 0XE, F: 0XF,\n    a: 0xa, b: 0xb, c: 0xc, d: 0xd, e: 0xe, f: 0xf,\n};\nexports.NUM = [\n    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n];\nexports.ALPHANUM = exports.ALPHA.concat(exports.NUM);\nexports.MARK = ['-', '_', '.', '!', '~', '*', '\\'', '(', ')'];\nexports.USERINFO_CHARS = exports.ALPHANUM\n    .concat(exports.MARK)\n    .concat(['%', ';', ':', '&', '=', '+', '$', ',']);\n// TODO(indutny): use RFC\nexports.STRICT_URL_CHAR = [\n    '!', '\"', '$', '%', '&', '\\'',\n    '(', ')', '*', '+', ',', '-', '.', '/',\n    ':', ';', '<', '=', '>',\n    '@', '[', '\\\\', ']', '^', '_',\n    '`',\n    '{', '|', '}', '~',\n].concat(exports.ALPHANUM);\nexports.URL_CHAR = exports.STRICT_URL_CHAR\n    .concat(['\\t', '\\f']);\n// All characters with 0x80 bit set to 1\nfor (let i = 0x80; i <= 0xff; i++) {\n    exports.URL_CHAR.push(i);\n}\nexports.HEX = exports.NUM.concat(['a', 'b', 'c', 'd', 'e', 'f', 'A', 'B', 'C', 'D', 'E', 'F']);\n/* Tokens as defined by rfc 2616. Also lowercases them.\n *        token       = 1*<any CHAR except CTLs or separators>\n *     separators     = \"(\" | \")\" | \"<\" | \">\" | \"@\"\n *                    | \",\" | \";\" | \":\" | \"\\\" | <\">\n *                    | \"/\" | \"[\" | \"]\" | \"?\" | \"=\"\n *                    | \"{\" | \"}\" | SP | HT\n */\nexports.STRICT_TOKEN = [\n    '!', '#', '$', '%', '&', '\\'',\n    '*', '+', '-', '.',\n    '^', '_', '`',\n    '|', '~',\n].concat(exports.ALPHANUM);\nexports.TOKEN = exports.STRICT_TOKEN.concat([' ']);\n/*\n * Verify that a char is a valid visible (printable) US-ASCII\n * character or %x80-FF\n */\nexports.HEADER_CHARS = ['\\t'];\nfor (let i = 32; i <= 255; i++) {\n    if (i !== 127) {\n        exports.HEADER_CHARS.push(i);\n    }\n}\n// ',' = \\x44\nexports.CONNECTION_TOKEN_CHARS = exports.HEADER_CHARS.filter((c) => c !== 44);\nexports.MAJOR = exports.NUM_MAP;\nexports.MINOR = exports.MAJOR;\nvar HEADER_STATE;\n(function (HEADER_STATE) {\n    HEADER_STATE[HEADER_STATE[\"GENERAL\"] = 0] = \"GENERAL\";\n    HEADER_STATE[HEADER_STATE[\"CONNECTION\"] = 1] = \"CONNECTION\";\n    HEADER_STATE[HEADER_STATE[\"CONTENT_LENGTH\"] = 2] = \"CONTENT_LENGTH\";\n    HEADER_STATE[HEADER_STATE[\"TRANSFER_ENCODING\"] = 3] = \"TRANSFER_ENCODING\";\n    HEADER_STATE[HEADER_STATE[\"UPGRADE\"] = 4] = \"UPGRADE\";\n    HEADER_STATE[HEADER_STATE[\"CONNECTION_KEEP_ALIVE\"] = 5] = \"CONNECTION_KEEP_ALIVE\";\n    HEADER_STATE[HEADER_STATE[\"CONNECTION_CLOSE\"] = 6] = \"CONNECTION_CLOSE\";\n    HEADER_STATE[HEADER_STATE[\"CONNECTION_UPGRADE\"] = 7] = \"CONNECTION_UPGRADE\";\n    HEADER_STATE[HEADER_STATE[\"TRANSFER_ENCODING_CHUNKED\"] = 8] = \"TRANSFER_ENCODING_CHUNKED\";\n})(HEADER_STATE = exports.HEADER_STATE || (exports.HEADER_STATE = {}));\nexports.SPECIAL_HEADERS = {\n    'connection': HEADER_STATE.CONNECTION,\n    'content-length': HEADER_STATE.CONTENT_LENGTH,\n    'proxy-connection': HEADER_STATE.CONNECTION,\n    'transfer-encoding': HEADER_STATE.TRANSFER_ENCODING,\n    'upgrade': HEADER_STATE.UPGRADE,\n};\n//# sourceMappingURL=constants.js.map","module.exports = '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'\n","module.exports = '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'\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.enumToMap = void 0;\nfunction enumToMap(obj) {\n    const res = {};\n    Object.keys(obj).forEach((key) => {\n        const value = obj[key];\n        if (typeof value === 'number') {\n            res[key] = value;\n        }\n    });\n    return res;\n}\nexports.enumToMap = enumToMap;\n//# sourceMappingURL=utils.js.map","'use strict'\n\nconst { kClients } = require('../core/symbols')\nconst Agent = require('../agent')\nconst {\n  kAgent,\n  kMockAgentSet,\n  kMockAgentGet,\n  kDispatches,\n  kIsMockActive,\n  kNetConnect,\n  kGetNetConnect,\n  kOptions,\n  kFactory\n} = require('./mock-symbols')\nconst MockClient = require('./mock-client')\nconst MockPool = require('./mock-pool')\nconst { matchValue, buildMockOptions } = require('./mock-utils')\nconst { InvalidArgumentError, UndiciError } = require('../core/errors')\nconst Dispatcher = require('../dispatcher')\nconst Pluralizer = require('./pluralizer')\nconst PendingInterceptorsFormatter = require('./pending-interceptors-formatter')\n\nclass FakeWeakRef {\n  constructor (value) {\n    this.value = value\n  }\n\n  deref () {\n    return this.value\n  }\n}\n\nclass MockAgent extends Dispatcher {\n  constructor (opts) {\n    super(opts)\n\n    this[kNetConnect] = true\n    this[kIsMockActive] = true\n\n    // Instantiate Agent and encapsulate\n    if ((opts && opts.agent && typeof opts.agent.dispatch !== 'function')) {\n      throw new InvalidArgumentError('Argument opts.agent must implement Agent')\n    }\n    const agent = opts && opts.agent ? opts.agent : new Agent(opts)\n    this[kAgent] = agent\n\n    this[kClients] = agent[kClients]\n    this[kOptions] = buildMockOptions(opts)\n  }\n\n  get (origin) {\n    let dispatcher = this[kMockAgentGet](origin)\n\n    if (!dispatcher) {\n      dispatcher = this[kFactory](origin)\n      this[kMockAgentSet](origin, dispatcher)\n    }\n    return dispatcher\n  }\n\n  dispatch (opts, handler) {\n    // Call MockAgent.get to perform additional setup before dispatching as normal\n    this.get(opts.origin)\n    return this[kAgent].dispatch(opts, handler)\n  }\n\n  async close () {\n    await this[kAgent].close()\n    this[kClients].clear()\n  }\n\n  deactivate () {\n    this[kIsMockActive] = false\n  }\n\n  activate () {\n    this[kIsMockActive] = true\n  }\n\n  enableNetConnect (matcher) {\n    if (typeof matcher === 'string' || typeof matcher === 'function' || matcher instanceof RegExp) {\n      if (Array.isArray(this[kNetConnect])) {\n        this[kNetConnect].push(matcher)\n      } else {\n        this[kNetConnect] = [matcher]\n      }\n    } else if (typeof matcher === 'undefined') {\n      this[kNetConnect] = true\n    } else {\n      throw new InvalidArgumentError('Unsupported matcher. Must be one of String|Function|RegExp.')\n    }\n  }\n\n  disableNetConnect () {\n    this[kNetConnect] = false\n  }\n\n  // This is required to bypass issues caused by using global symbols - see:\n  // https://github.com/nodejs/undici/issues/1447\n  get isMockActive () {\n    return this[kIsMockActive]\n  }\n\n  [kMockAgentSet] (origin, dispatcher) {\n    this[kClients].set(origin, new FakeWeakRef(dispatcher))\n  }\n\n  [kFactory] (origin) {\n    const mockOptions = Object.assign({ agent: this }, this[kOptions])\n    return this[kOptions] && this[kOptions].connections === 1\n      ? new MockClient(origin, mockOptions)\n      : new MockPool(origin, mockOptions)\n  }\n\n  [kMockAgentGet] (origin) {\n    // First check if we can immediately find it\n    const ref = this[kClients].get(origin)\n    if (ref) {\n      return ref.deref()\n    }\n\n    // If the origin is not a string create a dummy parent pool and return to user\n    if (typeof origin !== 'string') {\n      const dispatcher = this[kFactory]('http://localhost:9999')\n      this[kMockAgentSet](origin, dispatcher)\n      return dispatcher\n    }\n\n    // If we match, create a pool and assign the same dispatches\n    for (const [keyMatcher, nonExplicitRef] of Array.from(this[kClients])) {\n      const nonExplicitDispatcher = nonExplicitRef.deref()\n      if (nonExplicitDispatcher && typeof keyMatcher !== 'string' && matchValue(keyMatcher, origin)) {\n        const dispatcher = this[kFactory](origin)\n        this[kMockAgentSet](origin, dispatcher)\n        dispatcher[kDispatches] = nonExplicitDispatcher[kDispatches]\n        return dispatcher\n      }\n    }\n  }\n\n  [kGetNetConnect] () {\n    return this[kNetConnect]\n  }\n\n  pendingInterceptors () {\n    const mockAgentClients = this[kClients]\n\n    return Array.from(mockAgentClients.entries())\n      .flatMap(([origin, scope]) => scope.deref()[kDispatches].map(dispatch => ({ ...dispatch, origin })))\n      .filter(({ pending }) => pending)\n  }\n\n  assertNoPendingInterceptors ({ pendingInterceptorsFormatter = new PendingInterceptorsFormatter() } = {}) {\n    const pending = this.pendingInterceptors()\n\n    if (pending.length === 0) {\n      return\n    }\n\n    const pluralizer = new Pluralizer('interceptor', 'interceptors').pluralize(pending.length)\n\n    throw new UndiciError(`\n${pluralizer.count} ${pluralizer.noun} ${pluralizer.is} pending:\n\n${pendingInterceptorsFormatter.format(pending)}\n`.trim())\n  }\n}\n\nmodule.exports = MockAgent\n","'use strict'\n\nconst { promisify } = require('util')\nconst Client = require('../client')\nconst { buildMockDispatch } = require('./mock-utils')\nconst {\n  kDispatches,\n  kMockAgent,\n  kClose,\n  kOriginalClose,\n  kOrigin,\n  kOriginalDispatch,\n  kConnected\n} = require('./mock-symbols')\nconst { MockInterceptor } = require('./mock-interceptor')\nconst Symbols = require('../core/symbols')\nconst { InvalidArgumentError } = require('../core/errors')\n\n/**\n * MockClient provides an API that extends the Client to influence the mockDispatches.\n */\nclass MockClient extends Client {\n  constructor (origin, opts) {\n    super(origin, opts)\n\n    if (!opts || !opts.agent || typeof opts.agent.dispatch !== 'function') {\n      throw new InvalidArgumentError('Argument opts.agent must implement Agent')\n    }\n\n    this[kMockAgent] = opts.agent\n    this[kOrigin] = origin\n    this[kDispatches] = []\n    this[kConnected] = 1\n    this[kOriginalDispatch] = this.dispatch\n    this[kOriginalClose] = this.close.bind(this)\n\n    this.dispatch = buildMockDispatch.call(this)\n    this.close = this[kClose]\n  }\n\n  get [Symbols.kConnected] () {\n    return this[kConnected]\n  }\n\n  /**\n   * Sets up the base interceptor for mocking replies from undici.\n   */\n  intercept (opts) {\n    return new MockInterceptor(opts, this[kDispatches])\n  }\n\n  async [kClose] () {\n    await promisify(this[kOriginalClose])()\n    this[kConnected] = 0\n    this[kMockAgent][Symbols.kClients].delete(this[kOrigin])\n  }\n}\n\nmodule.exports = MockClient\n","'use strict'\n\nconst { UndiciError } = require('../core/errors')\n\nclass MockNotMatchedError extends UndiciError {\n  constructor (message) {\n    super(message)\n    Error.captureStackTrace(this, MockNotMatchedError)\n    this.name = 'MockNotMatchedError'\n    this.message = message || 'The request does not match any registered mock dispatches'\n    this.code = 'UND_MOCK_ERR_MOCK_NOT_MATCHED'\n  }\n}\n\nmodule.exports = {\n  MockNotMatchedError\n}\n","'use strict'\n\nconst { getResponseData, buildKey, addMockDispatch } = require('./mock-utils')\nconst {\n  kDispatches,\n  kDispatchKey,\n  kDefaultHeaders,\n  kDefaultTrailers,\n  kContentLength,\n  kMockDispatch\n} = require('./mock-symbols')\nconst { InvalidArgumentError } = require('../core/errors')\nconst { buildURL } = require('../core/util')\n\n/**\n * Defines the scope API for an interceptor reply\n */\nclass MockScope {\n  constructor (mockDispatch) {\n    this[kMockDispatch] = mockDispatch\n  }\n\n  /**\n   * Delay a reply by a set amount in ms.\n   */\n  delay (waitInMs) {\n    if (typeof waitInMs !== 'number' || !Number.isInteger(waitInMs) || waitInMs <= 0) {\n      throw new InvalidArgumentError('waitInMs must be a valid integer > 0')\n    }\n\n    this[kMockDispatch].delay = waitInMs\n    return this\n  }\n\n  /**\n   * For a defined reply, never mark as consumed.\n   */\n  persist () {\n    this[kMockDispatch].persist = true\n    return this\n  }\n\n  /**\n   * Allow one to define a reply for a set amount of matching requests.\n   */\n  times (repeatTimes) {\n    if (typeof repeatTimes !== 'number' || !Number.isInteger(repeatTimes) || repeatTimes <= 0) {\n      throw new InvalidArgumentError('repeatTimes must be a valid integer > 0')\n    }\n\n    this[kMockDispatch].times = repeatTimes\n    return this\n  }\n}\n\n/**\n * Defines an interceptor for a Mock\n */\nclass MockInterceptor {\n  constructor (opts, mockDispatches) {\n    if (typeof opts !== 'object') {\n      throw new InvalidArgumentError('opts must be an object')\n    }\n    if (typeof opts.path === 'undefined') {\n      throw new InvalidArgumentError('opts.path must be defined')\n    }\n    if (typeof opts.method === 'undefined') {\n      opts.method = 'GET'\n    }\n    // See https://github.com/nodejs/undici/issues/1245\n    // As per RFC 3986, clients are not supposed to send URI\n    // fragments to servers when they retrieve a document,\n    if (typeof opts.path === 'string') {\n      if (opts.query) {\n        opts.path = buildURL(opts.path, opts.query)\n      } else {\n        // Matches https://github.com/nodejs/undici/blob/main/lib/fetch/index.js#L1811\n        const parsedURL = new URL(opts.path, 'data://')\n        opts.path = parsedURL.pathname + parsedURL.search\n      }\n    }\n    if (typeof opts.method === 'string') {\n      opts.method = opts.method.toUpperCase()\n    }\n\n    this[kDispatchKey] = buildKey(opts)\n    this[kDispatches] = mockDispatches\n    this[kDefaultHeaders] = {}\n    this[kDefaultTrailers] = {}\n    this[kContentLength] = false\n  }\n\n  createMockScopeDispatchData (statusCode, data, responseOptions = {}) {\n    const responseData = getResponseData(data)\n    const contentLength = this[kContentLength] ? { 'content-length': responseData.length } : {}\n    const headers = { ...this[kDefaultHeaders], ...contentLength, ...responseOptions.headers }\n    const trailers = { ...this[kDefaultTrailers], ...responseOptions.trailers }\n\n    return { statusCode, data, headers, trailers }\n  }\n\n  validateReplyParameters (statusCode, data, responseOptions) {\n    if (typeof statusCode === 'undefined') {\n      throw new InvalidArgumentError('statusCode must be defined')\n    }\n    if (typeof data === 'undefined') {\n      throw new InvalidArgumentError('data must be defined')\n    }\n    if (typeof responseOptions !== 'object') {\n      throw new InvalidArgumentError('responseOptions must be an object')\n    }\n  }\n\n  /**\n   * Mock an undici request with a defined reply.\n   */\n  reply (replyData) {\n    // Values of reply aren't available right now as they\n    // can only be available when the reply callback is invoked.\n    if (typeof replyData === 'function') {\n      // We'll first wrap the provided callback in another function,\n      // this function will properly resolve the data from the callback\n      // when invoked.\n      const wrappedDefaultsCallback = (opts) => {\n        // Our reply options callback contains the parameter for statusCode, data and options.\n        const resolvedData = replyData(opts)\n\n        // Check if it is in the right format\n        if (typeof resolvedData !== 'object') {\n          throw new InvalidArgumentError('reply options callback must return an object')\n        }\n\n        const { statusCode, data = '', responseOptions = {} } = resolvedData\n        this.validateReplyParameters(statusCode, data, responseOptions)\n        // Since the values can be obtained immediately we return them\n        // from this higher order function that will be resolved later.\n        return {\n          ...this.createMockScopeDispatchData(statusCode, data, responseOptions)\n        }\n      }\n\n      // Add usual dispatch data, but this time set the data parameter to function that will eventually provide data.\n      const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], wrappedDefaultsCallback)\n      return new MockScope(newMockDispatch)\n    }\n\n    // We can have either one or three parameters, if we get here,\n    // we should have 1-3 parameters. So we spread the arguments of\n    // this function to obtain the parameters, since replyData will always\n    // just be the statusCode.\n    const [statusCode, data = '', responseOptions = {}] = [...arguments]\n    this.validateReplyParameters(statusCode, data, responseOptions)\n\n    // Send in-already provided data like usual\n    const dispatchData = this.createMockScopeDispatchData(statusCode, data, responseOptions)\n    const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], dispatchData)\n    return new MockScope(newMockDispatch)\n  }\n\n  /**\n   * Mock an undici request with a defined error.\n   */\n  replyWithError (error) {\n    if (typeof error === 'undefined') {\n      throw new InvalidArgumentError('error must be defined')\n    }\n\n    const newMockDispatch = addMockDispatch(this[kDispatches], this[kDispatchKey], { error })\n    return new MockScope(newMockDispatch)\n  }\n\n  /**\n   * Set default reply headers on the interceptor for subsequent replies\n   */\n  defaultReplyHeaders (headers) {\n    if (typeof headers === 'undefined') {\n      throw new InvalidArgumentError('headers must be defined')\n    }\n\n    this[kDefaultHeaders] = headers\n    return this\n  }\n\n  /**\n   * Set default reply trailers on the interceptor for subsequent replies\n   */\n  defaultReplyTrailers (trailers) {\n    if (typeof trailers === 'undefined') {\n      throw new InvalidArgumentError('trailers must be defined')\n    }\n\n    this[kDefaultTrailers] = trailers\n    return this\n  }\n\n  /**\n   * Set reply content length header for replies on the interceptor\n   */\n  replyContentLength () {\n    this[kContentLength] = true\n    return this\n  }\n}\n\nmodule.exports.MockInterceptor = MockInterceptor\nmodule.exports.MockScope = MockScope\n","'use strict'\n\nconst { promisify } = require('util')\nconst Pool = require('../pool')\nconst { buildMockDispatch } = require('./mock-utils')\nconst {\n  kDispatches,\n  kMockAgent,\n  kClose,\n  kOriginalClose,\n  kOrigin,\n  kOriginalDispatch,\n  kConnected\n} = require('./mock-symbols')\nconst { MockInterceptor } = require('./mock-interceptor')\nconst Symbols = require('../core/symbols')\nconst { InvalidArgumentError } = require('../core/errors')\n\n/**\n * MockPool provides an API that extends the Pool to influence the mockDispatches.\n */\nclass MockPool extends Pool {\n  constructor (origin, opts) {\n    super(origin, opts)\n\n    if (!opts || !opts.agent || typeof opts.agent.dispatch !== 'function') {\n      throw new InvalidArgumentError('Argument opts.agent must implement Agent')\n    }\n\n    this[kMockAgent] = opts.agent\n    this[kOrigin] = origin\n    this[kDispatches] = []\n    this[kConnected] = 1\n    this[kOriginalDispatch] = this.dispatch\n    this[kOriginalClose] = this.close.bind(this)\n\n    this.dispatch = buildMockDispatch.call(this)\n    this.close = this[kClose]\n  }\n\n  get [Symbols.kConnected] () {\n    return this[kConnected]\n  }\n\n  /**\n   * Sets up the base interceptor for mocking replies from undici.\n   */\n  intercept (opts) {\n    return new MockInterceptor(opts, this[kDispatches])\n  }\n\n  async [kClose] () {\n    await promisify(this[kOriginalClose])()\n    this[kConnected] = 0\n    this[kMockAgent][Symbols.kClients].delete(this[kOrigin])\n  }\n}\n\nmodule.exports = MockPool\n","'use strict'\n\nmodule.exports = {\n  kAgent: Symbol('agent'),\n  kOptions: Symbol('options'),\n  kFactory: Symbol('factory'),\n  kDispatches: Symbol('dispatches'),\n  kDispatchKey: Symbol('dispatch key'),\n  kDefaultHeaders: Symbol('default headers'),\n  kDefaultTrailers: Symbol('default trailers'),\n  kContentLength: Symbol('content length'),\n  kMockAgent: Symbol('mock agent'),\n  kMockAgentSet: Symbol('mock agent set'),\n  kMockAgentGet: Symbol('mock agent get'),\n  kMockDispatch: Symbol('mock dispatch'),\n  kClose: Symbol('close'),\n  kOriginalClose: Symbol('original agent close'),\n  kOrigin: Symbol('origin'),\n  kIsMockActive: Symbol('is mock active'),\n  kNetConnect: Symbol('net connect'),\n  kGetNetConnect: Symbol('get net connect'),\n  kConnected: Symbol('connected')\n}\n","'use strict'\n\nconst { MockNotMatchedError } = require('./mock-errors')\nconst {\n  kDispatches,\n  kMockAgent,\n  kOriginalDispatch,\n  kOrigin,\n  kGetNetConnect\n} = require('./mock-symbols')\nconst { buildURL, nop } = require('../core/util')\nconst { STATUS_CODES } = require('http')\nconst {\n  types: {\n    isPromise\n  }\n} = require('util')\n\nfunction matchValue (match, value) {\n  if (typeof match === 'string') {\n    return match === value\n  }\n  if (match instanceof RegExp) {\n    return match.test(value)\n  }\n  if (typeof match === 'function') {\n    return match(value) === true\n  }\n  return false\n}\n\nfunction lowerCaseEntries (headers) {\n  return Object.fromEntries(\n    Object.entries(headers).map(([headerName, headerValue]) => {\n      return [headerName.toLocaleLowerCase(), headerValue]\n    })\n  )\n}\n\n/**\n * @param {import('../../index').Headers|string[]|Record<string, string>} headers\n * @param {string} key\n */\nfunction getHeaderByName (headers, key) {\n  if (Array.isArray(headers)) {\n    for (let i = 0; i < headers.length; i += 2) {\n      if (headers[i].toLocaleLowerCase() === key.toLocaleLowerCase()) {\n        return headers[i + 1]\n      }\n    }\n\n    return undefined\n  } else if (typeof headers.get === 'function') {\n    return headers.get(key)\n  } else {\n    return lowerCaseEntries(headers)[key.toLocaleLowerCase()]\n  }\n}\n\n/** @param {string[]} headers */\nfunction buildHeadersFromArray (headers) { // fetch HeadersList\n  const clone = headers.slice()\n  const entries = []\n  for (let index = 0; index < clone.length; index += 2) {\n    entries.push([clone[index], clone[index + 1]])\n  }\n  return Object.fromEntries(entries)\n}\n\nfunction matchHeaders (mockDispatch, headers) {\n  if (typeof mockDispatch.headers === 'function') {\n    if (Array.isArray(headers)) { // fetch HeadersList\n      headers = buildHeadersFromArray(headers)\n    }\n    return mockDispatch.headers(headers ? lowerCaseEntries(headers) : {})\n  }\n  if (typeof mockDispatch.headers === 'undefined') {\n    return true\n  }\n  if (typeof headers !== 'object' || typeof mockDispatch.headers !== 'object') {\n    return false\n  }\n\n  for (const [matchHeaderName, matchHeaderValue] of Object.entries(mockDispatch.headers)) {\n    const headerValue = getHeaderByName(headers, matchHeaderName)\n\n    if (!matchValue(matchHeaderValue, headerValue)) {\n      return false\n    }\n  }\n  return true\n}\n\nfunction safeUrl (path) {\n  if (typeof path !== 'string') {\n    return path\n  }\n\n  const pathSegments = path.split('?')\n\n  if (pathSegments.length !== 2) {\n    return path\n  }\n\n  const qp = new URLSearchParams(pathSegments.pop())\n  qp.sort()\n  return [...pathSegments, qp.toString()].join('?')\n}\n\nfunction matchKey (mockDispatch, { path, method, body, headers }) {\n  const pathMatch = matchValue(mockDispatch.path, path)\n  const methodMatch = matchValue(mockDispatch.method, method)\n  const bodyMatch = typeof mockDispatch.body !== 'undefined' ? matchValue(mockDispatch.body, body) : true\n  const headersMatch = matchHeaders(mockDispatch, headers)\n  return pathMatch && methodMatch && bodyMatch && headersMatch\n}\n\nfunction getResponseData (data) {\n  if (Buffer.isBuffer(data)) {\n    return data\n  } else if (typeof data === 'object') {\n    return JSON.stringify(data)\n  } else {\n    return data.toString()\n  }\n}\n\nfunction getMockDispatch (mockDispatches, key) {\n  const basePath = key.query ? buildURL(key.path, key.query) : key.path\n  const resolvedPath = typeof basePath === 'string' ? safeUrl(basePath) : basePath\n\n  // Match path\n  let matchedMockDispatches = mockDispatches.filter(({ consumed }) => !consumed).filter(({ path }) => matchValue(safeUrl(path), resolvedPath))\n  if (matchedMockDispatches.length === 0) {\n    throw new MockNotMatchedError(`Mock dispatch not matched for path '${resolvedPath}'`)\n  }\n\n  // Match method\n  matchedMockDispatches = matchedMockDispatches.filter(({ method }) => matchValue(method, key.method))\n  if (matchedMockDispatches.length === 0) {\n    throw new MockNotMatchedError(`Mock dispatch not matched for method '${key.method}'`)\n  }\n\n  // Match body\n  matchedMockDispatches = matchedMockDispatches.filter(({ body }) => typeof body !== 'undefined' ? matchValue(body, key.body) : true)\n  if (matchedMockDispatches.length === 0) {\n    throw new MockNotMatchedError(`Mock dispatch not matched for body '${key.body}'`)\n  }\n\n  // Match headers\n  matchedMockDispatches = matchedMockDispatches.filter((mockDispatch) => matchHeaders(mockDispatch, key.headers))\n  if (matchedMockDispatches.length === 0) {\n    throw new MockNotMatchedError(`Mock dispatch not matched for headers '${typeof key.headers === 'object' ? JSON.stringify(key.headers) : key.headers}'`)\n  }\n\n  return matchedMockDispatches[0]\n}\n\nfunction addMockDispatch (mockDispatches, key, data) {\n  const baseData = { timesInvoked: 0, times: 1, persist: false, consumed: false }\n  const replyData = typeof data === 'function' ? { callback: data } : { ...data }\n  const newMockDispatch = { ...baseData, ...key, pending: true, data: { error: null, ...replyData } }\n  mockDispatches.push(newMockDispatch)\n  return newMockDispatch\n}\n\nfunction deleteMockDispatch (mockDispatches, key) {\n  const index = mockDispatches.findIndex(dispatch => {\n    if (!dispatch.consumed) {\n      return false\n    }\n    return matchKey(dispatch, key)\n  })\n  if (index !== -1) {\n    mockDispatches.splice(index, 1)\n  }\n}\n\nfunction buildKey (opts) {\n  const { path, method, body, headers, query } = opts\n  return {\n    path,\n    method,\n    body,\n    headers,\n    query\n  }\n}\n\nfunction generateKeyValues (data) {\n  return Object.entries(data).reduce((keyValuePairs, [key, value]) => [\n    ...keyValuePairs,\n    Buffer.from(`${key}`),\n    Array.isArray(value) ? value.map(x => Buffer.from(`${x}`)) : Buffer.from(`${value}`)\n  ], [])\n}\n\n/**\n * @see https://developer.mozilla.org/en-US/docs/Web/HTTP/Status\n * @param {number} statusCode\n */\nfunction getStatusText (statusCode) {\n  return STATUS_CODES[statusCode] || 'unknown'\n}\n\nasync function getResponse (body) {\n  const buffers = []\n  for await (const data of body) {\n    buffers.push(data)\n  }\n  return Buffer.concat(buffers).toString('utf8')\n}\n\n/**\n * Mock dispatch function used to simulate undici dispatches\n */\nfunction mockDispatch (opts, handler) {\n  // Get mock dispatch from built key\n  const key = buildKey(opts)\n  const mockDispatch = getMockDispatch(this[kDispatches], key)\n\n  mockDispatch.timesInvoked++\n\n  // Here's where we resolve a callback if a callback is present for the dispatch data.\n  if (mockDispatch.data.callback) {\n    mockDispatch.data = { ...mockDispatch.data, ...mockDispatch.data.callback(opts) }\n  }\n\n  // Parse mockDispatch data\n  const { data: { statusCode, data, headers, trailers, error }, delay, persist } = mockDispatch\n  const { timesInvoked, times } = mockDispatch\n\n  // If it's used up and not persistent, mark as consumed\n  mockDispatch.consumed = !persist && timesInvoked >= times\n  mockDispatch.pending = timesInvoked < times\n\n  // If specified, trigger dispatch error\n  if (error !== null) {\n    deleteMockDispatch(this[kDispatches], key)\n    handler.onError(error)\n    return true\n  }\n\n  // Handle the request with a delay if necessary\n  if (typeof delay === 'number' && delay > 0) {\n    setTimeout(() => {\n      handleReply(this[kDispatches])\n    }, delay)\n  } else {\n    handleReply(this[kDispatches])\n  }\n\n  function handleReply (mockDispatches, _data = data) {\n    // fetch's HeadersList is a 1D string array\n    const optsHeaders = Array.isArray(opts.headers)\n      ? buildHeadersFromArray(opts.headers)\n      : opts.headers\n    const body = typeof _data === 'function'\n      ? _data({ ...opts, headers: optsHeaders })\n      : _data\n\n    // util.types.isPromise is likely needed for jest.\n    if (isPromise(body)) {\n      // If handleReply is asynchronous, throwing an error\n      // in the callback will reject the promise, rather than\n      // synchronously throw the error, which breaks some tests.\n      // Rather, we wait for the callback to resolve if it is a\n      // promise, and then re-run handleReply with the new body.\n      body.then((newData) => handleReply(mockDispatches, newData))\n      return\n    }\n\n    const responseData = getResponseData(body)\n    const responseHeaders = generateKeyValues(headers)\n    const responseTrailers = generateKeyValues(trailers)\n\n    handler.abort = nop\n    handler.onHeaders(statusCode, responseHeaders, resume, getStatusText(statusCode))\n    handler.onData(Buffer.from(responseData))\n    handler.onComplete(responseTrailers)\n    deleteMockDispatch(mockDispatches, key)\n  }\n\n  function resume () {}\n\n  return true\n}\n\nfunction buildMockDispatch () {\n  const agent = this[kMockAgent]\n  const origin = this[kOrigin]\n  const originalDispatch = this[kOriginalDispatch]\n\n  return function dispatch (opts, handler) {\n    if (agent.isMockActive) {\n      try {\n        mockDispatch.call(this, opts, handler)\n      } catch (error) {\n        if (error instanceof MockNotMatchedError) {\n          const netConnect = agent[kGetNetConnect]()\n          if (netConnect === false) {\n            throw new MockNotMatchedError(`${error.message}: subsequent request to origin ${origin} was not allowed (net.connect disabled)`)\n          }\n          if (checkNetConnect(netConnect, origin)) {\n            originalDispatch.call(this, opts, handler)\n          } else {\n            throw new MockNotMatchedError(`${error.message}: subsequent request to origin ${origin} was not allowed (net.connect is not enabled for this origin)`)\n          }\n        } else {\n          throw error\n        }\n      }\n    } else {\n      originalDispatch.call(this, opts, handler)\n    }\n  }\n}\n\nfunction checkNetConnect (netConnect, origin) {\n  const url = new URL(origin)\n  if (netConnect === true) {\n    return true\n  } else if (Array.isArray(netConnect) && netConnect.some((matcher) => matchValue(matcher, url.host))) {\n    return true\n  }\n  return false\n}\n\nfunction buildMockOptions (opts) {\n  if (opts) {\n    const { agent, ...mockOptions } = opts\n    return mockOptions\n  }\n}\n\nmodule.exports = {\n  getResponseData,\n  getMockDispatch,\n  addMockDispatch,\n  deleteMockDispatch,\n  buildKey,\n  generateKeyValues,\n  matchValue,\n  getResponse,\n  getStatusText,\n  mockDispatch,\n  buildMockDispatch,\n  checkNetConnect,\n  buildMockOptions,\n  getHeaderByName\n}\n","'use strict'\n\nconst { Transform } = require('stream')\nconst { Console } = require('console')\n\n/**\n * Gets the output of `console.table()` as a string.\n */\nmodule.exports = class PendingInterceptorsFormatter {\n  constructor ({ disableColors } = {}) {\n    this.transform = new Transform({\n      transform (chunk, _enc, cb) {\n        cb(null, chunk)\n      }\n    })\n\n    this.logger = new Console({\n      stdout: this.transform,\n      inspectOptions: {\n        colors: !disableColors && !process.env.CI\n      }\n    })\n  }\n\n  format (pendingInterceptors) {\n    const withPrettyHeaders = pendingInterceptors.map(\n      ({ method, path, data: { statusCode }, persist, times, timesInvoked, origin }) => ({\n        Method: method,\n        Origin: origin,\n        Path: path,\n        'Status code': statusCode,\n        Persistent: persist ? '' : '',\n        Invocations: timesInvoked,\n        Remaining: persist ? Infinity : times - timesInvoked\n      }))\n\n    this.logger.table(withPrettyHeaders)\n    return this.transform.read().toString()\n  }\n}\n","'use strict'\n\nconst singulars = {\n  pronoun: 'it',\n  is: 'is',\n  was: 'was',\n  this: 'this'\n}\n\nconst plurals = {\n  pronoun: 'they',\n  is: 'are',\n  was: 'were',\n  this: 'these'\n}\n\nmodule.exports = class Pluralizer {\n  constructor (singular, plural) {\n    this.singular = singular\n    this.plural = plural\n  }\n\n  pluralize (count) {\n    const one = count === 1\n    const keys = one ? singulars : plurals\n    const noun = one ? this.singular : this.plural\n    return { ...keys, count, noun }\n  }\n}\n","/* eslint-disable */\n\n'use strict'\n\n// Extracted from node/lib/internal/fixed_queue.js\n\n// Currently optimal queue size, tested on V8 6.0 - 6.6. Must be power of two.\nconst kSize = 2048;\nconst kMask = kSize - 1;\n\n// The FixedQueue is implemented as a singly-linked list of fixed-size\n// circular buffers. It looks something like this:\n//\n//  head                                                       tail\n//    |                                                          |\n//    v                                                          v\n// +-----------+ <-----\\       +-----------+ <------\\         +-----------+\n// |  [null]   |        \\----- |   next    |         \\------- |   next    |\n// +-----------+               +-----------+                  +-----------+\n// |   item    | <-- bottom    |   item    | <-- bottom       |  [empty]  |\n// |   item    |               |   item    |                  |  [empty]  |\n// |   item    |               |   item    |                  |  [empty]  |\n// |   item    |               |   item    |                  |  [empty]  |\n// |   item    |               |   item    |       bottom --> |   item    |\n// |   item    |               |   item    |                  |   item    |\n// |    ...    |               |    ...    |                  |    ...    |\n// |   item    |               |   item    |                  |   item    |\n// |   item    |               |   item    |                  |   item    |\n// |  [empty]  | <-- top       |   item    |                  |   item    |\n// |  [empty]  |               |   item    |                  |   item    |\n// |  [empty]  |               |  [empty]  | <-- top  top --> |  [empty]  |\n// +-----------+               +-----------+                  +-----------+\n//\n// Or, if there is only one circular buffer, it looks something\n// like either of these:\n//\n//  head   tail                                 head   tail\n//    |     |                                     |     |\n//    v     v                                     v     v\n// +-----------+                               +-----------+\n// |  [null]   |                               |  [null]   |\n// +-----------+                               +-----------+\n// |  [empty]  |                               |   item    |\n// |  [empty]  |                               |   item    |\n// |   item    | <-- bottom            top --> |  [empty]  |\n// |   item    |                               |  [empty]  |\n// |  [empty]  | <-- top            bottom --> |   item    |\n// |  [empty]  |                               |   item    |\n// +-----------+                               +-----------+\n//\n// Adding a value means moving `top` forward by one, removing means\n// moving `bottom` forward by one. After reaching the end, the queue\n// wraps around.\n//\n// When `top === bottom` the current queue is empty and when\n// `top + 1 === bottom` it's full. This wastes a single space of storage\n// but allows much quicker checks.\n\nclass FixedCircularBuffer {\n  constructor() {\n    this.bottom = 0;\n    this.top = 0;\n    this.list = new Array(kSize);\n    this.next = null;\n  }\n\n  isEmpty() {\n    return this.top === this.bottom;\n  }\n\n  isFull() {\n    return ((this.top + 1) & kMask) === this.bottom;\n  }\n\n  push(data) {\n    this.list[this.top] = data;\n    this.top = (this.top + 1) & kMask;\n  }\n\n  shift() {\n    const nextItem = this.list[this.bottom];\n    if (nextItem === undefined)\n      return null;\n    this.list[this.bottom] = undefined;\n    this.bottom = (this.bottom + 1) & kMask;\n    return nextItem;\n  }\n}\n\nmodule.exports = class FixedQueue {\n  constructor() {\n    this.head = this.tail = new FixedCircularBuffer();\n  }\n\n  isEmpty() {\n    return this.head.isEmpty();\n  }\n\n  push(data) {\n    if (this.head.isFull()) {\n      // Head is full: Creates a new queue, sets the old queue's `.next` to it,\n      // and sets it as the new main queue.\n      this.head = this.head.next = new FixedCircularBuffer();\n    }\n    this.head.push(data);\n  }\n\n  shift() {\n    const tail = this.tail;\n    const next = tail.shift();\n    if (tail.isEmpty() && tail.next !== null) {\n      // If there is another queue, it forms the new tail.\n      this.tail = tail.next;\n    }\n    return next;\n  }\n};\n","'use strict'\n\nconst DispatcherBase = require('./dispatcher-base')\nconst FixedQueue = require('./node/fixed-queue')\nconst { kConnected, kSize, kRunning, kPending, kQueued, kBusy, kFree, kUrl, kClose, kDestroy, kDispatch } = require('./core/symbols')\nconst PoolStats = require('./pool-stats')\n\nconst kClients = Symbol('clients')\nconst kNeedDrain = Symbol('needDrain')\nconst kQueue = Symbol('queue')\nconst kClosedResolve = Symbol('closed resolve')\nconst kOnDrain = Symbol('onDrain')\nconst kOnConnect = Symbol('onConnect')\nconst kOnDisconnect = Symbol('onDisconnect')\nconst kOnConnectionError = Symbol('onConnectionError')\nconst kGetDispatcher = Symbol('get dispatcher')\nconst kAddClient = Symbol('add client')\nconst kRemoveClient = Symbol('remove client')\nconst kStats = Symbol('stats')\n\nclass PoolBase extends DispatcherBase {\n  constructor () {\n    super()\n\n    this[kQueue] = new FixedQueue()\n    this[kClients] = []\n    this[kQueued] = 0\n\n    const pool = this\n\n    this[kOnDrain] = function onDrain (origin, targets) {\n      const queue = pool[kQueue]\n\n      let needDrain = false\n\n      while (!needDrain) {\n        const item = queue.shift()\n        if (!item) {\n          break\n        }\n        pool[kQueued]--\n        needDrain = !this.dispatch(item.opts, item.handler)\n      }\n\n      this[kNeedDrain] = needDrain\n\n      if (!this[kNeedDrain] && pool[kNeedDrain]) {\n        pool[kNeedDrain] = false\n        pool.emit('drain', origin, [pool, ...targets])\n      }\n\n      if (pool[kClosedResolve] && queue.isEmpty()) {\n        Promise\n          .all(pool[kClients].map(c => c.close()))\n          .then(pool[kClosedResolve])\n      }\n    }\n\n    this[kOnConnect] = (origin, targets) => {\n      pool.emit('connect', origin, [pool, ...targets])\n    }\n\n    this[kOnDisconnect] = (origin, targets, err) => {\n      pool.emit('disconnect', origin, [pool, ...targets], err)\n    }\n\n    this[kOnConnectionError] = (origin, targets, err) => {\n      pool.emit('connectionError', origin, [pool, ...targets], err)\n    }\n\n    this[kStats] = new PoolStats(this)\n  }\n\n  get [kBusy] () {\n    return this[kNeedDrain]\n  }\n\n  get [kConnected] () {\n    return this[kClients].filter(client => client[kConnected]).length\n  }\n\n  get [kFree] () {\n    return this[kClients].filter(client => client[kConnected] && !client[kNeedDrain]).length\n  }\n\n  get [kPending] () {\n    let ret = this[kQueued]\n    for (const { [kPending]: pending } of this[kClients]) {\n      ret += pending\n    }\n    return ret\n  }\n\n  get [kRunning] () {\n    let ret = 0\n    for (const { [kRunning]: running } of this[kClients]) {\n      ret += running\n    }\n    return ret\n  }\n\n  get [kSize] () {\n    let ret = this[kQueued]\n    for (const { [kSize]: size } of this[kClients]) {\n      ret += size\n    }\n    return ret\n  }\n\n  get stats () {\n    return this[kStats]\n  }\n\n  async [kClose] () {\n    if (this[kQueue].isEmpty()) {\n      return Promise.all(this[kClients].map(c => c.close()))\n    } else {\n      return new Promise((resolve) => {\n        this[kClosedResolve] = resolve\n      })\n    }\n  }\n\n  async [kDestroy] (err) {\n    while (true) {\n      const item = this[kQueue].shift()\n      if (!item) {\n        break\n      }\n      item.handler.onError(err)\n    }\n\n    return Promise.all(this[kClients].map(c => c.destroy(err)))\n  }\n\n  [kDispatch] (opts, handler) {\n    const dispatcher = this[kGetDispatcher]()\n\n    if (!dispatcher) {\n      this[kNeedDrain] = true\n      this[kQueue].push({ opts, handler })\n      this[kQueued]++\n    } else if (!dispatcher.dispatch(opts, handler)) {\n      dispatcher[kNeedDrain] = true\n      this[kNeedDrain] = !this[kGetDispatcher]()\n    }\n\n    return !this[kNeedDrain]\n  }\n\n  [kAddClient] (client) {\n    client\n      .on('drain', this[kOnDrain])\n      .on('connect', this[kOnConnect])\n      .on('disconnect', this[kOnDisconnect])\n      .on('connectionError', this[kOnConnectionError])\n\n    this[kClients].push(client)\n\n    if (this[kNeedDrain]) {\n      process.nextTick(() => {\n        if (this[kNeedDrain]) {\n          this[kOnDrain](client[kUrl], [this, client])\n        }\n      })\n    }\n\n    return this\n  }\n\n  [kRemoveClient] (client) {\n    client.close(() => {\n      const idx = this[kClients].indexOf(client)\n      if (idx !== -1) {\n        this[kClients].splice(idx, 1)\n      }\n    })\n\n    this[kNeedDrain] = this[kClients].some(dispatcher => (\n      !dispatcher[kNeedDrain] &&\n      dispatcher.closed !== true &&\n      dispatcher.destroyed !== true\n    ))\n  }\n}\n\nmodule.exports = {\n  PoolBase,\n  kClients,\n  kNeedDrain,\n  kAddClient,\n  kRemoveClient,\n  kGetDispatcher\n}\n","const { kFree, kConnected, kPending, kQueued, kRunning, kSize } = require('./core/symbols')\nconst kPool = Symbol('pool')\n\nclass PoolStats {\n  constructor (pool) {\n    this[kPool] = pool\n  }\n\n  get connected () {\n    return this[kPool][kConnected]\n  }\n\n  get free () {\n    return this[kPool][kFree]\n  }\n\n  get pending () {\n    return this[kPool][kPending]\n  }\n\n  get queued () {\n    return this[kPool][kQueued]\n  }\n\n  get running () {\n    return this[kPool][kRunning]\n  }\n\n  get size () {\n    return this[kPool][kSize]\n  }\n}\n\nmodule.exports = PoolStats\n","'use strict'\n\nconst {\n  PoolBase,\n  kClients,\n  kNeedDrain,\n  kAddClient,\n  kGetDispatcher\n} = require('./pool-base')\nconst Client = require('./client')\nconst {\n  InvalidArgumentError\n} = require('./core/errors')\nconst util = require('./core/util')\nconst { kUrl, kInterceptors } = require('./core/symbols')\nconst buildConnector = require('./core/connect')\n\nconst kOptions = Symbol('options')\nconst kConnections = Symbol('connections')\nconst kFactory = Symbol('factory')\n\nfunction defaultFactory (origin, opts) {\n  return new Client(origin, opts)\n}\n\nclass Pool extends PoolBase {\n  constructor (origin, {\n    connections,\n    factory = defaultFactory,\n    connect,\n    connectTimeout,\n    tls,\n    maxCachedSessions,\n    socketPath,\n    autoSelectFamily,\n    autoSelectFamilyAttemptTimeout,\n    allowH2,\n    ...options\n  } = {}) {\n    super()\n\n    if (connections != null && (!Number.isFinite(connections) || connections < 0)) {\n      throw new InvalidArgumentError('invalid connections')\n    }\n\n    if (typeof factory !== 'function') {\n      throw new InvalidArgumentError('factory must be a function.')\n    }\n\n    if (connect != null && typeof connect !== 'function' && typeof connect !== 'object') {\n      throw new InvalidArgumentError('connect must be a function or an object')\n    }\n\n    if (typeof connect !== 'function') {\n      connect = buildConnector({\n        ...tls,\n        maxCachedSessions,\n        allowH2,\n        socketPath,\n        timeout: connectTimeout,\n        ...(util.nodeHasAutoSelectFamily && autoSelectFamily ? { autoSelectFamily, autoSelectFamilyAttemptTimeout } : undefined),\n        ...connect\n      })\n    }\n\n    this[kInterceptors] = options.interceptors && options.interceptors.Pool && Array.isArray(options.interceptors.Pool)\n      ? options.interceptors.Pool\n      : []\n    this[kConnections] = connections || null\n    this[kUrl] = util.parseOrigin(origin)\n    this[kOptions] = { ...util.deepClone(options), connect, allowH2 }\n    this[kOptions].interceptors = options.interceptors\n      ? { ...options.interceptors }\n      : undefined\n    this[kFactory] = factory\n  }\n\n  [kGetDispatcher] () {\n    let dispatcher = this[kClients].find(dispatcher => !dispatcher[kNeedDrain])\n\n    if (dispatcher) {\n      return dispatcher\n    }\n\n    if (!this[kConnections] || this[kClients].length < this[kConnections]) {\n      dispatcher = this[kFactory](this[kUrl], this[kOptions])\n      this[kAddClient](dispatcher)\n    }\n\n    return dispatcher\n  }\n}\n\nmodule.exports = Pool\n","'use strict'\n\nconst { kProxy, kClose, kDestroy, kInterceptors } = require('./core/symbols')\nconst { URL } = require('url')\nconst Agent = require('./agent')\nconst Pool = require('./pool')\nconst DispatcherBase = require('./dispatcher-base')\nconst { InvalidArgumentError, RequestAbortedError } = require('./core/errors')\nconst buildConnector = require('./core/connect')\n\nconst kAgent = Symbol('proxy agent')\nconst kClient = Symbol('proxy client')\nconst kProxyHeaders = Symbol('proxy headers')\nconst kRequestTls = Symbol('request tls settings')\nconst kProxyTls = Symbol('proxy tls settings')\nconst kConnectEndpoint = Symbol('connect endpoint function')\n\nfunction defaultProtocolPort (protocol) {\n  return protocol === 'https:' ? 443 : 80\n}\n\nfunction buildProxyOptions (opts) {\n  if (typeof opts === 'string') {\n    opts = { uri: opts }\n  }\n\n  if (!opts || !opts.uri) {\n    throw new InvalidArgumentError('Proxy opts.uri is mandatory')\n  }\n\n  return {\n    uri: opts.uri,\n    protocol: opts.protocol || 'https'\n  }\n}\n\nfunction defaultFactory (origin, opts) {\n  return new Pool(origin, opts)\n}\n\nclass ProxyAgent extends DispatcherBase {\n  constructor (opts) {\n    super(opts)\n    this[kProxy] = buildProxyOptions(opts)\n    this[kAgent] = new Agent(opts)\n    this[kInterceptors] = opts.interceptors && opts.interceptors.ProxyAgent && Array.isArray(opts.interceptors.ProxyAgent)\n      ? opts.interceptors.ProxyAgent\n      : []\n\n    if (typeof opts === 'string') {\n      opts = { uri: opts }\n    }\n\n    if (!opts || !opts.uri) {\n      throw new InvalidArgumentError('Proxy opts.uri is mandatory')\n    }\n\n    const { clientFactory = defaultFactory } = opts\n\n    if (typeof clientFactory !== 'function') {\n      throw new InvalidArgumentError('Proxy opts.clientFactory must be a function.')\n    }\n\n    this[kRequestTls] = opts.requestTls\n    this[kProxyTls] = opts.proxyTls\n    this[kProxyHeaders] = opts.headers || {}\n\n    const resolvedUrl = new URL(opts.uri)\n    const { origin, port, host, username, password } = resolvedUrl\n\n    if (opts.auth && opts.token) {\n      throw new InvalidArgumentError('opts.auth cannot be used in combination with opts.token')\n    } else if (opts.auth) {\n      /* @deprecated in favour of opts.token */\n      this[kProxyHeaders]['proxy-authorization'] = `Basic ${opts.auth}`\n    } else if (opts.token) {\n      this[kProxyHeaders]['proxy-authorization'] = opts.token\n    } else if (username && password) {\n      this[kProxyHeaders]['proxy-authorization'] = `Basic ${Buffer.from(`${decodeURIComponent(username)}:${decodeURIComponent(password)}`).toString('base64')}`\n    }\n\n    const connect = buildConnector({ ...opts.proxyTls })\n    this[kConnectEndpoint] = buildConnector({ ...opts.requestTls })\n    this[kClient] = clientFactory(resolvedUrl, { connect })\n    this[kAgent] = new Agent({\n      ...opts,\n      connect: async (opts, callback) => {\n        let requestedHost = opts.host\n        if (!opts.port) {\n          requestedHost += `:${defaultProtocolPort(opts.protocol)}`\n        }\n        try {\n          const { socket, statusCode } = await this[kClient].connect({\n            origin,\n            port,\n            path: requestedHost,\n            signal: opts.signal,\n            headers: {\n              ...this[kProxyHeaders],\n              host\n            }\n          })\n          if (statusCode !== 200) {\n            socket.on('error', () => {}).destroy()\n            callback(new RequestAbortedError(`Proxy response (${statusCode}) !== 200 when HTTP Tunneling`))\n          }\n          if (opts.protocol !== 'https:') {\n            callback(null, socket)\n            return\n          }\n          let servername\n          if (this[kRequestTls]) {\n            servername = this[kRequestTls].servername\n          } else {\n            servername = opts.servername\n          }\n          this[kConnectEndpoint]({ ...opts, servername, httpSocket: socket }, callback)\n        } catch (err) {\n          callback(err)\n        }\n      }\n    })\n  }\n\n  dispatch (opts, handler) {\n    const { host } = new URL(opts.origin)\n    const headers = buildHeaders(opts.headers)\n    throwIfProxyAuthIsSent(headers)\n    return this[kAgent].dispatch(\n      {\n        ...opts,\n        headers: {\n          ...headers,\n          host\n        }\n      },\n      handler\n    )\n  }\n\n  async [kClose] () {\n    await this[kAgent].close()\n    await this[kClient].close()\n  }\n\n  async [kDestroy] () {\n    await this[kAgent].destroy()\n    await this[kClient].destroy()\n  }\n}\n\n/**\n * @param {string[] | Record<string, string>} headers\n * @returns {Record<string, string>}\n */\nfunction buildHeaders (headers) {\n  // When using undici.fetch, the headers list is stored\n  // as an array.\n  if (Array.isArray(headers)) {\n    /** @type {Record<string, string>} */\n    const headersPair = {}\n\n    for (let i = 0; i < headers.length; i += 2) {\n      headersPair[headers[i]] = headers[i + 1]\n    }\n\n    return headersPair\n  }\n\n  return headers\n}\n\n/**\n * @param {Record<string, string>} headers\n *\n * Previous versions of ProxyAgent suggests the Proxy-Authorization in request headers\n * Nevertheless, it was changed and to avoid a security vulnerability by end users\n * this check was created.\n * It should be removed in the next major version for performance reasons\n */\nfunction throwIfProxyAuthIsSent (headers) {\n  const existProxyAuth = headers && Object.keys(headers)\n    .find((key) => key.toLowerCase() === 'proxy-authorization')\n  if (existProxyAuth) {\n    throw new InvalidArgumentError('Proxy-Authorization should be sent in ProxyAgent constructor')\n  }\n}\n\nmodule.exports = ProxyAgent\n","'use strict'\n\nlet fastNow = Date.now()\nlet fastNowTimeout\n\nconst fastTimers = []\n\nfunction onTimeout () {\n  fastNow = Date.now()\n\n  let len = fastTimers.length\n  let idx = 0\n  while (idx < len) {\n    const timer = fastTimers[idx]\n\n    if (timer.state === 0) {\n      timer.state = fastNow + timer.delay\n    } else if (timer.state > 0 && fastNow >= timer.state) {\n      timer.state = -1\n      timer.callback(timer.opaque)\n    }\n\n    if (timer.state === -1) {\n      timer.state = -2\n      if (idx !== len - 1) {\n        fastTimers[idx] = fastTimers.pop()\n      } else {\n        fastTimers.pop()\n      }\n      len -= 1\n    } else {\n      idx += 1\n    }\n  }\n\n  if (fastTimers.length > 0) {\n    refreshTimeout()\n  }\n}\n\nfunction refreshTimeout () {\n  if (fastNowTimeout && fastNowTimeout.refresh) {\n    fastNowTimeout.refresh()\n  } else {\n    clearTimeout(fastNowTimeout)\n    fastNowTimeout = setTimeout(onTimeout, 1e3)\n    if (fastNowTimeout.unref) {\n      fastNowTimeout.unref()\n    }\n  }\n}\n\nclass Timeout {\n  constructor (callback, delay, opaque) {\n    this.callback = callback\n    this.delay = delay\n    this.opaque = opaque\n\n    //  -2 not in timer list\n    //  -1 in timer list but inactive\n    //   0 in timer list waiting for time\n    // > 0 in timer list waiting for time to expire\n    this.state = -2\n\n    this.refresh()\n  }\n\n  refresh () {\n    if (this.state === -2) {\n      fastTimers.push(this)\n      if (!fastNowTimeout || fastTimers.length === 1) {\n        refreshTimeout()\n      }\n    }\n\n    this.state = 0\n  }\n\n  clear () {\n    this.state = -1\n  }\n}\n\nmodule.exports = {\n  setTimeout (callback, delay, opaque) {\n    return delay < 1e3\n      ? setTimeout(callback, delay, opaque)\n      : new Timeout(callback, delay, opaque)\n  },\n  clearTimeout (timeout) {\n    if (timeout instanceof Timeout) {\n      timeout.clear()\n    } else {\n      clearTimeout(timeout)\n    }\n  }\n}\n","'use strict'\n\nconst diagnosticsChannel = require('diagnostics_channel')\nconst { uid, states } = require('./constants')\nconst {\n  kReadyState,\n  kSentClose,\n  kByteParser,\n  kReceivedClose\n} = require('./symbols')\nconst { fireEvent, failWebsocketConnection } = require('./util')\nconst { CloseEvent } = require('./events')\nconst { makeRequest } = require('../fetch/request')\nconst { fetching } = require('../fetch/index')\nconst { Headers } = require('../fetch/headers')\nconst { getGlobalDispatcher } = require('../global')\nconst { kHeadersList } = require('../core/symbols')\n\nconst channels = {}\nchannels.open = diagnosticsChannel.channel('undici:websocket:open')\nchannels.close = diagnosticsChannel.channel('undici:websocket:close')\nchannels.socketError = diagnosticsChannel.channel('undici:websocket:socket_error')\n\n/** @type {import('crypto')} */\nlet crypto\ntry {\n  crypto = require('crypto')\n} catch {\n\n}\n\n/**\n * @see https://websockets.spec.whatwg.org/#concept-websocket-establish\n * @param {URL} url\n * @param {string|string[]} protocols\n * @param {import('./websocket').WebSocket} ws\n * @param {(response: any) => void} onEstablish\n * @param {Partial<import('../../types/websocket').WebSocketInit>} options\n */\nfunction establishWebSocketConnection (url, protocols, ws, onEstablish, options) {\n  // 1. Let requestURL be a copy of url, with its scheme set to \"http\", if urls\n  //    scheme is \"ws\", and to \"https\" otherwise.\n  const requestURL = url\n\n  requestURL.protocol = url.protocol === 'ws:' ? 'http:' : 'https:'\n\n  // 2. Let request be a new request, whose URL is requestURL, client is client,\n  //    service-workers mode is \"none\", referrer is \"no-referrer\", mode is\n  //    \"websocket\", credentials mode is \"include\", cache mode is \"no-store\" ,\n  //    and redirect mode is \"error\".\n  const request = makeRequest({\n    urlList: [requestURL],\n    serviceWorkers: 'none',\n    referrer: 'no-referrer',\n    mode: 'websocket',\n    credentials: 'include',\n    cache: 'no-store',\n    redirect: 'error'\n  })\n\n  // Note: undici extension, allow setting custom headers.\n  if (options.headers) {\n    const headersList = new Headers(options.headers)[kHeadersList]\n\n    request.headersList = headersList\n  }\n\n  // 3. Append (`Upgrade`, `websocket`) to requests header list.\n  // 4. Append (`Connection`, `Upgrade`) to requests header list.\n  // Note: both of these are handled by undici currently.\n  // https://github.com/nodejs/undici/blob/68c269c4144c446f3f1220951338daef4a6b5ec4/lib/client.js#L1397\n\n  // 5. Let keyValue be a nonce consisting of a randomly selected\n  //    16-byte value that has been forgiving-base64-encoded and\n  //    isomorphic encoded.\n  const keyValue = crypto.randomBytes(16).toString('base64')\n\n  // 6. Append (`Sec-WebSocket-Key`, keyValue) to requests\n  //    header list.\n  request.headersList.append('sec-websocket-key', keyValue)\n\n  // 7. Append (`Sec-WebSocket-Version`, `13`) to requests\n  //    header list.\n  request.headersList.append('sec-websocket-version', '13')\n\n  // 8. For each protocol in protocols, combine\n  //    (`Sec-WebSocket-Protocol`, protocol) in requests header\n  //    list.\n  for (const protocol of protocols) {\n    request.headersList.append('sec-websocket-protocol', protocol)\n  }\n\n  // 9. Let permessageDeflate be a user-agent defined\n  //    \"permessage-deflate\" extension header value.\n  // https://github.com/mozilla/gecko-dev/blob/ce78234f5e653a5d3916813ff990f053510227bc/netwerk/protocol/websocket/WebSocketChannel.cpp#L2673\n  // TODO: enable once permessage-deflate is supported\n  const permessageDeflate = '' // 'permessage-deflate; 15'\n\n  // 10. Append (`Sec-WebSocket-Extensions`, permessageDeflate) to\n  //     requests header list.\n  // request.headersList.append('sec-websocket-extensions', permessageDeflate)\n\n  // 11. Fetch request with useParallelQueue set to true, and\n  //     processResponse given response being these steps:\n  const controller = fetching({\n    request,\n    useParallelQueue: true,\n    dispatcher: options.dispatcher ?? getGlobalDispatcher(),\n    processResponse (response) {\n      // 1. If response is a network error or its status is not 101,\n      //    fail the WebSocket connection.\n      if (response.type === 'error' || response.status !== 101) {\n        failWebsocketConnection(ws, 'Received network error or non-101 status code.')\n        return\n      }\n\n      // 2. If protocols is not the empty list and extracting header\n      //    list values given `Sec-WebSocket-Protocol` and responses\n      //    header list results in null, failure, or the empty byte\n      //    sequence, then fail the WebSocket connection.\n      if (protocols.length !== 0 && !response.headersList.get('Sec-WebSocket-Protocol')) {\n        failWebsocketConnection(ws, 'Server did not respond with sent protocols.')\n        return\n      }\n\n      // 3. Follow the requirements stated step 2 to step 6, inclusive,\n      //    of the last set of steps in section 4.1 of The WebSocket\n      //    Protocol to validate response. This either results in fail\n      //    the WebSocket connection or the WebSocket connection is\n      //    established.\n\n      // 2. If the response lacks an |Upgrade| header field or the |Upgrade|\n      //    header field contains a value that is not an ASCII case-\n      //    insensitive match for the value \"websocket\", the client MUST\n      //    _Fail the WebSocket Connection_.\n      if (response.headersList.get('Upgrade')?.toLowerCase() !== 'websocket') {\n        failWebsocketConnection(ws, 'Server did not set Upgrade header to \"websocket\".')\n        return\n      }\n\n      // 3. If the response lacks a |Connection| header field or the\n      //    |Connection| header field doesn't contain a token that is an\n      //    ASCII case-insensitive match for the value \"Upgrade\", the client\n      //    MUST _Fail the WebSocket Connection_.\n      if (response.headersList.get('Connection')?.toLowerCase() !== 'upgrade') {\n        failWebsocketConnection(ws, 'Server did not set Connection header to \"upgrade\".')\n        return\n      }\n\n      // 4. If the response lacks a |Sec-WebSocket-Accept| header field or\n      //    the |Sec-WebSocket-Accept| contains a value other than the\n      //    base64-encoded SHA-1 of the concatenation of the |Sec-WebSocket-\n      //    Key| (as a string, not base64-decoded) with the string \"258EAFA5-\n      //    E914-47DA-95CA-C5AB0DC85B11\" but ignoring any leading and\n      //    trailing whitespace, the client MUST _Fail the WebSocket\n      //    Connection_.\n      const secWSAccept = response.headersList.get('Sec-WebSocket-Accept')\n      const digest = crypto.createHash('sha1').update(keyValue + uid).digest('base64')\n      if (secWSAccept !== digest) {\n        failWebsocketConnection(ws, 'Incorrect hash received in Sec-WebSocket-Accept header.')\n        return\n      }\n\n      // 5. If the response includes a |Sec-WebSocket-Extensions| header\n      //    field and this header field indicates the use of an extension\n      //    that was not present in the client's handshake (the server has\n      //    indicated an extension not requested by the client), the client\n      //    MUST _Fail the WebSocket Connection_.  (The parsing of this\n      //    header field to determine which extensions are requested is\n      //    discussed in Section 9.1.)\n      const secExtension = response.headersList.get('Sec-WebSocket-Extensions')\n\n      if (secExtension !== null && secExtension !== permessageDeflate) {\n        failWebsocketConnection(ws, 'Received different permessage-deflate than the one set.')\n        return\n      }\n\n      // 6. If the response includes a |Sec-WebSocket-Protocol| header field\n      //    and this header field indicates the use of a subprotocol that was\n      //    not present in the client's handshake (the server has indicated a\n      //    subprotocol not requested by the client), the client MUST _Fail\n      //    the WebSocket Connection_.\n      const secProtocol = response.headersList.get('Sec-WebSocket-Protocol')\n\n      if (secProtocol !== null && secProtocol !== request.headersList.get('Sec-WebSocket-Protocol')) {\n        failWebsocketConnection(ws, 'Protocol was not set in the opening handshake.')\n        return\n      }\n\n      response.socket.on('data', onSocketData)\n      response.socket.on('close', onSocketClose)\n      response.socket.on('error', onSocketError)\n\n      if (channels.open.hasSubscribers) {\n        channels.open.publish({\n          address: response.socket.address(),\n          protocol: secProtocol,\n          extensions: secExtension\n        })\n      }\n\n      onEstablish(response)\n    }\n  })\n\n  return controller\n}\n\n/**\n * @param {Buffer} chunk\n */\nfunction onSocketData (chunk) {\n  if (!this.ws[kByteParser].write(chunk)) {\n    this.pause()\n  }\n}\n\n/**\n * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol\n * @see https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.4\n */\nfunction onSocketClose () {\n  const { ws } = this\n\n  // If the TCP connection was closed after the\n  // WebSocket closing handshake was completed, the WebSocket connection\n  // is said to have been closed _cleanly_.\n  const wasClean = ws[kSentClose] && ws[kReceivedClose]\n\n  let code = 1005\n  let reason = ''\n\n  const result = ws[kByteParser].closingInfo\n\n  if (result) {\n    code = result.code ?? 1005\n    reason = result.reason\n  } else if (!ws[kSentClose]) {\n    // If _The WebSocket\n    // Connection is Closed_ and no Close control frame was received by the\n    // endpoint (such as could occur if the underlying transport connection\n    // is lost), _The WebSocket Connection Close Code_ is considered to be\n    // 1006.\n    code = 1006\n  }\n\n  // 1. Change the ready state to CLOSED (3).\n  ws[kReadyState] = states.CLOSED\n\n  // 2. If the user agent was required to fail the WebSocket\n  //    connection, or if the WebSocket connection was closed\n  //    after being flagged as full, fire an event named error\n  //    at the WebSocket object.\n  // TODO\n\n  // 3. Fire an event named close at the WebSocket object,\n  //    using CloseEvent, with the wasClean attribute\n  //    initialized to true if the connection closed cleanly\n  //    and false otherwise, the code attribute initialized to\n  //    the WebSocket connection close code, and the reason\n  //    attribute initialized to the result of applying UTF-8\n  //    decode without BOM to the WebSocket connection close\n  //    reason.\n  fireEvent('close', ws, CloseEvent, {\n    wasClean, code, reason\n  })\n\n  if (channels.close.hasSubscribers) {\n    channels.close.publish({\n      websocket: ws,\n      code,\n      reason\n    })\n  }\n}\n\nfunction onSocketError (error) {\n  const { ws } = this\n\n  ws[kReadyState] = states.CLOSING\n\n  if (channels.socketError.hasSubscribers) {\n    channels.socketError.publish(error)\n  }\n\n  this.destroy()\n}\n\nmodule.exports = {\n  establishWebSocketConnection\n}\n","'use strict'\n\n// This is a Globally Unique Identifier unique used\n// to validate that the endpoint accepts websocket\n// connections.\n// See https://www.rfc-editor.org/rfc/rfc6455.html#section-1.3\nconst uid = '258EAFA5-E914-47DA-95CA-C5AB0DC85B11'\n\n/** @type {PropertyDescriptor} */\nconst staticPropertyDescriptors = {\n  enumerable: true,\n  writable: false,\n  configurable: false\n}\n\nconst states = {\n  CONNECTING: 0,\n  OPEN: 1,\n  CLOSING: 2,\n  CLOSED: 3\n}\n\nconst opcodes = {\n  CONTINUATION: 0x0,\n  TEXT: 0x1,\n  BINARY: 0x2,\n  CLOSE: 0x8,\n  PING: 0x9,\n  PONG: 0xA\n}\n\nconst maxUnsigned16Bit = 2 ** 16 - 1 // 65535\n\nconst parserStates = {\n  INFO: 0,\n  PAYLOADLENGTH_16: 2,\n  PAYLOADLENGTH_64: 3,\n  READ_DATA: 4\n}\n\nconst emptyBuffer = Buffer.allocUnsafe(0)\n\nmodule.exports = {\n  uid,\n  staticPropertyDescriptors,\n  states,\n  opcodes,\n  maxUnsigned16Bit,\n  parserStates,\n  emptyBuffer\n}\n","'use strict'\n\nconst { webidl } = require('../fetch/webidl')\nconst { kEnumerableProperty } = require('../core/util')\nconst { MessagePort } = require('worker_threads')\n\n/**\n * @see https://html.spec.whatwg.org/multipage/comms.html#messageevent\n */\nclass MessageEvent extends Event {\n  #eventInit\n\n  constructor (type, eventInitDict = {}) {\n    webidl.argumentLengthCheck(arguments, 1, { header: 'MessageEvent constructor' })\n\n    type = webidl.converters.DOMString(type)\n    eventInitDict = webidl.converters.MessageEventInit(eventInitDict)\n\n    super(type, eventInitDict)\n\n    this.#eventInit = eventInitDict\n  }\n\n  get data () {\n    webidl.brandCheck(this, MessageEvent)\n\n    return this.#eventInit.data\n  }\n\n  get origin () {\n    webidl.brandCheck(this, MessageEvent)\n\n    return this.#eventInit.origin\n  }\n\n  get lastEventId () {\n    webidl.brandCheck(this, MessageEvent)\n\n    return this.#eventInit.lastEventId\n  }\n\n  get source () {\n    webidl.brandCheck(this, MessageEvent)\n\n    return this.#eventInit.source\n  }\n\n  get ports () {\n    webidl.brandCheck(this, MessageEvent)\n\n    if (!Object.isFrozen(this.#eventInit.ports)) {\n      Object.freeze(this.#eventInit.ports)\n    }\n\n    return this.#eventInit.ports\n  }\n\n  initMessageEvent (\n    type,\n    bubbles = false,\n    cancelable = false,\n    data = null,\n    origin = '',\n    lastEventId = '',\n    source = null,\n    ports = []\n  ) {\n    webidl.brandCheck(this, MessageEvent)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'MessageEvent.initMessageEvent' })\n\n    return new MessageEvent(type, {\n      bubbles, cancelable, data, origin, lastEventId, source, ports\n    })\n  }\n}\n\n/**\n * @see https://websockets.spec.whatwg.org/#the-closeevent-interface\n */\nclass CloseEvent extends Event {\n  #eventInit\n\n  constructor (type, eventInitDict = {}) {\n    webidl.argumentLengthCheck(arguments, 1, { header: 'CloseEvent constructor' })\n\n    type = webidl.converters.DOMString(type)\n    eventInitDict = webidl.converters.CloseEventInit(eventInitDict)\n\n    super(type, eventInitDict)\n\n    this.#eventInit = eventInitDict\n  }\n\n  get wasClean () {\n    webidl.brandCheck(this, CloseEvent)\n\n    return this.#eventInit.wasClean\n  }\n\n  get code () {\n    webidl.brandCheck(this, CloseEvent)\n\n    return this.#eventInit.code\n  }\n\n  get reason () {\n    webidl.brandCheck(this, CloseEvent)\n\n    return this.#eventInit.reason\n  }\n}\n\n// https://html.spec.whatwg.org/multipage/webappapis.html#the-errorevent-interface\nclass ErrorEvent extends Event {\n  #eventInit\n\n  constructor (type, eventInitDict) {\n    webidl.argumentLengthCheck(arguments, 1, { header: 'ErrorEvent constructor' })\n\n    super(type, eventInitDict)\n\n    type = webidl.converters.DOMString(type)\n    eventInitDict = webidl.converters.ErrorEventInit(eventInitDict ?? {})\n\n    this.#eventInit = eventInitDict\n  }\n\n  get message () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.message\n  }\n\n  get filename () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.filename\n  }\n\n  get lineno () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.lineno\n  }\n\n  get colno () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.colno\n  }\n\n  get error () {\n    webidl.brandCheck(this, ErrorEvent)\n\n    return this.#eventInit.error\n  }\n}\n\nObject.defineProperties(MessageEvent.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'MessageEvent',\n    configurable: true\n  },\n  data: kEnumerableProperty,\n  origin: kEnumerableProperty,\n  lastEventId: kEnumerableProperty,\n  source: kEnumerableProperty,\n  ports: kEnumerableProperty,\n  initMessageEvent: kEnumerableProperty\n})\n\nObject.defineProperties(CloseEvent.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'CloseEvent',\n    configurable: true\n  },\n  reason: kEnumerableProperty,\n  code: kEnumerableProperty,\n  wasClean: kEnumerableProperty\n})\n\nObject.defineProperties(ErrorEvent.prototype, {\n  [Symbol.toStringTag]: {\n    value: 'ErrorEvent',\n    configurable: true\n  },\n  message: kEnumerableProperty,\n  filename: kEnumerableProperty,\n  lineno: kEnumerableProperty,\n  colno: kEnumerableProperty,\n  error: kEnumerableProperty\n})\n\nwebidl.converters.MessagePort = webidl.interfaceConverter(MessagePort)\n\nwebidl.converters['sequence<MessagePort>'] = webidl.sequenceConverter(\n  webidl.converters.MessagePort\n)\n\nconst eventInit = [\n  {\n    key: 'bubbles',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'cancelable',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'composed',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  }\n]\n\nwebidl.converters.MessageEventInit = webidl.dictionaryConverter([\n  ...eventInit,\n  {\n    key: 'data',\n    converter: webidl.converters.any,\n    defaultValue: null\n  },\n  {\n    key: 'origin',\n    converter: webidl.converters.USVString,\n    defaultValue: ''\n  },\n  {\n    key: 'lastEventId',\n    converter: webidl.converters.DOMString,\n    defaultValue: ''\n  },\n  {\n    key: 'source',\n    // Node doesn't implement WindowProxy or ServiceWorker, so the only\n    // valid value for source is a MessagePort.\n    converter: webidl.nullableConverter(webidl.converters.MessagePort),\n    defaultValue: null\n  },\n  {\n    key: 'ports',\n    converter: webidl.converters['sequence<MessagePort>'],\n    get defaultValue () {\n      return []\n    }\n  }\n])\n\nwebidl.converters.CloseEventInit = webidl.dictionaryConverter([\n  ...eventInit,\n  {\n    key: 'wasClean',\n    converter: webidl.converters.boolean,\n    defaultValue: false\n  },\n  {\n    key: 'code',\n    converter: webidl.converters['unsigned short'],\n    defaultValue: 0\n  },\n  {\n    key: 'reason',\n    converter: webidl.converters.USVString,\n    defaultValue: ''\n  }\n])\n\nwebidl.converters.ErrorEventInit = webidl.dictionaryConverter([\n  ...eventInit,\n  {\n    key: 'message',\n    converter: webidl.converters.DOMString,\n    defaultValue: ''\n  },\n  {\n    key: 'filename',\n    converter: webidl.converters.USVString,\n    defaultValue: ''\n  },\n  {\n    key: 'lineno',\n    converter: webidl.converters['unsigned long'],\n    defaultValue: 0\n  },\n  {\n    key: 'colno',\n    converter: webidl.converters['unsigned long'],\n    defaultValue: 0\n  },\n  {\n    key: 'error',\n    converter: webidl.converters.any\n  }\n])\n\nmodule.exports = {\n  MessageEvent,\n  CloseEvent,\n  ErrorEvent\n}\n","'use strict'\n\nconst { maxUnsigned16Bit } = require('./constants')\n\n/** @type {import('crypto')} */\nlet crypto\ntry {\n  crypto = require('crypto')\n} catch {\n\n}\n\nclass WebsocketFrameSend {\n  /**\n   * @param {Buffer|undefined} data\n   */\n  constructor (data) {\n    this.frameData = data\n    this.maskKey = crypto.randomBytes(4)\n  }\n\n  createFrame (opcode) {\n    const bodyLength = this.frameData?.byteLength ?? 0\n\n    /** @type {number} */\n    let payloadLength = bodyLength // 0-125\n    let offset = 6\n\n    if (bodyLength > maxUnsigned16Bit) {\n      offset += 8 // payload length is next 8 bytes\n      payloadLength = 127\n    } else if (bodyLength > 125) {\n      offset += 2 // payload length is next 2 bytes\n      payloadLength = 126\n    }\n\n    const buffer = Buffer.allocUnsafe(bodyLength + offset)\n\n    // Clear first 2 bytes, everything else is overwritten\n    buffer[0] = buffer[1] = 0\n    buffer[0] |= 0x80 // FIN\n    buffer[0] = (buffer[0] & 0xF0) + opcode // opcode\n\n    /*! ws. MIT License. Einar Otto Stangvik <einaros@gmail.com> */\n    buffer[offset - 4] = this.maskKey[0]\n    buffer[offset - 3] = this.maskKey[1]\n    buffer[offset - 2] = this.maskKey[2]\n    buffer[offset - 1] = this.maskKey[3]\n\n    buffer[1] = payloadLength\n\n    if (payloadLength === 126) {\n      buffer.writeUInt16BE(bodyLength, 2)\n    } else if (payloadLength === 127) {\n      // Clear extended payload length\n      buffer[2] = buffer[3] = 0\n      buffer.writeUIntBE(bodyLength, 4, 6)\n    }\n\n    buffer[1] |= 0x80 // MASK\n\n    // mask body\n    for (let i = 0; i < bodyLength; i++) {\n      buffer[offset + i] = this.frameData[i] ^ this.maskKey[i % 4]\n    }\n\n    return buffer\n  }\n}\n\nmodule.exports = {\n  WebsocketFrameSend\n}\n","'use strict'\n\nconst { Writable } = require('stream')\nconst diagnosticsChannel = require('diagnostics_channel')\nconst { parserStates, opcodes, states, emptyBuffer } = require('./constants')\nconst { kReadyState, kSentClose, kResponse, kReceivedClose } = require('./symbols')\nconst { isValidStatusCode, failWebsocketConnection, websocketMessageReceived } = require('./util')\nconst { WebsocketFrameSend } = require('./frame')\n\n// This code was influenced by ws released under the MIT license.\n// Copyright (c) 2011 Einar Otto Stangvik <einaros@gmail.com>\n// Copyright (c) 2013 Arnout Kazemier and contributors\n// Copyright (c) 2016 Luigi Pinca and contributors\n\nconst channels = {}\nchannels.ping = diagnosticsChannel.channel('undici:websocket:ping')\nchannels.pong = diagnosticsChannel.channel('undici:websocket:pong')\n\nclass ByteParser extends Writable {\n  #buffers = []\n  #byteOffset = 0\n\n  #state = parserStates.INFO\n\n  #info = {}\n  #fragments = []\n\n  constructor (ws) {\n    super()\n\n    this.ws = ws\n  }\n\n  /**\n   * @param {Buffer} chunk\n   * @param {() => void} callback\n   */\n  _write (chunk, _, callback) {\n    this.#buffers.push(chunk)\n    this.#byteOffset += chunk.length\n\n    this.run(callback)\n  }\n\n  /**\n   * Runs whenever a new chunk is received.\n   * Callback is called whenever there are no more chunks buffering,\n   * or not enough bytes are buffered to parse.\n   */\n  run (callback) {\n    while (true) {\n      if (this.#state === parserStates.INFO) {\n        // If there aren't enough bytes to parse the payload length, etc.\n        if (this.#byteOffset < 2) {\n          return callback()\n        }\n\n        const buffer = this.consume(2)\n\n        this.#info.fin = (buffer[0] & 0x80) !== 0\n        this.#info.opcode = buffer[0] & 0x0F\n\n        // If we receive a fragmented message, we use the type of the first\n        // frame to parse the full message as binary/text, when it's terminated\n        this.#info.originalOpcode ??= this.#info.opcode\n\n        this.#info.fragmented = !this.#info.fin && this.#info.opcode !== opcodes.CONTINUATION\n\n        if (this.#info.fragmented && this.#info.opcode !== opcodes.BINARY && this.#info.opcode !== opcodes.TEXT) {\n          // Only text and binary frames can be fragmented\n          failWebsocketConnection(this.ws, 'Invalid frame type was fragmented.')\n          return\n        }\n\n        const payloadLength = buffer[1] & 0x7F\n\n        if (payloadLength <= 125) {\n          this.#info.payloadLength = payloadLength\n          this.#state = parserStates.READ_DATA\n        } else if (payloadLength === 126) {\n          this.#state = parserStates.PAYLOADLENGTH_16\n        } else if (payloadLength === 127) {\n          this.#state = parserStates.PAYLOADLENGTH_64\n        }\n\n        if (this.#info.fragmented && payloadLength > 125) {\n          // A fragmented frame can't be fragmented itself\n          failWebsocketConnection(this.ws, 'Fragmented frame exceeded 125 bytes.')\n          return\n        } else if (\n          (this.#info.opcode === opcodes.PING ||\n            this.#info.opcode === opcodes.PONG ||\n            this.#info.opcode === opcodes.CLOSE) &&\n          payloadLength > 125\n        ) {\n          // Control frames can have a payload length of 125 bytes MAX\n          failWebsocketConnection(this.ws, 'Payload length for control frame exceeded 125 bytes.')\n          return\n        } else if (this.#info.opcode === opcodes.CLOSE) {\n          if (payloadLength === 1) {\n            failWebsocketConnection(this.ws, 'Received close frame with a 1-byte body.')\n            return\n          }\n\n          const body = this.consume(payloadLength)\n\n          this.#info.closeInfo = this.parseCloseBody(false, body)\n\n          if (!this.ws[kSentClose]) {\n            // If an endpoint receives a Close frame and did not previously send a\n            // Close frame, the endpoint MUST send a Close frame in response.  (When\n            // sending a Close frame in response, the endpoint typically echos the\n            // status code it received.)\n            const body = Buffer.allocUnsafe(2)\n            body.writeUInt16BE(this.#info.closeInfo.code, 0)\n            const closeFrame = new WebsocketFrameSend(body)\n\n            this.ws[kResponse].socket.write(\n              closeFrame.createFrame(opcodes.CLOSE),\n              (err) => {\n                if (!err) {\n                  this.ws[kSentClose] = true\n                }\n              }\n            )\n          }\n\n          // Upon either sending or receiving a Close control frame, it is said\n          // that _The WebSocket Closing Handshake is Started_ and that the\n          // WebSocket connection is in the CLOSING state.\n          this.ws[kReadyState] = states.CLOSING\n          this.ws[kReceivedClose] = true\n\n          this.end()\n\n          return\n        } else if (this.#info.opcode === opcodes.PING) {\n          // Upon receipt of a Ping frame, an endpoint MUST send a Pong frame in\n          // response, unless it already received a Close frame.\n          // A Pong frame sent in response to a Ping frame must have identical\n          // \"Application data\"\n\n          const body = this.consume(payloadLength)\n\n          if (!this.ws[kReceivedClose]) {\n            const frame = new WebsocketFrameSend(body)\n\n            this.ws[kResponse].socket.write(frame.createFrame(opcodes.PONG))\n\n            if (channels.ping.hasSubscribers) {\n              channels.ping.publish({\n                payload: body\n              })\n            }\n          }\n\n          this.#state = parserStates.INFO\n\n          if (this.#byteOffset > 0) {\n            continue\n          } else {\n            callback()\n            return\n          }\n        } else if (this.#info.opcode === opcodes.PONG) {\n          // A Pong frame MAY be sent unsolicited.  This serves as a\n          // unidirectional heartbeat.  A response to an unsolicited Pong frame is\n          // not expected.\n\n          const body = this.consume(payloadLength)\n\n          if (channels.pong.hasSubscribers) {\n            channels.pong.publish({\n              payload: body\n            })\n          }\n\n          if (this.#byteOffset > 0) {\n            continue\n          } else {\n            callback()\n            return\n          }\n        }\n      } else if (this.#state === parserStates.PAYLOADLENGTH_16) {\n        if (this.#byteOffset < 2) {\n          return callback()\n        }\n\n        const buffer = this.consume(2)\n\n        this.#info.payloadLength = buffer.readUInt16BE(0)\n        this.#state = parserStates.READ_DATA\n      } else if (this.#state === parserStates.PAYLOADLENGTH_64) {\n        if (this.#byteOffset < 8) {\n          return callback()\n        }\n\n        const buffer = this.consume(8)\n        const upper = buffer.readUInt32BE(0)\n\n        // 2^31 is the maxinimum bytes an arraybuffer can contain\n        // on 32-bit systems. Although, on 64-bit systems, this is\n        // 2^53-1 bytes.\n        // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Errors/Invalid_array_length\n        // https://source.chromium.org/chromium/chromium/src/+/main:v8/src/common/globals.h;drc=1946212ac0100668f14eb9e2843bdd846e510a1e;bpv=1;bpt=1;l=1275\n        // https://source.chromium.org/chromium/chromium/src/+/main:v8/src/objects/js-array-buffer.h;l=34;drc=1946212ac0100668f14eb9e2843bdd846e510a1e\n        if (upper > 2 ** 31 - 1) {\n          failWebsocketConnection(this.ws, 'Received payload length > 2^31 bytes.')\n          return\n        }\n\n        const lower = buffer.readUInt32BE(4)\n\n        this.#info.payloadLength = (upper << 8) + lower\n        this.#state = parserStates.READ_DATA\n      } else if (this.#state === parserStates.READ_DATA) {\n        if (this.#byteOffset < this.#info.payloadLength) {\n          // If there is still more data in this chunk that needs to be read\n          return callback()\n        } else if (this.#byteOffset >= this.#info.payloadLength) {\n          // If the server sent multiple frames in a single chunk\n\n          const body = this.consume(this.#info.payloadLength)\n\n          this.#fragments.push(body)\n\n          // If the frame is unfragmented, or a fragmented frame was terminated,\n          // a message was received\n          if (!this.#info.fragmented || (this.#info.fin && this.#info.opcode === opcodes.CONTINUATION)) {\n            const fullMessage = Buffer.concat(this.#fragments)\n\n            websocketMessageReceived(this.ws, this.#info.originalOpcode, fullMessage)\n\n            this.#info = {}\n            this.#fragments.length = 0\n          }\n\n          this.#state = parserStates.INFO\n        }\n      }\n\n      if (this.#byteOffset > 0) {\n        continue\n      } else {\n        callback()\n        break\n      }\n    }\n  }\n\n  /**\n   * Take n bytes from the buffered Buffers\n   * @param {number} n\n   * @returns {Buffer|null}\n   */\n  consume (n) {\n    if (n > this.#byteOffset) {\n      return null\n    } else if (n === 0) {\n      return emptyBuffer\n    }\n\n    if (this.#buffers[0].length === n) {\n      this.#byteOffset -= this.#buffers[0].length\n      return this.#buffers.shift()\n    }\n\n    const buffer = Buffer.allocUnsafe(n)\n    let offset = 0\n\n    while (offset !== n) {\n      const next = this.#buffers[0]\n      const { length } = next\n\n      if (length + offset === n) {\n        buffer.set(this.#buffers.shift(), offset)\n        break\n      } else if (length + offset > n) {\n        buffer.set(next.subarray(0, n - offset), offset)\n        this.#buffers[0] = next.subarray(n - offset)\n        break\n      } else {\n        buffer.set(this.#buffers.shift(), offset)\n        offset += next.length\n      }\n    }\n\n    this.#byteOffset -= n\n\n    return buffer\n  }\n\n  parseCloseBody (onlyCode, data) {\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.5\n    /** @type {number|undefined} */\n    let code\n\n    if (data.length >= 2) {\n      // _The WebSocket Connection Close Code_ is\n      // defined as the status code (Section 7.4) contained in the first Close\n      // control frame received by the application\n      code = data.readUInt16BE(0)\n    }\n\n    if (onlyCode) {\n      if (!isValidStatusCode(code)) {\n        return null\n      }\n\n      return { code }\n    }\n\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-7.1.6\n    /** @type {Buffer} */\n    let reason = data.subarray(2)\n\n    // Remove BOM\n    if (reason[0] === 0xEF && reason[1] === 0xBB && reason[2] === 0xBF) {\n      reason = reason.subarray(3)\n    }\n\n    if (code !== undefined && !isValidStatusCode(code)) {\n      return null\n    }\n\n    try {\n      // TODO: optimize this\n      reason = new TextDecoder('utf-8', { fatal: true }).decode(reason)\n    } catch {\n      return null\n    }\n\n    return { code, reason }\n  }\n\n  get closingInfo () {\n    return this.#info.closeInfo\n  }\n}\n\nmodule.exports = {\n  ByteParser\n}\n","'use strict'\n\nmodule.exports = {\n  kWebSocketURL: Symbol('url'),\n  kReadyState: Symbol('ready state'),\n  kController: Symbol('controller'),\n  kResponse: Symbol('response'),\n  kBinaryType: Symbol('binary type'),\n  kSentClose: Symbol('sent close'),\n  kReceivedClose: Symbol('received close'),\n  kByteParser: Symbol('byte parser')\n}\n","'use strict'\n\nconst { kReadyState, kController, kResponse, kBinaryType, kWebSocketURL } = require('./symbols')\nconst { states, opcodes } = require('./constants')\nconst { MessageEvent, ErrorEvent } = require('./events')\n\n/* globals Blob */\n\n/**\n * @param {import('./websocket').WebSocket} ws\n */\nfunction isEstablished (ws) {\n  // If the server's response is validated as provided for above, it is\n  // said that _The WebSocket Connection is Established_ and that the\n  // WebSocket Connection is in the OPEN state.\n  return ws[kReadyState] === states.OPEN\n}\n\n/**\n * @param {import('./websocket').WebSocket} ws\n */\nfunction isClosing (ws) {\n  // Upon either sending or receiving a Close control frame, it is said\n  // that _The WebSocket Closing Handshake is Started_ and that the\n  // WebSocket connection is in the CLOSING state.\n  return ws[kReadyState] === states.CLOSING\n}\n\n/**\n * @param {import('./websocket').WebSocket} ws\n */\nfunction isClosed (ws) {\n  return ws[kReadyState] === states.CLOSED\n}\n\n/**\n * @see https://dom.spec.whatwg.org/#concept-event-fire\n * @param {string} e\n * @param {EventTarget} target\n * @param {EventInit | undefined} eventInitDict\n */\nfunction fireEvent (e, target, eventConstructor = Event, eventInitDict) {\n  // 1. If eventConstructor is not given, then let eventConstructor be Event.\n\n  // 2. Let event be the result of creating an event given eventConstructor,\n  //    in the relevant realm of target.\n  // 3. Initialize events type attribute to e.\n  const event = new eventConstructor(e, eventInitDict) // eslint-disable-line new-cap\n\n  // 4. Initialize any other IDL attributes of event as described in the\n  //    invocation of this algorithm.\n\n  // 5. Return the result of dispatching event at target, with legacy target\n  //    override flag set if set.\n  target.dispatchEvent(event)\n}\n\n/**\n * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol\n * @param {import('./websocket').WebSocket} ws\n * @param {number} type Opcode\n * @param {Buffer} data application data\n */\nfunction websocketMessageReceived (ws, type, data) {\n  // 1. If ready state is not OPEN (1), then return.\n  if (ws[kReadyState] !== states.OPEN) {\n    return\n  }\n\n  // 2. Let dataForEvent be determined by switching on type and binary type:\n  let dataForEvent\n\n  if (type === opcodes.TEXT) {\n    // -> type indicates that the data is Text\n    //      a new DOMString containing data\n    try {\n      dataForEvent = new TextDecoder('utf-8', { fatal: true }).decode(data)\n    } catch {\n      failWebsocketConnection(ws, 'Received invalid UTF-8 in text frame.')\n      return\n    }\n  } else if (type === opcodes.BINARY) {\n    if (ws[kBinaryType] === 'blob') {\n      // -> type indicates that the data is Binary and binary type is \"blob\"\n      //      a new Blob object, created in the relevant Realm of the WebSocket\n      //      object, that represents data as its raw data\n      dataForEvent = new Blob([data])\n    } else {\n      // -> type indicates that the data is Binary and binary type is \"arraybuffer\"\n      //      a new ArrayBuffer object, created in the relevant Realm of the\n      //      WebSocket object, whose contents are data\n      dataForEvent = new Uint8Array(data).buffer\n    }\n  }\n\n  // 3. Fire an event named message at the WebSocket object, using MessageEvent,\n  //    with the origin attribute initialized to the serialization of the WebSocket\n  //    objects url's origin, and the data attribute initialized to dataForEvent.\n  fireEvent('message', ws, MessageEvent, {\n    origin: ws[kWebSocketURL].origin,\n    data: dataForEvent\n  })\n}\n\n/**\n * @see https://datatracker.ietf.org/doc/html/rfc6455\n * @see https://datatracker.ietf.org/doc/html/rfc2616\n * @see https://bugs.chromium.org/p/chromium/issues/detail?id=398407\n * @param {string} protocol\n */\nfunction isValidSubprotocol (protocol) {\n  // If present, this value indicates one\n  // or more comma-separated subprotocol the client wishes to speak,\n  // ordered by preference.  The elements that comprise this value\n  // MUST be non-empty strings with characters in the range U+0021 to\n  // U+007E not including separator characters as defined in\n  // [RFC2616] and MUST all be unique strings.\n  if (protocol.length === 0) {\n    return false\n  }\n\n  for (const char of protocol) {\n    const code = char.charCodeAt(0)\n\n    if (\n      code < 0x21 ||\n      code > 0x7E ||\n      char === '(' ||\n      char === ')' ||\n      char === '<' ||\n      char === '>' ||\n      char === '@' ||\n      char === ',' ||\n      char === ';' ||\n      char === ':' ||\n      char === '\\\\' ||\n      char === '\"' ||\n      char === '/' ||\n      char === '[' ||\n      char === ']' ||\n      char === '?' ||\n      char === '=' ||\n      char === '{' ||\n      char === '}' ||\n      code === 32 || // SP\n      code === 9 // HT\n    ) {\n      return false\n    }\n  }\n\n  return true\n}\n\n/**\n * @see https://datatracker.ietf.org/doc/html/rfc6455#section-7-4\n * @param {number} code\n */\nfunction isValidStatusCode (code) {\n  if (code >= 1000 && code < 1015) {\n    return (\n      code !== 1004 && // reserved\n      code !== 1005 && // \"MUST NOT be set as a status code\"\n      code !== 1006 // \"MUST NOT be set as a status code\"\n    )\n  }\n\n  return code >= 3000 && code <= 4999\n}\n\n/**\n * @param {import('./websocket').WebSocket} ws\n * @param {string|undefined} reason\n */\nfunction failWebsocketConnection (ws, reason) {\n  const { [kController]: controller, [kResponse]: response } = ws\n\n  controller.abort()\n\n  if (response?.socket && !response.socket.destroyed) {\n    response.socket.destroy()\n  }\n\n  if (reason) {\n    fireEvent('error', ws, ErrorEvent, {\n      error: new Error(reason)\n    })\n  }\n}\n\nmodule.exports = {\n  isEstablished,\n  isClosing,\n  isClosed,\n  fireEvent,\n  isValidSubprotocol,\n  isValidStatusCode,\n  failWebsocketConnection,\n  websocketMessageReceived\n}\n","'use strict'\n\nconst { webidl } = require('../fetch/webidl')\nconst { DOMException } = require('../fetch/constants')\nconst { URLSerializer } = require('../fetch/dataURL')\nconst { getGlobalOrigin } = require('../fetch/global')\nconst { staticPropertyDescriptors, states, opcodes, emptyBuffer } = require('./constants')\nconst {\n  kWebSocketURL,\n  kReadyState,\n  kController,\n  kBinaryType,\n  kResponse,\n  kSentClose,\n  kByteParser\n} = require('./symbols')\nconst { isEstablished, isClosing, isValidSubprotocol, failWebsocketConnection, fireEvent } = require('./util')\nconst { establishWebSocketConnection } = require('./connection')\nconst { WebsocketFrameSend } = require('./frame')\nconst { ByteParser } = require('./receiver')\nconst { kEnumerableProperty, isBlobLike } = require('../core/util')\nconst { getGlobalDispatcher } = require('../global')\nconst { types } = require('util')\n\nlet experimentalWarned = false\n\n// https://websockets.spec.whatwg.org/#interface-definition\nclass WebSocket extends EventTarget {\n  #events = {\n    open: null,\n    error: null,\n    close: null,\n    message: null\n  }\n\n  #bufferedAmount = 0\n  #protocol = ''\n  #extensions = ''\n\n  /**\n   * @param {string} url\n   * @param {string|string[]} protocols\n   */\n  constructor (url, protocols = []) {\n    super()\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'WebSocket constructor' })\n\n    if (!experimentalWarned) {\n      experimentalWarned = true\n      process.emitWarning('WebSockets are experimental, expect them to change at any time.', {\n        code: 'UNDICI-WS'\n      })\n    }\n\n    const options = webidl.converters['DOMString or sequence<DOMString> or WebSocketInit'](protocols)\n\n    url = webidl.converters.USVString(url)\n    protocols = options.protocols\n\n    // 1. Let baseURL be this's relevant settings object's API base URL.\n    const baseURL = getGlobalOrigin()\n\n    // 1. Let urlRecord be the result of applying the URL parser to url with baseURL.\n    let urlRecord\n\n    try {\n      urlRecord = new URL(url, baseURL)\n    } catch (e) {\n      // 3. If urlRecord is failure, then throw a \"SyntaxError\" DOMException.\n      throw new DOMException(e, 'SyntaxError')\n    }\n\n    // 4. If urlRecords scheme is \"http\", then set urlRecords scheme to \"ws\".\n    if (urlRecord.protocol === 'http:') {\n      urlRecord.protocol = 'ws:'\n    } else if (urlRecord.protocol === 'https:') {\n      // 5. Otherwise, if urlRecords scheme is \"https\", set urlRecords scheme to \"wss\".\n      urlRecord.protocol = 'wss:'\n    }\n\n    // 6. If urlRecords scheme is not \"ws\" or \"wss\", then throw a \"SyntaxError\" DOMException.\n    if (urlRecord.protocol !== 'ws:' && urlRecord.protocol !== 'wss:') {\n      throw new DOMException(\n        `Expected a ws: or wss: protocol, got ${urlRecord.protocol}`,\n        'SyntaxError'\n      )\n    }\n\n    // 7. If urlRecords fragment is non-null, then throw a \"SyntaxError\"\n    //    DOMException.\n    if (urlRecord.hash || urlRecord.href.endsWith('#')) {\n      throw new DOMException('Got fragment', 'SyntaxError')\n    }\n\n    // 8. If protocols is a string, set protocols to a sequence consisting\n    //    of just that string.\n    if (typeof protocols === 'string') {\n      protocols = [protocols]\n    }\n\n    // 9. If any of the values in protocols occur more than once or otherwise\n    //    fail to match the requirements for elements that comprise the value\n    //    of `Sec-WebSocket-Protocol` fields as defined by The WebSocket\n    //    protocol, then throw a \"SyntaxError\" DOMException.\n    if (protocols.length !== new Set(protocols.map(p => p.toLowerCase())).size) {\n      throw new DOMException('Invalid Sec-WebSocket-Protocol value', 'SyntaxError')\n    }\n\n    if (protocols.length > 0 && !protocols.every(p => isValidSubprotocol(p))) {\n      throw new DOMException('Invalid Sec-WebSocket-Protocol value', 'SyntaxError')\n    }\n\n    // 10. Set this's url to urlRecord.\n    this[kWebSocketURL] = new URL(urlRecord.href)\n\n    // 11. Let client be this's relevant settings object.\n\n    // 12. Run this step in parallel:\n\n    //    1. Establish a WebSocket connection given urlRecord, protocols,\n    //       and client.\n    this[kController] = establishWebSocketConnection(\n      urlRecord,\n      protocols,\n      this,\n      (response) => this.#onConnectionEstablished(response),\n      options\n    )\n\n    // Each WebSocket object has an associated ready state, which is a\n    // number representing the state of the connection. Initially it must\n    // be CONNECTING (0).\n    this[kReadyState] = WebSocket.CONNECTING\n\n    // The extensions attribute must initially return the empty string.\n\n    // The protocol attribute must initially return the empty string.\n\n    // Each WebSocket object has an associated binary type, which is a\n    // BinaryType. Initially it must be \"blob\".\n    this[kBinaryType] = 'blob'\n  }\n\n  /**\n   * @see https://websockets.spec.whatwg.org/#dom-websocket-close\n   * @param {number|undefined} code\n   * @param {string|undefined} reason\n   */\n  close (code = undefined, reason = undefined) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (code !== undefined) {\n      code = webidl.converters['unsigned short'](code, { clamp: true })\n    }\n\n    if (reason !== undefined) {\n      reason = webidl.converters.USVString(reason)\n    }\n\n    // 1. If code is present, but is neither an integer equal to 1000 nor an\n    //    integer in the range 3000 to 4999, inclusive, throw an\n    //    \"InvalidAccessError\" DOMException.\n    if (code !== undefined) {\n      if (code !== 1000 && (code < 3000 || code > 4999)) {\n        throw new DOMException('invalid code', 'InvalidAccessError')\n      }\n    }\n\n    let reasonByteLength = 0\n\n    // 2. If reason is present, then run these substeps:\n    if (reason !== undefined) {\n      // 1. Let reasonBytes be the result of encoding reason.\n      // 2. If reasonBytes is longer than 123 bytes, then throw a\n      //    \"SyntaxError\" DOMException.\n      reasonByteLength = Buffer.byteLength(reason)\n\n      if (reasonByteLength > 123) {\n        throw new DOMException(\n          `Reason must be less than 123 bytes; received ${reasonByteLength}`,\n          'SyntaxError'\n        )\n      }\n    }\n\n    // 3. Run the first matching steps from the following list:\n    if (this[kReadyState] === WebSocket.CLOSING || this[kReadyState] === WebSocket.CLOSED) {\n      // If this's ready state is CLOSING (2) or CLOSED (3)\n      // Do nothing.\n    } else if (!isEstablished(this)) {\n      // If the WebSocket connection is not yet established\n      // Fail the WebSocket connection and set this's ready state\n      // to CLOSING (2).\n      failWebsocketConnection(this, 'Connection was closed before it was established.')\n      this[kReadyState] = WebSocket.CLOSING\n    } else if (!isClosing(this)) {\n      // If the WebSocket closing handshake has not yet been started\n      // Start the WebSocket closing handshake and set this's ready\n      // state to CLOSING (2).\n      // - If neither code nor reason is present, the WebSocket Close\n      //   message must not have a body.\n      // - If code is present, then the status code to use in the\n      //   WebSocket Close message must be the integer given by code.\n      // - If reason is also present, then reasonBytes must be\n      //   provided in the Close message after the status code.\n\n      const frame = new WebsocketFrameSend()\n\n      // If neither code nor reason is present, the WebSocket Close\n      // message must not have a body.\n\n      // If code is present, then the status code to use in the\n      // WebSocket Close message must be the integer given by code.\n      if (code !== undefined && reason === undefined) {\n        frame.frameData = Buffer.allocUnsafe(2)\n        frame.frameData.writeUInt16BE(code, 0)\n      } else if (code !== undefined && reason !== undefined) {\n        // If reason is also present, then reasonBytes must be\n        // provided in the Close message after the status code.\n        frame.frameData = Buffer.allocUnsafe(2 + reasonByteLength)\n        frame.frameData.writeUInt16BE(code, 0)\n        // the body MAY contain UTF-8-encoded data with value /reason/\n        frame.frameData.write(reason, 2, 'utf-8')\n      } else {\n        frame.frameData = emptyBuffer\n      }\n\n      /** @type {import('stream').Duplex} */\n      const socket = this[kResponse].socket\n\n      socket.write(frame.createFrame(opcodes.CLOSE), (err) => {\n        if (!err) {\n          this[kSentClose] = true\n        }\n      })\n\n      // Upon either sending or receiving a Close control frame, it is said\n      // that _The WebSocket Closing Handshake is Started_ and that the\n      // WebSocket connection is in the CLOSING state.\n      this[kReadyState] = states.CLOSING\n    } else {\n      // Otherwise\n      // Set this's ready state to CLOSING (2).\n      this[kReadyState] = WebSocket.CLOSING\n    }\n  }\n\n  /**\n   * @see https://websockets.spec.whatwg.org/#dom-websocket-send\n   * @param {NodeJS.TypedArray|ArrayBuffer|Blob|string} data\n   */\n  send (data) {\n    webidl.brandCheck(this, WebSocket)\n\n    webidl.argumentLengthCheck(arguments, 1, { header: 'WebSocket.send' })\n\n    data = webidl.converters.WebSocketSendData(data)\n\n    // 1. If this's ready state is CONNECTING, then throw an\n    //    \"InvalidStateError\" DOMException.\n    if (this[kReadyState] === WebSocket.CONNECTING) {\n      throw new DOMException('Sent before connected.', 'InvalidStateError')\n    }\n\n    // 2. Run the appropriate set of steps from the following list:\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-6.1\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-5.2\n\n    if (!isEstablished(this) || isClosing(this)) {\n      return\n    }\n\n    /** @type {import('stream').Duplex} */\n    const socket = this[kResponse].socket\n\n    // If data is a string\n    if (typeof data === 'string') {\n      // If the WebSocket connection is established and the WebSocket\n      // closing handshake has not yet started, then the user agent\n      // must send a WebSocket Message comprised of the data argument\n      // using a text frame opcode; if the data cannot be sent, e.g.\n      // because it would need to be buffered but the buffer is full,\n      // the user agent must flag the WebSocket as full and then close\n      // the WebSocket connection. Any invocation of this method with a\n      // string argument that does not throw an exception must increase\n      // the bufferedAmount attribute by the number of bytes needed to\n      // express the argument as UTF-8.\n\n      const value = Buffer.from(data)\n      const frame = new WebsocketFrameSend(value)\n      const buffer = frame.createFrame(opcodes.TEXT)\n\n      this.#bufferedAmount += value.byteLength\n      socket.write(buffer, () => {\n        this.#bufferedAmount -= value.byteLength\n      })\n    } else if (types.isArrayBuffer(data)) {\n      // If the WebSocket connection is established, and the WebSocket\n      // closing handshake has not yet started, then the user agent must\n      // send a WebSocket Message comprised of data using a binary frame\n      // opcode; if the data cannot be sent, e.g. because it would need\n      // to be buffered but the buffer is full, the user agent must flag\n      // the WebSocket as full and then close the WebSocket connection.\n      // The data to be sent is the data stored in the buffer described\n      // by the ArrayBuffer object. Any invocation of this method with an\n      // ArrayBuffer argument that does not throw an exception must\n      // increase the bufferedAmount attribute by the length of the\n      // ArrayBuffer in bytes.\n\n      const value = Buffer.from(data)\n      const frame = new WebsocketFrameSend(value)\n      const buffer = frame.createFrame(opcodes.BINARY)\n\n      this.#bufferedAmount += value.byteLength\n      socket.write(buffer, () => {\n        this.#bufferedAmount -= value.byteLength\n      })\n    } else if (ArrayBuffer.isView(data)) {\n      // If the WebSocket connection is established, and the WebSocket\n      // closing handshake has not yet started, then the user agent must\n      // send a WebSocket Message comprised of data using a binary frame\n      // opcode; if the data cannot be sent, e.g. because it would need to\n      // be buffered but the buffer is full, the user agent must flag the\n      // WebSocket as full and then close the WebSocket connection. The\n      // data to be sent is the data stored in the section of the buffer\n      // described by the ArrayBuffer object that data references. Any\n      // invocation of this method with this kind of argument that does\n      // not throw an exception must increase the bufferedAmount attribute\n      // by the length of datas buffer in bytes.\n\n      const ab = Buffer.from(data, data.byteOffset, data.byteLength)\n\n      const frame = new WebsocketFrameSend(ab)\n      const buffer = frame.createFrame(opcodes.BINARY)\n\n      this.#bufferedAmount += ab.byteLength\n      socket.write(buffer, () => {\n        this.#bufferedAmount -= ab.byteLength\n      })\n    } else if (isBlobLike(data)) {\n      // If the WebSocket connection is established, and the WebSocket\n      // closing handshake has not yet started, then the user agent must\n      // send a WebSocket Message comprised of data using a binary frame\n      // opcode; if the data cannot be sent, e.g. because it would need to\n      // be buffered but the buffer is full, the user agent must flag the\n      // WebSocket as full and then close the WebSocket connection. The data\n      // to be sent is the raw data represented by the Blob object. Any\n      // invocation of this method with a Blob argument that does not throw\n      // an exception must increase the bufferedAmount attribute by the size\n      // of the Blob objects raw data, in bytes.\n\n      const frame = new WebsocketFrameSend()\n\n      data.arrayBuffer().then((ab) => {\n        const value = Buffer.from(ab)\n        frame.frameData = value\n        const buffer = frame.createFrame(opcodes.BINARY)\n\n        this.#bufferedAmount += value.byteLength\n        socket.write(buffer, () => {\n          this.#bufferedAmount -= value.byteLength\n        })\n      })\n    }\n  }\n\n  get readyState () {\n    webidl.brandCheck(this, WebSocket)\n\n    // The readyState getter steps are to return this's ready state.\n    return this[kReadyState]\n  }\n\n  get bufferedAmount () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#bufferedAmount\n  }\n\n  get url () {\n    webidl.brandCheck(this, WebSocket)\n\n    // The url getter steps are to return this's url, serialized.\n    return URLSerializer(this[kWebSocketURL])\n  }\n\n  get extensions () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#extensions\n  }\n\n  get protocol () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#protocol\n  }\n\n  get onopen () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#events.open\n  }\n\n  set onopen (fn) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (this.#events.open) {\n      this.removeEventListener('open', this.#events.open)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.open = fn\n      this.addEventListener('open', fn)\n    } else {\n      this.#events.open = null\n    }\n  }\n\n  get onerror () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#events.error\n  }\n\n  set onerror (fn) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (this.#events.error) {\n      this.removeEventListener('error', this.#events.error)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.error = fn\n      this.addEventListener('error', fn)\n    } else {\n      this.#events.error = null\n    }\n  }\n\n  get onclose () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#events.close\n  }\n\n  set onclose (fn) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (this.#events.close) {\n      this.removeEventListener('close', this.#events.close)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.close = fn\n      this.addEventListener('close', fn)\n    } else {\n      this.#events.close = null\n    }\n  }\n\n  get onmessage () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this.#events.message\n  }\n\n  set onmessage (fn) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (this.#events.message) {\n      this.removeEventListener('message', this.#events.message)\n    }\n\n    if (typeof fn === 'function') {\n      this.#events.message = fn\n      this.addEventListener('message', fn)\n    } else {\n      this.#events.message = null\n    }\n  }\n\n  get binaryType () {\n    webidl.brandCheck(this, WebSocket)\n\n    return this[kBinaryType]\n  }\n\n  set binaryType (type) {\n    webidl.brandCheck(this, WebSocket)\n\n    if (type !== 'blob' && type !== 'arraybuffer') {\n      this[kBinaryType] = 'blob'\n    } else {\n      this[kBinaryType] = type\n    }\n  }\n\n  /**\n   * @see https://websockets.spec.whatwg.org/#feedback-from-the-protocol\n   */\n  #onConnectionEstablished (response) {\n    // processResponse is called when the \"responses header list has been received and initialized.\"\n    // once this happens, the connection is open\n    this[kResponse] = response\n\n    const parser = new ByteParser(this)\n    parser.on('drain', function onParserDrain () {\n      this.ws[kResponse].socket.resume()\n    })\n\n    response.socket.ws = this\n    this[kByteParser] = parser\n\n    // 1. Change the ready state to OPEN (1).\n    this[kReadyState] = states.OPEN\n\n    // 2. Change the extensions attributes value to the extensions in use, if\n    //    it is not the null value.\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-9.1\n    const extensions = response.headersList.get('sec-websocket-extensions')\n\n    if (extensions !== null) {\n      this.#extensions = extensions\n    }\n\n    // 3. Change the protocol attributes value to the subprotocol in use, if\n    //    it is not the null value.\n    // https://datatracker.ietf.org/doc/html/rfc6455#section-1.9\n    const protocol = response.headersList.get('sec-websocket-protocol')\n\n    if (protocol !== null) {\n      this.#protocol = protocol\n    }\n\n    // 4. Fire an event named open at the WebSocket object.\n    fireEvent('open', this)\n  }\n}\n\n// https://websockets.spec.whatwg.org/#dom-websocket-connecting\nWebSocket.CONNECTING = WebSocket.prototype.CONNECTING = states.CONNECTING\n// https://websockets.spec.whatwg.org/#dom-websocket-open\nWebSocket.OPEN = WebSocket.prototype.OPEN = states.OPEN\n// https://websockets.spec.whatwg.org/#dom-websocket-closing\nWebSocket.CLOSING = WebSocket.prototype.CLOSING = states.CLOSING\n// https://websockets.spec.whatwg.org/#dom-websocket-closed\nWebSocket.CLOSED = WebSocket.prototype.CLOSED = states.CLOSED\n\nObject.defineProperties(WebSocket.prototype, {\n  CONNECTING: staticPropertyDescriptors,\n  OPEN: staticPropertyDescriptors,\n  CLOSING: staticPropertyDescriptors,\n  CLOSED: staticPropertyDescriptors,\n  url: kEnumerableProperty,\n  readyState: kEnumerableProperty,\n  bufferedAmount: kEnumerableProperty,\n  onopen: kEnumerableProperty,\n  onerror: kEnumerableProperty,\n  onclose: kEnumerableProperty,\n  close: kEnumerableProperty,\n  onmessage: kEnumerableProperty,\n  binaryType: kEnumerableProperty,\n  send: kEnumerableProperty,\n  extensions: kEnumerableProperty,\n  protocol: kEnumerableProperty,\n  [Symbol.toStringTag]: {\n    value: 'WebSocket',\n    writable: false,\n    enumerable: false,\n    configurable: true\n  }\n})\n\nObject.defineProperties(WebSocket, {\n  CONNECTING: staticPropertyDescriptors,\n  OPEN: staticPropertyDescriptors,\n  CLOSING: staticPropertyDescriptors,\n  CLOSED: staticPropertyDescriptors\n})\n\nwebidl.converters['sequence<DOMString>'] = webidl.sequenceConverter(\n  webidl.converters.DOMString\n)\n\nwebidl.converters['DOMString or sequence<DOMString>'] = function (V) {\n  if (webidl.util.Type(V) === 'Object' && Symbol.iterator in V) {\n    return webidl.converters['sequence<DOMString>'](V)\n  }\n\n  return webidl.converters.DOMString(V)\n}\n\n// This implements the propsal made in https://github.com/whatwg/websockets/issues/42\nwebidl.converters.WebSocketInit = webidl.dictionaryConverter([\n  {\n    key: 'protocols',\n    converter: webidl.converters['DOMString or sequence<DOMString>'],\n    get defaultValue () {\n      return []\n    }\n  },\n  {\n    key: 'dispatcher',\n    converter: (V) => V,\n    get defaultValue () {\n      return getGlobalDispatcher()\n    }\n  },\n  {\n    key: 'headers',\n    converter: webidl.nullableConverter(webidl.converters.HeadersInit)\n  }\n])\n\nwebidl.converters['DOMString or sequence<DOMString> or WebSocketInit'] = function (V) {\n  if (webidl.util.Type(V) === 'Object' && !(Symbol.iterator in V)) {\n    return webidl.converters.WebSocketInit(V)\n  }\n\n  return { protocols: webidl.converters['DOMString or sequence<DOMString>'](V) }\n}\n\nwebidl.converters.WebSocketSendData = function (V) {\n  if (webidl.util.Type(V) === 'Object') {\n    if (isBlobLike(V)) {\n      return webidl.converters.Blob(V, { strict: false })\n    }\n\n    if (ArrayBuffer.isView(V) || types.isAnyArrayBuffer(V)) {\n      return webidl.converters.BufferSource(V)\n    }\n  }\n\n  return webidl.converters.USVString(V)\n}\n\nmodule.exports = {\n  WebSocket\n}\n","'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nfunction getUserAgent() {\n  if (typeof navigator === \"object\" && \"userAgent\" in navigator) {\n    return navigator.userAgent;\n  }\n\n  if (typeof process === \"object\" && process.version !== undefined) {\n    return `Node.js/${process.version.substr(1)} (${process.platform}; ${process.arch})`;\n  }\n\n  return \"<environment undetectable>\";\n}\n\nexports.getUserAgent = getUserAgent;\n//# sourceMappingURL=index.js.map\n","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nObject.defineProperty(exports, \"v1\", {\n  enumerable: true,\n  get: function () {\n    return _v.default;\n  }\n});\nObject.defineProperty(exports, \"v3\", {\n  enumerable: true,\n  get: function () {\n    return _v2.default;\n  }\n});\nObject.defineProperty(exports, \"v4\", {\n  enumerable: true,\n  get: function () {\n    return _v3.default;\n  }\n});\nObject.defineProperty(exports, \"v5\", {\n  enumerable: true,\n  get: function () {\n    return _v4.default;\n  }\n});\nObject.defineProperty(exports, \"NIL\", {\n  enumerable: true,\n  get: function () {\n    return _nil.default;\n  }\n});\nObject.defineProperty(exports, \"version\", {\n  enumerable: true,\n  get: function () {\n    return _version.default;\n  }\n});\nObject.defineProperty(exports, \"validate\", {\n  enumerable: true,\n  get: function () {\n    return _validate.default;\n  }\n});\nObject.defineProperty(exports, \"stringify\", {\n  enumerable: true,\n  get: function () {\n    return _stringify.default;\n  }\n});\nObject.defineProperty(exports, \"parse\", {\n  enumerable: true,\n  get: function () {\n    return _parse.default;\n  }\n});\n\nvar _v = _interopRequireDefault(require(\"./v1.js\"));\n\nvar _v2 = _interopRequireDefault(require(\"./v3.js\"));\n\nvar _v3 = _interopRequireDefault(require(\"./v4.js\"));\n\nvar _v4 = _interopRequireDefault(require(\"./v5.js\"));\n\nvar _nil = _interopRequireDefault(require(\"./nil.js\"));\n\nvar _version = _interopRequireDefault(require(\"./version.js\"));\n\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\n\nvar _stringify = _interopRequireDefault(require(\"./stringify.js\"));\n\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _crypto = _interopRequireDefault(require(\"crypto\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction md5(bytes) {\n  if (Array.isArray(bytes)) {\n    bytes = Buffer.from(bytes);\n  } else if (typeof bytes === 'string') {\n    bytes = Buffer.from(bytes, 'utf8');\n  }\n\n  return _crypto.default.createHash('md5').update(bytes).digest();\n}\n\nvar _default = md5;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = '00000000-0000-0000-0000-000000000000';\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction parse(uuid) {\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n\n  let v;\n  const arr = new Uint8Array(16); // Parse ########-....-....-....-............\n\n  arr[0] = (v = parseInt(uuid.slice(0, 8), 16)) >>> 24;\n  arr[1] = v >>> 16 & 0xff;\n  arr[2] = v >>> 8 & 0xff;\n  arr[3] = v & 0xff; // Parse ........-####-....-....-............\n\n  arr[4] = (v = parseInt(uuid.slice(9, 13), 16)) >>> 8;\n  arr[5] = v & 0xff; // Parse ........-....-####-....-............\n\n  arr[6] = (v = parseInt(uuid.slice(14, 18), 16)) >>> 8;\n  arr[7] = v & 0xff; // Parse ........-....-....-####-............\n\n  arr[8] = (v = parseInt(uuid.slice(19, 23), 16)) >>> 8;\n  arr[9] = v & 0xff; // Parse ........-....-....-....-############\n  // (Use \"/\" to avoid 32-bit truncation when bit-shifting high-order bytes)\n\n  arr[10] = (v = parseInt(uuid.slice(24, 36), 16)) / 0x10000000000 & 0xff;\n  arr[11] = v / 0x100000000 & 0xff;\n  arr[12] = v >>> 24 & 0xff;\n  arr[13] = v >>> 16 & 0xff;\n  arr[14] = v >>> 8 & 0xff;\n  arr[15] = v & 0xff;\n  return arr;\n}\n\nvar _default = parse;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\nvar _default = /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-5][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000)$/i;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = rng;\n\nvar _crypto = _interopRequireDefault(require(\"crypto\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nconst rnds8Pool = new Uint8Array(256); // # of random values to pre-allocate\n\nlet poolPtr = rnds8Pool.length;\n\nfunction rng() {\n  if (poolPtr > rnds8Pool.length - 16) {\n    _crypto.default.randomFillSync(rnds8Pool);\n\n    poolPtr = 0;\n  }\n\n  return rnds8Pool.slice(poolPtr, poolPtr += 16);\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _crypto = _interopRequireDefault(require(\"crypto\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction sha1(bytes) {\n  if (Array.isArray(bytes)) {\n    bytes = Buffer.from(bytes);\n  } else if (typeof bytes === 'string') {\n    bytes = Buffer.from(bytes, 'utf8');\n  }\n\n  return _crypto.default.createHash('sha1').update(bytes).digest();\n}\n\nvar _default = sha1;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n/**\n * Convert array of 16 byte values to UUID string format of the form:\n * XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\n */\nconst byteToHex = [];\n\nfor (let i = 0; i < 256; ++i) {\n  byteToHex.push((i + 0x100).toString(16).substr(1));\n}\n\nfunction stringify(arr, offset = 0) {\n  // Note: Be careful editing this code!  It's been tuned for performance\n  // and works in ways you may not expect. See https://github.com/uuidjs/uuid/pull/434\n  const uuid = (byteToHex[arr[offset + 0]] + byteToHex[arr[offset + 1]] + byteToHex[arr[offset + 2]] + byteToHex[arr[offset + 3]] + '-' + byteToHex[arr[offset + 4]] + byteToHex[arr[offset + 5]] + '-' + byteToHex[arr[offset + 6]] + byteToHex[arr[offset + 7]] + '-' + byteToHex[arr[offset + 8]] + byteToHex[arr[offset + 9]] + '-' + byteToHex[arr[offset + 10]] + byteToHex[arr[offset + 11]] + byteToHex[arr[offset + 12]] + byteToHex[arr[offset + 13]] + byteToHex[arr[offset + 14]] + byteToHex[arr[offset + 15]]).toLowerCase(); // Consistency check for valid UUID.  If this throws, it's likely due to one\n  // of the following:\n  // - One or more input array values don't map to a hex octet (leading to\n  // \"undefined\" in the uuid)\n  // - Invalid input values for the RFC `version` or `variant` fields\n\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Stringified UUID is invalid');\n  }\n\n  return uuid;\n}\n\nvar _default = stringify;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\n\nvar _stringify = _interopRequireDefault(require(\"./stringify.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\n// **`v1()` - Generate time-based UUID**\n//\n// Inspired by https://github.com/LiosK/UUID.js\n// and http://docs.python.org/library/uuid.html\nlet _nodeId;\n\nlet _clockseq; // Previous uuid creation time\n\n\nlet _lastMSecs = 0;\nlet _lastNSecs = 0; // See https://github.com/uuidjs/uuid for API details\n\nfunction v1(options, buf, offset) {\n  let i = buf && offset || 0;\n  const b = buf || new Array(16);\n  options = options || {};\n  let node = options.node || _nodeId;\n  let clockseq = options.clockseq !== undefined ? options.clockseq : _clockseq; // node and clockseq need to be initialized to random values if they're not\n  // specified.  We do this lazily to minimize issues related to insufficient\n  // system entropy.  See #189\n\n  if (node == null || clockseq == null) {\n    const seedBytes = options.random || (options.rng || _rng.default)();\n\n    if (node == null) {\n      // Per 4.5, create and 48-bit node id, (47 random bits + multicast bit = 1)\n      node = _nodeId = [seedBytes[0] | 0x01, seedBytes[1], seedBytes[2], seedBytes[3], seedBytes[4], seedBytes[5]];\n    }\n\n    if (clockseq == null) {\n      // Per 4.2.2, randomize (14 bit) clockseq\n      clockseq = _clockseq = (seedBytes[6] << 8 | seedBytes[7]) & 0x3fff;\n    }\n  } // UUID timestamps are 100 nano-second units since the Gregorian epoch,\n  // (1582-10-15 00:00).  JSNumbers aren't precise enough for this, so\n  // time is handled internally as 'msecs' (integer milliseconds) and 'nsecs'\n  // (100-nanoseconds offset from msecs) since unix epoch, 1970-01-01 00:00.\n\n\n  let msecs = options.msecs !== undefined ? options.msecs : Date.now(); // Per 4.2.1.2, use count of uuid's generated during the current clock\n  // cycle to simulate higher resolution clock\n\n  let nsecs = options.nsecs !== undefined ? options.nsecs : _lastNSecs + 1; // Time since last uuid creation (in msecs)\n\n  const dt = msecs - _lastMSecs + (nsecs - _lastNSecs) / 10000; // Per 4.2.1.2, Bump clockseq on clock regression\n\n  if (dt < 0 && options.clockseq === undefined) {\n    clockseq = clockseq + 1 & 0x3fff;\n  } // Reset nsecs if clock regresses (new clockseq) or we've moved onto a new\n  // time interval\n\n\n  if ((dt < 0 || msecs > _lastMSecs) && options.nsecs === undefined) {\n    nsecs = 0;\n  } // Per 4.2.1.2 Throw error if too many uuids are requested\n\n\n  if (nsecs >= 10000) {\n    throw new Error(\"uuid.v1(): Can't create more than 10M uuids/sec\");\n  }\n\n  _lastMSecs = msecs;\n  _lastNSecs = nsecs;\n  _clockseq = clockseq; // Per 4.1.4 - Convert from unix epoch to Gregorian epoch\n\n  msecs += 12219292800000; // `time_low`\n\n  const tl = ((msecs & 0xfffffff) * 10000 + nsecs) % 0x100000000;\n  b[i++] = tl >>> 24 & 0xff;\n  b[i++] = tl >>> 16 & 0xff;\n  b[i++] = tl >>> 8 & 0xff;\n  b[i++] = tl & 0xff; // `time_mid`\n\n  const tmh = msecs / 0x100000000 * 10000 & 0xfffffff;\n  b[i++] = tmh >>> 8 & 0xff;\n  b[i++] = tmh & 0xff; // `time_high_and_version`\n\n  b[i++] = tmh >>> 24 & 0xf | 0x10; // include version\n\n  b[i++] = tmh >>> 16 & 0xff; // `clock_seq_hi_and_reserved` (Per 4.2.2 - include variant)\n\n  b[i++] = clockseq >>> 8 | 0x80; // `clock_seq_low`\n\n  b[i++] = clockseq & 0xff; // `node`\n\n  for (let n = 0; n < 6; ++n) {\n    b[i + n] = node[n];\n  }\n\n  return buf || (0, _stringify.default)(b);\n}\n\nvar _default = v1;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _v = _interopRequireDefault(require(\"./v35.js\"));\n\nvar _md = _interopRequireDefault(require(\"./md5.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nconst v3 = (0, _v.default)('v3', 0x30, _md.default);\nvar _default = v3;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = _default;\nexports.URL = exports.DNS = void 0;\n\nvar _stringify = _interopRequireDefault(require(\"./stringify.js\"));\n\nvar _parse = _interopRequireDefault(require(\"./parse.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction stringToBytes(str) {\n  str = unescape(encodeURIComponent(str)); // UTF8 escape\n\n  const bytes = [];\n\n  for (let i = 0; i < str.length; ++i) {\n    bytes.push(str.charCodeAt(i));\n  }\n\n  return bytes;\n}\n\nconst DNS = '6ba7b810-9dad-11d1-80b4-00c04fd430c8';\nexports.DNS = DNS;\nconst URL = '6ba7b811-9dad-11d1-80b4-00c04fd430c8';\nexports.URL = URL;\n\nfunction _default(name, version, hashfunc) {\n  function generateUUID(value, namespace, buf, offset) {\n    if (typeof value === 'string') {\n      value = stringToBytes(value);\n    }\n\n    if (typeof namespace === 'string') {\n      namespace = (0, _parse.default)(namespace);\n    }\n\n    if (namespace.length !== 16) {\n      throw TypeError('Namespace must be array-like (16 iterable integer values, 0-255)');\n    } // Compute hash of namespace and value, Per 4.3\n    // Future: Use spread syntax when supported on all platforms, e.g. `bytes =\n    // hashfunc([...namespace, ... value])`\n\n\n    let bytes = new Uint8Array(16 + value.length);\n    bytes.set(namespace);\n    bytes.set(value, namespace.length);\n    bytes = hashfunc(bytes);\n    bytes[6] = bytes[6] & 0x0f | version;\n    bytes[8] = bytes[8] & 0x3f | 0x80;\n\n    if (buf) {\n      offset = offset || 0;\n\n      for (let i = 0; i < 16; ++i) {\n        buf[offset + i] = bytes[i];\n      }\n\n      return buf;\n    }\n\n    return (0, _stringify.default)(bytes);\n  } // Function#name is not settable on some platforms (#270)\n\n\n  try {\n    generateUUID.name = name; // eslint-disable-next-line no-empty\n  } catch (err) {} // For CommonJS default export support\n\n\n  generateUUID.DNS = DNS;\n  generateUUID.URL = URL;\n  return generateUUID;\n}","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _rng = _interopRequireDefault(require(\"./rng.js\"));\n\nvar _stringify = _interopRequireDefault(require(\"./stringify.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction v4(options, buf, offset) {\n  options = options || {};\n\n  const rnds = options.random || (options.rng || _rng.default)(); // Per 4.4, set bits for version and `clock_seq_hi_and_reserved`\n\n\n  rnds[6] = rnds[6] & 0x0f | 0x40;\n  rnds[8] = rnds[8] & 0x3f | 0x80; // Copy bytes to buffer, if provided\n\n  if (buf) {\n    offset = offset || 0;\n\n    for (let i = 0; i < 16; ++i) {\n      buf[offset + i] = rnds[i];\n    }\n\n    return buf;\n  }\n\n  return (0, _stringify.default)(rnds);\n}\n\nvar _default = v4;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _v = _interopRequireDefault(require(\"./v35.js\"));\n\nvar _sha = _interopRequireDefault(require(\"./sha1.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nconst v5 = (0, _v.default)('v5', 0x50, _sha.default);\nvar _default = v5;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _regex = _interopRequireDefault(require(\"./regex.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction validate(uuid) {\n  return typeof uuid === 'string' && _regex.default.test(uuid);\n}\n\nvar _default = validate;\nexports.default = _default;","\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.default = void 0;\n\nvar _validate = _interopRequireDefault(require(\"./validate.js\"));\n\nfunction _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }\n\nfunction version(uuid) {\n  if (!(0, _validate.default)(uuid)) {\n    throw TypeError('Invalid UUID');\n  }\n\n  return parseInt(uuid.substr(14, 1), 16);\n}\n\nvar _default = version;\nexports.default = _default;","// Returns a wrapper function that returns a wrapped callback\n// The wrapper function should do some stuff, and return a\n// presumably different callback function.\n// This makes sure that own properties are retained, so that\n// decorations and such are not lost along the way.\nmodule.exports = wrappy\nfunction wrappy (fn, cb) {\n  if (fn && cb) return wrappy(fn)(cb)\n\n  if (typeof fn !== 'function')\n    throw new TypeError('need wrapper function')\n\n  Object.keys(fn).forEach(function (k) {\n    wrapper[k] = fn[k]\n  })\n\n  return wrapper\n\n  function wrapper() {\n    var args = new Array(arguments.length)\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i]\n    }\n    var ret = fn.apply(this, args)\n    var cb = args[args.length-1]\n    if (typeof ret === 'function' && ret !== cb) {\n      Object.keys(cb).forEach(function (k) {\n        ret[k] = cb[k]\n      })\n    }\n    return ret\n  }\n}\n","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"assert\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"async_hooks\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"buffer\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"console\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"crypto\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"diagnostics_channel\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"events\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"fs\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"http\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"http2\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"https\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"net\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"node:events\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"node:stream\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"node:util\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"os\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"path\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"perf_hooks\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"querystring\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"stream\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"stream/web\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"string_decoder\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"tls\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"url\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"util\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"util/types\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"worker_threads\");","module.exports = __WEBPACK_EXTERNAL_createRequire(import.meta.url)(\"zlib\");","'use strict'\n\nconst WritableStream = require('node:stream').Writable\nconst inherits = require('node:util').inherits\n\nconst StreamSearch = require('../../streamsearch/sbmh')\n\nconst PartStream = require('./PartStream')\nconst HeaderParser = require('./HeaderParser')\n\nconst DASH = 45\nconst B_ONEDASH = Buffer.from('-')\nconst B_CRLF = Buffer.from('\\r\\n')\nconst EMPTY_FN = function () {}\n\nfunction Dicer (cfg) {\n  if (!(this instanceof Dicer)) { return new Dicer(cfg) }\n  WritableStream.call(this, cfg)\n\n  if (!cfg || (!cfg.headerFirst && typeof cfg.boundary !== 'string')) { throw new TypeError('Boundary required') }\n\n  if (typeof cfg.boundary === 'string') { this.setBoundary(cfg.boundary) } else { this._bparser = undefined }\n\n  this._headerFirst = cfg.headerFirst\n\n  this._dashes = 0\n  this._parts = 0\n  this._finished = false\n  this._realFinish = false\n  this._isPreamble = true\n  this._justMatched = false\n  this._firstWrite = true\n  this._inHeader = true\n  this._part = undefined\n  this._cb = undefined\n  this._ignoreData = false\n  this._partOpts = { highWaterMark: cfg.partHwm }\n  this._pause = false\n\n  const self = this\n  this._hparser = new HeaderParser(cfg)\n  this._hparser.on('header', function (header) {\n    self._inHeader = false\n    self._part.emit('header', header)\n  })\n}\ninherits(Dicer, WritableStream)\n\nDicer.prototype.emit = function (ev) {\n  if (ev === 'finish' && !this._realFinish) {\n    if (!this._finished) {\n      const self = this\n      process.nextTick(function () {\n        self.emit('error', new Error('Unexpected end of multipart data'))\n        if (self._part && !self._ignoreData) {\n          const type = (self._isPreamble ? 'Preamble' : 'Part')\n          self._part.emit('error', new Error(type + ' terminated early due to unexpected end of multipart data'))\n          self._part.push(null)\n          process.nextTick(function () {\n            self._realFinish = true\n            self.emit('finish')\n            self._realFinish = false\n          })\n          return\n        }\n        self._realFinish = true\n        self.emit('finish')\n        self._realFinish = false\n      })\n    }\n  } else { WritableStream.prototype.emit.apply(this, arguments) }\n}\n\nDicer.prototype._write = function (data, encoding, cb) {\n  // ignore unexpected data (e.g. extra trailer data after finished)\n  if (!this._hparser && !this._bparser) { return cb() }\n\n  if (this._headerFirst && this._isPreamble) {\n    if (!this._part) {\n      this._part = new PartStream(this._partOpts)\n      if (this.listenerCount('preamble') !== 0) { this.emit('preamble', this._part) } else { this._ignore() }\n    }\n    const r = this._hparser.push(data)\n    if (!this._inHeader && r !== undefined && r < data.length) { data = data.slice(r) } else { return cb() }\n  }\n\n  // allows for \"easier\" testing\n  if (this._firstWrite) {\n    this._bparser.push(B_CRLF)\n    this._firstWrite = false\n  }\n\n  this._bparser.push(data)\n\n  if (this._pause) { this._cb = cb } else { cb() }\n}\n\nDicer.prototype.reset = function () {\n  this._part = undefined\n  this._bparser = undefined\n  this._hparser = undefined\n}\n\nDicer.prototype.setBoundary = function (boundary) {\n  const self = this\n  this._bparser = new StreamSearch('\\r\\n--' + boundary)\n  this._bparser.on('info', function (isMatch, data, start, end) {\n    self._oninfo(isMatch, data, start, end)\n  })\n}\n\nDicer.prototype._ignore = function () {\n  if (this._part && !this._ignoreData) {\n    this._ignoreData = true\n    this._part.on('error', EMPTY_FN)\n    // we must perform some kind of read on the stream even though we are\n    // ignoring the data, otherwise node's Readable stream will not emit 'end'\n    // after pushing null to the stream\n    this._part.resume()\n  }\n}\n\nDicer.prototype._oninfo = function (isMatch, data, start, end) {\n  let buf; const self = this; let i = 0; let r; let shouldWriteMore = true\n\n  if (!this._part && this._justMatched && data) {\n    while (this._dashes < 2 && (start + i) < end) {\n      if (data[start + i] === DASH) {\n        ++i\n        ++this._dashes\n      } else {\n        if (this._dashes) { buf = B_ONEDASH }\n        this._dashes = 0\n        break\n      }\n    }\n    if (this._dashes === 2) {\n      if ((start + i) < end && this.listenerCount('trailer') !== 0) { this.emit('trailer', data.slice(start + i, end)) }\n      this.reset()\n      this._finished = true\n      // no more parts will be added\n      if (self._parts === 0) {\n        self._realFinish = true\n        self.emit('finish')\n        self._realFinish = false\n      }\n    }\n    if (this._dashes) { return }\n  }\n  if (this._justMatched) { this._justMatched = false }\n  if (!this._part) {\n    this._part = new PartStream(this._partOpts)\n    this._part._read = function (n) {\n      self._unpause()\n    }\n    if (this._isPreamble && this.listenerCount('preamble') !== 0) {\n      this.emit('preamble', this._part)\n    } else if (this._isPreamble !== true && this.listenerCount('part') !== 0) {\n      this.emit('part', this._part)\n    } else {\n      this._ignore()\n    }\n    if (!this._isPreamble) { this._inHeader = true }\n  }\n  if (data && start < end && !this._ignoreData) {\n    if (this._isPreamble || !this._inHeader) {\n      if (buf) { shouldWriteMore = this._part.push(buf) }\n      shouldWriteMore = this._part.push(data.slice(start, end))\n      if (!shouldWriteMore) { this._pause = true }\n    } else if (!this._isPreamble && this._inHeader) {\n      if (buf) { this._hparser.push(buf) }\n      r = this._hparser.push(data.slice(start, end))\n      if (!this._inHeader && r !== undefined && r < end) { this._oninfo(false, data, start + r, end) }\n    }\n  }\n  if (isMatch) {\n    this._hparser.reset()\n    if (this._isPreamble) { this._isPreamble = false } else {\n      if (start !== end) {\n        ++this._parts\n        this._part.on('end', function () {\n          if (--self._parts === 0) {\n            if (self._finished) {\n              self._realFinish = true\n              self.emit('finish')\n              self._realFinish = false\n            } else {\n              self._unpause()\n            }\n          }\n        })\n      }\n    }\n    this._part.push(null)\n    this._part = undefined\n    this._ignoreData = false\n    this._justMatched = true\n    this._dashes = 0\n  }\n}\n\nDicer.prototype._unpause = function () {\n  if (!this._pause) { return }\n\n  this._pause = false\n  if (this._cb) {\n    const cb = this._cb\n    this._cb = undefined\n    cb()\n  }\n}\n\nmodule.exports = Dicer\n","'use strict'\n\nconst EventEmitter = require('node:events').EventEmitter\nconst inherits = require('node:util').inherits\nconst getLimit = require('../../../lib/utils/getLimit')\n\nconst StreamSearch = require('../../streamsearch/sbmh')\n\nconst B_DCRLF = Buffer.from('\\r\\n\\r\\n')\nconst RE_CRLF = /\\r\\n/g\nconst RE_HDR = /^([^:]+):[ \\t]?([\\x00-\\xFF]+)?$/ // eslint-disable-line no-control-regex\n\nfunction HeaderParser (cfg) {\n  EventEmitter.call(this)\n\n  cfg = cfg || {}\n  const self = this\n  this.nread = 0\n  this.maxed = false\n  this.npairs = 0\n  this.maxHeaderPairs = getLimit(cfg, 'maxHeaderPairs', 2000)\n  this.maxHeaderSize = getLimit(cfg, 'maxHeaderSize', 80 * 1024)\n  this.buffer = ''\n  this.header = {}\n  this.finished = false\n  this.ss = new StreamSearch(B_DCRLF)\n  this.ss.on('info', function (isMatch, data, start, end) {\n    if (data && !self.maxed) {\n      if (self.nread + end - start >= self.maxHeaderSize) {\n        end = self.maxHeaderSize - self.nread + start\n        self.nread = self.maxHeaderSize\n        self.maxed = true\n      } else { self.nread += (end - start) }\n\n      self.buffer += data.toString('binary', start, end)\n    }\n    if (isMatch) { self._finish() }\n  })\n}\ninherits(HeaderParser, EventEmitter)\n\nHeaderParser.prototype.push = function (data) {\n  const r = this.ss.push(data)\n  if (this.finished) { return r }\n}\n\nHeaderParser.prototype.reset = function () {\n  this.finished = false\n  this.buffer = ''\n  this.header = {}\n  this.ss.reset()\n}\n\nHeaderParser.prototype._finish = function () {\n  if (this.buffer) { this._parseHeader() }\n  this.ss.matches = this.ss.maxMatches\n  const header = this.header\n  this.header = {}\n  this.buffer = ''\n  this.finished = true\n  this.nread = this.npairs = 0\n  this.maxed = false\n  this.emit('header', header)\n}\n\nHeaderParser.prototype._parseHeader = function () {\n  if (this.npairs === this.maxHeaderPairs) { return }\n\n  const lines = this.buffer.split(RE_CRLF)\n  const len = lines.length\n  let m, h\n\n  for (var i = 0; i < len; ++i) { // eslint-disable-line no-var\n    if (lines[i].length === 0) { continue }\n    if (lines[i][0] === '\\t' || lines[i][0] === ' ') {\n      // folded header content\n      // RFC2822 says to just remove the CRLF and not the whitespace following\n      // it, so we follow the RFC and include the leading whitespace ...\n      if (h) {\n        this.header[h][this.header[h].length - 1] += lines[i]\n        continue\n      }\n    }\n\n    const posColon = lines[i].indexOf(':')\n    if (\n      posColon === -1 ||\n      posColon === 0\n    ) {\n      return\n    }\n    m = RE_HDR.exec(lines[i])\n    h = m[1].toLowerCase()\n    this.header[h] = this.header[h] || []\n    this.header[h].push((m[2] || ''))\n    if (++this.npairs === this.maxHeaderPairs) { break }\n  }\n}\n\nmodule.exports = HeaderParser\n","'use strict'\n\nconst inherits = require('node:util').inherits\nconst ReadableStream = require('node:stream').Readable\n\nfunction PartStream (opts) {\n  ReadableStream.call(this, opts)\n}\ninherits(PartStream, ReadableStream)\n\nPartStream.prototype._read = function (n) {}\n\nmodule.exports = PartStream\n","'use strict'\n\n/**\n * Copyright Brian White. All rights reserved.\n *\n * @see https://github.com/mscdex/streamsearch\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this software and associated documentation files (the \"Software\"), to\n * deal in the Software without restriction, including without limitation the\n * rights to use, copy, modify, merge, publish, distribute, sublicense, and/or\n * sell copies of the Software, and to permit persons to whom the Software is\n * furnished to do so, subject to the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n * IN THE SOFTWARE.\n *\n * Based heavily on the Streaming Boyer-Moore-Horspool C++ implementation\n * by Hongli Lai at: https://github.com/FooBarWidget/boyer-moore-horspool\n */\nconst EventEmitter = require('node:events').EventEmitter\nconst inherits = require('node:util').inherits\n\nfunction SBMH (needle) {\n  if (typeof needle === 'string') {\n    needle = Buffer.from(needle)\n  }\n\n  if (!Buffer.isBuffer(needle)) {\n    throw new TypeError('The needle has to be a String or a Buffer.')\n  }\n\n  const needleLength = needle.length\n\n  if (needleLength === 0) {\n    throw new Error('The needle cannot be an empty String/Buffer.')\n  }\n\n  if (needleLength > 256) {\n    throw new Error('The needle cannot have a length bigger than 256.')\n  }\n\n  this.maxMatches = Infinity\n  this.matches = 0\n\n  this._occ = new Array(256)\n    .fill(needleLength) // Initialize occurrence table.\n  this._lookbehind_size = 0\n  this._needle = needle\n  this._bufpos = 0\n\n  this._lookbehind = Buffer.alloc(needleLength)\n\n  // Populate occurrence table with analysis of the needle,\n  // ignoring last letter.\n  for (var i = 0; i < needleLength - 1; ++i) { // eslint-disable-line no-var\n    this._occ[needle[i]] = needleLength - 1 - i\n  }\n}\ninherits(SBMH, EventEmitter)\n\nSBMH.prototype.reset = function () {\n  this._lookbehind_size = 0\n  this.matches = 0\n  this._bufpos = 0\n}\n\nSBMH.prototype.push = function (chunk, pos) {\n  if (!Buffer.isBuffer(chunk)) {\n    chunk = Buffer.from(chunk, 'binary')\n  }\n  const chlen = chunk.length\n  this._bufpos = pos || 0\n  let r\n  while (r !== chlen && this.matches < this.maxMatches) { r = this._sbmh_feed(chunk) }\n  return r\n}\n\nSBMH.prototype._sbmh_feed = function (data) {\n  const len = data.length\n  const needle = this._needle\n  const needleLength = needle.length\n  const lastNeedleChar = needle[needleLength - 1]\n\n  // Positive: points to a position in `data`\n  //           pos == 3 points to data[3]\n  // Negative: points to a position in the lookbehind buffer\n  //           pos == -2 points to lookbehind[lookbehind_size - 2]\n  let pos = -this._lookbehind_size\n  let ch\n\n  if (pos < 0) {\n    // Lookbehind buffer is not empty. Perform Boyer-Moore-Horspool\n    // search with character lookup code that considers both the\n    // lookbehind buffer and the current round's haystack data.\n    //\n    // Loop until\n    //   there is a match.\n    // or until\n    //   we've moved past the position that requires the\n    //   lookbehind buffer. In this case we switch to the\n    //   optimized loop.\n    // or until\n    //   the character to look at lies outside the haystack.\n    while (pos < 0 && pos <= len - needleLength) {\n      ch = this._sbmh_lookup_char(data, pos + needleLength - 1)\n\n      if (\n        ch === lastNeedleChar &&\n        this._sbmh_memcmp(data, pos, needleLength - 1)\n      ) {\n        this._lookbehind_size = 0\n        ++this.matches\n        this.emit('info', true)\n\n        return (this._bufpos = pos + needleLength)\n      }\n      pos += this._occ[ch]\n    }\n\n    // No match.\n\n    if (pos < 0) {\n      // There's too few data for Boyer-Moore-Horspool to run,\n      // so let's use a different algorithm to skip as much as\n      // we can.\n      // Forward pos until\n      //   the trailing part of lookbehind + data\n      //   looks like the beginning of the needle\n      // or until\n      //   pos == 0\n      while (pos < 0 && !this._sbmh_memcmp(data, pos, len - pos)) { ++pos }\n    }\n\n    if (pos >= 0) {\n      // Discard lookbehind buffer.\n      this.emit('info', false, this._lookbehind, 0, this._lookbehind_size)\n      this._lookbehind_size = 0\n    } else {\n      // Cut off part of the lookbehind buffer that has\n      // been processed and append the entire haystack\n      // into it.\n      const bytesToCutOff = this._lookbehind_size + pos\n      if (bytesToCutOff > 0) {\n        // The cut off data is guaranteed not to contain the needle.\n        this.emit('info', false, this._lookbehind, 0, bytesToCutOff)\n      }\n\n      this._lookbehind.copy(this._lookbehind, 0, bytesToCutOff,\n        this._lookbehind_size - bytesToCutOff)\n      this._lookbehind_size -= bytesToCutOff\n\n      data.copy(this._lookbehind, this._lookbehind_size)\n      this._lookbehind_size += len\n\n      this._bufpos = len\n      return len\n    }\n  }\n\n  pos += (pos >= 0) * this._bufpos\n\n  // Lookbehind buffer is now empty. We only need to check if the\n  // needle is in the haystack.\n  if (data.indexOf(needle, pos) !== -1) {\n    pos = data.indexOf(needle, pos)\n    ++this.matches\n    if (pos > 0) { this.emit('info', true, data, this._bufpos, pos) } else { this.emit('info', true) }\n\n    return (this._bufpos = pos + needleLength)\n  } else {\n    pos = len - needleLength\n  }\n\n  // There was no match. If there's trailing haystack data that we cannot\n  // match yet using the Boyer-Moore-Horspool algorithm (because the trailing\n  // data is less than the needle size) then match using a modified\n  // algorithm that starts matching from the beginning instead of the end.\n  // Whatever trailing data is left after running this algorithm is added to\n  // the lookbehind buffer.\n  while (\n    pos < len &&\n    (\n      data[pos] !== needle[0] ||\n      (\n        (Buffer.compare(\n          data.subarray(pos, pos + len - pos),\n          needle.subarray(0, len - pos)\n        ) !== 0)\n      )\n    )\n  ) {\n    ++pos\n  }\n  if (pos < len) {\n    data.copy(this._lookbehind, 0, pos, pos + (len - pos))\n    this._lookbehind_size = len - pos\n  }\n\n  // Everything until pos is guaranteed not to contain needle data.\n  if (pos > 0) { this.emit('info', false, data, this._bufpos, pos < len ? pos : len) }\n\n  this._bufpos = len\n  return len\n}\n\nSBMH.prototype._sbmh_lookup_char = function (data, pos) {\n  return (pos < 0)\n    ? this._lookbehind[this._lookbehind_size + pos]\n    : data[pos]\n}\n\nSBMH.prototype._sbmh_memcmp = function (data, pos, len) {\n  for (var i = 0; i < len; ++i) { // eslint-disable-line no-var\n    if (this._sbmh_lookup_char(data, pos + i) !== this._needle[i]) { return false }\n  }\n  return true\n}\n\nmodule.exports = SBMH\n","'use strict'\n\nconst WritableStream = require('node:stream').Writable\nconst { inherits } = require('node:util')\nconst Dicer = require('../deps/dicer/lib/Dicer')\n\nconst MultipartParser = require('./types/multipart')\nconst UrlencodedParser = require('./types/urlencoded')\nconst parseParams = require('./utils/parseParams')\n\nfunction Busboy (opts) {\n  if (!(this instanceof Busboy)) { return new Busboy(opts) }\n\n  if (typeof opts !== 'object') {\n    throw new TypeError('Busboy expected an options-Object.')\n  }\n  if (typeof opts.headers !== 'object') {\n    throw new TypeError('Busboy expected an options-Object with headers-attribute.')\n  }\n  if (typeof opts.headers['content-type'] !== 'string') {\n    throw new TypeError('Missing Content-Type-header.')\n  }\n\n  const {\n    headers,\n    ...streamOptions\n  } = opts\n\n  this.opts = {\n    autoDestroy: false,\n    ...streamOptions\n  }\n  WritableStream.call(this, this.opts)\n\n  this._done = false\n  this._parser = this.getParserByHeaders(headers)\n  this._finished = false\n}\ninherits(Busboy, WritableStream)\n\nBusboy.prototype.emit = function (ev) {\n  if (ev === 'finish') {\n    if (!this._done) {\n      this._parser?.end()\n      return\n    } else if (this._finished) {\n      return\n    }\n    this._finished = true\n  }\n  WritableStream.prototype.emit.apply(this, arguments)\n}\n\nBusboy.prototype.getParserByHeaders = function (headers) {\n  const parsed = parseParams(headers['content-type'])\n\n  const cfg = {\n    defCharset: this.opts.defCharset,\n    fileHwm: this.opts.fileHwm,\n    headers,\n    highWaterMark: this.opts.highWaterMark,\n    isPartAFile: this.opts.isPartAFile,\n    limits: this.opts.limits,\n    parsedConType: parsed,\n    preservePath: this.opts.preservePath\n  }\n\n  if (MultipartParser.detect.test(parsed[0])) {\n    return new MultipartParser(this, cfg)\n  }\n  if (UrlencodedParser.detect.test(parsed[0])) {\n    return new UrlencodedParser(this, cfg)\n  }\n  throw new Error('Unsupported Content-Type.')\n}\n\nBusboy.prototype._write = function (chunk, encoding, cb) {\n  this._parser.write(chunk, cb)\n}\n\nmodule.exports = Busboy\nmodule.exports.default = Busboy\nmodule.exports.Busboy = Busboy\n\nmodule.exports.Dicer = Dicer\n","'use strict'\n\n// TODO:\n//  * support 1 nested multipart level\n//    (see second multipart example here:\n//     http://www.w3.org/TR/html401/interact/forms.html#didx-multipartform-data)\n//  * support limits.fieldNameSize\n//     -- this will require modifications to utils.parseParams\n\nconst { Readable } = require('node:stream')\nconst { inherits } = require('node:util')\n\nconst Dicer = require('../../deps/dicer/lib/Dicer')\n\nconst parseParams = require('../utils/parseParams')\nconst decodeText = require('../utils/decodeText')\nconst basename = require('../utils/basename')\nconst getLimit = require('../utils/getLimit')\n\nconst RE_BOUNDARY = /^boundary$/i\nconst RE_FIELD = /^form-data$/i\nconst RE_CHARSET = /^charset$/i\nconst RE_FILENAME = /^filename$/i\nconst RE_NAME = /^name$/i\n\nMultipart.detect = /^multipart\\/form-data/i\nfunction Multipart (boy, cfg) {\n  let i\n  let len\n  const self = this\n  let boundary\n  const limits = cfg.limits\n  const isPartAFile = cfg.isPartAFile || ((fieldName, contentType, fileName) => (contentType === 'application/octet-stream' || fileName !== undefined))\n  const parsedConType = cfg.parsedConType || []\n  const defCharset = cfg.defCharset || 'utf8'\n  const preservePath = cfg.preservePath\n  const fileOpts = { highWaterMark: cfg.fileHwm }\n\n  for (i = 0, len = parsedConType.length; i < len; ++i) {\n    if (Array.isArray(parsedConType[i]) &&\n      RE_BOUNDARY.test(parsedConType[i][0])) {\n      boundary = parsedConType[i][1]\n      break\n    }\n  }\n\n  function checkFinished () {\n    if (nends === 0 && finished && !boy._done) {\n      finished = false\n      self.end()\n    }\n  }\n\n  if (typeof boundary !== 'string') { throw new Error('Multipart: Boundary not found') }\n\n  const fieldSizeLimit = getLimit(limits, 'fieldSize', 1 * 1024 * 1024)\n  const fileSizeLimit = getLimit(limits, 'fileSize', Infinity)\n  const filesLimit = getLimit(limits, 'files', Infinity)\n  const fieldsLimit = getLimit(limits, 'fields', Infinity)\n  const partsLimit = getLimit(limits, 'parts', Infinity)\n  const headerPairsLimit = getLimit(limits, 'headerPairs', 2000)\n  const headerSizeLimit = getLimit(limits, 'headerSize', 80 * 1024)\n\n  let nfiles = 0\n  let nfields = 0\n  let nends = 0\n  let curFile\n  let curField\n  let finished = false\n\n  this._needDrain = false\n  this._pause = false\n  this._cb = undefined\n  this._nparts = 0\n  this._boy = boy\n\n  const parserCfg = {\n    boundary,\n    maxHeaderPairs: headerPairsLimit,\n    maxHeaderSize: headerSizeLimit,\n    partHwm: fileOpts.highWaterMark,\n    highWaterMark: cfg.highWaterMark\n  }\n\n  this.parser = new Dicer(parserCfg)\n  this.parser.on('drain', function () {\n    self._needDrain = false\n    if (self._cb && !self._pause) {\n      const cb = self._cb\n      self._cb = undefined\n      cb()\n    }\n  }).on('part', function onPart (part) {\n    if (++self._nparts > partsLimit) {\n      self.parser.removeListener('part', onPart)\n      self.parser.on('part', skipPart)\n      boy.hitPartsLimit = true\n      boy.emit('partsLimit')\n      return skipPart(part)\n    }\n\n    // hack because streams2 _always_ doesn't emit 'end' until nextTick, so let\n    // us emit 'end' early since we know the part has ended if we are already\n    // seeing the next part\n    if (curField) {\n      const field = curField\n      field.emit('end')\n      field.removeAllListeners('end')\n    }\n\n    part.on('header', function (header) {\n      let contype\n      let fieldname\n      let parsed\n      let charset\n      let encoding\n      let filename\n      let nsize = 0\n\n      if (header['content-type']) {\n        parsed = parseParams(header['content-type'][0])\n        if (parsed[0]) {\n          contype = parsed[0].toLowerCase()\n          for (i = 0, len = parsed.length; i < len; ++i) {\n            if (RE_CHARSET.test(parsed[i][0])) {\n              charset = parsed[i][1].toLowerCase()\n              break\n            }\n          }\n        }\n      }\n\n      if (contype === undefined) { contype = 'text/plain' }\n      if (charset === undefined) { charset = defCharset }\n\n      if (header['content-disposition']) {\n        parsed = parseParams(header['content-disposition'][0])\n        if (!RE_FIELD.test(parsed[0])) { return skipPart(part) }\n        for (i = 0, len = parsed.length; i < len; ++i) {\n          if (RE_NAME.test(parsed[i][0])) {\n            fieldname = parsed[i][1]\n          } else if (RE_FILENAME.test(parsed[i][0])) {\n            filename = parsed[i][1]\n            if (!preservePath) { filename = basename(filename) }\n          }\n        }\n      } else { return skipPart(part) }\n\n      if (header['content-transfer-encoding']) { encoding = header['content-transfer-encoding'][0].toLowerCase() } else { encoding = '7bit' }\n\n      let onData,\n        onEnd\n\n      if (isPartAFile(fieldname, contype, filename)) {\n        // file/binary field\n        if (nfiles === filesLimit) {\n          if (!boy.hitFilesLimit) {\n            boy.hitFilesLimit = true\n            boy.emit('filesLimit')\n          }\n          return skipPart(part)\n        }\n\n        ++nfiles\n\n        if (boy.listenerCount('file') === 0) {\n          self.parser._ignore()\n          return\n        }\n\n        ++nends\n        const file = new FileStream(fileOpts)\n        curFile = file\n        file.on('end', function () {\n          --nends\n          self._pause = false\n          checkFinished()\n          if (self._cb && !self._needDrain) {\n            const cb = self._cb\n            self._cb = undefined\n            cb()\n          }\n        })\n        file._read = function (n) {\n          if (!self._pause) { return }\n          self._pause = false\n          if (self._cb && !self._needDrain) {\n            const cb = self._cb\n            self._cb = undefined\n            cb()\n          }\n        }\n        boy.emit('file', fieldname, file, filename, encoding, contype)\n\n        onData = function (data) {\n          if ((nsize += data.length) > fileSizeLimit) {\n            const extralen = fileSizeLimit - nsize + data.length\n            if (extralen > 0) { file.push(data.slice(0, extralen)) }\n            file.truncated = true\n            file.bytesRead = fileSizeLimit\n            part.removeAllListeners('data')\n            file.emit('limit')\n            return\n          } else if (!file.push(data)) { self._pause = true }\n\n          file.bytesRead = nsize\n        }\n\n        onEnd = function () {\n          curFile = undefined\n          file.push(null)\n        }\n      } else {\n        // non-file field\n        if (nfields === fieldsLimit) {\n          if (!boy.hitFieldsLimit) {\n            boy.hitFieldsLimit = true\n            boy.emit('fieldsLimit')\n          }\n          return skipPart(part)\n        }\n\n        ++nfields\n        ++nends\n        let buffer = ''\n        let truncated = false\n        curField = part\n\n        onData = function (data) {\n          if ((nsize += data.length) > fieldSizeLimit) {\n            const extralen = (fieldSizeLimit - (nsize - data.length))\n            buffer += data.toString('binary', 0, extralen)\n            truncated = true\n            part.removeAllListeners('data')\n          } else { buffer += data.toString('binary') }\n        }\n\n        onEnd = function () {\n          curField = undefined\n          if (buffer.length) { buffer = decodeText(buffer, 'binary', charset) }\n          boy.emit('field', fieldname, buffer, false, truncated, encoding, contype)\n          --nends\n          checkFinished()\n        }\n      }\n\n      /* As of node@2efe4ab761666 (v0.10.29+/v0.11.14+), busboy had become\n         broken. Streams2/streams3 is a huge black box of confusion, but\n         somehow overriding the sync state seems to fix things again (and still\n         seems to work for previous node versions).\n      */\n      part._readableState.sync = false\n\n      part.on('data', onData)\n      part.on('end', onEnd)\n    }).on('error', function (err) {\n      if (curFile) { curFile.emit('error', err) }\n    })\n  }).on('error', function (err) {\n    boy.emit('error', err)\n  }).on('finish', function () {\n    finished = true\n    checkFinished()\n  })\n}\n\nMultipart.prototype.write = function (chunk, cb) {\n  const r = this.parser.write(chunk)\n  if (r && !this._pause) {\n    cb()\n  } else {\n    this._needDrain = !r\n    this._cb = cb\n  }\n}\n\nMultipart.prototype.end = function () {\n  const self = this\n\n  if (self.parser.writable) {\n    self.parser.end()\n  } else if (!self._boy._done) {\n    process.nextTick(function () {\n      self._boy._done = true\n      self._boy.emit('finish')\n    })\n  }\n}\n\nfunction skipPart (part) {\n  part.resume()\n}\n\nfunction FileStream (opts) {\n  Readable.call(this, opts)\n\n  this.bytesRead = 0\n\n  this.truncated = false\n}\n\ninherits(FileStream, Readable)\n\nFileStream.prototype._read = function (n) {}\n\nmodule.exports = Multipart\n","'use strict'\n\nconst Decoder = require('../utils/Decoder')\nconst decodeText = require('../utils/decodeText')\nconst getLimit = require('../utils/getLimit')\n\nconst RE_CHARSET = /^charset$/i\n\nUrlEncoded.detect = /^application\\/x-www-form-urlencoded/i\nfunction UrlEncoded (boy, cfg) {\n  const limits = cfg.limits\n  const parsedConType = cfg.parsedConType\n  this.boy = boy\n\n  this.fieldSizeLimit = getLimit(limits, 'fieldSize', 1 * 1024 * 1024)\n  this.fieldNameSizeLimit = getLimit(limits, 'fieldNameSize', 100)\n  this.fieldsLimit = getLimit(limits, 'fields', Infinity)\n\n  let charset\n  for (var i = 0, len = parsedConType.length; i < len; ++i) { // eslint-disable-line no-var\n    if (Array.isArray(parsedConType[i]) &&\n        RE_CHARSET.test(parsedConType[i][0])) {\n      charset = parsedConType[i][1].toLowerCase()\n      break\n    }\n  }\n\n  if (charset === undefined) { charset = cfg.defCharset || 'utf8' }\n\n  this.decoder = new Decoder()\n  this.charset = charset\n  this._fields = 0\n  this._state = 'key'\n  this._checkingBytes = true\n  this._bytesKey = 0\n  this._bytesVal = 0\n  this._key = ''\n  this._val = ''\n  this._keyTrunc = false\n  this._valTrunc = false\n  this._hitLimit = false\n}\n\nUrlEncoded.prototype.write = function (data, cb) {\n  if (this._fields === this.fieldsLimit) {\n    if (!this.boy.hitFieldsLimit) {\n      this.boy.hitFieldsLimit = true\n      this.boy.emit('fieldsLimit')\n    }\n    return cb()\n  }\n\n  let idxeq; let idxamp; let i; let p = 0; const len = data.length\n\n  while (p < len) {\n    if (this._state === 'key') {\n      idxeq = idxamp = undefined\n      for (i = p; i < len; ++i) {\n        if (!this._checkingBytes) { ++p }\n        if (data[i] === 0x3D/* = */) {\n          idxeq = i\n          break\n        } else if (data[i] === 0x26/* & */) {\n          idxamp = i\n          break\n        }\n        if (this._checkingBytes && this._bytesKey === this.fieldNameSizeLimit) {\n          this._hitLimit = true\n          break\n        } else if (this._checkingBytes) { ++this._bytesKey }\n      }\n\n      if (idxeq !== undefined) {\n        // key with assignment\n        if (idxeq > p) { this._key += this.decoder.write(data.toString('binary', p, idxeq)) }\n        this._state = 'val'\n\n        this._hitLimit = false\n        this._checkingBytes = true\n        this._val = ''\n        this._bytesVal = 0\n        this._valTrunc = false\n        this.decoder.reset()\n\n        p = idxeq + 1\n      } else if (idxamp !== undefined) {\n        // key with no assignment\n        ++this._fields\n        let key; const keyTrunc = this._keyTrunc\n        if (idxamp > p) { key = (this._key += this.decoder.write(data.toString('binary', p, idxamp))) } else { key = this._key }\n\n        this._hitLimit = false\n        this._checkingBytes = true\n        this._key = ''\n        this._bytesKey = 0\n        this._keyTrunc = false\n        this.decoder.reset()\n\n        if (key.length) {\n          this.boy.emit('field', decodeText(key, 'binary', this.charset),\n            '',\n            keyTrunc,\n            false)\n        }\n\n        p = idxamp + 1\n        if (this._fields === this.fieldsLimit) { return cb() }\n      } else if (this._hitLimit) {\n        // we may not have hit the actual limit if there are encoded bytes...\n        if (i > p) { this._key += this.decoder.write(data.toString('binary', p, i)) }\n        p = i\n        if ((this._bytesKey = this._key.length) === this.fieldNameSizeLimit) {\n          // yep, we actually did hit the limit\n          this._checkingBytes = false\n          this._keyTrunc = true\n        }\n      } else {\n        if (p < len) { this._key += this.decoder.write(data.toString('binary', p)) }\n        p = len\n      }\n    } else {\n      idxamp = undefined\n      for (i = p; i < len; ++i) {\n        if (!this._checkingBytes) { ++p }\n        if (data[i] === 0x26/* & */) {\n          idxamp = i\n          break\n        }\n        if (this._checkingBytes && this._bytesVal === this.fieldSizeLimit) {\n          this._hitLimit = true\n          break\n        } else if (this._checkingBytes) { ++this._bytesVal }\n      }\n\n      if (idxamp !== undefined) {\n        ++this._fields\n        if (idxamp > p) { this._val += this.decoder.write(data.toString('binary', p, idxamp)) }\n        this.boy.emit('field', decodeText(this._key, 'binary', this.charset),\n          decodeText(this._val, 'binary', this.charset),\n          this._keyTrunc,\n          this._valTrunc)\n        this._state = 'key'\n\n        this._hitLimit = false\n        this._checkingBytes = true\n        this._key = ''\n        this._bytesKey = 0\n        this._keyTrunc = false\n        this.decoder.reset()\n\n        p = idxamp + 1\n        if (this._fields === this.fieldsLimit) { return cb() }\n      } else if (this._hitLimit) {\n        // we may not have hit the actual limit if there are encoded bytes...\n        if (i > p) { this._val += this.decoder.write(data.toString('binary', p, i)) }\n        p = i\n        if ((this._val === '' && this.fieldSizeLimit === 0) ||\n            (this._bytesVal = this._val.length) === this.fieldSizeLimit) {\n          // yep, we actually did hit the limit\n          this._checkingBytes = false\n          this._valTrunc = true\n        }\n      } else {\n        if (p < len) { this._val += this.decoder.write(data.toString('binary', p)) }\n        p = len\n      }\n    }\n  }\n  cb()\n}\n\nUrlEncoded.prototype.end = function () {\n  if (this.boy._done) { return }\n\n  if (this._state === 'key' && this._key.length > 0) {\n    this.boy.emit('field', decodeText(this._key, 'binary', this.charset),\n      '',\n      this._keyTrunc,\n      false)\n  } else if (this._state === 'val') {\n    this.boy.emit('field', decodeText(this._key, 'binary', this.charset),\n      decodeText(this._val, 'binary', this.charset),\n      this._keyTrunc,\n      this._valTrunc)\n  }\n  this.boy._done = true\n  this.boy.emit('finish')\n}\n\nmodule.exports = UrlEncoded\n","'use strict'\n\nconst RE_PLUS = /\\+/g\n\nconst HEX = [\n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n  0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n  0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0\n]\n\nfunction Decoder () {\n  this.buffer = undefined\n}\nDecoder.prototype.write = function (str) {\n  // Replace '+' with ' ' before decoding\n  str = str.replace(RE_PLUS, ' ')\n  let res = ''\n  let i = 0; let p = 0; const len = str.length\n  for (; i < len; ++i) {\n    if (this.buffer !== undefined) {\n      if (!HEX[str.charCodeAt(i)]) {\n        res += '%' + this.buffer\n        this.buffer = undefined\n        --i // retry character\n      } else {\n        this.buffer += str[i]\n        ++p\n        if (this.buffer.length === 2) {\n          res += String.fromCharCode(parseInt(this.buffer, 16))\n          this.buffer = undefined\n        }\n      }\n    } else if (str[i] === '%') {\n      if (i > p) {\n        res += str.substring(p, i)\n        p = i\n      }\n      this.buffer = ''\n      ++p\n    }\n  }\n  if (p < len && this.buffer === undefined) { res += str.substring(p) }\n  return res\n}\nDecoder.prototype.reset = function () {\n  this.buffer = undefined\n}\n\nmodule.exports = Decoder\n","'use strict'\n\nmodule.exports = function basename (path) {\n  if (typeof path !== 'string') { return '' }\n  for (var i = path.length - 1; i >= 0; --i) { // eslint-disable-line no-var\n    switch (path.charCodeAt(i)) {\n      case 0x2F: // '/'\n      case 0x5C: // '\\'\n        path = path.slice(i + 1)\n        return (path === '..' || path === '.' ? '' : path)\n    }\n  }\n  return (path === '..' || path === '.' ? '' : path)\n}\n","'use strict'\n\n// Node has always utf-8\nconst utf8Decoder = new TextDecoder('utf-8')\nconst textDecoders = new Map([\n  ['utf-8', utf8Decoder],\n  ['utf8', utf8Decoder]\n])\n\nfunction getDecoder (charset) {\n  let lc\n  while (true) {\n    switch (charset) {\n      case 'utf-8':\n      case 'utf8':\n        return decoders.utf8\n      case 'latin1':\n      case 'ascii': // TODO: Make these a separate, strict decoder?\n      case 'us-ascii':\n      case 'iso-8859-1':\n      case 'iso8859-1':\n      case 'iso88591':\n      case 'iso_8859-1':\n      case 'windows-1252':\n      case 'iso_8859-1:1987':\n      case 'cp1252':\n      case 'x-cp1252':\n        return decoders.latin1\n      case 'utf16le':\n      case 'utf-16le':\n      case 'ucs2':\n      case 'ucs-2':\n        return decoders.utf16le\n      case 'base64':\n        return decoders.base64\n      default:\n        if (lc === undefined) {\n          lc = true\n          charset = charset.toLowerCase()\n          continue\n        }\n        return decoders.other.bind(charset)\n    }\n  }\n}\n\nconst decoders = {\n  utf8: (data, sourceEncoding) => {\n    if (data.length === 0) {\n      return ''\n    }\n    if (typeof data === 'string') {\n      data = Buffer.from(data, sourceEncoding)\n    }\n    return data.utf8Slice(0, data.length)\n  },\n\n  latin1: (data, sourceEncoding) => {\n    if (data.length === 0) {\n      return ''\n    }\n    if (typeof data === 'string') {\n      return data\n    }\n    return data.latin1Slice(0, data.length)\n  },\n\n  utf16le: (data, sourceEncoding) => {\n    if (data.length === 0) {\n      return ''\n    }\n    if (typeof data === 'string') {\n      data = Buffer.from(data, sourceEncoding)\n    }\n    return data.ucs2Slice(0, data.length)\n  },\n\n  base64: (data, sourceEncoding) => {\n    if (data.length === 0) {\n      return ''\n    }\n    if (typeof data === 'string') {\n      data = Buffer.from(data, sourceEncoding)\n    }\n    return data.base64Slice(0, data.length)\n  },\n\n  other: (data, sourceEncoding) => {\n    if (data.length === 0) {\n      return ''\n    }\n    if (typeof data === 'string') {\n      data = Buffer.from(data, sourceEncoding)\n    }\n\n    if (textDecoders.has(this.toString())) {\n      try {\n        return textDecoders.get(this).decode(data)\n      } catch {}\n    }\n    return typeof data === 'string'\n      ? data\n      : data.toString()\n  }\n}\n\nfunction decodeText (text, sourceEncoding, destEncoding) {\n  if (text) {\n    return getDecoder(destEncoding)(text, sourceEncoding)\n  }\n  return text\n}\n\nmodule.exports = decodeText\n","'use strict'\n\nmodule.exports = function getLimit (limits, name, defaultLimit) {\n  if (\n    !limits ||\n    limits[name] === undefined ||\n    limits[name] === null\n  ) { return defaultLimit }\n\n  if (\n    typeof limits[name] !== 'number' ||\n    isNaN(limits[name])\n  ) { throw new TypeError('Limit ' + name + ' is not a valid number') }\n\n  return limits[name]\n}\n","/* eslint-disable object-property-newline */\n'use strict'\n\nconst decodeText = require('./decodeText')\n\nconst RE_ENCODED = /%[a-fA-F0-9][a-fA-F0-9]/g\n\nconst EncodedLookup = {\n  '%00': '\\x00', '%01': '\\x01', '%02': '\\x02', '%03': '\\x03', '%04': '\\x04',\n  '%05': '\\x05', '%06': '\\x06', '%07': '\\x07', '%08': '\\x08', '%09': '\\x09',\n  '%0a': '\\x0a', '%0A': '\\x0a', '%0b': '\\x0b', '%0B': '\\x0b', '%0c': '\\x0c',\n  '%0C': '\\x0c', '%0d': '\\x0d', '%0D': '\\x0d', '%0e': '\\x0e', '%0E': '\\x0e',\n  '%0f': '\\x0f', '%0F': '\\x0f', '%10': '\\x10', '%11': '\\x11', '%12': '\\x12',\n  '%13': '\\x13', '%14': '\\x14', '%15': '\\x15', '%16': '\\x16', '%17': '\\x17',\n  '%18': '\\x18', '%19': '\\x19', '%1a': '\\x1a', '%1A': '\\x1a', '%1b': '\\x1b',\n  '%1B': '\\x1b', '%1c': '\\x1c', '%1C': '\\x1c', '%1d': '\\x1d', '%1D': '\\x1d',\n  '%1e': '\\x1e', '%1E': '\\x1e', '%1f': '\\x1f', '%1F': '\\x1f', '%20': '\\x20',\n  '%21': '\\x21', '%22': '\\x22', '%23': '\\x23', '%24': '\\x24', '%25': '\\x25',\n  '%26': '\\x26', '%27': '\\x27', '%28': '\\x28', '%29': '\\x29', '%2a': '\\x2a',\n  '%2A': '\\x2a', '%2b': '\\x2b', '%2B': '\\x2b', '%2c': '\\x2c', '%2C': '\\x2c',\n  '%2d': '\\x2d', '%2D': '\\x2d', '%2e': '\\x2e', '%2E': '\\x2e', '%2f': '\\x2f',\n  '%2F': '\\x2f', '%30': '\\x30', '%31': '\\x31', '%32': '\\x32', '%33': '\\x33',\n  '%34': '\\x34', '%35': '\\x35', '%36': '\\x36', '%37': '\\x37', '%38': '\\x38',\n  '%39': '\\x39', '%3a': '\\x3a', '%3A': '\\x3a', '%3b': '\\x3b', '%3B': '\\x3b',\n  '%3c': '\\x3c', '%3C': '\\x3c', '%3d': '\\x3d', '%3D': '\\x3d', '%3e': '\\x3e',\n  '%3E': '\\x3e', '%3f': '\\x3f', '%3F': '\\x3f', '%40': '\\x40', '%41': '\\x41',\n  '%42': '\\x42', '%43': '\\x43', '%44': '\\x44', '%45': '\\x45', '%46': '\\x46',\n  '%47': '\\x47', '%48': '\\x48', '%49': '\\x49', '%4a': '\\x4a', '%4A': '\\x4a',\n  '%4b': '\\x4b', '%4B': '\\x4b', '%4c': '\\x4c', '%4C': '\\x4c', '%4d': '\\x4d',\n  '%4D': '\\x4d', '%4e': '\\x4e', '%4E': '\\x4e', '%4f': '\\x4f', '%4F': '\\x4f',\n  '%50': '\\x50', '%51': '\\x51', '%52': '\\x52', '%53': '\\x53', '%54': '\\x54',\n  '%55': '\\x55', '%56': '\\x56', '%57': '\\x57', '%58': '\\x58', '%59': '\\x59',\n  '%5a': '\\x5a', '%5A': '\\x5a', '%5b': '\\x5b', '%5B': '\\x5b', '%5c': '\\x5c',\n  '%5C': '\\x5c', '%5d': '\\x5d', '%5D': '\\x5d', '%5e': '\\x5e', '%5E': '\\x5e',\n  '%5f': '\\x5f', '%5F': '\\x5f', '%60': '\\x60', '%61': '\\x61', '%62': '\\x62',\n  '%63': '\\x63', '%64': '\\x64', '%65': '\\x65', '%66': '\\x66', '%67': '\\x67',\n  '%68': '\\x68', '%69': '\\x69', '%6a': '\\x6a', '%6A': '\\x6a', '%6b': '\\x6b',\n  '%6B': '\\x6b', '%6c': '\\x6c', '%6C': '\\x6c', '%6d': '\\x6d', '%6D': '\\x6d',\n  '%6e': '\\x6e', '%6E': '\\x6e', '%6f': '\\x6f', '%6F': '\\x6f', '%70': '\\x70',\n  '%71': '\\x71', '%72': '\\x72', '%73': '\\x73', '%74': '\\x74', '%75': '\\x75',\n  '%76': '\\x76', '%77': '\\x77', '%78': '\\x78', '%79': '\\x79', '%7a': '\\x7a',\n  '%7A': '\\x7a', '%7b': '\\x7b', '%7B': '\\x7b', '%7c': '\\x7c', '%7C': '\\x7c',\n  '%7d': '\\x7d', '%7D': '\\x7d', '%7e': '\\x7e', '%7E': '\\x7e', '%7f': '\\x7f',\n  '%7F': '\\x7f', '%80': '\\x80', '%81': '\\x81', '%82': '\\x82', '%83': '\\x83',\n  '%84': '\\x84', '%85': '\\x85', '%86': '\\x86', '%87': '\\x87', '%88': '\\x88',\n  '%89': '\\x89', '%8a': '\\x8a', '%8A': '\\x8a', '%8b': '\\x8b', '%8B': '\\x8b',\n  '%8c': '\\x8c', '%8C': '\\x8c', '%8d': '\\x8d', '%8D': '\\x8d', '%8e': '\\x8e',\n  '%8E': '\\x8e', '%8f': '\\x8f', '%8F': '\\x8f', '%90': '\\x90', '%91': '\\x91',\n  '%92': '\\x92', '%93': '\\x93', '%94': '\\x94', '%95': '\\x95', '%96': '\\x96',\n  '%97': '\\x97', '%98': '\\x98', '%99': '\\x99', '%9a': '\\x9a', '%9A': '\\x9a',\n  '%9b': '\\x9b', '%9B': '\\x9b', '%9c': '\\x9c', '%9C': '\\x9c', '%9d': '\\x9d',\n  '%9D': '\\x9d', '%9e': '\\x9e', '%9E': '\\x9e', '%9f': '\\x9f', '%9F': '\\x9f',\n  '%a0': '\\xa0', '%A0': '\\xa0', '%a1': '\\xa1', '%A1': '\\xa1', '%a2': '\\xa2',\n  '%A2': '\\xa2', '%a3': '\\xa3', '%A3': '\\xa3', '%a4': '\\xa4', '%A4': '\\xa4',\n  '%a5': '\\xa5', '%A5': '\\xa5', '%a6': '\\xa6', '%A6': '\\xa6', '%a7': '\\xa7',\n  '%A7': '\\xa7', '%a8': '\\xa8', '%A8': '\\xa8', '%a9': '\\xa9', '%A9': '\\xa9',\n  '%aa': '\\xaa', '%Aa': '\\xaa', '%aA': '\\xaa', '%AA': '\\xaa', '%ab': '\\xab',\n  '%Ab': '\\xab', '%aB': '\\xab', '%AB': '\\xab', '%ac': '\\xac', '%Ac': '\\xac',\n  '%aC': '\\xac', '%AC': '\\xac', '%ad': '\\xad', '%Ad': '\\xad', '%aD': '\\xad',\n  '%AD': '\\xad', '%ae': '\\xae', '%Ae': '\\xae', '%aE': '\\xae', '%AE': '\\xae',\n  '%af': '\\xaf', '%Af': '\\xaf', '%aF': '\\xaf', '%AF': '\\xaf', '%b0': '\\xb0',\n  '%B0': '\\xb0', '%b1': '\\xb1', '%B1': '\\xb1', '%b2': '\\xb2', '%B2': '\\xb2',\n  '%b3': '\\xb3', '%B3': '\\xb3', '%b4': '\\xb4', '%B4': '\\xb4', '%b5': '\\xb5',\n  '%B5': '\\xb5', '%b6': '\\xb6', '%B6': '\\xb6', '%b7': '\\xb7', '%B7': '\\xb7',\n  '%b8': '\\xb8', '%B8': '\\xb8', '%b9': '\\xb9', '%B9': '\\xb9', '%ba': '\\xba',\n  '%Ba': '\\xba', '%bA': '\\xba', '%BA': '\\xba', '%bb': '\\xbb', '%Bb': '\\xbb',\n  '%bB': '\\xbb', '%BB': '\\xbb', '%bc': '\\xbc', '%Bc': '\\xbc', '%bC': '\\xbc',\n  '%BC': '\\xbc', '%bd': '\\xbd', '%Bd': '\\xbd', '%bD': '\\xbd', '%BD': '\\xbd',\n  '%be': '\\xbe', '%Be': '\\xbe', '%bE': '\\xbe', '%BE': '\\xbe', '%bf': '\\xbf',\n  '%Bf': '\\xbf', '%bF': '\\xbf', '%BF': '\\xbf', '%c0': '\\xc0', '%C0': '\\xc0',\n  '%c1': '\\xc1', '%C1': '\\xc1', '%c2': '\\xc2', '%C2': '\\xc2', '%c3': '\\xc3',\n  '%C3': '\\xc3', '%c4': '\\xc4', '%C4': '\\xc4', '%c5': '\\xc5', '%C5': '\\xc5',\n  '%c6': '\\xc6', '%C6': '\\xc6', '%c7': '\\xc7', '%C7': '\\xc7', '%c8': '\\xc8',\n  '%C8': '\\xc8', '%c9': '\\xc9', '%C9': '\\xc9', '%ca': '\\xca', '%Ca': '\\xca',\n  '%cA': '\\xca', '%CA': '\\xca', '%cb': '\\xcb', '%Cb': '\\xcb', '%cB': '\\xcb',\n  '%CB': '\\xcb', '%cc': '\\xcc', '%Cc': '\\xcc', '%cC': '\\xcc', '%CC': '\\xcc',\n  '%cd': '\\xcd', '%Cd': '\\xcd', '%cD': '\\xcd', '%CD': '\\xcd', '%ce': '\\xce',\n  '%Ce': '\\xce', '%cE': '\\xce', '%CE': '\\xce', '%cf': '\\xcf', '%Cf': '\\xcf',\n  '%cF': '\\xcf', '%CF': '\\xcf', '%d0': '\\xd0', '%D0': '\\xd0', '%d1': '\\xd1',\n  '%D1': '\\xd1', '%d2': '\\xd2', '%D2': '\\xd2', '%d3': '\\xd3', '%D3': '\\xd3',\n  '%d4': '\\xd4', '%D4': '\\xd4', '%d5': '\\xd5', '%D5': '\\xd5', '%d6': '\\xd6',\n  '%D6': '\\xd6', '%d7': '\\xd7', '%D7': '\\xd7', '%d8': '\\xd8', '%D8': '\\xd8',\n  '%d9': '\\xd9', '%D9': '\\xd9', '%da': '\\xda', '%Da': '\\xda', '%dA': '\\xda',\n  '%DA': '\\xda', '%db': '\\xdb', '%Db': '\\xdb', '%dB': '\\xdb', '%DB': '\\xdb',\n  '%dc': '\\xdc', '%Dc': '\\xdc', '%dC': '\\xdc', '%DC': '\\xdc', '%dd': '\\xdd',\n  '%Dd': '\\xdd', '%dD': '\\xdd', '%DD': '\\xdd', '%de': '\\xde', '%De': '\\xde',\n  '%dE': '\\xde', '%DE': '\\xde', '%df': '\\xdf', '%Df': '\\xdf', '%dF': '\\xdf',\n  '%DF': '\\xdf', '%e0': '\\xe0', '%E0': '\\xe0', '%e1': '\\xe1', '%E1': '\\xe1',\n  '%e2': '\\xe2', '%E2': '\\xe2', '%e3': '\\xe3', '%E3': '\\xe3', '%e4': '\\xe4',\n  '%E4': '\\xe4', '%e5': '\\xe5', '%E5': '\\xe5', '%e6': '\\xe6', '%E6': '\\xe6',\n  '%e7': '\\xe7', '%E7': '\\xe7', '%e8': '\\xe8', '%E8': '\\xe8', '%e9': '\\xe9',\n  '%E9': '\\xe9', '%ea': '\\xea', '%Ea': '\\xea', '%eA': '\\xea', '%EA': '\\xea',\n  '%eb': '\\xeb', '%Eb': '\\xeb', '%eB': '\\xeb', '%EB': '\\xeb', '%ec': '\\xec',\n  '%Ec': '\\xec', '%eC': '\\xec', '%EC': '\\xec', '%ed': '\\xed', '%Ed': '\\xed',\n  '%eD': '\\xed', '%ED': '\\xed', '%ee': '\\xee', '%Ee': '\\xee', '%eE': '\\xee',\n  '%EE': '\\xee', '%ef': '\\xef', '%Ef': '\\xef', '%eF': '\\xef', '%EF': '\\xef',\n  '%f0': '\\xf0', '%F0': '\\xf0', '%f1': '\\xf1', '%F1': '\\xf1', '%f2': '\\xf2',\n  '%F2': '\\xf2', '%f3': '\\xf3', '%F3': '\\xf3', '%f4': '\\xf4', '%F4': '\\xf4',\n  '%f5': '\\xf5', '%F5': '\\xf5', '%f6': '\\xf6', '%F6': '\\xf6', '%f7': '\\xf7',\n  '%F7': '\\xf7', '%f8': '\\xf8', '%F8': '\\xf8', '%f9': '\\xf9', '%F9': '\\xf9',\n  '%fa': '\\xfa', '%Fa': '\\xfa', '%fA': '\\xfa', '%FA': '\\xfa', '%fb': '\\xfb',\n  '%Fb': '\\xfb', '%fB': '\\xfb', '%FB': '\\xfb', '%fc': '\\xfc', '%Fc': '\\xfc',\n  '%fC': '\\xfc', '%FC': '\\xfc', '%fd': '\\xfd', '%Fd': '\\xfd', '%fD': '\\xfd',\n  '%FD': '\\xfd', '%fe': '\\xfe', '%Fe': '\\xfe', '%fE': '\\xfe', '%FE': '\\xfe',\n  '%ff': '\\xff', '%Ff': '\\xff', '%fF': '\\xff', '%FF': '\\xff'\n}\n\nfunction encodedReplacer (match) {\n  return EncodedLookup[match]\n}\n\nconst STATE_KEY = 0\nconst STATE_VALUE = 1\nconst STATE_CHARSET = 2\nconst STATE_LANG = 3\n\nfunction parseParams (str) {\n  const res = []\n  let state = STATE_KEY\n  let charset = ''\n  let inquote = false\n  let escaping = false\n  let p = 0\n  let tmp = ''\n  const len = str.length\n\n  for (var i = 0; i < len; ++i) { // eslint-disable-line no-var\n    const char = str[i]\n    if (char === '\\\\' && inquote) {\n      if (escaping) { escaping = false } else {\n        escaping = true\n        continue\n      }\n    } else if (char === '\"') {\n      if (!escaping) {\n        if (inquote) {\n          inquote = false\n          state = STATE_KEY\n        } else { inquote = true }\n        continue\n      } else { escaping = false }\n    } else {\n      if (escaping && inquote) { tmp += '\\\\' }\n      escaping = false\n      if ((state === STATE_CHARSET || state === STATE_LANG) && char === \"'\") {\n        if (state === STATE_CHARSET) {\n          state = STATE_LANG\n          charset = tmp.substring(1)\n        } else { state = STATE_VALUE }\n        tmp = ''\n        continue\n      } else if (state === STATE_KEY &&\n        (char === '*' || char === '=') &&\n        res.length) {\n        state = char === '*'\n          ? STATE_CHARSET\n          : STATE_VALUE\n        res[p] = [tmp, undefined]\n        tmp = ''\n        continue\n      } else if (!inquote && char === ';') {\n        state = STATE_KEY\n        if (charset) {\n          if (tmp.length) {\n            tmp = decodeText(tmp.replace(RE_ENCODED, encodedReplacer),\n              'binary',\n              charset)\n          }\n          charset = ''\n        } else if (tmp.length) {\n          tmp = decodeText(tmp, 'binary', 'utf8')\n        }\n        if (res[p] === undefined) { res[p] = tmp } else { res[p][1] = tmp }\n        tmp = ''\n        ++p\n        continue\n      } else if (!inquote && (char === ' ' || char === '\\t')) { continue }\n    }\n    tmp += char\n  }\n  if (charset && tmp.length) {\n    tmp = decodeText(tmp.replace(RE_ENCODED, encodedReplacer),\n      'binary',\n      charset)\n  } else if (tmp) {\n    tmp = decodeText(tmp, 'binary', 'utf8')\n  }\n\n  if (res[p] === undefined) {\n    if (tmp) { res[p] = tmp }\n  } else { res[p][1] = tmp }\n\n  return res\n}\n\nmodule.exports = parseParams\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar Scalar = require('../nodes/Scalar.js');\nvar YAMLMap = require('../nodes/YAMLMap.js');\nvar YAMLSeq = require('../nodes/YAMLSeq.js');\nvar resolveBlockMap = require('./resolve-block-map.js');\nvar resolveBlockSeq = require('./resolve-block-seq.js');\nvar resolveFlowCollection = require('./resolve-flow-collection.js');\n\nfunction resolveCollection(CN, ctx, token, onError, tagName, tag) {\n    const coll = token.type === 'block-map'\n        ? resolveBlockMap.resolveBlockMap(CN, ctx, token, onError, tag)\n        : token.type === 'block-seq'\n            ? resolveBlockSeq.resolveBlockSeq(CN, ctx, token, onError, tag)\n            : resolveFlowCollection.resolveFlowCollection(CN, ctx, token, onError, tag);\n    const Coll = coll.constructor;\n    // If we got a tagName matching the class, or the tag name is '!',\n    // then use the tagName from the node class used to create it.\n    if (tagName === '!' || tagName === Coll.tagName) {\n        coll.tag = Coll.tagName;\n        return coll;\n    }\n    if (tagName)\n        coll.tag = tagName;\n    return coll;\n}\nfunction composeCollection(CN, ctx, token, tagToken, onError) {\n    const tagName = !tagToken\n        ? null\n        : ctx.directives.tagName(tagToken.source, msg => onError(tagToken, 'TAG_RESOLVE_FAILED', msg));\n    const expType = token.type === 'block-map'\n        ? 'map'\n        : token.type === 'block-seq'\n            ? 'seq'\n            : token.start.source === '{'\n                ? 'map'\n                : 'seq';\n    // shortcut: check if it's a generic YAMLMap or YAMLSeq\n    // before jumping into the custom tag logic.\n    if (!tagToken ||\n        !tagName ||\n        tagName === '!' ||\n        (tagName === YAMLMap.YAMLMap.tagName && expType === 'map') ||\n        (tagName === YAMLSeq.YAMLSeq.tagName && expType === 'seq') ||\n        !expType) {\n        return resolveCollection(CN, ctx, token, onError, tagName);\n    }\n    let tag = ctx.schema.tags.find(t => t.tag === tagName && t.collection === expType);\n    if (!tag) {\n        const kt = ctx.schema.knownTags[tagName];\n        if (kt && kt.collection === expType) {\n            ctx.schema.tags.push(Object.assign({}, kt, { default: false }));\n            tag = kt;\n        }\n        else {\n            if (kt?.collection) {\n                onError(tagToken, 'BAD_COLLECTION_TYPE', `${kt.tag} used for ${expType} collection, but expects ${kt.collection}`, true);\n            }\n            else {\n                onError(tagToken, 'TAG_RESOLVE_FAILED', `Unresolved tag: ${tagName}`, true);\n            }\n            return resolveCollection(CN, ctx, token, onError, tagName);\n        }\n    }\n    const coll = resolveCollection(CN, ctx, token, onError, tagName, tag);\n    const res = tag.resolve?.(coll, msg => onError(tagToken, 'TAG_RESOLVE_FAILED', msg), ctx.options) ?? coll;\n    const node = identity.isNode(res)\n        ? res\n        : new Scalar.Scalar(res);\n    node.range = coll.range;\n    node.tag = tagName;\n    if (tag?.format)\n        node.format = tag.format;\n    return node;\n}\n\nexports.composeCollection = composeCollection;\n","'use strict';\n\nvar Document = require('../doc/Document.js');\nvar composeNode = require('./compose-node.js');\nvar resolveEnd = require('./resolve-end.js');\nvar resolveProps = require('./resolve-props.js');\n\nfunction composeDoc(options, directives, { offset, start, value, end }, onError) {\n    const opts = Object.assign({ _directives: directives }, options);\n    const doc = new Document.Document(undefined, opts);\n    const ctx = {\n        atRoot: true,\n        directives: doc.directives,\n        options: doc.options,\n        schema: doc.schema\n    };\n    const props = resolveProps.resolveProps(start, {\n        indicator: 'doc-start',\n        next: value ?? end?.[0],\n        offset,\n        onError,\n        startOnNewline: true\n    });\n    if (props.found) {\n        doc.directives.docStart = true;\n        if (value &&\n            (value.type === 'block-map' || value.type === 'block-seq') &&\n            !props.hasNewline)\n            onError(props.end, 'MISSING_CHAR', 'Block collection cannot start on same line with directives-end marker');\n    }\n    // @ts-expect-error If Contents is set, let's trust the user\n    doc.contents = value\n        ? composeNode.composeNode(ctx, value, props, onError)\n        : composeNode.composeEmptyNode(ctx, props.end, start, null, props, onError);\n    const contentEnd = doc.contents.range[2];\n    const re = resolveEnd.resolveEnd(end, contentEnd, false, onError);\n    if (re.comment)\n        doc.comment = re.comment;\n    doc.range = [offset, contentEnd, re.offset];\n    return doc;\n}\n\nexports.composeDoc = composeDoc;\n","'use strict';\n\nvar Alias = require('../nodes/Alias.js');\nvar composeCollection = require('./compose-collection.js');\nvar composeScalar = require('./compose-scalar.js');\nvar resolveEnd = require('./resolve-end.js');\nvar utilEmptyScalarPosition = require('./util-empty-scalar-position.js');\n\nconst CN = { composeNode, composeEmptyNode };\nfunction composeNode(ctx, token, props, onError) {\n    const { spaceBefore, comment, anchor, tag } = props;\n    let node;\n    let isSrcToken = true;\n    switch (token.type) {\n        case 'alias':\n            node = composeAlias(ctx, token, onError);\n            if (anchor || tag)\n                onError(token, 'ALIAS_PROPS', 'An alias node must not specify any properties');\n            break;\n        case 'scalar':\n        case 'single-quoted-scalar':\n        case 'double-quoted-scalar':\n        case 'block-scalar':\n            node = composeScalar.composeScalar(ctx, token, tag, onError);\n            if (anchor)\n                node.anchor = anchor.source.substring(1);\n            break;\n        case 'block-map':\n        case 'block-seq':\n        case 'flow-collection':\n            node = composeCollection.composeCollection(CN, ctx, token, tag, onError);\n            if (anchor)\n                node.anchor = anchor.source.substring(1);\n            break;\n        default: {\n            const message = token.type === 'error'\n                ? token.message\n                : `Unsupported token (type: ${token.type})`;\n            onError(token, 'UNEXPECTED_TOKEN', message);\n            node = composeEmptyNode(ctx, token.offset, undefined, null, props, onError);\n            isSrcToken = false;\n        }\n    }\n    if (anchor && node.anchor === '')\n        onError(anchor, 'BAD_ALIAS', 'Anchor cannot be an empty string');\n    if (spaceBefore)\n        node.spaceBefore = true;\n    if (comment) {\n        if (token.type === 'scalar' && token.source === '')\n            node.comment = comment;\n        else\n            node.commentBefore = comment;\n    }\n    // @ts-expect-error Type checking misses meaning of isSrcToken\n    if (ctx.options.keepSourceTokens && isSrcToken)\n        node.srcToken = token;\n    return node;\n}\nfunction composeEmptyNode(ctx, offset, before, pos, { spaceBefore, comment, anchor, tag, end }, onError) {\n    const token = {\n        type: 'scalar',\n        offset: utilEmptyScalarPosition.emptyScalarPosition(offset, before, pos),\n        indent: -1,\n        source: ''\n    };\n    const node = composeScalar.composeScalar(ctx, token, tag, onError);\n    if (anchor) {\n        node.anchor = anchor.source.substring(1);\n        if (node.anchor === '')\n            onError(anchor, 'BAD_ALIAS', 'Anchor cannot be an empty string');\n    }\n    if (spaceBefore)\n        node.spaceBefore = true;\n    if (comment) {\n        node.comment = comment;\n        node.range[2] = end;\n    }\n    return node;\n}\nfunction composeAlias({ options }, { offset, source, end }, onError) {\n    const alias = new Alias.Alias(source.substring(1));\n    if (alias.source === '')\n        onError(offset, 'BAD_ALIAS', 'Alias cannot be an empty string');\n    if (alias.source.endsWith(':'))\n        onError(offset + source.length - 1, 'BAD_ALIAS', 'Alias ending in : is ambiguous', true);\n    const valueEnd = offset + source.length;\n    const re = resolveEnd.resolveEnd(end, valueEnd, options.strict, onError);\n    alias.range = [offset, valueEnd, re.offset];\n    if (re.comment)\n        alias.comment = re.comment;\n    return alias;\n}\n\nexports.composeEmptyNode = composeEmptyNode;\nexports.composeNode = composeNode;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar Scalar = require('../nodes/Scalar.js');\nvar resolveBlockScalar = require('./resolve-block-scalar.js');\nvar resolveFlowScalar = require('./resolve-flow-scalar.js');\n\nfunction composeScalar(ctx, token, tagToken, onError) {\n    const { value, type, comment, range } = token.type === 'block-scalar'\n        ? resolveBlockScalar.resolveBlockScalar(token, ctx.options.strict, onError)\n        : resolveFlowScalar.resolveFlowScalar(token, ctx.options.strict, onError);\n    const tagName = tagToken\n        ? ctx.directives.tagName(tagToken.source, msg => onError(tagToken, 'TAG_RESOLVE_FAILED', msg))\n        : null;\n    const tag = tagToken && tagName\n        ? findScalarTagByName(ctx.schema, value, tagName, tagToken, onError)\n        : token.type === 'scalar'\n            ? findScalarTagByTest(ctx, value, token, onError)\n            : ctx.schema[identity.SCALAR];\n    let scalar;\n    try {\n        const res = tag.resolve(value, msg => onError(tagToken ?? token, 'TAG_RESOLVE_FAILED', msg), ctx.options);\n        scalar = identity.isScalar(res) ? res : new Scalar.Scalar(res);\n    }\n    catch (error) {\n        const msg = error instanceof Error ? error.message : String(error);\n        onError(tagToken ?? token, 'TAG_RESOLVE_FAILED', msg);\n        scalar = new Scalar.Scalar(value);\n    }\n    scalar.range = range;\n    scalar.source = value;\n    if (type)\n        scalar.type = type;\n    if (tagName)\n        scalar.tag = tagName;\n    if (tag.format)\n        scalar.format = tag.format;\n    if (comment)\n        scalar.comment = comment;\n    return scalar;\n}\nfunction findScalarTagByName(schema, value, tagName, tagToken, onError) {\n    if (tagName === '!')\n        return schema[identity.SCALAR]; // non-specific tag\n    const matchWithTest = [];\n    for (const tag of schema.tags) {\n        if (!tag.collection && tag.tag === tagName) {\n            if (tag.default && tag.test)\n                matchWithTest.push(tag);\n            else\n                return tag;\n        }\n    }\n    for (const tag of matchWithTest)\n        if (tag.test?.test(value))\n            return tag;\n    const kt = schema.knownTags[tagName];\n    if (kt && !kt.collection) {\n        // Ensure that the known tag is available for stringifying,\n        // but does not get used by default.\n        schema.tags.push(Object.assign({}, kt, { default: false, test: undefined }));\n        return kt;\n    }\n    onError(tagToken, 'TAG_RESOLVE_FAILED', `Unresolved tag: ${tagName}`, tagName !== 'tag:yaml.org,2002:str');\n    return schema[identity.SCALAR];\n}\nfunction findScalarTagByTest({ directives, schema }, value, token, onError) {\n    const tag = schema.tags.find(tag => tag.default && tag.test?.test(value)) || schema[identity.SCALAR];\n    if (schema.compat) {\n        const compat = schema.compat.find(tag => tag.default && tag.test?.test(value)) ??\n            schema[identity.SCALAR];\n        if (tag.tag !== compat.tag) {\n            const ts = directives.tagString(tag.tag);\n            const cs = directives.tagString(compat.tag);\n            const msg = `Value may be parsed as either ${ts} or ${cs}`;\n            onError(token, 'TAG_RESOLVE_FAILED', msg, true);\n        }\n    }\n    return tag;\n}\n\nexports.composeScalar = composeScalar;\n","'use strict';\n\nvar directives = require('../doc/directives.js');\nvar Document = require('../doc/Document.js');\nvar errors = require('../errors.js');\nvar identity = require('../nodes/identity.js');\nvar composeDoc = require('./compose-doc.js');\nvar resolveEnd = require('./resolve-end.js');\n\nfunction getErrorPos(src) {\n    if (typeof src === 'number')\n        return [src, src + 1];\n    if (Array.isArray(src))\n        return src.length === 2 ? src : [src[0], src[1]];\n    const { offset, source } = src;\n    return [offset, offset + (typeof source === 'string' ? source.length : 1)];\n}\nfunction parsePrelude(prelude) {\n    let comment = '';\n    let atComment = false;\n    let afterEmptyLine = false;\n    for (let i = 0; i < prelude.length; ++i) {\n        const source = prelude[i];\n        switch (source[0]) {\n            case '#':\n                comment +=\n                    (comment === '' ? '' : afterEmptyLine ? '\\n\\n' : '\\n') +\n                        (source.substring(1) || ' ');\n                atComment = true;\n                afterEmptyLine = false;\n                break;\n            case '%':\n                if (prelude[i + 1]?.[0] !== '#')\n                    i += 1;\n                atComment = false;\n                break;\n            default:\n                // This may be wrong after doc-end, but in that case it doesn't matter\n                if (!atComment)\n                    afterEmptyLine = true;\n                atComment = false;\n        }\n    }\n    return { comment, afterEmptyLine };\n}\n/**\n * Compose a stream of CST nodes into a stream of YAML Documents.\n *\n * ```ts\n * import { Composer, Parser } from 'yaml'\n *\n * const src: string = ...\n * const tokens = new Parser().parse(src)\n * const docs = new Composer().compose(tokens)\n * ```\n */\nclass Composer {\n    constructor(options = {}) {\n        this.doc = null;\n        this.atDirectives = false;\n        this.prelude = [];\n        this.errors = [];\n        this.warnings = [];\n        this.onError = (source, code, message, warning) => {\n            const pos = getErrorPos(source);\n            if (warning)\n                this.warnings.push(new errors.YAMLWarning(pos, code, message));\n            else\n                this.errors.push(new errors.YAMLParseError(pos, code, message));\n        };\n        // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing\n        this.directives = new directives.Directives({ version: options.version || '1.2' });\n        this.options = options;\n    }\n    decorate(doc, afterDoc) {\n        const { comment, afterEmptyLine } = parsePrelude(this.prelude);\n        //console.log({ dc: doc.comment, prelude, comment })\n        if (comment) {\n            const dc = doc.contents;\n            if (afterDoc) {\n                doc.comment = doc.comment ? `${doc.comment}\\n${comment}` : comment;\n            }\n            else if (afterEmptyLine || doc.directives.docStart || !dc) {\n                doc.commentBefore = comment;\n            }\n            else if (identity.isCollection(dc) && !dc.flow && dc.items.length > 0) {\n                let it = dc.items[0];\n                if (identity.isPair(it))\n                    it = it.key;\n                const cb = it.commentBefore;\n                it.commentBefore = cb ? `${comment}\\n${cb}` : comment;\n            }\n            else {\n                const cb = dc.commentBefore;\n                dc.commentBefore = cb ? `${comment}\\n${cb}` : comment;\n            }\n        }\n        if (afterDoc) {\n            Array.prototype.push.apply(doc.errors, this.errors);\n            Array.prototype.push.apply(doc.warnings, this.warnings);\n        }\n        else {\n            doc.errors = this.errors;\n            doc.warnings = this.warnings;\n        }\n        this.prelude = [];\n        this.errors = [];\n        this.warnings = [];\n    }\n    /**\n     * Current stream status information.\n     *\n     * Mostly useful at the end of input for an empty stream.\n     */\n    streamInfo() {\n        return {\n            comment: parsePrelude(this.prelude).comment,\n            directives: this.directives,\n            errors: this.errors,\n            warnings: this.warnings\n        };\n    }\n    /**\n     * Compose tokens into documents.\n     *\n     * @param forceDoc - If the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document.\n     * @param endOffset - Should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.\n     */\n    *compose(tokens, forceDoc = false, endOffset = -1) {\n        for (const token of tokens)\n            yield* this.next(token);\n        yield* this.end(forceDoc, endOffset);\n    }\n    /** Advance the composer by one CST token. */\n    *next(token) {\n        if (process.env.LOG_STREAM)\n            console.dir(token, { depth: null });\n        switch (token.type) {\n            case 'directive':\n                this.directives.add(token.source, (offset, message, warning) => {\n                    const pos = getErrorPos(token);\n                    pos[0] += offset;\n                    this.onError(pos, 'BAD_DIRECTIVE', message, warning);\n                });\n                this.prelude.push(token.source);\n                this.atDirectives = true;\n                break;\n            case 'document': {\n                const doc = composeDoc.composeDoc(this.options, this.directives, token, this.onError);\n                if (this.atDirectives && !doc.directives.docStart)\n                    this.onError(token, 'MISSING_CHAR', 'Missing directives-end/doc-start indicator line');\n                this.decorate(doc, false);\n                if (this.doc)\n                    yield this.doc;\n                this.doc = doc;\n                this.atDirectives = false;\n                break;\n            }\n            case 'byte-order-mark':\n            case 'space':\n                break;\n            case 'comment':\n            case 'newline':\n                this.prelude.push(token.source);\n                break;\n            case 'error': {\n                const msg = token.source\n                    ? `${token.message}: ${JSON.stringify(token.source)}`\n                    : token.message;\n                const error = new errors.YAMLParseError(getErrorPos(token), 'UNEXPECTED_TOKEN', msg);\n                if (this.atDirectives || !this.doc)\n                    this.errors.push(error);\n                else\n                    this.doc.errors.push(error);\n                break;\n            }\n            case 'doc-end': {\n                if (!this.doc) {\n                    const msg = 'Unexpected doc-end without preceding document';\n                    this.errors.push(new errors.YAMLParseError(getErrorPos(token), 'UNEXPECTED_TOKEN', msg));\n                    break;\n                }\n                this.doc.directives.docEnd = true;\n                const end = resolveEnd.resolveEnd(token.end, token.offset + token.source.length, this.doc.options.strict, this.onError);\n                this.decorate(this.doc, true);\n                if (end.comment) {\n                    const dc = this.doc.comment;\n                    this.doc.comment = dc ? `${dc}\\n${end.comment}` : end.comment;\n                }\n                this.doc.range[2] = end.offset;\n                break;\n            }\n            default:\n                this.errors.push(new errors.YAMLParseError(getErrorPos(token), 'UNEXPECTED_TOKEN', `Unsupported token ${token.type}`));\n        }\n    }\n    /**\n     * Call at end of input to yield any remaining document.\n     *\n     * @param forceDoc - If the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document.\n     * @param endOffset - Should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.\n     */\n    *end(forceDoc = false, endOffset = -1) {\n        if (this.doc) {\n            this.decorate(this.doc, true);\n            yield this.doc;\n            this.doc = null;\n        }\n        else if (forceDoc) {\n            const opts = Object.assign({ _directives: this.directives }, this.options);\n            const doc = new Document.Document(undefined, opts);\n            if (this.atDirectives)\n                this.onError(endOffset, 'MISSING_CHAR', 'Missing directives-end indicator line');\n            doc.range = [0, endOffset, endOffset];\n            this.decorate(doc, false);\n            yield doc;\n        }\n    }\n}\n\nexports.Composer = Composer;\n","'use strict';\n\nvar Pair = require('../nodes/Pair.js');\nvar YAMLMap = require('../nodes/YAMLMap.js');\nvar resolveProps = require('./resolve-props.js');\nvar utilContainsNewline = require('./util-contains-newline.js');\nvar utilFlowIndentCheck = require('./util-flow-indent-check.js');\nvar utilMapIncludes = require('./util-map-includes.js');\n\nconst startColMsg = 'All mapping items must start at the same column';\nfunction resolveBlockMap({ composeNode, composeEmptyNode }, ctx, bm, onError, tag) {\n    const NodeClass = tag?.nodeClass ?? YAMLMap.YAMLMap;\n    const map = new NodeClass(ctx.schema);\n    if (ctx.atRoot)\n        ctx.atRoot = false;\n    let offset = bm.offset;\n    let commentEnd = null;\n    for (const collItem of bm.items) {\n        const { start, key, sep, value } = collItem;\n        // key properties\n        const keyProps = resolveProps.resolveProps(start, {\n            indicator: 'explicit-key-ind',\n            next: key ?? sep?.[0],\n            offset,\n            onError,\n            startOnNewline: true\n        });\n        const implicitKey = !keyProps.found;\n        if (implicitKey) {\n            if (key) {\n                if (key.type === 'block-seq')\n                    onError(offset, 'BLOCK_AS_IMPLICIT_KEY', 'A block sequence may not be used as an implicit map key');\n                else if ('indent' in key && key.indent !== bm.indent)\n                    onError(offset, 'BAD_INDENT', startColMsg);\n            }\n            if (!keyProps.anchor && !keyProps.tag && !sep) {\n                commentEnd = keyProps.end;\n                if (keyProps.comment) {\n                    if (map.comment)\n                        map.comment += '\\n' + keyProps.comment;\n                    else\n                        map.comment = keyProps.comment;\n                }\n                continue;\n            }\n            if (keyProps.hasNewlineAfterProp || utilContainsNewline.containsNewline(key)) {\n                onError(key ?? start[start.length - 1], 'MULTILINE_IMPLICIT_KEY', 'Implicit keys need to be on a single line');\n            }\n        }\n        else if (keyProps.found?.indent !== bm.indent) {\n            onError(offset, 'BAD_INDENT', startColMsg);\n        }\n        // key value\n        const keyStart = keyProps.end;\n        const keyNode = key\n            ? composeNode(ctx, key, keyProps, onError)\n            : composeEmptyNode(ctx, keyStart, start, null, keyProps, onError);\n        if (ctx.schema.compat)\n            utilFlowIndentCheck.flowIndentCheck(bm.indent, key, onError);\n        if (utilMapIncludes.mapIncludes(ctx, map.items, keyNode))\n            onError(keyStart, 'DUPLICATE_KEY', 'Map keys must be unique');\n        // value properties\n        const valueProps = resolveProps.resolveProps(sep ?? [], {\n            indicator: 'map-value-ind',\n            next: value,\n            offset: keyNode.range[2],\n            onError,\n            startOnNewline: !key || key.type === 'block-scalar'\n        });\n        offset = valueProps.end;\n        if (valueProps.found) {\n            if (implicitKey) {\n                if (value?.type === 'block-map' && !valueProps.hasNewline)\n                    onError(offset, 'BLOCK_AS_IMPLICIT_KEY', 'Nested mappings are not allowed in compact mappings');\n                if (ctx.options.strict &&\n                    keyProps.start < valueProps.found.offset - 1024)\n                    onError(keyNode.range, 'KEY_OVER_1024_CHARS', 'The : indicator must be at most 1024 chars after the start of an implicit block mapping key');\n            }\n            // value value\n            const valueNode = value\n                ? composeNode(ctx, value, valueProps, onError)\n                : composeEmptyNode(ctx, offset, sep, null, valueProps, onError);\n            if (ctx.schema.compat)\n                utilFlowIndentCheck.flowIndentCheck(bm.indent, value, onError);\n            offset = valueNode.range[2];\n            const pair = new Pair.Pair(keyNode, valueNode);\n            if (ctx.options.keepSourceTokens)\n                pair.srcToken = collItem;\n            map.items.push(pair);\n        }\n        else {\n            // key with no value\n            if (implicitKey)\n                onError(keyNode.range, 'MISSING_CHAR', 'Implicit map keys need to be followed by map values');\n            if (valueProps.comment) {\n                if (keyNode.comment)\n                    keyNode.comment += '\\n' + valueProps.comment;\n                else\n                    keyNode.comment = valueProps.comment;\n            }\n            const pair = new Pair.Pair(keyNode);\n            if (ctx.options.keepSourceTokens)\n                pair.srcToken = collItem;\n            map.items.push(pair);\n        }\n    }\n    if (commentEnd && commentEnd < offset)\n        onError(commentEnd, 'IMPOSSIBLE', 'Map comment with trailing content');\n    map.range = [bm.offset, offset, commentEnd ?? offset];\n    return map;\n}\n\nexports.resolveBlockMap = resolveBlockMap;\n","'use strict';\n\nvar Scalar = require('../nodes/Scalar.js');\n\nfunction resolveBlockScalar(scalar, strict, onError) {\n    const start = scalar.offset;\n    const header = parseBlockScalarHeader(scalar, strict, onError);\n    if (!header)\n        return { value: '', type: null, comment: '', range: [start, start, start] };\n    const type = header.mode === '>' ? Scalar.Scalar.BLOCK_FOLDED : Scalar.Scalar.BLOCK_LITERAL;\n    const lines = scalar.source ? splitLines(scalar.source) : [];\n    // determine the end of content & start of chomping\n    let chompStart = lines.length;\n    for (let i = lines.length - 1; i >= 0; --i) {\n        const content = lines[i][1];\n        if (content === '' || content === '\\r')\n            chompStart = i;\n        else\n            break;\n    }\n    // shortcut for empty contents\n    if (chompStart === 0) {\n        const value = header.chomp === '+' && lines.length > 0\n            ? '\\n'.repeat(Math.max(1, lines.length - 1))\n            : '';\n        let end = start + header.length;\n        if (scalar.source)\n            end += scalar.source.length;\n        return { value, type, comment: header.comment, range: [start, end, end] };\n    }\n    // find the indentation level to trim from start\n    let trimIndent = scalar.indent + header.indent;\n    let offset = scalar.offset + header.length;\n    let contentStart = 0;\n    for (let i = 0; i < chompStart; ++i) {\n        const [indent, content] = lines[i];\n        if (content === '' || content === '\\r') {\n            if (header.indent === 0 && indent.length > trimIndent)\n                trimIndent = indent.length;\n        }\n        else {\n            if (indent.length < trimIndent) {\n                const message = 'Block scalars with more-indented leading empty lines must use an explicit indentation indicator';\n                onError(offset + indent.length, 'MISSING_CHAR', message);\n            }\n            if (header.indent === 0)\n                trimIndent = indent.length;\n            contentStart = i;\n            break;\n        }\n        offset += indent.length + content.length + 1;\n    }\n    // include trailing more-indented empty lines in content\n    for (let i = lines.length - 1; i >= chompStart; --i) {\n        if (lines[i][0].length > trimIndent)\n            chompStart = i + 1;\n    }\n    let value = '';\n    let sep = '';\n    let prevMoreIndented = false;\n    // leading whitespace is kept intact\n    for (let i = 0; i < contentStart; ++i)\n        value += lines[i][0].slice(trimIndent) + '\\n';\n    for (let i = contentStart; i < chompStart; ++i) {\n        let [indent, content] = lines[i];\n        offset += indent.length + content.length + 1;\n        const crlf = content[content.length - 1] === '\\r';\n        if (crlf)\n            content = content.slice(0, -1);\n        /* istanbul ignore if already caught in lexer */\n        if (content && indent.length < trimIndent) {\n            const src = header.indent\n                ? 'explicit indentation indicator'\n                : 'first line';\n            const message = `Block scalar lines must not be less indented than their ${src}`;\n            onError(offset - content.length - (crlf ? 2 : 1), 'BAD_INDENT', message);\n            indent = '';\n        }\n        if (type === Scalar.Scalar.BLOCK_LITERAL) {\n            value += sep + indent.slice(trimIndent) + content;\n            sep = '\\n';\n        }\n        else if (indent.length > trimIndent || content[0] === '\\t') {\n            // more-indented content within a folded block\n            if (sep === ' ')\n                sep = '\\n';\n            else if (!prevMoreIndented && sep === '\\n')\n                sep = '\\n\\n';\n            value += sep + indent.slice(trimIndent) + content;\n            sep = '\\n';\n            prevMoreIndented = true;\n        }\n        else if (content === '') {\n            // empty line\n            if (sep === '\\n')\n                value += '\\n';\n            else\n                sep = '\\n';\n        }\n        else {\n            value += sep + content;\n            sep = ' ';\n            prevMoreIndented = false;\n        }\n    }\n    switch (header.chomp) {\n        case '-':\n            break;\n        case '+':\n            for (let i = chompStart; i < lines.length; ++i)\n                value += '\\n' + lines[i][0].slice(trimIndent);\n            if (value[value.length - 1] !== '\\n')\n                value += '\\n';\n            break;\n        default:\n            value += '\\n';\n    }\n    const end = start + header.length + scalar.source.length;\n    return { value, type, comment: header.comment, range: [start, end, end] };\n}\nfunction parseBlockScalarHeader({ offset, props }, strict, onError) {\n    /* istanbul ignore if should not happen */\n    if (props[0].type !== 'block-scalar-header') {\n        onError(props[0], 'IMPOSSIBLE', 'Block scalar header not found');\n        return null;\n    }\n    const { source } = props[0];\n    const mode = source[0];\n    let indent = 0;\n    let chomp = '';\n    let error = -1;\n    for (let i = 1; i < source.length; ++i) {\n        const ch = source[i];\n        if (!chomp && (ch === '-' || ch === '+'))\n            chomp = ch;\n        else {\n            const n = Number(ch);\n            if (!indent && n)\n                indent = n;\n            else if (error === -1)\n                error = offset + i;\n        }\n    }\n    if (error !== -1)\n        onError(error, 'UNEXPECTED_TOKEN', `Block scalar header includes extra characters: ${source}`);\n    let hasSpace = false;\n    let comment = '';\n    let length = source.length;\n    for (let i = 1; i < props.length; ++i) {\n        const token = props[i];\n        switch (token.type) {\n            case 'space':\n                hasSpace = true;\n            // fallthrough\n            case 'newline':\n                length += token.source.length;\n                break;\n            case 'comment':\n                if (strict && !hasSpace) {\n                    const message = 'Comments must be separated from other tokens by white space characters';\n                    onError(token, 'MISSING_CHAR', message);\n                }\n                length += token.source.length;\n                comment = token.source.substring(1);\n                break;\n            case 'error':\n                onError(token, 'UNEXPECTED_TOKEN', token.message);\n                length += token.source.length;\n                break;\n            /* istanbul ignore next should not happen */\n            default: {\n                const message = `Unexpected token in block scalar header: ${token.type}`;\n                onError(token, 'UNEXPECTED_TOKEN', message);\n                const ts = token.source;\n                if (ts && typeof ts === 'string')\n                    length += ts.length;\n            }\n        }\n    }\n    return { mode, indent, chomp, comment, length };\n}\n/** @returns Array of lines split up as `[indent, content]` */\nfunction splitLines(source) {\n    const split = source.split(/\\n( *)/);\n    const first = split[0];\n    const m = first.match(/^( *)/);\n    const line0 = m?.[1]\n        ? [m[1], first.slice(m[1].length)]\n        : ['', first];\n    const lines = [line0];\n    for (let i = 1; i < split.length; i += 2)\n        lines.push([split[i], split[i + 1]]);\n    return lines;\n}\n\nexports.resolveBlockScalar = resolveBlockScalar;\n","'use strict';\n\nvar YAMLSeq = require('../nodes/YAMLSeq.js');\nvar resolveProps = require('./resolve-props.js');\nvar utilFlowIndentCheck = require('./util-flow-indent-check.js');\n\nfunction resolveBlockSeq({ composeNode, composeEmptyNode }, ctx, bs, onError, tag) {\n    const NodeClass = tag?.nodeClass ?? YAMLSeq.YAMLSeq;\n    const seq = new NodeClass(ctx.schema);\n    if (ctx.atRoot)\n        ctx.atRoot = false;\n    let offset = bs.offset;\n    let commentEnd = null;\n    for (const { start, value } of bs.items) {\n        const props = resolveProps.resolveProps(start, {\n            indicator: 'seq-item-ind',\n            next: value,\n            offset,\n            onError,\n            startOnNewline: true\n        });\n        if (!props.found) {\n            if (props.anchor || props.tag || value) {\n                if (value && value.type === 'block-seq')\n                    onError(props.end, 'BAD_INDENT', 'All sequence items must start at the same column');\n                else\n                    onError(offset, 'MISSING_CHAR', 'Sequence item without - indicator');\n            }\n            else {\n                commentEnd = props.end;\n                if (props.comment)\n                    seq.comment = props.comment;\n                continue;\n            }\n        }\n        const node = value\n            ? composeNode(ctx, value, props, onError)\n            : composeEmptyNode(ctx, props.end, start, null, props, onError);\n        if (ctx.schema.compat)\n            utilFlowIndentCheck.flowIndentCheck(bs.indent, value, onError);\n        offset = node.range[2];\n        seq.items.push(node);\n    }\n    seq.range = [bs.offset, offset, commentEnd ?? offset];\n    return seq;\n}\n\nexports.resolveBlockSeq = resolveBlockSeq;\n","'use strict';\n\nfunction resolveEnd(end, offset, reqSpace, onError) {\n    let comment = '';\n    if (end) {\n        let hasSpace = false;\n        let sep = '';\n        for (const token of end) {\n            const { source, type } = token;\n            switch (type) {\n                case 'space':\n                    hasSpace = true;\n                    break;\n                case 'comment': {\n                    if (reqSpace && !hasSpace)\n                        onError(token, 'MISSING_CHAR', 'Comments must be separated from other tokens by white space characters');\n                    const cb = source.substring(1) || ' ';\n                    if (!comment)\n                        comment = cb;\n                    else\n                        comment += sep + cb;\n                    sep = '';\n                    break;\n                }\n                case 'newline':\n                    if (comment)\n                        sep += source;\n                    hasSpace = true;\n                    break;\n                default:\n                    onError(token, 'UNEXPECTED_TOKEN', `Unexpected ${type} at node end`);\n            }\n            offset += source.length;\n        }\n    }\n    return { comment, offset };\n}\n\nexports.resolveEnd = resolveEnd;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar Pair = require('../nodes/Pair.js');\nvar YAMLMap = require('../nodes/YAMLMap.js');\nvar YAMLSeq = require('../nodes/YAMLSeq.js');\nvar resolveEnd = require('./resolve-end.js');\nvar resolveProps = require('./resolve-props.js');\nvar utilContainsNewline = require('./util-contains-newline.js');\nvar utilMapIncludes = require('./util-map-includes.js');\n\nconst blockMsg = 'Block collections are not allowed within flow collections';\nconst isBlock = (token) => token && (token.type === 'block-map' || token.type === 'block-seq');\nfunction resolveFlowCollection({ composeNode, composeEmptyNode }, ctx, fc, onError, tag) {\n    const isMap = fc.start.source === '{';\n    const fcName = isMap ? 'flow map' : 'flow sequence';\n    const NodeClass = (tag?.nodeClass ?? (isMap ? YAMLMap.YAMLMap : YAMLSeq.YAMLSeq));\n    const coll = new NodeClass(ctx.schema);\n    coll.flow = true;\n    const atRoot = ctx.atRoot;\n    if (atRoot)\n        ctx.atRoot = false;\n    let offset = fc.offset + fc.start.source.length;\n    for (let i = 0; i < fc.items.length; ++i) {\n        const collItem = fc.items[i];\n        const { start, key, sep, value } = collItem;\n        const props = resolveProps.resolveProps(start, {\n            flow: fcName,\n            indicator: 'explicit-key-ind',\n            next: key ?? sep?.[0],\n            offset,\n            onError,\n            startOnNewline: false\n        });\n        if (!props.found) {\n            if (!props.anchor && !props.tag && !sep && !value) {\n                if (i === 0 && props.comma)\n                    onError(props.comma, 'UNEXPECTED_TOKEN', `Unexpected , in ${fcName}`);\n                else if (i < fc.items.length - 1)\n                    onError(props.start, 'UNEXPECTED_TOKEN', `Unexpected empty item in ${fcName}`);\n                if (props.comment) {\n                    if (coll.comment)\n                        coll.comment += '\\n' + props.comment;\n                    else\n                        coll.comment = props.comment;\n                }\n                offset = props.end;\n                continue;\n            }\n            if (!isMap && ctx.options.strict && utilContainsNewline.containsNewline(key))\n                onError(key, // checked by containsNewline()\n                'MULTILINE_IMPLICIT_KEY', 'Implicit keys of flow sequence pairs need to be on a single line');\n        }\n        if (i === 0) {\n            if (props.comma)\n                onError(props.comma, 'UNEXPECTED_TOKEN', `Unexpected , in ${fcName}`);\n        }\n        else {\n            if (!props.comma)\n                onError(props.start, 'MISSING_CHAR', `Missing , between ${fcName} items`);\n            if (props.comment) {\n                let prevItemComment = '';\n                loop: for (const st of start) {\n                    switch (st.type) {\n                        case 'comma':\n                        case 'space':\n                            break;\n                        case 'comment':\n                            prevItemComment = st.source.substring(1);\n                            break loop;\n                        default:\n                            break loop;\n                    }\n                }\n                if (prevItemComment) {\n                    let prev = coll.items[coll.items.length - 1];\n                    if (identity.isPair(prev))\n                        prev = prev.value ?? prev.key;\n                    if (prev.comment)\n                        prev.comment += '\\n' + prevItemComment;\n                    else\n                        prev.comment = prevItemComment;\n                    props.comment = props.comment.substring(prevItemComment.length + 1);\n                }\n            }\n        }\n        if (!isMap && !sep && !props.found) {\n            // item is a value in a seq\n            //  key & sep are empty, start does not include ? or :\n            const valueNode = value\n                ? composeNode(ctx, value, props, onError)\n                : composeEmptyNode(ctx, props.end, sep, null, props, onError);\n            coll.items.push(valueNode);\n            offset = valueNode.range[2];\n            if (isBlock(value))\n                onError(valueNode.range, 'BLOCK_IN_FLOW', blockMsg);\n        }\n        else {\n            // item is a key+value pair\n            // key value\n            const keyStart = props.end;\n            const keyNode = key\n                ? composeNode(ctx, key, props, onError)\n                : composeEmptyNode(ctx, keyStart, start, null, props, onError);\n            if (isBlock(key))\n                onError(keyNode.range, 'BLOCK_IN_FLOW', blockMsg);\n            // value properties\n            const valueProps = resolveProps.resolveProps(sep ?? [], {\n                flow: fcName,\n                indicator: 'map-value-ind',\n                next: value,\n                offset: keyNode.range[2],\n                onError,\n                startOnNewline: false\n            });\n            if (valueProps.found) {\n                if (!isMap && !props.found && ctx.options.strict) {\n                    if (sep)\n                        for (const st of sep) {\n                            if (st === valueProps.found)\n                                break;\n                            if (st.type === 'newline') {\n                                onError(st, 'MULTILINE_IMPLICIT_KEY', 'Implicit keys of flow sequence pairs need to be on a single line');\n                                break;\n                            }\n                        }\n                    if (props.start < valueProps.found.offset - 1024)\n                        onError(valueProps.found, 'KEY_OVER_1024_CHARS', 'The : indicator must be at most 1024 chars after the start of an implicit flow sequence key');\n                }\n            }\n            else if (value) {\n                if ('source' in value && value.source && value.source[0] === ':')\n                    onError(value, 'MISSING_CHAR', `Missing space after : in ${fcName}`);\n                else\n                    onError(valueProps.start, 'MISSING_CHAR', `Missing , or : between ${fcName} items`);\n            }\n            // value value\n            const valueNode = value\n                ? composeNode(ctx, value, valueProps, onError)\n                : valueProps.found\n                    ? composeEmptyNode(ctx, valueProps.end, sep, null, valueProps, onError)\n                    : null;\n            if (valueNode) {\n                if (isBlock(value))\n                    onError(valueNode.range, 'BLOCK_IN_FLOW', blockMsg);\n            }\n            else if (valueProps.comment) {\n                if (keyNode.comment)\n                    keyNode.comment += '\\n' + valueProps.comment;\n                else\n                    keyNode.comment = valueProps.comment;\n            }\n            const pair = new Pair.Pair(keyNode, valueNode);\n            if (ctx.options.keepSourceTokens)\n                pair.srcToken = collItem;\n            if (isMap) {\n                const map = coll;\n                if (utilMapIncludes.mapIncludes(ctx, map.items, keyNode))\n                    onError(keyStart, 'DUPLICATE_KEY', 'Map keys must be unique');\n                map.items.push(pair);\n            }\n            else {\n                const map = new YAMLMap.YAMLMap(ctx.schema);\n                map.flow = true;\n                map.items.push(pair);\n                coll.items.push(map);\n            }\n            offset = valueNode ? valueNode.range[2] : valueProps.end;\n        }\n    }\n    const expectedEnd = isMap ? '}' : ']';\n    const [ce, ...ee] = fc.end;\n    let cePos = offset;\n    if (ce && ce.source === expectedEnd)\n        cePos = ce.offset + ce.source.length;\n    else {\n        const name = fcName[0].toUpperCase() + fcName.substring(1);\n        const msg = atRoot\n            ? `${name} must end with a ${expectedEnd}`\n            : `${name} in block collection must be sufficiently indented and end with a ${expectedEnd}`;\n        onError(offset, atRoot ? 'MISSING_CHAR' : 'BAD_INDENT', msg);\n        if (ce && ce.source.length !== 1)\n            ee.unshift(ce);\n    }\n    if (ee.length > 0) {\n        const end = resolveEnd.resolveEnd(ee, cePos, ctx.options.strict, onError);\n        if (end.comment) {\n            if (coll.comment)\n                coll.comment += '\\n' + end.comment;\n            else\n                coll.comment = end.comment;\n        }\n        coll.range = [fc.offset, cePos, end.offset];\n    }\n    else {\n        coll.range = [fc.offset, cePos, cePos];\n    }\n    return coll;\n}\n\nexports.resolveFlowCollection = resolveFlowCollection;\n","'use strict';\n\nvar Scalar = require('../nodes/Scalar.js');\nvar resolveEnd = require('./resolve-end.js');\n\nfunction resolveFlowScalar(scalar, strict, onError) {\n    const { offset, type, source, end } = scalar;\n    let _type;\n    let value;\n    const _onError = (rel, code, msg) => onError(offset + rel, code, msg);\n    switch (type) {\n        case 'scalar':\n            _type = Scalar.Scalar.PLAIN;\n            value = plainValue(source, _onError);\n            break;\n        case 'single-quoted-scalar':\n            _type = Scalar.Scalar.QUOTE_SINGLE;\n            value = singleQuotedValue(source, _onError);\n            break;\n        case 'double-quoted-scalar':\n            _type = Scalar.Scalar.QUOTE_DOUBLE;\n            value = doubleQuotedValue(source, _onError);\n            break;\n        /* istanbul ignore next should not happen */\n        default:\n            onError(scalar, 'UNEXPECTED_TOKEN', `Expected a flow scalar value, but found: ${type}`);\n            return {\n                value: '',\n                type: null,\n                comment: '',\n                range: [offset, offset + source.length, offset + source.length]\n            };\n    }\n    const valueEnd = offset + source.length;\n    const re = resolveEnd.resolveEnd(end, valueEnd, strict, onError);\n    return {\n        value,\n        type: _type,\n        comment: re.comment,\n        range: [offset, valueEnd, re.offset]\n    };\n}\nfunction plainValue(source, onError) {\n    let badChar = '';\n    switch (source[0]) {\n        /* istanbul ignore next should not happen */\n        case '\\t':\n            badChar = 'a tab character';\n            break;\n        case ',':\n            badChar = 'flow indicator character ,';\n            break;\n        case '%':\n            badChar = 'directive indicator character %';\n            break;\n        case '|':\n        case '>': {\n            badChar = `block scalar indicator ${source[0]}`;\n            break;\n        }\n        case '@':\n        case '`': {\n            badChar = `reserved character ${source[0]}`;\n            break;\n        }\n    }\n    if (badChar)\n        onError(0, 'BAD_SCALAR_START', `Plain value cannot start with ${badChar}`);\n    return foldLines(source);\n}\nfunction singleQuotedValue(source, onError) {\n    if (source[source.length - 1] !== \"'\" || source.length === 1)\n        onError(source.length, 'MISSING_CHAR', \"Missing closing 'quote\");\n    return foldLines(source.slice(1, -1)).replace(/''/g, \"'\");\n}\nfunction foldLines(source) {\n    /**\n     * The negative lookbehind here and in the `re` RegExp is to\n     * prevent causing a polynomial search time in certain cases.\n     *\n     * The try-catch is for Safari, which doesn't support this yet:\n     * https://caniuse.com/js-regexp-lookbehind\n     */\n    let first, line;\n    try {\n        first = new RegExp('(.*?)(?<![ \\t])[ \\t]*\\r?\\n', 'sy');\n        line = new RegExp('[ \\t]*(.*?)(?:(?<![ \\t])[ \\t]*)?\\r?\\n', 'sy');\n    }\n    catch (_) {\n        first = /(.*?)[ \\t]*\\r?\\n/sy;\n        line = /[ \\t]*(.*?)[ \\t]*\\r?\\n/sy;\n    }\n    let match = first.exec(source);\n    if (!match)\n        return source;\n    let res = match[1];\n    let sep = ' ';\n    let pos = first.lastIndex;\n    line.lastIndex = pos;\n    while ((match = line.exec(source))) {\n        if (match[1] === '') {\n            if (sep === '\\n')\n                res += sep;\n            else\n                sep = '\\n';\n        }\n        else {\n            res += sep + match[1];\n            sep = ' ';\n        }\n        pos = line.lastIndex;\n    }\n    const last = /[ \\t]*(.*)/sy;\n    last.lastIndex = pos;\n    match = last.exec(source);\n    return res + sep + (match?.[1] ?? '');\n}\nfunction doubleQuotedValue(source, onError) {\n    let res = '';\n    for (let i = 1; i < source.length - 1; ++i) {\n        const ch = source[i];\n        if (ch === '\\r' && source[i + 1] === '\\n')\n            continue;\n        if (ch === '\\n') {\n            const { fold, offset } = foldNewline(source, i);\n            res += fold;\n            i = offset;\n        }\n        else if (ch === '\\\\') {\n            let next = source[++i];\n            const cc = escapeCodes[next];\n            if (cc)\n                res += cc;\n            else if (next === '\\n') {\n                // skip escaped newlines, but still trim the following line\n                next = source[i + 1];\n                while (next === ' ' || next === '\\t')\n                    next = source[++i + 1];\n            }\n            else if (next === '\\r' && source[i + 1] === '\\n') {\n                // skip escaped CRLF newlines, but still trim the following line\n                next = source[++i + 1];\n                while (next === ' ' || next === '\\t')\n                    next = source[++i + 1];\n            }\n            else if (next === 'x' || next === 'u' || next === 'U') {\n                const length = { x: 2, u: 4, U: 8 }[next];\n                res += parseCharCode(source, i + 1, length, onError);\n                i += length;\n            }\n            else {\n                const raw = source.substr(i - 1, 2);\n                onError(i - 1, 'BAD_DQ_ESCAPE', `Invalid escape sequence ${raw}`);\n                res += raw;\n            }\n        }\n        else if (ch === ' ' || ch === '\\t') {\n            // trim trailing whitespace\n            const wsStart = i;\n            let next = source[i + 1];\n            while (next === ' ' || next === '\\t')\n                next = source[++i + 1];\n            if (next !== '\\n' && !(next === '\\r' && source[i + 2] === '\\n'))\n                res += i > wsStart ? source.slice(wsStart, i + 1) : ch;\n        }\n        else {\n            res += ch;\n        }\n    }\n    if (source[source.length - 1] !== '\"' || source.length === 1)\n        onError(source.length, 'MISSING_CHAR', 'Missing closing \"quote');\n    return res;\n}\n/**\n * Fold a single newline into a space, multiple newlines to N - 1 newlines.\n * Presumes `source[offset] === '\\n'`\n */\nfunction foldNewline(source, offset) {\n    let fold = '';\n    let ch = source[offset + 1];\n    while (ch === ' ' || ch === '\\t' || ch === '\\n' || ch === '\\r') {\n        if (ch === '\\r' && source[offset + 2] !== '\\n')\n            break;\n        if (ch === '\\n')\n            fold += '\\n';\n        offset += 1;\n        ch = source[offset + 1];\n    }\n    if (!fold)\n        fold = ' ';\n    return { fold, offset };\n}\nconst escapeCodes = {\n    '0': '\\0', // null character\n    a: '\\x07', // bell character\n    b: '\\b', // backspace\n    e: '\\x1b', // escape character\n    f: '\\f', // form feed\n    n: '\\n', // line feed\n    r: '\\r', // carriage return\n    t: '\\t', // horizontal tab\n    v: '\\v', // vertical tab\n    N: '\\u0085', // Unicode next line\n    _: '\\u00a0', // Unicode non-breaking space\n    L: '\\u2028', // Unicode line separator\n    P: '\\u2029', // Unicode paragraph separator\n    ' ': ' ',\n    '\"': '\"',\n    '/': '/',\n    '\\\\': '\\\\',\n    '\\t': '\\t'\n};\nfunction parseCharCode(source, offset, length, onError) {\n    const cc = source.substr(offset, length);\n    const ok = cc.length === length && /^[0-9a-fA-F]+$/.test(cc);\n    const code = ok ? parseInt(cc, 16) : NaN;\n    if (isNaN(code)) {\n        const raw = source.substr(offset - 2, length + 2);\n        onError(offset - 2, 'BAD_DQ_ESCAPE', `Invalid escape sequence ${raw}`);\n        return raw;\n    }\n    return String.fromCodePoint(code);\n}\n\nexports.resolveFlowScalar = resolveFlowScalar;\n","'use strict';\n\nfunction resolveProps(tokens, { flow, indicator, next, offset, onError, startOnNewline }) {\n    let spaceBefore = false;\n    let atNewline = startOnNewline;\n    let hasSpace = startOnNewline;\n    let comment = '';\n    let commentSep = '';\n    let hasNewline = false;\n    let hasNewlineAfterProp = false;\n    let reqSpace = false;\n    let anchor = null;\n    let tag = null;\n    let comma = null;\n    let found = null;\n    let start = null;\n    for (const token of tokens) {\n        if (reqSpace) {\n            if (token.type !== 'space' &&\n                token.type !== 'newline' &&\n                token.type !== 'comma')\n                onError(token.offset, 'MISSING_CHAR', 'Tags and anchors must be separated from the next token by white space');\n            reqSpace = false;\n        }\n        switch (token.type) {\n            case 'space':\n                // At the doc level, tabs at line start may be parsed\n                // as leading white space rather than indentation.\n                // In a flow collection, only the parser handles indent.\n                if (!flow &&\n                    atNewline &&\n                    indicator !== 'doc-start' &&\n                    token.source[0] === '\\t')\n                    onError(token, 'TAB_AS_INDENT', 'Tabs are not allowed as indentation');\n                hasSpace = true;\n                break;\n            case 'comment': {\n                if (!hasSpace)\n                    onError(token, 'MISSING_CHAR', 'Comments must be separated from other tokens by white space characters');\n                const cb = token.source.substring(1) || ' ';\n                if (!comment)\n                    comment = cb;\n                else\n                    comment += commentSep + cb;\n                commentSep = '';\n                atNewline = false;\n                break;\n            }\n            case 'newline':\n                if (atNewline) {\n                    if (comment)\n                        comment += token.source;\n                    else\n                        spaceBefore = true;\n                }\n                else\n                    commentSep += token.source;\n                atNewline = true;\n                hasNewline = true;\n                if (anchor || tag)\n                    hasNewlineAfterProp = true;\n                hasSpace = true;\n                break;\n            case 'anchor':\n                if (anchor)\n                    onError(token, 'MULTIPLE_ANCHORS', 'A node can have at most one anchor');\n                if (token.source.endsWith(':'))\n                    onError(token.offset + token.source.length - 1, 'BAD_ALIAS', 'Anchor ending in : is ambiguous', true);\n                anchor = token;\n                if (start === null)\n                    start = token.offset;\n                atNewline = false;\n                hasSpace = false;\n                reqSpace = true;\n                break;\n            case 'tag': {\n                if (tag)\n                    onError(token, 'MULTIPLE_TAGS', 'A node can have at most one tag');\n                tag = token;\n                if (start === null)\n                    start = token.offset;\n                atNewline = false;\n                hasSpace = false;\n                reqSpace = true;\n                break;\n            }\n            case indicator:\n                // Could here handle preceding comments differently\n                if (anchor || tag)\n                    onError(token, 'BAD_PROP_ORDER', `Anchors and tags must be after the ${token.source} indicator`);\n                if (found)\n                    onError(token, 'UNEXPECTED_TOKEN', `Unexpected ${token.source} in ${flow ?? 'collection'}`);\n                found = token;\n                atNewline = false;\n                hasSpace = false;\n                break;\n            case 'comma':\n                if (flow) {\n                    if (comma)\n                        onError(token, 'UNEXPECTED_TOKEN', `Unexpected , in ${flow}`);\n                    comma = token;\n                    atNewline = false;\n                    hasSpace = false;\n                    break;\n                }\n            // else fallthrough\n            default:\n                onError(token, 'UNEXPECTED_TOKEN', `Unexpected ${token.type} token`);\n                atNewline = false;\n                hasSpace = false;\n        }\n    }\n    const last = tokens[tokens.length - 1];\n    const end = last ? last.offset + last.source.length : offset;\n    if (reqSpace &&\n        next &&\n        next.type !== 'space' &&\n        next.type !== 'newline' &&\n        next.type !== 'comma' &&\n        (next.type !== 'scalar' || next.source !== ''))\n        onError(next.offset, 'MISSING_CHAR', 'Tags and anchors must be separated from the next token by white space');\n    return {\n        comma,\n        found,\n        spaceBefore,\n        comment,\n        hasNewline,\n        hasNewlineAfterProp,\n        anchor,\n        tag,\n        end,\n        start: start ?? end\n    };\n}\n\nexports.resolveProps = resolveProps;\n","'use strict';\n\nfunction containsNewline(key) {\n    if (!key)\n        return null;\n    switch (key.type) {\n        case 'alias':\n        case 'scalar':\n        case 'double-quoted-scalar':\n        case 'single-quoted-scalar':\n            if (key.source.includes('\\n'))\n                return true;\n            if (key.end)\n                for (const st of key.end)\n                    if (st.type === 'newline')\n                        return true;\n            return false;\n        case 'flow-collection':\n            for (const it of key.items) {\n                for (const st of it.start)\n                    if (st.type === 'newline')\n                        return true;\n                if (it.sep)\n                    for (const st of it.sep)\n                        if (st.type === 'newline')\n                            return true;\n                if (containsNewline(it.key) || containsNewline(it.value))\n                    return true;\n            }\n            return false;\n        default:\n            return true;\n    }\n}\n\nexports.containsNewline = containsNewline;\n","'use strict';\n\nfunction emptyScalarPosition(offset, before, pos) {\n    if (before) {\n        if (pos === null)\n            pos = before.length;\n        for (let i = pos - 1; i >= 0; --i) {\n            let st = before[i];\n            switch (st.type) {\n                case 'space':\n                case 'comment':\n                case 'newline':\n                    offset -= st.source.length;\n                    continue;\n            }\n            // Technically, an empty scalar is immediately after the last non-empty\n            // node, but it's more useful to place it after any whitespace.\n            st = before[++i];\n            while (st?.type === 'space') {\n                offset += st.source.length;\n                st = before[++i];\n            }\n            break;\n        }\n    }\n    return offset;\n}\n\nexports.emptyScalarPosition = emptyScalarPosition;\n","'use strict';\n\nvar utilContainsNewline = require('./util-contains-newline.js');\n\nfunction flowIndentCheck(indent, fc, onError) {\n    if (fc?.type === 'flow-collection') {\n        const end = fc.end[0];\n        if (end.indent === indent &&\n            (end.source === ']' || end.source === '}') &&\n            utilContainsNewline.containsNewline(fc)) {\n            const msg = 'Flow end indicator should be more indented than parent';\n            onError(end, 'BAD_INDENT', msg, true);\n        }\n    }\n}\n\nexports.flowIndentCheck = flowIndentCheck;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\n\nfunction mapIncludes(ctx, items, search) {\n    const { uniqueKeys } = ctx.options;\n    if (uniqueKeys === false)\n        return false;\n    const isEqual = typeof uniqueKeys === 'function'\n        ? uniqueKeys\n        : (a, b) => a === b ||\n            (identity.isScalar(a) &&\n                identity.isScalar(b) &&\n                a.value === b.value &&\n                !(a.value === '<<' && ctx.schema.merge));\n    return items.some(pair => isEqual(pair.key, search));\n}\n\nexports.mapIncludes = mapIncludes;\n","'use strict';\n\nvar Alias = require('../nodes/Alias.js');\nvar Collection = require('../nodes/Collection.js');\nvar identity = require('../nodes/identity.js');\nvar Pair = require('../nodes/Pair.js');\nvar toJS = require('../nodes/toJS.js');\nvar Schema = require('../schema/Schema.js');\nvar stringifyDocument = require('../stringify/stringifyDocument.js');\nvar anchors = require('./anchors.js');\nvar applyReviver = require('./applyReviver.js');\nvar createNode = require('./createNode.js');\nvar directives = require('./directives.js');\n\nclass Document {\n    constructor(value, replacer, options) {\n        /** A comment before this Document */\n        this.commentBefore = null;\n        /** A comment immediately after this Document */\n        this.comment = null;\n        /** Errors encountered during parsing. */\n        this.errors = [];\n        /** Warnings encountered during parsing. */\n        this.warnings = [];\n        Object.defineProperty(this, identity.NODE_TYPE, { value: identity.DOC });\n        let _replacer = null;\n        if (typeof replacer === 'function' || Array.isArray(replacer)) {\n            _replacer = replacer;\n        }\n        else if (options === undefined && replacer) {\n            options = replacer;\n            replacer = undefined;\n        }\n        const opt = Object.assign({\n            intAsBigInt: false,\n            keepSourceTokens: false,\n            logLevel: 'warn',\n            prettyErrors: true,\n            strict: true,\n            uniqueKeys: true,\n            version: '1.2'\n        }, options);\n        this.options = opt;\n        let { version } = opt;\n        if (options?._directives) {\n            this.directives = options._directives.atDocument();\n            if (this.directives.yaml.explicit)\n                version = this.directives.yaml.version;\n        }\n        else\n            this.directives = new directives.Directives({ version });\n        this.setSchema(version, options);\n        // @ts-expect-error We can't really know that this matches Contents.\n        this.contents =\n            value === undefined ? null : this.createNode(value, _replacer, options);\n    }\n    /**\n     * Create a deep copy of this Document and its contents.\n     *\n     * Custom Node values that inherit from `Object` still refer to their original instances.\n     */\n    clone() {\n        const copy = Object.create(Document.prototype, {\n            [identity.NODE_TYPE]: { value: identity.DOC }\n        });\n        copy.commentBefore = this.commentBefore;\n        copy.comment = this.comment;\n        copy.errors = this.errors.slice();\n        copy.warnings = this.warnings.slice();\n        copy.options = Object.assign({}, this.options);\n        if (this.directives)\n            copy.directives = this.directives.clone();\n        copy.schema = this.schema.clone();\n        // @ts-expect-error We can't really know that this matches Contents.\n        copy.contents = identity.isNode(this.contents)\n            ? this.contents.clone(copy.schema)\n            : this.contents;\n        if (this.range)\n            copy.range = this.range.slice();\n        return copy;\n    }\n    /** Adds a value to the document. */\n    add(value) {\n        if (assertCollection(this.contents))\n            this.contents.add(value);\n    }\n    /** Adds a value to the document. */\n    addIn(path, value) {\n        if (assertCollection(this.contents))\n            this.contents.addIn(path, value);\n    }\n    /**\n     * Create a new `Alias` node, ensuring that the target `node` has the required anchor.\n     *\n     * If `node` already has an anchor, `name` is ignored.\n     * Otherwise, the `node.anchor` value will be set to `name`,\n     * or if an anchor with that name is already present in the document,\n     * `name` will be used as a prefix for a new unique anchor.\n     * If `name` is undefined, the generated anchor will use 'a' as a prefix.\n     */\n    createAlias(node, name) {\n        if (!node.anchor) {\n            const prev = anchors.anchorNames(this);\n            node.anchor =\n                // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing\n                !name || prev.has(name) ? anchors.findNewAnchor(name || 'a', prev) : name;\n        }\n        return new Alias.Alias(node.anchor);\n    }\n    createNode(value, replacer, options) {\n        let _replacer = undefined;\n        if (typeof replacer === 'function') {\n            value = replacer.call({ '': value }, '', value);\n            _replacer = replacer;\n        }\n        else if (Array.isArray(replacer)) {\n            const keyToStr = (v) => typeof v === 'number' || v instanceof String || v instanceof Number;\n            const asStr = replacer.filter(keyToStr).map(String);\n            if (asStr.length > 0)\n                replacer = replacer.concat(asStr);\n            _replacer = replacer;\n        }\n        else if (options === undefined && replacer) {\n            options = replacer;\n            replacer = undefined;\n        }\n        const { aliasDuplicateObjects, anchorPrefix, flow, keepUndefined, onTagObj, tag } = options ?? {};\n        const { onAnchor, setAnchors, sourceObjects } = anchors.createNodeAnchors(this, \n        // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing\n        anchorPrefix || 'a');\n        const ctx = {\n            aliasDuplicateObjects: aliasDuplicateObjects ?? true,\n            keepUndefined: keepUndefined ?? false,\n            onAnchor,\n            onTagObj,\n            replacer: _replacer,\n            schema: this.schema,\n            sourceObjects\n        };\n        const node = createNode.createNode(value, tag, ctx);\n        if (flow && identity.isCollection(node))\n            node.flow = true;\n        setAnchors();\n        return node;\n    }\n    /**\n     * Convert a key and a value into a `Pair` using the current schema,\n     * recursively wrapping all values as `Scalar` or `Collection` nodes.\n     */\n    createPair(key, value, options = {}) {\n        const k = this.createNode(key, null, options);\n        const v = this.createNode(value, null, options);\n        return new Pair.Pair(k, v);\n    }\n    /**\n     * Removes a value from the document.\n     * @returns `true` if the item was found and removed.\n     */\n    delete(key) {\n        return assertCollection(this.contents) ? this.contents.delete(key) : false;\n    }\n    /**\n     * Removes a value from the document.\n     * @returns `true` if the item was found and removed.\n     */\n    deleteIn(path) {\n        if (Collection.isEmptyPath(path)) {\n            if (this.contents == null)\n                return false;\n            // @ts-expect-error Presumed impossible if Strict extends false\n            this.contents = null;\n            return true;\n        }\n        return assertCollection(this.contents)\n            ? this.contents.deleteIn(path)\n            : false;\n    }\n    /**\n     * Returns item at `key`, or `undefined` if not found. By default unwraps\n     * scalar values from their surrounding node; to disable set `keepScalar` to\n     * `true` (collections are always returned intact).\n     */\n    get(key, keepScalar) {\n        return identity.isCollection(this.contents)\n            ? this.contents.get(key, keepScalar)\n            : undefined;\n    }\n    /**\n     * Returns item at `path`, or `undefined` if not found. By default unwraps\n     * scalar values from their surrounding node; to disable set `keepScalar` to\n     * `true` (collections are always returned intact).\n     */\n    getIn(path, keepScalar) {\n        if (Collection.isEmptyPath(path))\n            return !keepScalar && identity.isScalar(this.contents)\n                ? this.contents.value\n                : this.contents;\n        return identity.isCollection(this.contents)\n            ? this.contents.getIn(path, keepScalar)\n            : undefined;\n    }\n    /**\n     * Checks if the document includes a value with the key `key`.\n     */\n    has(key) {\n        return identity.isCollection(this.contents) ? this.contents.has(key) : false;\n    }\n    /**\n     * Checks if the document includes a value at `path`.\n     */\n    hasIn(path) {\n        if (Collection.isEmptyPath(path))\n            return this.contents !== undefined;\n        return identity.isCollection(this.contents) ? this.contents.hasIn(path) : false;\n    }\n    /**\n     * Sets a value in this document. For `!!set`, `value` needs to be a\n     * boolean to add/remove the item from the set.\n     */\n    set(key, value) {\n        if (this.contents == null) {\n            // @ts-expect-error We can't really know that this matches Contents.\n            this.contents = Collection.collectionFromPath(this.schema, [key], value);\n        }\n        else if (assertCollection(this.contents)) {\n            this.contents.set(key, value);\n        }\n    }\n    /**\n     * Sets a value in this document. For `!!set`, `value` needs to be a\n     * boolean to add/remove the item from the set.\n     */\n    setIn(path, value) {\n        if (Collection.isEmptyPath(path)) {\n            // @ts-expect-error We can't really know that this matches Contents.\n            this.contents = value;\n        }\n        else if (this.contents == null) {\n            // @ts-expect-error We can't really know that this matches Contents.\n            this.contents = Collection.collectionFromPath(this.schema, Array.from(path), value);\n        }\n        else if (assertCollection(this.contents)) {\n            this.contents.setIn(path, value);\n        }\n    }\n    /**\n     * Change the YAML version and schema used by the document.\n     * A `null` version disables support for directives, explicit tags, anchors, and aliases.\n     * It also requires the `schema` option to be given as a `Schema` instance value.\n     *\n     * Overrides all previously set schema options.\n     */\n    setSchema(version, options = {}) {\n        if (typeof version === 'number')\n            version = String(version);\n        let opt;\n        switch (version) {\n            case '1.1':\n                if (this.directives)\n                    this.directives.yaml.version = '1.1';\n                else\n                    this.directives = new directives.Directives({ version: '1.1' });\n                opt = { merge: true, resolveKnownTags: false, schema: 'yaml-1.1' };\n                break;\n            case '1.2':\n            case 'next':\n                if (this.directives)\n                    this.directives.yaml.version = version;\n                else\n                    this.directives = new directives.Directives({ version });\n                opt = { merge: false, resolveKnownTags: true, schema: 'core' };\n                break;\n            case null:\n                if (this.directives)\n                    delete this.directives;\n                opt = null;\n                break;\n            default: {\n                const sv = JSON.stringify(version);\n                throw new Error(`Expected '1.1', '1.2' or null as first argument, but found: ${sv}`);\n            }\n        }\n        // Not using `instanceof Schema` to allow for duck typing\n        if (options.schema instanceof Object)\n            this.schema = options.schema;\n        else if (opt)\n            this.schema = new Schema.Schema(Object.assign(opt, options));\n        else\n            throw new Error(`With a null YAML version, the { schema: Schema } option is required`);\n    }\n    // json & jsonArg are only used from toJSON()\n    toJS({ json, jsonArg, mapAsMap, maxAliasCount, onAnchor, reviver } = {}) {\n        const ctx = {\n            anchors: new Map(),\n            doc: this,\n            keep: !json,\n            mapAsMap: mapAsMap === true,\n            mapKeyWarned: false,\n            maxAliasCount: typeof maxAliasCount === 'number' ? maxAliasCount : 100\n        };\n        const res = toJS.toJS(this.contents, jsonArg ?? '', ctx);\n        if (typeof onAnchor === 'function')\n            for (const { count, res } of ctx.anchors.values())\n                onAnchor(res, count);\n        return typeof reviver === 'function'\n            ? applyReviver.applyReviver(reviver, { '': res }, '', res)\n            : res;\n    }\n    /**\n     * A JSON representation of the document `contents`.\n     *\n     * @param jsonArg Used by `JSON.stringify` to indicate the array index or\n     *   property name.\n     */\n    toJSON(jsonArg, onAnchor) {\n        return this.toJS({ json: true, jsonArg, mapAsMap: false, onAnchor });\n    }\n    /** A YAML representation of the document. */\n    toString(options = {}) {\n        if (this.errors.length > 0)\n            throw new Error('Document with errors cannot be stringified');\n        if ('indent' in options &&\n            (!Number.isInteger(options.indent) || Number(options.indent) <= 0)) {\n            const s = JSON.stringify(options.indent);\n            throw new Error(`\"indent\" option must be a positive integer, not ${s}`);\n        }\n        return stringifyDocument.stringifyDocument(this, options);\n    }\n}\nfunction assertCollection(contents) {\n    if (identity.isCollection(contents))\n        return true;\n    throw new Error('Expected a YAML collection as document contents');\n}\n\nexports.Document = Document;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar visit = require('../visit.js');\n\n/**\n * Verify that the input string is a valid anchor.\n *\n * Will throw on errors.\n */\nfunction anchorIsValid(anchor) {\n    if (/[\\x00-\\x19\\s,[\\]{}]/.test(anchor)) {\n        const sa = JSON.stringify(anchor);\n        const msg = `Anchor must not contain whitespace or control characters: ${sa}`;\n        throw new Error(msg);\n    }\n    return true;\n}\nfunction anchorNames(root) {\n    const anchors = new Set();\n    visit.visit(root, {\n        Value(_key, node) {\n            if (node.anchor)\n                anchors.add(node.anchor);\n        }\n    });\n    return anchors;\n}\n/** Find a new anchor name with the given `prefix` and a one-indexed suffix. */\nfunction findNewAnchor(prefix, exclude) {\n    for (let i = 1; true; ++i) {\n        const name = `${prefix}${i}`;\n        if (!exclude.has(name))\n            return name;\n    }\n}\nfunction createNodeAnchors(doc, prefix) {\n    const aliasObjects = [];\n    const sourceObjects = new Map();\n    let prevAnchors = null;\n    return {\n        onAnchor: (source) => {\n            aliasObjects.push(source);\n            if (!prevAnchors)\n                prevAnchors = anchorNames(doc);\n            const anchor = findNewAnchor(prefix, prevAnchors);\n            prevAnchors.add(anchor);\n            return anchor;\n        },\n        /**\n         * With circular references, the source node is only resolved after all\n         * of its child nodes are. This is why anchors are set only after all of\n         * the nodes have been created.\n         */\n        setAnchors: () => {\n            for (const source of aliasObjects) {\n                const ref = sourceObjects.get(source);\n                if (typeof ref === 'object' &&\n                    ref.anchor &&\n                    (identity.isScalar(ref.node) || identity.isCollection(ref.node))) {\n                    ref.node.anchor = ref.anchor;\n                }\n                else {\n                    const error = new Error('Failed to resolve repeated object (this should not happen)');\n                    error.source = source;\n                    throw error;\n                }\n            }\n        },\n        sourceObjects\n    };\n}\n\nexports.anchorIsValid = anchorIsValid;\nexports.anchorNames = anchorNames;\nexports.createNodeAnchors = createNodeAnchors;\nexports.findNewAnchor = findNewAnchor;\n","'use strict';\n\n/**\n * Applies the JSON.parse reviver algorithm as defined in the ECMA-262 spec,\n * in section 24.5.1.1 \"Runtime Semantics: InternalizeJSONProperty\" of the\n * 2021 edition: https://tc39.es/ecma262/#sec-json.parse\n *\n * Includes extensions for handling Map and Set objects.\n */\nfunction applyReviver(reviver, obj, key, val) {\n    if (val && typeof val === 'object') {\n        if (Array.isArray(val)) {\n            for (let i = 0, len = val.length; i < len; ++i) {\n                const v0 = val[i];\n                const v1 = applyReviver(reviver, val, String(i), v0);\n                if (v1 === undefined)\n                    delete val[i];\n                else if (v1 !== v0)\n                    val[i] = v1;\n            }\n        }\n        else if (val instanceof Map) {\n            for (const k of Array.from(val.keys())) {\n                const v0 = val.get(k);\n                const v1 = applyReviver(reviver, val, k, v0);\n                if (v1 === undefined)\n                    val.delete(k);\n                else if (v1 !== v0)\n                    val.set(k, v1);\n            }\n        }\n        else if (val instanceof Set) {\n            for (const v0 of Array.from(val)) {\n                const v1 = applyReviver(reviver, val, v0, v0);\n                if (v1 === undefined)\n                    val.delete(v0);\n                else if (v1 !== v0) {\n                    val.delete(v0);\n                    val.add(v1);\n                }\n            }\n        }\n        else {\n            for (const [k, v0] of Object.entries(val)) {\n                const v1 = applyReviver(reviver, val, k, v0);\n                if (v1 === undefined)\n                    delete val[k];\n                else if (v1 !== v0)\n                    val[k] = v1;\n            }\n        }\n    }\n    return reviver.call(obj, key, val);\n}\n\nexports.applyReviver = applyReviver;\n","'use strict';\n\nvar Alias = require('../nodes/Alias.js');\nvar identity = require('../nodes/identity.js');\nvar Scalar = require('../nodes/Scalar.js');\n\nconst defaultTagPrefix = 'tag:yaml.org,2002:';\nfunction findTagObject(value, tagName, tags) {\n    if (tagName) {\n        const match = tags.filter(t => t.tag === tagName);\n        const tagObj = match.find(t => !t.format) ?? match[0];\n        if (!tagObj)\n            throw new Error(`Tag ${tagName} not found`);\n        return tagObj;\n    }\n    return tags.find(t => t.identify?.(value) && !t.format);\n}\nfunction createNode(value, tagName, ctx) {\n    if (identity.isDocument(value))\n        value = value.contents;\n    if (identity.isNode(value))\n        return value;\n    if (identity.isPair(value)) {\n        const map = ctx.schema[identity.MAP].createNode?.(ctx.schema, null, ctx);\n        map.items.push(value);\n        return map;\n    }\n    if (value instanceof String ||\n        value instanceof Number ||\n        value instanceof Boolean ||\n        (typeof BigInt !== 'undefined' && value instanceof BigInt) // not supported everywhere\n    ) {\n        // https://tc39.es/ecma262/#sec-serializejsonproperty\n        value = value.valueOf();\n    }\n    const { aliasDuplicateObjects, onAnchor, onTagObj, schema, sourceObjects } = ctx;\n    // Detect duplicate references to the same object & use Alias nodes for all\n    // after first. The `ref` wrapper allows for circular references to resolve.\n    let ref = undefined;\n    if (aliasDuplicateObjects && value && typeof value === 'object') {\n        ref = sourceObjects.get(value);\n        if (ref) {\n            if (!ref.anchor)\n                ref.anchor = onAnchor(value);\n            return new Alias.Alias(ref.anchor);\n        }\n        else {\n            ref = { anchor: null, node: null };\n            sourceObjects.set(value, ref);\n        }\n    }\n    if (tagName?.startsWith('!!'))\n        tagName = defaultTagPrefix + tagName.slice(2);\n    let tagObj = findTagObject(value, tagName, schema.tags);\n    if (!tagObj) {\n        if (value && typeof value.toJSON === 'function') {\n            // eslint-disable-next-line @typescript-eslint/no-unsafe-call\n            value = value.toJSON();\n        }\n        if (!value || typeof value !== 'object') {\n            const node = new Scalar.Scalar(value);\n            if (ref)\n                ref.node = node;\n            return node;\n        }\n        tagObj =\n            value instanceof Map\n                ? schema[identity.MAP]\n                : Symbol.iterator in Object(value)\n                    ? schema[identity.SEQ]\n                    : schema[identity.MAP];\n    }\n    if (onTagObj) {\n        onTagObj(tagObj);\n        delete ctx.onTagObj;\n    }\n    const node = tagObj?.createNode\n        ? tagObj.createNode(ctx.schema, value, ctx)\n        : typeof tagObj?.nodeClass?.from === 'function'\n            ? tagObj.nodeClass.from(ctx.schema, value, ctx)\n            : new Scalar.Scalar(value);\n    if (tagName)\n        node.tag = tagName;\n    else if (!tagObj.default)\n        node.tag = tagObj.tag;\n    if (ref)\n        ref.node = node;\n    return node;\n}\n\nexports.createNode = createNode;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar visit = require('../visit.js');\n\nconst escapeChars = {\n    '!': '%21',\n    ',': '%2C',\n    '[': '%5B',\n    ']': '%5D',\n    '{': '%7B',\n    '}': '%7D'\n};\nconst escapeTagName = (tn) => tn.replace(/[!,[\\]{}]/g, ch => escapeChars[ch]);\nclass Directives {\n    constructor(yaml, tags) {\n        /**\n         * The directives-end/doc-start marker `---`. If `null`, a marker may still be\n         * included in the document's stringified representation.\n         */\n        this.docStart = null;\n        /** The doc-end marker `...`.  */\n        this.docEnd = false;\n        this.yaml = Object.assign({}, Directives.defaultYaml, yaml);\n        this.tags = Object.assign({}, Directives.defaultTags, tags);\n    }\n    clone() {\n        const copy = new Directives(this.yaml, this.tags);\n        copy.docStart = this.docStart;\n        return copy;\n    }\n    /**\n     * During parsing, get a Directives instance for the current document and\n     * update the stream state according to the current version's spec.\n     */\n    atDocument() {\n        const res = new Directives(this.yaml, this.tags);\n        switch (this.yaml.version) {\n            case '1.1':\n                this.atNextDocument = true;\n                break;\n            case '1.2':\n                this.atNextDocument = false;\n                this.yaml = {\n                    explicit: Directives.defaultYaml.explicit,\n                    version: '1.2'\n                };\n                this.tags = Object.assign({}, Directives.defaultTags);\n                break;\n        }\n        return res;\n    }\n    /**\n     * @param onError - May be called even if the action was successful\n     * @returns `true` on success\n     */\n    add(line, onError) {\n        if (this.atNextDocument) {\n            this.yaml = { explicit: Directives.defaultYaml.explicit, version: '1.1' };\n            this.tags = Object.assign({}, Directives.defaultTags);\n            this.atNextDocument = false;\n        }\n        const parts = line.trim().split(/[ \\t]+/);\n        const name = parts.shift();\n        switch (name) {\n            case '%TAG': {\n                if (parts.length !== 2) {\n                    onError(0, '%TAG directive should contain exactly two parts');\n                    if (parts.length < 2)\n                        return false;\n                }\n                const [handle, prefix] = parts;\n                this.tags[handle] = prefix;\n                return true;\n            }\n            case '%YAML': {\n                this.yaml.explicit = true;\n                if (parts.length !== 1) {\n                    onError(0, '%YAML directive should contain exactly one part');\n                    return false;\n                }\n                const [version] = parts;\n                if (version === '1.1' || version === '1.2') {\n                    this.yaml.version = version;\n                    return true;\n                }\n                else {\n                    const isValid = /^\\d+\\.\\d+$/.test(version);\n                    onError(6, `Unsupported YAML version ${version}`, isValid);\n                    return false;\n                }\n            }\n            default:\n                onError(0, `Unknown directive ${name}`, true);\n                return false;\n        }\n    }\n    /**\n     * Resolves a tag, matching handles to those defined in %TAG directives.\n     *\n     * @returns Resolved tag, which may also be the non-specific tag `'!'` or a\n     *   `'!local'` tag, or `null` if unresolvable.\n     */\n    tagName(source, onError) {\n        if (source === '!')\n            return '!'; // non-specific tag\n        if (source[0] !== '!') {\n            onError(`Not a valid tag: ${source}`);\n            return null;\n        }\n        if (source[1] === '<') {\n            const verbatim = source.slice(2, -1);\n            if (verbatim === '!' || verbatim === '!!') {\n                onError(`Verbatim tags aren't resolved, so ${source} is invalid.`);\n                return null;\n            }\n            if (source[source.length - 1] !== '>')\n                onError('Verbatim tags must end with a >');\n            return verbatim;\n        }\n        const [, handle, suffix] = source.match(/^(.*!)([^!]*)$/s);\n        if (!suffix)\n            onError(`The ${source} tag has no suffix`);\n        const prefix = this.tags[handle];\n        if (prefix) {\n            try {\n                return prefix + decodeURIComponent(suffix);\n            }\n            catch (error) {\n                onError(String(error));\n                return null;\n            }\n        }\n        if (handle === '!')\n            return source; // local tag\n        onError(`Could not resolve tag: ${source}`);\n        return null;\n    }\n    /**\n     * Given a fully resolved tag, returns its printable string form,\n     * taking into account current tag prefixes and defaults.\n     */\n    tagString(tag) {\n        for (const [handle, prefix] of Object.entries(this.tags)) {\n            if (tag.startsWith(prefix))\n                return handle + escapeTagName(tag.substring(prefix.length));\n        }\n        return tag[0] === '!' ? tag : `!<${tag}>`;\n    }\n    toString(doc) {\n        const lines = this.yaml.explicit\n            ? [`%YAML ${this.yaml.version || '1.2'}`]\n            : [];\n        const tagEntries = Object.entries(this.tags);\n        let tagNames;\n        if (doc && tagEntries.length > 0 && identity.isNode(doc.contents)) {\n            const tags = {};\n            visit.visit(doc.contents, (_key, node) => {\n                if (identity.isNode(node) && node.tag)\n                    tags[node.tag] = true;\n            });\n            tagNames = Object.keys(tags);\n        }\n        else\n            tagNames = [];\n        for (const [handle, prefix] of tagEntries) {\n            if (handle === '!!' && prefix === 'tag:yaml.org,2002:')\n                continue;\n            if (!doc || tagNames.some(tn => tn.startsWith(prefix)))\n                lines.push(`%TAG ${handle} ${prefix}`);\n        }\n        return lines.join('\\n');\n    }\n}\nDirectives.defaultYaml = { explicit: false, version: '1.2' };\nDirectives.defaultTags = { '!!': 'tag:yaml.org,2002:' };\n\nexports.Directives = Directives;\n","'use strict';\n\nclass YAMLError extends Error {\n    constructor(name, pos, code, message) {\n        super();\n        this.name = name;\n        this.code = code;\n        this.message = message;\n        this.pos = pos;\n    }\n}\nclass YAMLParseError extends YAMLError {\n    constructor(pos, code, message) {\n        super('YAMLParseError', pos, code, message);\n    }\n}\nclass YAMLWarning extends YAMLError {\n    constructor(pos, code, message) {\n        super('YAMLWarning', pos, code, message);\n    }\n}\nconst prettifyError = (src, lc) => (error) => {\n    if (error.pos[0] === -1)\n        return;\n    error.linePos = error.pos.map(pos => lc.linePos(pos));\n    const { line, col } = error.linePos[0];\n    error.message += ` at line ${line}, column ${col}`;\n    let ci = col - 1;\n    let lineStr = src\n        .substring(lc.lineStarts[line - 1], lc.lineStarts[line])\n        .replace(/[\\n\\r]+$/, '');\n    // Trim to max 80 chars, keeping col position near the middle\n    if (ci >= 60 && lineStr.length > 80) {\n        const trimStart = Math.min(ci - 39, lineStr.length - 79);\n        lineStr = '' + lineStr.substring(trimStart);\n        ci -= trimStart - 1;\n    }\n    if (lineStr.length > 80)\n        lineStr = lineStr.substring(0, 79) + '';\n    // Include previous line in context if pointing at line start\n    if (line > 1 && /^ *$/.test(lineStr.substring(0, ci))) {\n        // Regexp won't match if start is trimmed\n        let prev = src.substring(lc.lineStarts[line - 2], lc.lineStarts[line - 1]);\n        if (prev.length > 80)\n            prev = prev.substring(0, 79) + '\\n';\n        lineStr = prev + lineStr;\n    }\n    if (/[^ ]/.test(lineStr)) {\n        let count = 1;\n        const end = error.linePos[1];\n        if (end && end.line === line && end.col > col) {\n            count = Math.max(1, Math.min(end.col - col, 80 - ci));\n        }\n        const pointer = ' '.repeat(ci) + '^'.repeat(count);\n        error.message += `:\\n\\n${lineStr}\\n${pointer}\\n`;\n    }\n};\n\nexports.YAMLError = YAMLError;\nexports.YAMLParseError = YAMLParseError;\nexports.YAMLWarning = YAMLWarning;\nexports.prettifyError = prettifyError;\n","'use strict';\n\nvar composer = require('./compose/composer.js');\nvar Document = require('./doc/Document.js');\nvar Schema = require('./schema/Schema.js');\nvar errors = require('./errors.js');\nvar Alias = require('./nodes/Alias.js');\nvar identity = require('./nodes/identity.js');\nvar Pair = require('./nodes/Pair.js');\nvar Scalar = require('./nodes/Scalar.js');\nvar YAMLMap = require('./nodes/YAMLMap.js');\nvar YAMLSeq = require('./nodes/YAMLSeq.js');\nvar cst = require('./parse/cst.js');\nvar lexer = require('./parse/lexer.js');\nvar lineCounter = require('./parse/line-counter.js');\nvar parser = require('./parse/parser.js');\nvar publicApi = require('./public-api.js');\nvar visit = require('./visit.js');\n\n\n\nexports.Composer = composer.Composer;\nexports.Document = Document.Document;\nexports.Schema = Schema.Schema;\nexports.YAMLError = errors.YAMLError;\nexports.YAMLParseError = errors.YAMLParseError;\nexports.YAMLWarning = errors.YAMLWarning;\nexports.Alias = Alias.Alias;\nexports.isAlias = identity.isAlias;\nexports.isCollection = identity.isCollection;\nexports.isDocument = identity.isDocument;\nexports.isMap = identity.isMap;\nexports.isNode = identity.isNode;\nexports.isPair = identity.isPair;\nexports.isScalar = identity.isScalar;\nexports.isSeq = identity.isSeq;\nexports.Pair = Pair.Pair;\nexports.Scalar = Scalar.Scalar;\nexports.YAMLMap = YAMLMap.YAMLMap;\nexports.YAMLSeq = YAMLSeq.YAMLSeq;\nexports.CST = cst;\nexports.Lexer = lexer.Lexer;\nexports.LineCounter = lineCounter.LineCounter;\nexports.Parser = parser.Parser;\nexports.parse = publicApi.parse;\nexports.parseAllDocuments = publicApi.parseAllDocuments;\nexports.parseDocument = publicApi.parseDocument;\nexports.stringify = publicApi.stringify;\nexports.visit = visit.visit;\nexports.visitAsync = visit.visitAsync;\n","'use strict';\n\nfunction debug(logLevel, ...messages) {\n    if (logLevel === 'debug')\n        console.log(...messages);\n}\nfunction warn(logLevel, warning) {\n    if (logLevel === 'debug' || logLevel === 'warn') {\n        // https://github.com/typescript-eslint/typescript-eslint/issues/7478\n        // eslint-disable-next-line @typescript-eslint/prefer-optional-chain\n        if (typeof process !== 'undefined' && process.emitWarning)\n            process.emitWarning(warning);\n        else\n            console.warn(warning);\n    }\n}\n\nexports.debug = debug;\nexports.warn = warn;\n","'use strict';\n\nvar anchors = require('../doc/anchors.js');\nvar visit = require('../visit.js');\nvar identity = require('./identity.js');\nvar Node = require('./Node.js');\nvar toJS = require('./toJS.js');\n\nclass Alias extends Node.NodeBase {\n    constructor(source) {\n        super(identity.ALIAS);\n        this.source = source;\n        Object.defineProperty(this, 'tag', {\n            set() {\n                throw new Error('Alias nodes cannot have tags');\n            }\n        });\n    }\n    /**\n     * Resolve the value of this alias within `doc`, finding the last\n     * instance of the `source` anchor before this node.\n     */\n    resolve(doc) {\n        let found = undefined;\n        visit.visit(doc, {\n            Node: (_key, node) => {\n                if (node === this)\n                    return visit.visit.BREAK;\n                if (node.anchor === this.source)\n                    found = node;\n            }\n        });\n        return found;\n    }\n    toJSON(_arg, ctx) {\n        if (!ctx)\n            return { source: this.source };\n        const { anchors, doc, maxAliasCount } = ctx;\n        const source = this.resolve(doc);\n        if (!source) {\n            const msg = `Unresolved alias (the anchor must be set before the alias): ${this.source}`;\n            throw new ReferenceError(msg);\n        }\n        let data = anchors.get(source);\n        if (!data) {\n            // Resolve anchors for Node.prototype.toJS()\n            toJS.toJS(source, null, ctx);\n            data = anchors.get(source);\n        }\n        /* istanbul ignore if */\n        if (!data || data.res === undefined) {\n            const msg = 'This should not happen: Alias anchor was not resolved?';\n            throw new ReferenceError(msg);\n        }\n        if (maxAliasCount >= 0) {\n            data.count += 1;\n            if (data.aliasCount === 0)\n                data.aliasCount = getAliasCount(doc, source, anchors);\n            if (data.count * data.aliasCount > maxAliasCount) {\n                const msg = 'Excessive alias count indicates a resource exhaustion attack';\n                throw new ReferenceError(msg);\n            }\n        }\n        return data.res;\n    }\n    toString(ctx, _onComment, _onChompKeep) {\n        const src = `*${this.source}`;\n        if (ctx) {\n            anchors.anchorIsValid(this.source);\n            if (ctx.options.verifyAliasOrder && !ctx.anchors.has(this.source)) {\n                const msg = `Unresolved alias (the anchor must be set before the alias): ${this.source}`;\n                throw new Error(msg);\n            }\n            if (ctx.implicitKey)\n                return `${src} `;\n        }\n        return src;\n    }\n}\nfunction getAliasCount(doc, node, anchors) {\n    if (identity.isAlias(node)) {\n        const source = node.resolve(doc);\n        const anchor = anchors && source && anchors.get(source);\n        return anchor ? anchor.count * anchor.aliasCount : 0;\n    }\n    else if (identity.isCollection(node)) {\n        let count = 0;\n        for (const item of node.items) {\n            const c = getAliasCount(doc, item, anchors);\n            if (c > count)\n                count = c;\n        }\n        return count;\n    }\n    else if (identity.isPair(node)) {\n        const kc = getAliasCount(doc, node.key, anchors);\n        const vc = getAliasCount(doc, node.value, anchors);\n        return Math.max(kc, vc);\n    }\n    return 1;\n}\n\nexports.Alias = Alias;\n","'use strict';\n\nvar createNode = require('../doc/createNode.js');\nvar identity = require('./identity.js');\nvar Node = require('./Node.js');\n\nfunction collectionFromPath(schema, path, value) {\n    let v = value;\n    for (let i = path.length - 1; i >= 0; --i) {\n        const k = path[i];\n        if (typeof k === 'number' && Number.isInteger(k) && k >= 0) {\n            const a = [];\n            a[k] = v;\n            v = a;\n        }\n        else {\n            v = new Map([[k, v]]);\n        }\n    }\n    return createNode.createNode(v, undefined, {\n        aliasDuplicateObjects: false,\n        keepUndefined: false,\n        onAnchor: () => {\n            throw new Error('This should not happen, please report a bug.');\n        },\n        schema,\n        sourceObjects: new Map()\n    });\n}\n// Type guard is intentionally a little wrong so as to be more useful,\n// as it does not cover untypable empty non-string iterables (e.g. []).\nconst isEmptyPath = (path) => path == null ||\n    (typeof path === 'object' && !!path[Symbol.iterator]().next().done);\nclass Collection extends Node.NodeBase {\n    constructor(type, schema) {\n        super(type);\n        Object.defineProperty(this, 'schema', {\n            value: schema,\n            configurable: true,\n            enumerable: false,\n            writable: true\n        });\n    }\n    /**\n     * Create a copy of this collection.\n     *\n     * @param schema - If defined, overwrites the original's schema\n     */\n    clone(schema) {\n        const copy = Object.create(Object.getPrototypeOf(this), Object.getOwnPropertyDescriptors(this));\n        if (schema)\n            copy.schema = schema;\n        copy.items = copy.items.map(it => identity.isNode(it) || identity.isPair(it) ? it.clone(schema) : it);\n        if (this.range)\n            copy.range = this.range.slice();\n        return copy;\n    }\n    /**\n     * Adds a value to the collection. For `!!map` and `!!omap` the value must\n     * be a Pair instance or a `{ key, value }` object, which may not have a key\n     * that already exists in the map.\n     */\n    addIn(path, value) {\n        if (isEmptyPath(path))\n            this.add(value);\n        else {\n            const [key, ...rest] = path;\n            const node = this.get(key, true);\n            if (identity.isCollection(node))\n                node.addIn(rest, value);\n            else if (node === undefined && this.schema)\n                this.set(key, collectionFromPath(this.schema, rest, value));\n            else\n                throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);\n        }\n    }\n    /**\n     * Removes a value from the collection.\n     * @returns `true` if the item was found and removed.\n     */\n    deleteIn(path) {\n        const [key, ...rest] = path;\n        if (rest.length === 0)\n            return this.delete(key);\n        const node = this.get(key, true);\n        if (identity.isCollection(node))\n            return node.deleteIn(rest);\n        else\n            throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);\n    }\n    /**\n     * Returns item at `key`, or `undefined` if not found. By default unwraps\n     * scalar values from their surrounding node; to disable set `keepScalar` to\n     * `true` (collections are always returned intact).\n     */\n    getIn(path, keepScalar) {\n        const [key, ...rest] = path;\n        const node = this.get(key, true);\n        if (rest.length === 0)\n            return !keepScalar && identity.isScalar(node) ? node.value : node;\n        else\n            return identity.isCollection(node) ? node.getIn(rest, keepScalar) : undefined;\n    }\n    hasAllNullValues(allowScalar) {\n        return this.items.every(node => {\n            if (!identity.isPair(node))\n                return false;\n            const n = node.value;\n            return (n == null ||\n                (allowScalar &&\n                    identity.isScalar(n) &&\n                    n.value == null &&\n                    !n.commentBefore &&\n                    !n.comment &&\n                    !n.tag));\n        });\n    }\n    /**\n     * Checks if the collection includes a value with the key `key`.\n     */\n    hasIn(path) {\n        const [key, ...rest] = path;\n        if (rest.length === 0)\n            return this.has(key);\n        const node = this.get(key, true);\n        return identity.isCollection(node) ? node.hasIn(rest) : false;\n    }\n    /**\n     * Sets a value in this collection. For `!!set`, `value` needs to be a\n     * boolean to add/remove the item from the set.\n     */\n    setIn(path, value) {\n        const [key, ...rest] = path;\n        if (rest.length === 0) {\n            this.set(key, value);\n        }\n        else {\n            const node = this.get(key, true);\n            if (identity.isCollection(node))\n                node.setIn(rest, value);\n            else if (node === undefined && this.schema)\n                this.set(key, collectionFromPath(this.schema, rest, value));\n            else\n                throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);\n        }\n    }\n}\nCollection.maxFlowStringSingleLineLength = 60;\n\nexports.Collection = Collection;\nexports.collectionFromPath = collectionFromPath;\nexports.isEmptyPath = isEmptyPath;\n","'use strict';\n\nvar applyReviver = require('../doc/applyReviver.js');\nvar identity = require('./identity.js');\nvar toJS = require('./toJS.js');\n\nclass NodeBase {\n    constructor(type) {\n        Object.defineProperty(this, identity.NODE_TYPE, { value: type });\n    }\n    /** Create a copy of this node.  */\n    clone() {\n        const copy = Object.create(Object.getPrototypeOf(this), Object.getOwnPropertyDescriptors(this));\n        if (this.range)\n            copy.range = this.range.slice();\n        return copy;\n    }\n    /** A plain JavaScript representation of this node. */\n    toJS(doc, { mapAsMap, maxAliasCount, onAnchor, reviver } = {}) {\n        if (!identity.isDocument(doc))\n            throw new TypeError('A document argument is required');\n        const ctx = {\n            anchors: new Map(),\n            doc,\n            keep: true,\n            mapAsMap: mapAsMap === true,\n            mapKeyWarned: false,\n            maxAliasCount: typeof maxAliasCount === 'number' ? maxAliasCount : 100\n        };\n        const res = toJS.toJS(this, '', ctx);\n        if (typeof onAnchor === 'function')\n            for (const { count, res } of ctx.anchors.values())\n                onAnchor(res, count);\n        return typeof reviver === 'function'\n            ? applyReviver.applyReviver(reviver, { '': res }, '', res)\n            : res;\n    }\n}\n\nexports.NodeBase = NodeBase;\n","'use strict';\n\nvar createNode = require('../doc/createNode.js');\nvar stringifyPair = require('../stringify/stringifyPair.js');\nvar addPairToJSMap = require('./addPairToJSMap.js');\nvar identity = require('./identity.js');\n\nfunction createPair(key, value, ctx) {\n    const k = createNode.createNode(key, undefined, ctx);\n    const v = createNode.createNode(value, undefined, ctx);\n    return new Pair(k, v);\n}\nclass Pair {\n    constructor(key, value = null) {\n        Object.defineProperty(this, identity.NODE_TYPE, { value: identity.PAIR });\n        this.key = key;\n        this.value = value;\n    }\n    clone(schema) {\n        let { key, value } = this;\n        if (identity.isNode(key))\n            key = key.clone(schema);\n        if (identity.isNode(value))\n            value = value.clone(schema);\n        return new Pair(key, value);\n    }\n    toJSON(_, ctx) {\n        const pair = ctx?.mapAsMap ? new Map() : {};\n        return addPairToJSMap.addPairToJSMap(ctx, pair, this);\n    }\n    toString(ctx, onComment, onChompKeep) {\n        return ctx?.doc\n            ? stringifyPair.stringifyPair(this, ctx, onComment, onChompKeep)\n            : JSON.stringify(this);\n    }\n}\n\nexports.Pair = Pair;\nexports.createPair = createPair;\n","'use strict';\n\nvar identity = require('./identity.js');\nvar Node = require('./Node.js');\nvar toJS = require('./toJS.js');\n\nconst isScalarValue = (value) => !value || (typeof value !== 'function' && typeof value !== 'object');\nclass Scalar extends Node.NodeBase {\n    constructor(value) {\n        super(identity.SCALAR);\n        this.value = value;\n    }\n    toJSON(arg, ctx) {\n        return ctx?.keep ? this.value : toJS.toJS(this.value, arg, ctx);\n    }\n    toString() {\n        return String(this.value);\n    }\n}\nScalar.BLOCK_FOLDED = 'BLOCK_FOLDED';\nScalar.BLOCK_LITERAL = 'BLOCK_LITERAL';\nScalar.PLAIN = 'PLAIN';\nScalar.QUOTE_DOUBLE = 'QUOTE_DOUBLE';\nScalar.QUOTE_SINGLE = 'QUOTE_SINGLE';\n\nexports.Scalar = Scalar;\nexports.isScalarValue = isScalarValue;\n","'use strict';\n\nvar stringifyCollection = require('../stringify/stringifyCollection.js');\nvar addPairToJSMap = require('./addPairToJSMap.js');\nvar Collection = require('./Collection.js');\nvar identity = require('./identity.js');\nvar Pair = require('./Pair.js');\nvar Scalar = require('./Scalar.js');\n\nfunction findPair(items, key) {\n    const k = identity.isScalar(key) ? key.value : key;\n    for (const it of items) {\n        if (identity.isPair(it)) {\n            if (it.key === key || it.key === k)\n                return it;\n            if (identity.isScalar(it.key) && it.key.value === k)\n                return it;\n        }\n    }\n    return undefined;\n}\nclass YAMLMap extends Collection.Collection {\n    static get tagName() {\n        return 'tag:yaml.org,2002:map';\n    }\n    constructor(schema) {\n        super(identity.MAP, schema);\n        this.items = [];\n    }\n    /**\n     * A generic collection parsing method that can be extended\n     * to other node classes that inherit from YAMLMap\n     */\n    static from(schema, obj, ctx) {\n        const { keepUndefined, replacer } = ctx;\n        const map = new this(schema);\n        const add = (key, value) => {\n            if (typeof replacer === 'function')\n                value = replacer.call(obj, key, value);\n            else if (Array.isArray(replacer) && !replacer.includes(key))\n                return;\n            if (value !== undefined || keepUndefined)\n                map.items.push(Pair.createPair(key, value, ctx));\n        };\n        if (obj instanceof Map) {\n            for (const [key, value] of obj)\n                add(key, value);\n        }\n        else if (obj && typeof obj === 'object') {\n            for (const key of Object.keys(obj))\n                add(key, obj[key]);\n        }\n        if (typeof schema.sortMapEntries === 'function') {\n            map.items.sort(schema.sortMapEntries);\n        }\n        return map;\n    }\n    /**\n     * Adds a value to the collection.\n     *\n     * @param overwrite - If not set `true`, using a key that is already in the\n     *   collection will throw. Otherwise, overwrites the previous value.\n     */\n    add(pair, overwrite) {\n        let _pair;\n        if (identity.isPair(pair))\n            _pair = pair;\n        else if (!pair || typeof pair !== 'object' || !('key' in pair)) {\n            // In TypeScript, this never happens.\n            _pair = new Pair.Pair(pair, pair?.value);\n        }\n        else\n            _pair = new Pair.Pair(pair.key, pair.value);\n        const prev = findPair(this.items, _pair.key);\n        const sortEntries = this.schema?.sortMapEntries;\n        if (prev) {\n            if (!overwrite)\n                throw new Error(`Key ${_pair.key} already set`);\n            // For scalars, keep the old node & its comments and anchors\n            if (identity.isScalar(prev.value) && Scalar.isScalarValue(_pair.value))\n                prev.value.value = _pair.value;\n            else\n                prev.value = _pair.value;\n        }\n        else if (sortEntries) {\n            const i = this.items.findIndex(item => sortEntries(_pair, item) < 0);\n            if (i === -1)\n                this.items.push(_pair);\n            else\n                this.items.splice(i, 0, _pair);\n        }\n        else {\n            this.items.push(_pair);\n        }\n    }\n    delete(key) {\n        const it = findPair(this.items, key);\n        if (!it)\n            return false;\n        const del = this.items.splice(this.items.indexOf(it), 1);\n        return del.length > 0;\n    }\n    get(key, keepScalar) {\n        const it = findPair(this.items, key);\n        const node = it?.value;\n        return (!keepScalar && identity.isScalar(node) ? node.value : node) ?? undefined;\n    }\n    has(key) {\n        return !!findPair(this.items, key);\n    }\n    set(key, value) {\n        this.add(new Pair.Pair(key, value), true);\n    }\n    /**\n     * @param ctx - Conversion context, originally set in Document#toJS()\n     * @param {Class} Type - If set, forces the returned collection type\n     * @returns Instance of Type, Map, or Object\n     */\n    toJSON(_, ctx, Type) {\n        const map = Type ? new Type() : ctx?.mapAsMap ? new Map() : {};\n        if (ctx?.onCreate)\n            ctx.onCreate(map);\n        for (const item of this.items)\n            addPairToJSMap.addPairToJSMap(ctx, map, item);\n        return map;\n    }\n    toString(ctx, onComment, onChompKeep) {\n        if (!ctx)\n            return JSON.stringify(this);\n        for (const item of this.items) {\n            if (!identity.isPair(item))\n                throw new Error(`Map items must all be pairs; found ${JSON.stringify(item)} instead`);\n        }\n        if (!ctx.allNullValues && this.hasAllNullValues(false))\n            ctx = Object.assign({}, ctx, { allNullValues: true });\n        return stringifyCollection.stringifyCollection(this, ctx, {\n            blockItemPrefix: '',\n            flowChars: { start: '{', end: '}' },\n            itemIndent: ctx.indent || '',\n            onChompKeep,\n            onComment\n        });\n    }\n}\n\nexports.YAMLMap = YAMLMap;\nexports.findPair = findPair;\n","'use strict';\n\nvar createNode = require('../doc/createNode.js');\nvar stringifyCollection = require('../stringify/stringifyCollection.js');\nvar Collection = require('./Collection.js');\nvar identity = require('./identity.js');\nvar Scalar = require('./Scalar.js');\nvar toJS = require('./toJS.js');\n\nclass YAMLSeq extends Collection.Collection {\n    static get tagName() {\n        return 'tag:yaml.org,2002:seq';\n    }\n    constructor(schema) {\n        super(identity.SEQ, schema);\n        this.items = [];\n    }\n    add(value) {\n        this.items.push(value);\n    }\n    /**\n     * Removes a value from the collection.\n     *\n     * `key` must contain a representation of an integer for this to succeed.\n     * It may be wrapped in a `Scalar`.\n     *\n     * @returns `true` if the item was found and removed.\n     */\n    delete(key) {\n        const idx = asItemIndex(key);\n        if (typeof idx !== 'number')\n            return false;\n        const del = this.items.splice(idx, 1);\n        return del.length > 0;\n    }\n    get(key, keepScalar) {\n        const idx = asItemIndex(key);\n        if (typeof idx !== 'number')\n            return undefined;\n        const it = this.items[idx];\n        return !keepScalar && identity.isScalar(it) ? it.value : it;\n    }\n    /**\n     * Checks if the collection includes a value with the key `key`.\n     *\n     * `key` must contain a representation of an integer for this to succeed.\n     * It may be wrapped in a `Scalar`.\n     */\n    has(key) {\n        const idx = asItemIndex(key);\n        return typeof idx === 'number' && idx < this.items.length;\n    }\n    /**\n     * Sets a value in this collection. For `!!set`, `value` needs to be a\n     * boolean to add/remove the item from the set.\n     *\n     * If `key` does not contain a representation of an integer, this will throw.\n     * It may be wrapped in a `Scalar`.\n     */\n    set(key, value) {\n        const idx = asItemIndex(key);\n        if (typeof idx !== 'number')\n            throw new Error(`Expected a valid index, not ${key}.`);\n        const prev = this.items[idx];\n        if (identity.isScalar(prev) && Scalar.isScalarValue(value))\n            prev.value = value;\n        else\n            this.items[idx] = value;\n    }\n    toJSON(_, ctx) {\n        const seq = [];\n        if (ctx?.onCreate)\n            ctx.onCreate(seq);\n        let i = 0;\n        for (const item of this.items)\n            seq.push(toJS.toJS(item, String(i++), ctx));\n        return seq;\n    }\n    toString(ctx, onComment, onChompKeep) {\n        if (!ctx)\n            return JSON.stringify(this);\n        return stringifyCollection.stringifyCollection(this, ctx, {\n            blockItemPrefix: '- ',\n            flowChars: { start: '[', end: ']' },\n            itemIndent: (ctx.indent || '') + '  ',\n            onChompKeep,\n            onComment\n        });\n    }\n    static from(schema, obj, ctx) {\n        const { replacer } = ctx;\n        const seq = new this(schema);\n        if (obj && Symbol.iterator in Object(obj)) {\n            let i = 0;\n            for (let it of obj) {\n                if (typeof replacer === 'function') {\n                    const key = obj instanceof Set ? it : String(i++);\n                    it = replacer.call(obj, key, it);\n                }\n                seq.items.push(createNode.createNode(it, undefined, ctx));\n            }\n        }\n        return seq;\n    }\n}\nfunction asItemIndex(key) {\n    let idx = identity.isScalar(key) ? key.value : key;\n    if (idx && typeof idx === 'string')\n        idx = Number(idx);\n    return typeof idx === 'number' && Number.isInteger(idx) && idx >= 0\n        ? idx\n        : null;\n}\n\nexports.YAMLSeq = YAMLSeq;\n","'use strict';\n\nvar log = require('../log.js');\nvar stringify = require('../stringify/stringify.js');\nvar identity = require('./identity.js');\nvar Scalar = require('./Scalar.js');\nvar toJS = require('./toJS.js');\n\nconst MERGE_KEY = '<<';\nfunction addPairToJSMap(ctx, map, { key, value }) {\n    if (ctx?.doc.schema.merge && isMergeKey(key)) {\n        value = identity.isAlias(value) ? value.resolve(ctx.doc) : value;\n        if (identity.isSeq(value))\n            for (const it of value.items)\n                mergeToJSMap(ctx, map, it);\n        else if (Array.isArray(value))\n            for (const it of value)\n                mergeToJSMap(ctx, map, it);\n        else\n            mergeToJSMap(ctx, map, value);\n    }\n    else {\n        const jsKey = toJS.toJS(key, '', ctx);\n        if (map instanceof Map) {\n            map.set(jsKey, toJS.toJS(value, jsKey, ctx));\n        }\n        else if (map instanceof Set) {\n            map.add(jsKey);\n        }\n        else {\n            const stringKey = stringifyKey(key, jsKey, ctx);\n            const jsValue = toJS.toJS(value, stringKey, ctx);\n            if (stringKey in map)\n                Object.defineProperty(map, stringKey, {\n                    value: jsValue,\n                    writable: true,\n                    enumerable: true,\n                    configurable: true\n                });\n            else\n                map[stringKey] = jsValue;\n        }\n    }\n    return map;\n}\nconst isMergeKey = (key) => key === MERGE_KEY ||\n    (identity.isScalar(key) &&\n        key.value === MERGE_KEY &&\n        (!key.type || key.type === Scalar.Scalar.PLAIN));\n// If the value associated with a merge key is a single mapping node, each of\n// its key/value pairs is inserted into the current mapping, unless the key\n// already exists in it. If the value associated with the merge key is a\n// sequence, then this sequence is expected to contain mapping nodes and each\n// of these nodes is merged in turn according to its order in the sequence.\n// Keys in mapping nodes earlier in the sequence override keys specified in\n// later mapping nodes. -- http://yaml.org/type/merge.html\nfunction mergeToJSMap(ctx, map, value) {\n    const source = ctx && identity.isAlias(value) ? value.resolve(ctx.doc) : value;\n    if (!identity.isMap(source))\n        throw new Error('Merge sources must be maps or map aliases');\n    const srcMap = source.toJSON(null, ctx, Map);\n    for (const [key, value] of srcMap) {\n        if (map instanceof Map) {\n            if (!map.has(key))\n                map.set(key, value);\n        }\n        else if (map instanceof Set) {\n            map.add(key);\n        }\n        else if (!Object.prototype.hasOwnProperty.call(map, key)) {\n            Object.defineProperty(map, key, {\n                value,\n                writable: true,\n                enumerable: true,\n                configurable: true\n            });\n        }\n    }\n    return map;\n}\nfunction stringifyKey(key, jsKey, ctx) {\n    if (jsKey === null)\n        return '';\n    if (typeof jsKey !== 'object')\n        return String(jsKey);\n    if (identity.isNode(key) && ctx?.doc) {\n        const strCtx = stringify.createStringifyContext(ctx.doc, {});\n        strCtx.anchors = new Set();\n        for (const node of ctx.anchors.keys())\n            strCtx.anchors.add(node.anchor);\n        strCtx.inFlow = true;\n        strCtx.inStringifyKey = true;\n        const strKey = key.toString(strCtx);\n        if (!ctx.mapKeyWarned) {\n            let jsonStr = JSON.stringify(strKey);\n            if (jsonStr.length > 40)\n                jsonStr = jsonStr.substring(0, 36) + '...\"';\n            log.warn(ctx.doc.options.logLevel, `Keys with collection values will be stringified due to JS Object restrictions: ${jsonStr}. Set mapAsMap: true to use object keys.`);\n            ctx.mapKeyWarned = true;\n        }\n        return strKey;\n    }\n    return JSON.stringify(jsKey);\n}\n\nexports.addPairToJSMap = addPairToJSMap;\n","'use strict';\n\nconst ALIAS = Symbol.for('yaml.alias');\nconst DOC = Symbol.for('yaml.document');\nconst MAP = Symbol.for('yaml.map');\nconst PAIR = Symbol.for('yaml.pair');\nconst SCALAR = Symbol.for('yaml.scalar');\nconst SEQ = Symbol.for('yaml.seq');\nconst NODE_TYPE = Symbol.for('yaml.node.type');\nconst isAlias = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === ALIAS;\nconst isDocument = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === DOC;\nconst isMap = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === MAP;\nconst isPair = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === PAIR;\nconst isScalar = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === SCALAR;\nconst isSeq = (node) => !!node && typeof node === 'object' && node[NODE_TYPE] === SEQ;\nfunction isCollection(node) {\n    if (node && typeof node === 'object')\n        switch (node[NODE_TYPE]) {\n            case MAP:\n            case SEQ:\n                return true;\n        }\n    return false;\n}\nfunction isNode(node) {\n    if (node && typeof node === 'object')\n        switch (node[NODE_TYPE]) {\n            case ALIAS:\n            case MAP:\n            case SCALAR:\n            case SEQ:\n                return true;\n        }\n    return false;\n}\nconst hasAnchor = (node) => (isScalar(node) || isCollection(node)) && !!node.anchor;\n\nexports.ALIAS = ALIAS;\nexports.DOC = DOC;\nexports.MAP = MAP;\nexports.NODE_TYPE = NODE_TYPE;\nexports.PAIR = PAIR;\nexports.SCALAR = SCALAR;\nexports.SEQ = SEQ;\nexports.hasAnchor = hasAnchor;\nexports.isAlias = isAlias;\nexports.isCollection = isCollection;\nexports.isDocument = isDocument;\nexports.isMap = isMap;\nexports.isNode = isNode;\nexports.isPair = isPair;\nexports.isScalar = isScalar;\nexports.isSeq = isSeq;\n","'use strict';\n\nvar identity = require('./identity.js');\n\n/**\n * Recursively convert any node or its contents to native JavaScript\n *\n * @param value - The input value\n * @param arg - If `value` defines a `toJSON()` method, use this\n *   as its first argument\n * @param ctx - Conversion context, originally set in Document#toJS(). If\n *   `{ keep: true }` is not set, output should be suitable for JSON\n *   stringification.\n */\nfunction toJS(value, arg, ctx) {\n    // eslint-disable-next-line @typescript-eslint/no-unsafe-return\n    if (Array.isArray(value))\n        return value.map((v, i) => toJS(v, String(i), ctx));\n    if (value && typeof value.toJSON === 'function') {\n        // eslint-disable-next-line @typescript-eslint/no-unsafe-call\n        if (!ctx || !identity.hasAnchor(value))\n            return value.toJSON(arg, ctx);\n        const data = { aliasCount: 0, count: 1, res: undefined };\n        ctx.anchors.set(value, data);\n        ctx.onCreate = res => {\n            data.res = res;\n            delete ctx.onCreate;\n        };\n        const res = value.toJSON(arg, ctx);\n        if (ctx.onCreate)\n            ctx.onCreate(res);\n        return res;\n    }\n    if (typeof value === 'bigint' && !ctx?.keep)\n        return Number(value);\n    return value;\n}\n\nexports.toJS = toJS;\n","'use strict';\n\nvar resolveBlockScalar = require('../compose/resolve-block-scalar.js');\nvar resolveFlowScalar = require('../compose/resolve-flow-scalar.js');\nvar errors = require('../errors.js');\nvar stringifyString = require('../stringify/stringifyString.js');\n\nfunction resolveAsScalar(token, strict = true, onError) {\n    if (token) {\n        const _onError = (pos, code, message) => {\n            const offset = typeof pos === 'number' ? pos : Array.isArray(pos) ? pos[0] : pos.offset;\n            if (onError)\n                onError(offset, code, message);\n            else\n                throw new errors.YAMLParseError([offset, offset + 1], code, message);\n        };\n        switch (token.type) {\n            case 'scalar':\n            case 'single-quoted-scalar':\n            case 'double-quoted-scalar':\n                return resolveFlowScalar.resolveFlowScalar(token, strict, _onError);\n            case 'block-scalar':\n                return resolveBlockScalar.resolveBlockScalar(token, strict, _onError);\n        }\n    }\n    return null;\n}\n/**\n * Create a new scalar token with `value`\n *\n * Values that represent an actual string but may be parsed as a different type should use a `type` other than `'PLAIN'`,\n * as this function does not support any schema operations and won't check for such conflicts.\n *\n * @param value The string representation of the value, which will have its content properly indented.\n * @param context.end Comments and whitespace after the end of the value, or after the block scalar header. If undefined, a newline will be added.\n * @param context.implicitKey Being within an implicit key may affect the resolved type of the token's value.\n * @param context.indent The indent level of the token.\n * @param context.inFlow Is this scalar within a flow collection? This may affect the resolved type of the token's value.\n * @param context.offset The offset position of the token.\n * @param context.type The preferred type of the scalar token. If undefined, the previous type of the `token` will be used, defaulting to `'PLAIN'`.\n */\nfunction createScalarToken(value, context) {\n    const { implicitKey = false, indent, inFlow = false, offset = -1, type = 'PLAIN' } = context;\n    const source = stringifyString.stringifyString({ type, value }, {\n        implicitKey,\n        indent: indent > 0 ? ' '.repeat(indent) : '',\n        inFlow,\n        options: { blockQuote: true, lineWidth: -1 }\n    });\n    const end = context.end ?? [\n        { type: 'newline', offset: -1, indent, source: '\\n' }\n    ];\n    switch (source[0]) {\n        case '|':\n        case '>': {\n            const he = source.indexOf('\\n');\n            const head = source.substring(0, he);\n            const body = source.substring(he + 1) + '\\n';\n            const props = [\n                { type: 'block-scalar-header', offset, indent, source: head }\n            ];\n            if (!addEndtoBlockProps(props, end))\n                props.push({ type: 'newline', offset: -1, indent, source: '\\n' });\n            return { type: 'block-scalar', offset, indent, props, source: body };\n        }\n        case '\"':\n            return { type: 'double-quoted-scalar', offset, indent, source, end };\n        case \"'\":\n            return { type: 'single-quoted-scalar', offset, indent, source, end };\n        default:\n            return { type: 'scalar', offset, indent, source, end };\n    }\n}\n/**\n * Set the value of `token` to the given string `value`, overwriting any previous contents and type that it may have.\n *\n * Best efforts are made to retain any comments previously associated with the `token`,\n * though all contents within a collection's `items` will be overwritten.\n *\n * Values that represent an actual string but may be parsed as a different type should use a `type` other than `'PLAIN'`,\n * as this function does not support any schema operations and won't check for such conflicts.\n *\n * @param token Any token. If it does not include an `indent` value, the value will be stringified as if it were an implicit key.\n * @param value The string representation of the value, which will have its content properly indented.\n * @param context.afterKey In most cases, values after a key should have an additional level of indentation.\n * @param context.implicitKey Being within an implicit key may affect the resolved type of the token's value.\n * @param context.inFlow Being within a flow collection may affect the resolved type of the token's value.\n * @param context.type The preferred type of the scalar token. If undefined, the previous type of the `token` will be used, defaulting to `'PLAIN'`.\n */\nfunction setScalarValue(token, value, context = {}) {\n    let { afterKey = false, implicitKey = false, inFlow = false, type } = context;\n    let indent = 'indent' in token ? token.indent : null;\n    if (afterKey && typeof indent === 'number')\n        indent += 2;\n    if (!type)\n        switch (token.type) {\n            case 'single-quoted-scalar':\n                type = 'QUOTE_SINGLE';\n                break;\n            case 'double-quoted-scalar':\n                type = 'QUOTE_DOUBLE';\n                break;\n            case 'block-scalar': {\n                const header = token.props[0];\n                if (header.type !== 'block-scalar-header')\n                    throw new Error('Invalid block scalar header');\n                type = header.source[0] === '>' ? 'BLOCK_FOLDED' : 'BLOCK_LITERAL';\n                break;\n            }\n            default:\n                type = 'PLAIN';\n        }\n    const source = stringifyString.stringifyString({ type, value }, {\n        implicitKey: implicitKey || indent === null,\n        indent: indent !== null && indent > 0 ? ' '.repeat(indent) : '',\n        inFlow,\n        options: { blockQuote: true, lineWidth: -1 }\n    });\n    switch (source[0]) {\n        case '|':\n        case '>':\n            setBlockScalarValue(token, source);\n            break;\n        case '\"':\n            setFlowScalarValue(token, source, 'double-quoted-scalar');\n            break;\n        case \"'\":\n            setFlowScalarValue(token, source, 'single-quoted-scalar');\n            break;\n        default:\n            setFlowScalarValue(token, source, 'scalar');\n    }\n}\nfunction setBlockScalarValue(token, source) {\n    const he = source.indexOf('\\n');\n    const head = source.substring(0, he);\n    const body = source.substring(he + 1) + '\\n';\n    if (token.type === 'block-scalar') {\n        const header = token.props[0];\n        if (header.type !== 'block-scalar-header')\n            throw new Error('Invalid block scalar header');\n        header.source = head;\n        token.source = body;\n    }\n    else {\n        const { offset } = token;\n        const indent = 'indent' in token ? token.indent : -1;\n        const props = [\n            { type: 'block-scalar-header', offset, indent, source: head }\n        ];\n        if (!addEndtoBlockProps(props, 'end' in token ? token.end : undefined))\n            props.push({ type: 'newline', offset: -1, indent, source: '\\n' });\n        for (const key of Object.keys(token))\n            if (key !== 'type' && key !== 'offset')\n                delete token[key];\n        Object.assign(token, { type: 'block-scalar', indent, props, source: body });\n    }\n}\n/** @returns `true` if last token is a newline */\nfunction addEndtoBlockProps(props, end) {\n    if (end)\n        for (const st of end)\n            switch (st.type) {\n                case 'space':\n                case 'comment':\n                    props.push(st);\n                    break;\n                case 'newline':\n                    props.push(st);\n                    return true;\n            }\n    return false;\n}\nfunction setFlowScalarValue(token, source, type) {\n    switch (token.type) {\n        case 'scalar':\n        case 'double-quoted-scalar':\n        case 'single-quoted-scalar':\n            token.type = type;\n            token.source = source;\n            break;\n        case 'block-scalar': {\n            const end = token.props.slice(1);\n            let oa = source.length;\n            if (token.props[0].type === 'block-scalar-header')\n                oa -= token.props[0].source.length;\n            for (const tok of end)\n                tok.offset += oa;\n            delete token.props;\n            Object.assign(token, { type, source, end });\n            break;\n        }\n        case 'block-map':\n        case 'block-seq': {\n            const offset = token.offset + source.length;\n            const nl = { type: 'newline', offset, indent: token.indent, source: '\\n' };\n            delete token.items;\n            Object.assign(token, { type, source, end: [nl] });\n            break;\n        }\n        default: {\n            const indent = 'indent' in token ? token.indent : -1;\n            const end = 'end' in token && Array.isArray(token.end)\n                ? token.end.filter(st => st.type === 'space' ||\n                    st.type === 'comment' ||\n                    st.type === 'newline')\n                : [];\n            for (const key of Object.keys(token))\n                if (key !== 'type' && key !== 'offset')\n                    delete token[key];\n            Object.assign(token, { type, indent, source, end });\n        }\n    }\n}\n\nexports.createScalarToken = createScalarToken;\nexports.resolveAsScalar = resolveAsScalar;\nexports.setScalarValue = setScalarValue;\n","'use strict';\n\n/**\n * Stringify a CST document, token, or collection item\n *\n * Fair warning: This applies no validation whatsoever, and\n * simply concatenates the sources in their logical order.\n */\nconst stringify = (cst) => 'type' in cst ? stringifyToken(cst) : stringifyItem(cst);\nfunction stringifyToken(token) {\n    switch (token.type) {\n        case 'block-scalar': {\n            let res = '';\n            for (const tok of token.props)\n                res += stringifyToken(tok);\n            return res + token.source;\n        }\n        case 'block-map':\n        case 'block-seq': {\n            let res = '';\n            for (const item of token.items)\n                res += stringifyItem(item);\n            return res;\n        }\n        case 'flow-collection': {\n            let res = token.start.source;\n            for (const item of token.items)\n                res += stringifyItem(item);\n            for (const st of token.end)\n                res += st.source;\n            return res;\n        }\n        case 'document': {\n            let res = stringifyItem(token);\n            if (token.end)\n                for (const st of token.end)\n                    res += st.source;\n            return res;\n        }\n        default: {\n            let res = token.source;\n            if ('end' in token && token.end)\n                for (const st of token.end)\n                    res += st.source;\n            return res;\n        }\n    }\n}\nfunction stringifyItem({ start, key, sep, value }) {\n    let res = '';\n    for (const st of start)\n        res += st.source;\n    if (key)\n        res += stringifyToken(key);\n    if (sep)\n        for (const st of sep)\n            res += st.source;\n    if (value)\n        res += stringifyToken(value);\n    return res;\n}\n\nexports.stringify = stringify;\n","'use strict';\n\nconst BREAK = Symbol('break visit');\nconst SKIP = Symbol('skip children');\nconst REMOVE = Symbol('remove item');\n/**\n * Apply a visitor to a CST document or item.\n *\n * Walks through the tree (depth-first) starting from the root, calling a\n * `visitor` function with two arguments when entering each item:\n *   - `item`: The current item, which included the following members:\n *     - `start: SourceToken[]`  Source tokens before the key or value,\n *       possibly including its anchor or tag.\n *     - `key?: Token | null`  Set for pair values. May then be `null`, if\n *       the key before the `:` separator is empty.\n *     - `sep?: SourceToken[]`  Source tokens between the key and the value,\n *       which should include the `:` map value indicator if `value` is set.\n *     - `value?: Token`  The value of a sequence item, or of a map pair.\n *   - `path`: The steps from the root to the current node, as an array of\n *     `['key' | 'value', number]` tuples.\n *\n * The return value of the visitor may be used to control the traversal:\n *   - `undefined` (default): Do nothing and continue\n *   - `visit.SKIP`: Do not visit the children of this token, continue with\n *      next sibling\n *   - `visit.BREAK`: Terminate traversal completely\n *   - `visit.REMOVE`: Remove the current item, then continue with the next one\n *   - `number`: Set the index of the next step. This is useful especially if\n *     the index of the current token has changed.\n *   - `function`: Define the next visitor for this item. After the original\n *     visitor is called on item entry, next visitors are called after handling\n *     a non-empty `key` and when exiting the item.\n */\nfunction visit(cst, visitor) {\n    if ('type' in cst && cst.type === 'document')\n        cst = { start: cst.start, value: cst.value };\n    _visit(Object.freeze([]), cst, visitor);\n}\n// Without the `as symbol` casts, TS declares these in the `visit`\n// namespace using `var`, but then complains about that because\n// `unique symbol` must be `const`.\n/** Terminate visit traversal completely */\nvisit.BREAK = BREAK;\n/** Do not visit the children of the current item */\nvisit.SKIP = SKIP;\n/** Remove the current item */\nvisit.REMOVE = REMOVE;\n/** Find the item at `path` from `cst` as the root */\nvisit.itemAtPath = (cst, path) => {\n    let item = cst;\n    for (const [field, index] of path) {\n        const tok = item?.[field];\n        if (tok && 'items' in tok) {\n            item = tok.items[index];\n        }\n        else\n            return undefined;\n    }\n    return item;\n};\n/**\n * Get the immediate parent collection of the item at `path` from `cst` as the root.\n *\n * Throws an error if the collection is not found, which should never happen if the item itself exists.\n */\nvisit.parentCollection = (cst, path) => {\n    const parent = visit.itemAtPath(cst, path.slice(0, -1));\n    const field = path[path.length - 1][0];\n    const coll = parent?.[field];\n    if (coll && 'items' in coll)\n        return coll;\n    throw new Error('Parent collection not found');\n};\nfunction _visit(path, item, visitor) {\n    let ctrl = visitor(item, path);\n    if (typeof ctrl === 'symbol')\n        return ctrl;\n    for (const field of ['key', 'value']) {\n        const token = item[field];\n        if (token && 'items' in token) {\n            for (let i = 0; i < token.items.length; ++i) {\n                const ci = _visit(Object.freeze(path.concat([[field, i]])), token.items[i], visitor);\n                if (typeof ci === 'number')\n                    i = ci - 1;\n                else if (ci === BREAK)\n                    return BREAK;\n                else if (ci === REMOVE) {\n                    token.items.splice(i, 1);\n                    i -= 1;\n                }\n            }\n            if (typeof ctrl === 'function' && field === 'key')\n                ctrl = ctrl(item, path);\n        }\n    }\n    return typeof ctrl === 'function' ? ctrl(item, path) : ctrl;\n}\n\nexports.visit = visit;\n","'use strict';\n\nvar cstScalar = require('./cst-scalar.js');\nvar cstStringify = require('./cst-stringify.js');\nvar cstVisit = require('./cst-visit.js');\n\n/** The byte order mark */\nconst BOM = '\\u{FEFF}';\n/** Start of doc-mode */\nconst DOCUMENT = '\\x02'; // C0: Start of Text\n/** Unexpected end of flow-mode */\nconst FLOW_END = '\\x18'; // C0: Cancel\n/** Next token is a scalar value */\nconst SCALAR = '\\x1f'; // C0: Unit Separator\n/** @returns `true` if `token` is a flow or block collection */\nconst isCollection = (token) => !!token && 'items' in token;\n/** @returns `true` if `token` is a flow or block scalar; not an alias */\nconst isScalar = (token) => !!token &&\n    (token.type === 'scalar' ||\n        token.type === 'single-quoted-scalar' ||\n        token.type === 'double-quoted-scalar' ||\n        token.type === 'block-scalar');\n/* istanbul ignore next */\n/** Get a printable representation of a lexer token */\nfunction prettyToken(token) {\n    switch (token) {\n        case BOM:\n            return '<BOM>';\n        case DOCUMENT:\n            return '<DOC>';\n        case FLOW_END:\n            return '<FLOW_END>';\n        case SCALAR:\n            return '<SCALAR>';\n        default:\n            return JSON.stringify(token);\n    }\n}\n/** Identify the type of a lexer token. May return `null` for unknown tokens. */\nfunction tokenType(source) {\n    switch (source) {\n        case BOM:\n            return 'byte-order-mark';\n        case DOCUMENT:\n            return 'doc-mode';\n        case FLOW_END:\n            return 'flow-error-end';\n        case SCALAR:\n            return 'scalar';\n        case '---':\n            return 'doc-start';\n        case '...':\n            return 'doc-end';\n        case '':\n        case '\\n':\n        case '\\r\\n':\n            return 'newline';\n        case '-':\n            return 'seq-item-ind';\n        case '?':\n            return 'explicit-key-ind';\n        case ':':\n            return 'map-value-ind';\n        case '{':\n            return 'flow-map-start';\n        case '}':\n            return 'flow-map-end';\n        case '[':\n            return 'flow-seq-start';\n        case ']':\n            return 'flow-seq-end';\n        case ',':\n            return 'comma';\n    }\n    switch (source[0]) {\n        case ' ':\n        case '\\t':\n            return 'space';\n        case '#':\n            return 'comment';\n        case '%':\n            return 'directive-line';\n        case '*':\n            return 'alias';\n        case '&':\n            return 'anchor';\n        case '!':\n            return 'tag';\n        case \"'\":\n            return 'single-quoted-scalar';\n        case '\"':\n            return 'double-quoted-scalar';\n        case '|':\n        case '>':\n            return 'block-scalar-header';\n    }\n    return null;\n}\n\nexports.createScalarToken = cstScalar.createScalarToken;\nexports.resolveAsScalar = cstScalar.resolveAsScalar;\nexports.setScalarValue = cstScalar.setScalarValue;\nexports.stringify = cstStringify.stringify;\nexports.visit = cstVisit.visit;\nexports.BOM = BOM;\nexports.DOCUMENT = DOCUMENT;\nexports.FLOW_END = FLOW_END;\nexports.SCALAR = SCALAR;\nexports.isCollection = isCollection;\nexports.isScalar = isScalar;\nexports.prettyToken = prettyToken;\nexports.tokenType = tokenType;\n","'use strict';\n\nvar cst = require('./cst.js');\n\n/*\nSTART -> stream\n\nstream\n  directive -> line-end -> stream\n  indent + line-end -> stream\n  [else] -> line-start\n\nline-end\n  comment -> line-end\n  newline -> .\n  input-end -> END\n\nline-start\n  doc-start -> doc\n  doc-end -> stream\n  [else] -> indent -> block-start\n\nblock-start\n  seq-item-start -> block-start\n  explicit-key-start -> block-start\n  map-value-start -> block-start\n  [else] -> doc\n\ndoc\n  line-end -> line-start\n  spaces -> doc\n  anchor -> doc\n  tag -> doc\n  flow-start -> flow -> doc\n  flow-end -> error -> doc\n  seq-item-start -> error -> doc\n  explicit-key-start -> error -> doc\n  map-value-start -> doc\n  alias -> doc\n  quote-start -> quoted-scalar -> doc\n  block-scalar-header -> line-end -> block-scalar(min) -> line-start\n  [else] -> plain-scalar(false, min) -> doc\n\nflow\n  line-end -> flow\n  spaces -> flow\n  anchor -> flow\n  tag -> flow\n  flow-start -> flow -> flow\n  flow-end -> .\n  seq-item-start -> error -> flow\n  explicit-key-start -> flow\n  map-value-start -> flow\n  alias -> flow\n  quote-start -> quoted-scalar -> flow\n  comma -> flow\n  [else] -> plain-scalar(true, 0) -> flow\n\nquoted-scalar\n  quote-end -> .\n  [else] -> quoted-scalar\n\nblock-scalar(min)\n  newline + peek(indent < min) -> .\n  [else] -> block-scalar(min)\n\nplain-scalar(is-flow, min)\n  scalar-end(is-flow) -> .\n  peek(newline + (indent < min)) -> .\n  [else] -> plain-scalar(min)\n*/\nfunction isEmpty(ch) {\n    switch (ch) {\n        case undefined:\n        case ' ':\n        case '\\n':\n        case '\\r':\n        case '\\t':\n            return true;\n        default:\n            return false;\n    }\n}\nconst hexDigits = '0123456789ABCDEFabcdef'.split('');\nconst tagChars = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-#;/?:@&=+$_.!~*'()\".split('');\nconst invalidFlowScalarChars = ',[]{}'.split('');\nconst invalidAnchorChars = ' ,[]{}\\n\\r\\t'.split('');\nconst isNotAnchorChar = (ch) => !ch || invalidAnchorChars.includes(ch);\n/**\n * Splits an input string into lexical tokens, i.e. smaller strings that are\n * easily identifiable by `tokens.tokenType()`.\n *\n * Lexing starts always in a \"stream\" context. Incomplete input may be buffered\n * until a complete token can be emitted.\n *\n * In addition to slices of the original input, the following control characters\n * may also be emitted:\n *\n * - `\\x02` (Start of Text): A document starts with the next token\n * - `\\x18` (Cancel): Unexpected end of flow-mode (indicates an error)\n * - `\\x1f` (Unit Separator): Next token is a scalar value\n * - `\\u{FEFF}` (Byte order mark): Emitted separately outside documents\n */\nclass Lexer {\n    constructor() {\n        /**\n         * Flag indicating whether the end of the current buffer marks the end of\n         * all input\n         */\n        this.atEnd = false;\n        /**\n         * Explicit indent set in block scalar header, as an offset from the current\n         * minimum indent, so e.g. set to 1 from a header `|2+`. Set to -1 if not\n         * explicitly set.\n         */\n        this.blockScalarIndent = -1;\n        /**\n         * Block scalars that include a + (keep) chomping indicator in their header\n         * include trailing empty lines, which are otherwise excluded from the\n         * scalar's contents.\n         */\n        this.blockScalarKeep = false;\n        /** Current input */\n        this.buffer = '';\n        /**\n         * Flag noting whether the map value indicator : can immediately follow this\n         * node within a flow context.\n         */\n        this.flowKey = false;\n        /** Count of surrounding flow collection levels. */\n        this.flowLevel = 0;\n        /**\n         * Minimum level of indentation required for next lines to be parsed as a\n         * part of the current scalar value.\n         */\n        this.indentNext = 0;\n        /** Indentation level of the current line. */\n        this.indentValue = 0;\n        /** Position of the next \\n character. */\n        this.lineEndPos = null;\n        /** Stores the state of the lexer if reaching the end of incpomplete input */\n        this.next = null;\n        /** A pointer to `buffer`; the current position of the lexer. */\n        this.pos = 0;\n    }\n    /**\n     * Generate YAML tokens from the `source` string. If `incomplete`,\n     * a part of the last line may be left as a buffer for the next call.\n     *\n     * @returns A generator of lexical tokens\n     */\n    *lex(source, incomplete = false) {\n        if (source) {\n            this.buffer = this.buffer ? this.buffer + source : source;\n            this.lineEndPos = null;\n        }\n        this.atEnd = !incomplete;\n        let next = this.next ?? 'stream';\n        while (next && (incomplete || this.hasChars(1)))\n            next = yield* this.parseNext(next);\n    }\n    atLineEnd() {\n        let i = this.pos;\n        let ch = this.buffer[i];\n        while (ch === ' ' || ch === '\\t')\n            ch = this.buffer[++i];\n        if (!ch || ch === '#' || ch === '\\n')\n            return true;\n        if (ch === '\\r')\n            return this.buffer[i + 1] === '\\n';\n        return false;\n    }\n    charAt(n) {\n        return this.buffer[this.pos + n];\n    }\n    continueScalar(offset) {\n        let ch = this.buffer[offset];\n        if (this.indentNext > 0) {\n            let indent = 0;\n            while (ch === ' ')\n                ch = this.buffer[++indent + offset];\n            if (ch === '\\r') {\n                const next = this.buffer[indent + offset + 1];\n                if (next === '\\n' || (!next && !this.atEnd))\n                    return offset + indent + 1;\n            }\n            return ch === '\\n' || indent >= this.indentNext || (!ch && !this.atEnd)\n                ? offset + indent\n                : -1;\n        }\n        if (ch === '-' || ch === '.') {\n            const dt = this.buffer.substr(offset, 3);\n            if ((dt === '---' || dt === '...') && isEmpty(this.buffer[offset + 3]))\n                return -1;\n        }\n        return offset;\n    }\n    getLine() {\n        let end = this.lineEndPos;\n        if (typeof end !== 'number' || (end !== -1 && end < this.pos)) {\n            end = this.buffer.indexOf('\\n', this.pos);\n            this.lineEndPos = end;\n        }\n        if (end === -1)\n            return this.atEnd ? this.buffer.substring(this.pos) : null;\n        if (this.buffer[end - 1] === '\\r')\n            end -= 1;\n        return this.buffer.substring(this.pos, end);\n    }\n    hasChars(n) {\n        return this.pos + n <= this.buffer.length;\n    }\n    setNext(state) {\n        this.buffer = this.buffer.substring(this.pos);\n        this.pos = 0;\n        this.lineEndPos = null;\n        this.next = state;\n        return null;\n    }\n    peek(n) {\n        return this.buffer.substr(this.pos, n);\n    }\n    *parseNext(next) {\n        switch (next) {\n            case 'stream':\n                return yield* this.parseStream();\n            case 'line-start':\n                return yield* this.parseLineStart();\n            case 'block-start':\n                return yield* this.parseBlockStart();\n            case 'doc':\n                return yield* this.parseDocument();\n            case 'flow':\n                return yield* this.parseFlowCollection();\n            case 'quoted-scalar':\n                return yield* this.parseQuotedScalar();\n            case 'block-scalar':\n                return yield* this.parseBlockScalar();\n            case 'plain-scalar':\n                return yield* this.parsePlainScalar();\n        }\n    }\n    *parseStream() {\n        let line = this.getLine();\n        if (line === null)\n            return this.setNext('stream');\n        if (line[0] === cst.BOM) {\n            yield* this.pushCount(1);\n            line = line.substring(1);\n        }\n        if (line[0] === '%') {\n            let dirEnd = line.length;\n            const cs = line.indexOf('#');\n            if (cs !== -1) {\n                const ch = line[cs - 1];\n                if (ch === ' ' || ch === '\\t')\n                    dirEnd = cs - 1;\n            }\n            while (true) {\n                const ch = line[dirEnd - 1];\n                if (ch === ' ' || ch === '\\t')\n                    dirEnd -= 1;\n                else\n                    break;\n            }\n            const n = (yield* this.pushCount(dirEnd)) + (yield* this.pushSpaces(true));\n            yield* this.pushCount(line.length - n); // possible comment\n            this.pushNewline();\n            return 'stream';\n        }\n        if (this.atLineEnd()) {\n            const sp = yield* this.pushSpaces(true);\n            yield* this.pushCount(line.length - sp);\n            yield* this.pushNewline();\n            return 'stream';\n        }\n        yield cst.DOCUMENT;\n        return yield* this.parseLineStart();\n    }\n    *parseLineStart() {\n        const ch = this.charAt(0);\n        if (!ch && !this.atEnd)\n            return this.setNext('line-start');\n        if (ch === '-' || ch === '.') {\n            if (!this.atEnd && !this.hasChars(4))\n                return this.setNext('line-start');\n            const s = this.peek(3);\n            if (s === '---' && isEmpty(this.charAt(3))) {\n                yield* this.pushCount(3);\n                this.indentValue = 0;\n                this.indentNext = 0;\n                return 'doc';\n            }\n            else if (s === '...' && isEmpty(this.charAt(3))) {\n                yield* this.pushCount(3);\n                return 'stream';\n            }\n        }\n        this.indentValue = yield* this.pushSpaces(false);\n        if (this.indentNext > this.indentValue && !isEmpty(this.charAt(1)))\n            this.indentNext = this.indentValue;\n        return yield* this.parseBlockStart();\n    }\n    *parseBlockStart() {\n        const [ch0, ch1] = this.peek(2);\n        if (!ch1 && !this.atEnd)\n            return this.setNext('block-start');\n        if ((ch0 === '-' || ch0 === '?' || ch0 === ':') && isEmpty(ch1)) {\n            const n = (yield* this.pushCount(1)) + (yield* this.pushSpaces(true));\n            this.indentNext = this.indentValue + 1;\n            this.indentValue += n;\n            return yield* this.parseBlockStart();\n        }\n        return 'doc';\n    }\n    *parseDocument() {\n        yield* this.pushSpaces(true);\n        const line = this.getLine();\n        if (line === null)\n            return this.setNext('doc');\n        let n = yield* this.pushIndicators();\n        switch (line[n]) {\n            case '#':\n                yield* this.pushCount(line.length - n);\n            // fallthrough\n            case undefined:\n                yield* this.pushNewline();\n                return yield* this.parseLineStart();\n            case '{':\n            case '[':\n                yield* this.pushCount(1);\n                this.flowKey = false;\n                this.flowLevel = 1;\n                return 'flow';\n            case '}':\n            case ']':\n                // this is an error\n                yield* this.pushCount(1);\n                return 'doc';\n            case '*':\n                yield* this.pushUntil(isNotAnchorChar);\n                return 'doc';\n            case '\"':\n            case \"'\":\n                return yield* this.parseQuotedScalar();\n            case '|':\n            case '>':\n                n += yield* this.parseBlockScalarHeader();\n                n += yield* this.pushSpaces(true);\n                yield* this.pushCount(line.length - n);\n                yield* this.pushNewline();\n                return yield* this.parseBlockScalar();\n            default:\n                return yield* this.parsePlainScalar();\n        }\n    }\n    *parseFlowCollection() {\n        let nl, sp;\n        let indent = -1;\n        do {\n            nl = yield* this.pushNewline();\n            if (nl > 0) {\n                sp = yield* this.pushSpaces(false);\n                this.indentValue = indent = sp;\n            }\n            else {\n                sp = 0;\n            }\n            sp += yield* this.pushSpaces(true);\n        } while (nl + sp > 0);\n        const line = this.getLine();\n        if (line === null)\n            return this.setNext('flow');\n        if ((indent !== -1 && indent < this.indentNext && line[0] !== '#') ||\n            (indent === 0 &&\n                (line.startsWith('---') || line.startsWith('...')) &&\n                isEmpty(line[3]))) {\n            // Allowing for the terminal ] or } at the same (rather than greater)\n            // indent level as the initial [ or { is technically invalid, but\n            // failing here would be surprising to users.\n            const atFlowEndMarker = indent === this.indentNext - 1 &&\n                this.flowLevel === 1 &&\n                (line[0] === ']' || line[0] === '}');\n            if (!atFlowEndMarker) {\n                // this is an error\n                this.flowLevel = 0;\n                yield cst.FLOW_END;\n                return yield* this.parseLineStart();\n            }\n        }\n        let n = 0;\n        while (line[n] === ',') {\n            n += yield* this.pushCount(1);\n            n += yield* this.pushSpaces(true);\n            this.flowKey = false;\n        }\n        n += yield* this.pushIndicators();\n        switch (line[n]) {\n            case undefined:\n                return 'flow';\n            case '#':\n                yield* this.pushCount(line.length - n);\n                return 'flow';\n            case '{':\n            case '[':\n                yield* this.pushCount(1);\n                this.flowKey = false;\n                this.flowLevel += 1;\n                return 'flow';\n            case '}':\n            case ']':\n                yield* this.pushCount(1);\n                this.flowKey = true;\n                this.flowLevel -= 1;\n                return this.flowLevel ? 'flow' : 'doc';\n            case '*':\n                yield* this.pushUntil(isNotAnchorChar);\n                return 'flow';\n            case '\"':\n            case \"'\":\n                this.flowKey = true;\n                return yield* this.parseQuotedScalar();\n            case ':': {\n                const next = this.charAt(1);\n                if (this.flowKey || isEmpty(next) || next === ',') {\n                    this.flowKey = false;\n                    yield* this.pushCount(1);\n                    yield* this.pushSpaces(true);\n                    return 'flow';\n                }\n            }\n            // fallthrough\n            default:\n                this.flowKey = false;\n                return yield* this.parsePlainScalar();\n        }\n    }\n    *parseQuotedScalar() {\n        const quote = this.charAt(0);\n        let end = this.buffer.indexOf(quote, this.pos + 1);\n        if (quote === \"'\") {\n            while (end !== -1 && this.buffer[end + 1] === \"'\")\n                end = this.buffer.indexOf(\"'\", end + 2);\n        }\n        else {\n            // double-quote\n            while (end !== -1) {\n                let n = 0;\n                while (this.buffer[end - 1 - n] === '\\\\')\n                    n += 1;\n                if (n % 2 === 0)\n                    break;\n                end = this.buffer.indexOf('\"', end + 1);\n            }\n        }\n        // Only looking for newlines within the quotes\n        const qb = this.buffer.substring(0, end);\n        let nl = qb.indexOf('\\n', this.pos);\n        if (nl !== -1) {\n            while (nl !== -1) {\n                const cs = this.continueScalar(nl + 1);\n                if (cs === -1)\n                    break;\n                nl = qb.indexOf('\\n', cs);\n            }\n            if (nl !== -1) {\n                // this is an error caused by an unexpected unindent\n                end = nl - (qb[nl - 1] === '\\r' ? 2 : 1);\n            }\n        }\n        if (end === -1) {\n            if (!this.atEnd)\n                return this.setNext('quoted-scalar');\n            end = this.buffer.length;\n        }\n        yield* this.pushToIndex(end + 1, false);\n        return this.flowLevel ? 'flow' : 'doc';\n    }\n    *parseBlockScalarHeader() {\n        this.blockScalarIndent = -1;\n        this.blockScalarKeep = false;\n        let i = this.pos;\n        while (true) {\n            const ch = this.buffer[++i];\n            if (ch === '+')\n                this.blockScalarKeep = true;\n            else if (ch > '0' && ch <= '9')\n                this.blockScalarIndent = Number(ch) - 1;\n            else if (ch !== '-')\n                break;\n        }\n        return yield* this.pushUntil(ch => isEmpty(ch) || ch === '#');\n    }\n    *parseBlockScalar() {\n        let nl = this.pos - 1; // may be -1 if this.pos === 0\n        let indent = 0;\n        let ch;\n        loop: for (let i = this.pos; (ch = this.buffer[i]); ++i) {\n            switch (ch) {\n                case ' ':\n                    indent += 1;\n                    break;\n                case '\\n':\n                    nl = i;\n                    indent = 0;\n                    break;\n                case '\\r': {\n                    const next = this.buffer[i + 1];\n                    if (!next && !this.atEnd)\n                        return this.setNext('block-scalar');\n                    if (next === '\\n')\n                        break;\n                } // fallthrough\n                default:\n                    break loop;\n            }\n        }\n        if (!ch && !this.atEnd)\n            return this.setNext('block-scalar');\n        if (indent >= this.indentNext) {\n            if (this.blockScalarIndent === -1)\n                this.indentNext = indent;\n            else\n                this.indentNext += this.blockScalarIndent;\n            do {\n                const cs = this.continueScalar(nl + 1);\n                if (cs === -1)\n                    break;\n                nl = this.buffer.indexOf('\\n', cs);\n            } while (nl !== -1);\n            if (nl === -1) {\n                if (!this.atEnd)\n                    return this.setNext('block-scalar');\n                nl = this.buffer.length;\n            }\n        }\n        if (!this.blockScalarKeep) {\n            do {\n                let i = nl - 1;\n                let ch = this.buffer[i];\n                if (ch === '\\r')\n                    ch = this.buffer[--i];\n                const lastChar = i; // Drop the line if last char not more indented\n                while (ch === ' ' || ch === '\\t')\n                    ch = this.buffer[--i];\n                if (ch === '\\n' && i >= this.pos && i + 1 + indent > lastChar)\n                    nl = i;\n                else\n                    break;\n            } while (true);\n        }\n        yield cst.SCALAR;\n        yield* this.pushToIndex(nl + 1, true);\n        return yield* this.parseLineStart();\n    }\n    *parsePlainScalar() {\n        const inFlow = this.flowLevel > 0;\n        let end = this.pos - 1;\n        let i = this.pos - 1;\n        let ch;\n        while ((ch = this.buffer[++i])) {\n            if (ch === ':') {\n                const next = this.buffer[i + 1];\n                if (isEmpty(next) || (inFlow && next === ','))\n                    break;\n                end = i;\n            }\n            else if (isEmpty(ch)) {\n                let next = this.buffer[i + 1];\n                if (ch === '\\r') {\n                    if (next === '\\n') {\n                        i += 1;\n                        ch = '\\n';\n                        next = this.buffer[i + 1];\n                    }\n                    else\n                        end = i;\n                }\n                if (next === '#' || (inFlow && invalidFlowScalarChars.includes(next)))\n                    break;\n                if (ch === '\\n') {\n                    const cs = this.continueScalar(i + 1);\n                    if (cs === -1)\n                        break;\n                    i = Math.max(i, cs - 2); // to advance, but still account for ' #'\n                }\n            }\n            else {\n                if (inFlow && invalidFlowScalarChars.includes(ch))\n                    break;\n                end = i;\n            }\n        }\n        if (!ch && !this.atEnd)\n            return this.setNext('plain-scalar');\n        yield cst.SCALAR;\n        yield* this.pushToIndex(end + 1, true);\n        return inFlow ? 'flow' : 'doc';\n    }\n    *pushCount(n) {\n        if (n > 0) {\n            yield this.buffer.substr(this.pos, n);\n            this.pos += n;\n            return n;\n        }\n        return 0;\n    }\n    *pushToIndex(i, allowEmpty) {\n        const s = this.buffer.slice(this.pos, i);\n        if (s) {\n            yield s;\n            this.pos += s.length;\n            return s.length;\n        }\n        else if (allowEmpty)\n            yield '';\n        return 0;\n    }\n    *pushIndicators() {\n        switch (this.charAt(0)) {\n            case '!':\n                return ((yield* this.pushTag()) +\n                    (yield* this.pushSpaces(true)) +\n                    (yield* this.pushIndicators()));\n            case '&':\n                return ((yield* this.pushUntil(isNotAnchorChar)) +\n                    (yield* this.pushSpaces(true)) +\n                    (yield* this.pushIndicators()));\n            case '-': // this is an error\n            case '?': // this is an error outside flow collections\n            case ':': {\n                const inFlow = this.flowLevel > 0;\n                const ch1 = this.charAt(1);\n                if (isEmpty(ch1) || (inFlow && invalidFlowScalarChars.includes(ch1))) {\n                    if (!inFlow)\n                        this.indentNext = this.indentValue + 1;\n                    else if (this.flowKey)\n                        this.flowKey = false;\n                    return ((yield* this.pushCount(1)) +\n                        (yield* this.pushSpaces(true)) +\n                        (yield* this.pushIndicators()));\n                }\n            }\n        }\n        return 0;\n    }\n    *pushTag() {\n        if (this.charAt(1) === '<') {\n            let i = this.pos + 2;\n            let ch = this.buffer[i];\n            while (!isEmpty(ch) && ch !== '>')\n                ch = this.buffer[++i];\n            return yield* this.pushToIndex(ch === '>' ? i + 1 : i, false);\n        }\n        else {\n            let i = this.pos + 1;\n            let ch = this.buffer[i];\n            while (ch) {\n                if (tagChars.includes(ch))\n                    ch = this.buffer[++i];\n                else if (ch === '%' &&\n                    hexDigits.includes(this.buffer[i + 1]) &&\n                    hexDigits.includes(this.buffer[i + 2])) {\n                    ch = this.buffer[(i += 3)];\n                }\n                else\n                    break;\n            }\n            return yield* this.pushToIndex(i, false);\n        }\n    }\n    *pushNewline() {\n        const ch = this.buffer[this.pos];\n        if (ch === '\\n')\n            return yield* this.pushCount(1);\n        else if (ch === '\\r' && this.charAt(1) === '\\n')\n            return yield* this.pushCount(2);\n        else\n            return 0;\n    }\n    *pushSpaces(allowTabs) {\n        let i = this.pos - 1;\n        let ch;\n        do {\n            ch = this.buffer[++i];\n        } while (ch === ' ' || (allowTabs && ch === '\\t'));\n        const n = i - this.pos;\n        if (n > 0) {\n            yield this.buffer.substr(this.pos, n);\n            this.pos = i;\n        }\n        return n;\n    }\n    *pushUntil(test) {\n        let i = this.pos;\n        let ch = this.buffer[i];\n        while (!test(ch))\n            ch = this.buffer[++i];\n        return yield* this.pushToIndex(i, false);\n    }\n}\n\nexports.Lexer = Lexer;\n","'use strict';\n\n/**\n * Tracks newlines during parsing in order to provide an efficient API for\n * determining the one-indexed `{ line, col }` position for any offset\n * within the input.\n */\nclass LineCounter {\n    constructor() {\n        this.lineStarts = [];\n        /**\n         * Should be called in ascending order. Otherwise, call\n         * `lineCounter.lineStarts.sort()` before calling `linePos()`.\n         */\n        this.addNewLine = (offset) => this.lineStarts.push(offset);\n        /**\n         * Performs a binary search and returns the 1-indexed { line, col }\n         * position of `offset`. If `line === 0`, `addNewLine` has never been\n         * called or `offset` is before the first known newline.\n         */\n        this.linePos = (offset) => {\n            let low = 0;\n            let high = this.lineStarts.length;\n            while (low < high) {\n                const mid = (low + high) >> 1; // Math.floor((low + high) / 2)\n                if (this.lineStarts[mid] < offset)\n                    low = mid + 1;\n                else\n                    high = mid;\n            }\n            if (this.lineStarts[low] === offset)\n                return { line: low + 1, col: 1 };\n            if (low === 0)\n                return { line: 0, col: offset };\n            const start = this.lineStarts[low - 1];\n            return { line: low, col: offset - start + 1 };\n        };\n    }\n}\n\nexports.LineCounter = LineCounter;\n","'use strict';\n\nvar cst = require('./cst.js');\nvar lexer = require('./lexer.js');\n\nfunction includesToken(list, type) {\n    for (let i = 0; i < list.length; ++i)\n        if (list[i].type === type)\n            return true;\n    return false;\n}\nfunction findNonEmptyIndex(list) {\n    for (let i = 0; i < list.length; ++i) {\n        switch (list[i].type) {\n            case 'space':\n            case 'comment':\n            case 'newline':\n                break;\n            default:\n                return i;\n        }\n    }\n    return -1;\n}\nfunction isFlowToken(token) {\n    switch (token?.type) {\n        case 'alias':\n        case 'scalar':\n        case 'single-quoted-scalar':\n        case 'double-quoted-scalar':\n        case 'flow-collection':\n            return true;\n        default:\n            return false;\n    }\n}\nfunction getPrevProps(parent) {\n    switch (parent.type) {\n        case 'document':\n            return parent.start;\n        case 'block-map': {\n            const it = parent.items[parent.items.length - 1];\n            return it.sep ?? it.start;\n        }\n        case 'block-seq':\n            return parent.items[parent.items.length - 1].start;\n        /* istanbul ignore next should not happen */\n        default:\n            return [];\n    }\n}\n/** Note: May modify input array */\nfunction getFirstKeyStartProps(prev) {\n    if (prev.length === 0)\n        return [];\n    let i = prev.length;\n    loop: while (--i >= 0) {\n        switch (prev[i].type) {\n            case 'doc-start':\n            case 'explicit-key-ind':\n            case 'map-value-ind':\n            case 'seq-item-ind':\n            case 'newline':\n                break loop;\n        }\n    }\n    while (prev[++i]?.type === 'space') {\n        /* loop */\n    }\n    return prev.splice(i, prev.length);\n}\nfunction fixFlowSeqItems(fc) {\n    if (fc.start.type === 'flow-seq-start') {\n        for (const it of fc.items) {\n            if (it.sep &&\n                !it.value &&\n                !includesToken(it.start, 'explicit-key-ind') &&\n                !includesToken(it.sep, 'map-value-ind')) {\n                if (it.key)\n                    it.value = it.key;\n                delete it.key;\n                if (isFlowToken(it.value)) {\n                    if (it.value.end)\n                        Array.prototype.push.apply(it.value.end, it.sep);\n                    else\n                        it.value.end = it.sep;\n                }\n                else\n                    Array.prototype.push.apply(it.start, it.sep);\n                delete it.sep;\n            }\n        }\n    }\n}\n/**\n * A YAML concrete syntax tree (CST) parser\n *\n * ```ts\n * const src: string = ...\n * for (const token of new Parser().parse(src)) {\n *   // token: Token\n * }\n * ```\n *\n * To use the parser with a user-provided lexer:\n *\n * ```ts\n * function* parse(source: string, lexer: Lexer) {\n *   const parser = new Parser()\n *   for (const lexeme of lexer.lex(source))\n *     yield* parser.next(lexeme)\n *   yield* parser.end()\n * }\n *\n * const src: string = ...\n * const lexer = new Lexer()\n * for (const token of parse(src, lexer)) {\n *   // token: Token\n * }\n * ```\n */\nclass Parser {\n    /**\n     * @param onNewLine - If defined, called separately with the start position of\n     *   each new line (in `parse()`, including the start of input).\n     */\n    constructor(onNewLine) {\n        /** If true, space and sequence indicators count as indentation */\n        this.atNewLine = true;\n        /** If true, next token is a scalar value */\n        this.atScalar = false;\n        /** Current indentation level */\n        this.indent = 0;\n        /** Current offset since the start of parsing */\n        this.offset = 0;\n        /** On the same line with a block map key */\n        this.onKeyLine = false;\n        /** Top indicates the node that's currently being built */\n        this.stack = [];\n        /** The source of the current token, set in parse() */\n        this.source = '';\n        /** The type of the current token, set in parse() */\n        this.type = '';\n        // Must be defined after `next()`\n        this.lexer = new lexer.Lexer();\n        this.onNewLine = onNewLine;\n    }\n    /**\n     * Parse `source` as a YAML stream.\n     * If `incomplete`, a part of the last line may be left as a buffer for the next call.\n     *\n     * Errors are not thrown, but yielded as `{ type: 'error', message }` tokens.\n     *\n     * @returns A generator of tokens representing each directive, document, and other structure.\n     */\n    *parse(source, incomplete = false) {\n        if (this.onNewLine && this.offset === 0)\n            this.onNewLine(0);\n        for (const lexeme of this.lexer.lex(source, incomplete))\n            yield* this.next(lexeme);\n        if (!incomplete)\n            yield* this.end();\n    }\n    /**\n     * Advance the parser by the `source` of one lexical token.\n     */\n    *next(source) {\n        this.source = source;\n        if (process.env.LOG_TOKENS)\n            console.log('|', cst.prettyToken(source));\n        if (this.atScalar) {\n            this.atScalar = false;\n            yield* this.step();\n            this.offset += source.length;\n            return;\n        }\n        const type = cst.tokenType(source);\n        if (!type) {\n            const message = `Not a YAML token: ${source}`;\n            yield* this.pop({ type: 'error', offset: this.offset, message, source });\n            this.offset += source.length;\n        }\n        else if (type === 'scalar') {\n            this.atNewLine = false;\n            this.atScalar = true;\n            this.type = 'scalar';\n        }\n        else {\n            this.type = type;\n            yield* this.step();\n            switch (type) {\n                case 'newline':\n                    this.atNewLine = true;\n                    this.indent = 0;\n                    if (this.onNewLine)\n                        this.onNewLine(this.offset + source.length);\n                    break;\n                case 'space':\n                    if (this.atNewLine && source[0] === ' ')\n                        this.indent += source.length;\n                    break;\n                case 'explicit-key-ind':\n                case 'map-value-ind':\n                case 'seq-item-ind':\n                    if (this.atNewLine)\n                        this.indent += source.length;\n                    break;\n                case 'doc-mode':\n                case 'flow-error-end':\n                    return;\n                default:\n                    this.atNewLine = false;\n            }\n            this.offset += source.length;\n        }\n    }\n    /** Call at end of input to push out any remaining constructions */\n    *end() {\n        while (this.stack.length > 0)\n            yield* this.pop();\n    }\n    get sourceToken() {\n        const st = {\n            type: this.type,\n            offset: this.offset,\n            indent: this.indent,\n            source: this.source\n        };\n        return st;\n    }\n    *step() {\n        const top = this.peek(1);\n        if (this.type === 'doc-end' && (!top || top.type !== 'doc-end')) {\n            while (this.stack.length > 0)\n                yield* this.pop();\n            this.stack.push({\n                type: 'doc-end',\n                offset: this.offset,\n                source: this.source\n            });\n            return;\n        }\n        if (!top)\n            return yield* this.stream();\n        switch (top.type) {\n            case 'document':\n                return yield* this.document(top);\n            case 'alias':\n            case 'scalar':\n            case 'single-quoted-scalar':\n            case 'double-quoted-scalar':\n                return yield* this.scalar(top);\n            case 'block-scalar':\n                return yield* this.blockScalar(top);\n            case 'block-map':\n                return yield* this.blockMap(top);\n            case 'block-seq':\n                return yield* this.blockSequence(top);\n            case 'flow-collection':\n                return yield* this.flowCollection(top);\n            case 'doc-end':\n                return yield* this.documentEnd(top);\n        }\n        /* istanbul ignore next should not happen */\n        yield* this.pop();\n    }\n    peek(n) {\n        return this.stack[this.stack.length - n];\n    }\n    *pop(error) {\n        const token = error ?? this.stack.pop();\n        /* istanbul ignore if should not happen */\n        if (!token) {\n            const message = 'Tried to pop an empty stack';\n            yield { type: 'error', offset: this.offset, source: '', message };\n        }\n        else if (this.stack.length === 0) {\n            yield token;\n        }\n        else {\n            const top = this.peek(1);\n            if (token.type === 'block-scalar') {\n                // Block scalars use their parent rather than header indent\n                token.indent = 'indent' in top ? top.indent : 0;\n            }\n            else if (token.type === 'flow-collection' && top.type === 'document') {\n                // Ignore all indent for top-level flow collections\n                token.indent = 0;\n            }\n            if (token.type === 'flow-collection')\n                fixFlowSeqItems(token);\n            switch (top.type) {\n                case 'document':\n                    top.value = token;\n                    break;\n                case 'block-scalar':\n                    top.props.push(token); // error\n                    break;\n                case 'block-map': {\n                    const it = top.items[top.items.length - 1];\n                    if (it.value) {\n                        top.items.push({ start: [], key: token, sep: [] });\n                        this.onKeyLine = true;\n                        return;\n                    }\n                    else if (it.sep) {\n                        it.value = token;\n                    }\n                    else {\n                        Object.assign(it, { key: token, sep: [] });\n                        this.onKeyLine = !includesToken(it.start, 'explicit-key-ind');\n                        return;\n                    }\n                    break;\n                }\n                case 'block-seq': {\n                    const it = top.items[top.items.length - 1];\n                    if (it.value)\n                        top.items.push({ start: [], value: token });\n                    else\n                        it.value = token;\n                    break;\n                }\n                case 'flow-collection': {\n                    const it = top.items[top.items.length - 1];\n                    if (!it || it.value)\n                        top.items.push({ start: [], key: token, sep: [] });\n                    else if (it.sep)\n                        it.value = token;\n                    else\n                        Object.assign(it, { key: token, sep: [] });\n                    return;\n                }\n                /* istanbul ignore next should not happen */\n                default:\n                    yield* this.pop();\n                    yield* this.pop(token);\n            }\n            if ((top.type === 'document' ||\n                top.type === 'block-map' ||\n                top.type === 'block-seq') &&\n                (token.type === 'block-map' || token.type === 'block-seq')) {\n                const last = token.items[token.items.length - 1];\n                if (last &&\n                    !last.sep &&\n                    !last.value &&\n                    last.start.length > 0 &&\n                    findNonEmptyIndex(last.start) === -1 &&\n                    (token.indent === 0 ||\n                        last.start.every(st => st.type !== 'comment' || st.indent < token.indent))) {\n                    if (top.type === 'document')\n                        top.end = last.start;\n                    else\n                        top.items.push({ start: last.start });\n                    token.items.splice(-1, 1);\n                }\n            }\n        }\n    }\n    *stream() {\n        switch (this.type) {\n            case 'directive-line':\n                yield { type: 'directive', offset: this.offset, source: this.source };\n                return;\n            case 'byte-order-mark':\n            case 'space':\n            case 'comment':\n            case 'newline':\n                yield this.sourceToken;\n                return;\n            case 'doc-mode':\n            case 'doc-start': {\n                const doc = {\n                    type: 'document',\n                    offset: this.offset,\n                    start: []\n                };\n                if (this.type === 'doc-start')\n                    doc.start.push(this.sourceToken);\n                this.stack.push(doc);\n                return;\n            }\n        }\n        yield {\n            type: 'error',\n            offset: this.offset,\n            message: `Unexpected ${this.type} token in YAML stream`,\n            source: this.source\n        };\n    }\n    *document(doc) {\n        if (doc.value)\n            return yield* this.lineEnd(doc);\n        switch (this.type) {\n            case 'doc-start': {\n                if (findNonEmptyIndex(doc.start) !== -1) {\n                    yield* this.pop();\n                    yield* this.step();\n                }\n                else\n                    doc.start.push(this.sourceToken);\n                return;\n            }\n            case 'anchor':\n            case 'tag':\n            case 'space':\n            case 'comment':\n            case 'newline':\n                doc.start.push(this.sourceToken);\n                return;\n        }\n        const bv = this.startBlockValue(doc);\n        if (bv)\n            this.stack.push(bv);\n        else {\n            yield {\n                type: 'error',\n                offset: this.offset,\n                message: `Unexpected ${this.type} token in YAML document`,\n                source: this.source\n            };\n        }\n    }\n    *scalar(scalar) {\n        if (this.type === 'map-value-ind') {\n            const prev = getPrevProps(this.peek(2));\n            const start = getFirstKeyStartProps(prev);\n            let sep;\n            if (scalar.end) {\n                sep = scalar.end;\n                sep.push(this.sourceToken);\n                delete scalar.end;\n            }\n            else\n                sep = [this.sourceToken];\n            const map = {\n                type: 'block-map',\n                offset: scalar.offset,\n                indent: scalar.indent,\n                items: [{ start, key: scalar, sep }]\n            };\n            this.onKeyLine = true;\n            this.stack[this.stack.length - 1] = map;\n        }\n        else\n            yield* this.lineEnd(scalar);\n    }\n    *blockScalar(scalar) {\n        switch (this.type) {\n            case 'space':\n            case 'comment':\n            case 'newline':\n                scalar.props.push(this.sourceToken);\n                return;\n            case 'scalar':\n                scalar.source = this.source;\n                // block-scalar source includes trailing newline\n                this.atNewLine = true;\n                this.indent = 0;\n                if (this.onNewLine) {\n                    let nl = this.source.indexOf('\\n') + 1;\n                    while (nl !== 0) {\n                        this.onNewLine(this.offset + nl);\n                        nl = this.source.indexOf('\\n', nl) + 1;\n                    }\n                }\n                yield* this.pop();\n                break;\n            /* istanbul ignore next should not happen */\n            default:\n                yield* this.pop();\n                yield* this.step();\n        }\n    }\n    *blockMap(map) {\n        const it = map.items[map.items.length - 1];\n        // it.sep is true-ish if pair already has key or : separator\n        switch (this.type) {\n            case 'newline':\n                this.onKeyLine = false;\n                if (it.value) {\n                    const end = 'end' in it.value ? it.value.end : undefined;\n                    const last = Array.isArray(end) ? end[end.length - 1] : undefined;\n                    if (last?.type === 'comment')\n                        end?.push(this.sourceToken);\n                    else\n                        map.items.push({ start: [this.sourceToken] });\n                }\n                else if (it.sep) {\n                    it.sep.push(this.sourceToken);\n                }\n                else {\n                    it.start.push(this.sourceToken);\n                }\n                return;\n            case 'space':\n            case 'comment':\n                if (it.value) {\n                    map.items.push({ start: [this.sourceToken] });\n                }\n                else if (it.sep) {\n                    it.sep.push(this.sourceToken);\n                }\n                else {\n                    if (this.atIndentedComment(it.start, map.indent)) {\n                        const prev = map.items[map.items.length - 2];\n                        const end = prev?.value?.end;\n                        if (Array.isArray(end)) {\n                            Array.prototype.push.apply(end, it.start);\n                            end.push(this.sourceToken);\n                            map.items.pop();\n                            return;\n                        }\n                    }\n                    it.start.push(this.sourceToken);\n                }\n                return;\n        }\n        if (this.indent >= map.indent) {\n            const atNextItem = !this.onKeyLine &&\n                this.indent === map.indent &&\n                it.sep &&\n                this.type !== 'seq-item-ind';\n            // For empty nodes, assign newline-separated not indented empty tokens to following node\n            let start = [];\n            if (atNextItem && it.sep && !it.value) {\n                const nl = [];\n                for (let i = 0; i < it.sep.length; ++i) {\n                    const st = it.sep[i];\n                    switch (st.type) {\n                        case 'newline':\n                            nl.push(i);\n                            break;\n                        case 'space':\n                            break;\n                        case 'comment':\n                            if (st.indent > map.indent)\n                                nl.length = 0;\n                            break;\n                        default:\n                            nl.length = 0;\n                    }\n                }\n                if (nl.length >= 2)\n                    start = it.sep.splice(nl[1]);\n            }\n            switch (this.type) {\n                case 'anchor':\n                case 'tag':\n                    if (atNextItem || it.value) {\n                        start.push(this.sourceToken);\n                        map.items.push({ start });\n                        this.onKeyLine = true;\n                    }\n                    else if (it.sep) {\n                        it.sep.push(this.sourceToken);\n                    }\n                    else {\n                        it.start.push(this.sourceToken);\n                    }\n                    return;\n                case 'explicit-key-ind':\n                    if (!it.sep && !includesToken(it.start, 'explicit-key-ind')) {\n                        it.start.push(this.sourceToken);\n                    }\n                    else if (atNextItem || it.value) {\n                        start.push(this.sourceToken);\n                        map.items.push({ start });\n                    }\n                    else {\n                        this.stack.push({\n                            type: 'block-map',\n                            offset: this.offset,\n                            indent: this.indent,\n                            items: [{ start: [this.sourceToken] }]\n                        });\n                    }\n                    this.onKeyLine = true;\n                    return;\n                case 'map-value-ind':\n                    if (includesToken(it.start, 'explicit-key-ind')) {\n                        if (!it.sep) {\n                            if (includesToken(it.start, 'newline')) {\n                                Object.assign(it, { key: null, sep: [this.sourceToken] });\n                            }\n                            else {\n                                const start = getFirstKeyStartProps(it.start);\n                                this.stack.push({\n                                    type: 'block-map',\n                                    offset: this.offset,\n                                    indent: this.indent,\n                                    items: [{ start, key: null, sep: [this.sourceToken] }]\n                                });\n                            }\n                        }\n                        else if (it.value) {\n                            map.items.push({ start: [], key: null, sep: [this.sourceToken] });\n                        }\n                        else if (includesToken(it.sep, 'map-value-ind')) {\n                            this.stack.push({\n                                type: 'block-map',\n                                offset: this.offset,\n                                indent: this.indent,\n                                items: [{ start, key: null, sep: [this.sourceToken] }]\n                            });\n                        }\n                        else if (isFlowToken(it.key) &&\n                            !includesToken(it.sep, 'newline')) {\n                            const start = getFirstKeyStartProps(it.start);\n                            const key = it.key;\n                            const sep = it.sep;\n                            sep.push(this.sourceToken);\n                            // @ts-expect-error type guard is wrong here\n                            delete it.key, delete it.sep;\n                            this.stack.push({\n                                type: 'block-map',\n                                offset: this.offset,\n                                indent: this.indent,\n                                items: [{ start, key, sep }]\n                            });\n                        }\n                        else if (start.length > 0) {\n                            // Not actually at next item\n                            it.sep = it.sep.concat(start, this.sourceToken);\n                        }\n                        else {\n                            it.sep.push(this.sourceToken);\n                        }\n                    }\n                    else {\n                        if (!it.sep) {\n                            Object.assign(it, { key: null, sep: [this.sourceToken] });\n                        }\n                        else if (it.value || atNextItem) {\n                            map.items.push({ start, key: null, sep: [this.sourceToken] });\n                        }\n                        else if (includesToken(it.sep, 'map-value-ind')) {\n                            this.stack.push({\n                                type: 'block-map',\n                                offset: this.offset,\n                                indent: this.indent,\n                                items: [{ start: [], key: null, sep: [this.sourceToken] }]\n                            });\n                        }\n                        else {\n                            it.sep.push(this.sourceToken);\n                        }\n                    }\n                    this.onKeyLine = true;\n                    return;\n                case 'alias':\n                case 'scalar':\n                case 'single-quoted-scalar':\n                case 'double-quoted-scalar': {\n                    const fs = this.flowScalar(this.type);\n                    if (atNextItem || it.value) {\n                        map.items.push({ start, key: fs, sep: [] });\n                        this.onKeyLine = true;\n                    }\n                    else if (it.sep) {\n                        this.stack.push(fs);\n                    }\n                    else {\n                        Object.assign(it, { key: fs, sep: [] });\n                        this.onKeyLine = true;\n                    }\n                    return;\n                }\n                default: {\n                    const bv = this.startBlockValue(map);\n                    if (bv) {\n                        if (atNextItem &&\n                            bv.type !== 'block-seq' &&\n                            includesToken(it.start, 'explicit-key-ind')) {\n                            map.items.push({ start });\n                        }\n                        this.stack.push(bv);\n                        return;\n                    }\n                }\n            }\n        }\n        yield* this.pop();\n        yield* this.step();\n    }\n    *blockSequence(seq) {\n        const it = seq.items[seq.items.length - 1];\n        switch (this.type) {\n            case 'newline':\n                if (it.value) {\n                    const end = 'end' in it.value ? it.value.end : undefined;\n                    const last = Array.isArray(end) ? end[end.length - 1] : undefined;\n                    if (last?.type === 'comment')\n                        end?.push(this.sourceToken);\n                    else\n                        seq.items.push({ start: [this.sourceToken] });\n                }\n                else\n                    it.start.push(this.sourceToken);\n                return;\n            case 'space':\n            case 'comment':\n                if (it.value)\n                    seq.items.push({ start: [this.sourceToken] });\n                else {\n                    if (this.atIndentedComment(it.start, seq.indent)) {\n                        const prev = seq.items[seq.items.length - 2];\n                        const end = prev?.value?.end;\n                        if (Array.isArray(end)) {\n                            Array.prototype.push.apply(end, it.start);\n                            end.push(this.sourceToken);\n                            seq.items.pop();\n                            return;\n                        }\n                    }\n                    it.start.push(this.sourceToken);\n                }\n                return;\n            case 'anchor':\n            case 'tag':\n                if (it.value || this.indent <= seq.indent)\n                    break;\n                it.start.push(this.sourceToken);\n                return;\n            case 'seq-item-ind':\n                if (this.indent !== seq.indent)\n                    break;\n                if (it.value || includesToken(it.start, 'seq-item-ind'))\n                    seq.items.push({ start: [this.sourceToken] });\n                else\n                    it.start.push(this.sourceToken);\n                return;\n        }\n        if (this.indent > seq.indent) {\n            const bv = this.startBlockValue(seq);\n            if (bv) {\n                this.stack.push(bv);\n                return;\n            }\n        }\n        yield* this.pop();\n        yield* this.step();\n    }\n    *flowCollection(fc) {\n        const it = fc.items[fc.items.length - 1];\n        if (this.type === 'flow-error-end') {\n            let top;\n            do {\n                yield* this.pop();\n                top = this.peek(1);\n            } while (top && top.type === 'flow-collection');\n        }\n        else if (fc.end.length === 0) {\n            switch (this.type) {\n                case 'comma':\n                case 'explicit-key-ind':\n                    if (!it || it.sep)\n                        fc.items.push({ start: [this.sourceToken] });\n                    else\n                        it.start.push(this.sourceToken);\n                    return;\n                case 'map-value-ind':\n                    if (!it || it.value)\n                        fc.items.push({ start: [], key: null, sep: [this.sourceToken] });\n                    else if (it.sep)\n                        it.sep.push(this.sourceToken);\n                    else\n                        Object.assign(it, { key: null, sep: [this.sourceToken] });\n                    return;\n                case 'space':\n                case 'comment':\n                case 'newline':\n                case 'anchor':\n                case 'tag':\n                    if (!it || it.value)\n                        fc.items.push({ start: [this.sourceToken] });\n                    else if (it.sep)\n                        it.sep.push(this.sourceToken);\n                    else\n                        it.start.push(this.sourceToken);\n                    return;\n                case 'alias':\n                case 'scalar':\n                case 'single-quoted-scalar':\n                case 'double-quoted-scalar': {\n                    const fs = this.flowScalar(this.type);\n                    if (!it || it.value)\n                        fc.items.push({ start: [], key: fs, sep: [] });\n                    else if (it.sep)\n                        this.stack.push(fs);\n                    else\n                        Object.assign(it, { key: fs, sep: [] });\n                    return;\n                }\n                case 'flow-map-end':\n                case 'flow-seq-end':\n                    fc.end.push(this.sourceToken);\n                    return;\n            }\n            const bv = this.startBlockValue(fc);\n            /* istanbul ignore else should not happen */\n            if (bv)\n                this.stack.push(bv);\n            else {\n                yield* this.pop();\n                yield* this.step();\n            }\n        }\n        else {\n            const parent = this.peek(2);\n            if (parent.type === 'block-map' &&\n                ((this.type === 'map-value-ind' && parent.indent === fc.indent) ||\n                    (this.type === 'newline' &&\n                        !parent.items[parent.items.length - 1].sep))) {\n                yield* this.pop();\n                yield* this.step();\n            }\n            else if (this.type === 'map-value-ind' &&\n                parent.type !== 'flow-collection') {\n                const prev = getPrevProps(parent);\n                const start = getFirstKeyStartProps(prev);\n                fixFlowSeqItems(fc);\n                const sep = fc.end.splice(1, fc.end.length);\n                sep.push(this.sourceToken);\n                const map = {\n                    type: 'block-map',\n                    offset: fc.offset,\n                    indent: fc.indent,\n                    items: [{ start, key: fc, sep }]\n                };\n                this.onKeyLine = true;\n                this.stack[this.stack.length - 1] = map;\n            }\n            else {\n                yield* this.lineEnd(fc);\n            }\n        }\n    }\n    flowScalar(type) {\n        if (this.onNewLine) {\n            let nl = this.source.indexOf('\\n') + 1;\n            while (nl !== 0) {\n                this.onNewLine(this.offset + nl);\n                nl = this.source.indexOf('\\n', nl) + 1;\n            }\n        }\n        return {\n            type,\n            offset: this.offset,\n            indent: this.indent,\n            source: this.source\n        };\n    }\n    startBlockValue(parent) {\n        switch (this.type) {\n            case 'alias':\n            case 'scalar':\n            case 'single-quoted-scalar':\n            case 'double-quoted-scalar':\n                return this.flowScalar(this.type);\n            case 'block-scalar-header':\n                return {\n                    type: 'block-scalar',\n                    offset: this.offset,\n                    indent: this.indent,\n                    props: [this.sourceToken],\n                    source: ''\n                };\n            case 'flow-map-start':\n            case 'flow-seq-start':\n                return {\n                    type: 'flow-collection',\n                    offset: this.offset,\n                    indent: this.indent,\n                    start: this.sourceToken,\n                    items: [],\n                    end: []\n                };\n            case 'seq-item-ind':\n                return {\n                    type: 'block-seq',\n                    offset: this.offset,\n                    indent: this.indent,\n                    items: [{ start: [this.sourceToken] }]\n                };\n            case 'explicit-key-ind': {\n                this.onKeyLine = true;\n                const prev = getPrevProps(parent);\n                const start = getFirstKeyStartProps(prev);\n                start.push(this.sourceToken);\n                return {\n                    type: 'block-map',\n                    offset: this.offset,\n                    indent: this.indent,\n                    items: [{ start }]\n                };\n            }\n            case 'map-value-ind': {\n                this.onKeyLine = true;\n                const prev = getPrevProps(parent);\n                const start = getFirstKeyStartProps(prev);\n                return {\n                    type: 'block-map',\n                    offset: this.offset,\n                    indent: this.indent,\n                    items: [{ start, key: null, sep: [this.sourceToken] }]\n                };\n            }\n        }\n        return null;\n    }\n    atIndentedComment(start, indent) {\n        if (this.type !== 'comment')\n            return false;\n        if (this.indent <= indent)\n            return false;\n        return start.every(st => st.type === 'newline' || st.type === 'space');\n    }\n    *documentEnd(docEnd) {\n        if (this.type !== 'doc-mode') {\n            if (docEnd.end)\n                docEnd.end.push(this.sourceToken);\n            else\n                docEnd.end = [this.sourceToken];\n            if (this.type === 'newline')\n                yield* this.pop();\n        }\n    }\n    *lineEnd(token) {\n        switch (this.type) {\n            case 'comma':\n            case 'doc-start':\n            case 'doc-end':\n            case 'flow-seq-end':\n            case 'flow-map-end':\n            case 'map-value-ind':\n                yield* this.pop();\n                yield* this.step();\n                break;\n            case 'newline':\n                this.onKeyLine = false;\n            // fallthrough\n            case 'space':\n            case 'comment':\n            default:\n                // all other values are errors\n                if (token.end)\n                    token.end.push(this.sourceToken);\n                else\n                    token.end = [this.sourceToken];\n                if (this.type === 'newline')\n                    yield* this.pop();\n        }\n    }\n}\n\nexports.Parser = Parser;\n","'use strict';\n\nvar composer = require('./compose/composer.js');\nvar Document = require('./doc/Document.js');\nvar errors = require('./errors.js');\nvar log = require('./log.js');\nvar lineCounter = require('./parse/line-counter.js');\nvar parser = require('./parse/parser.js');\n\nfunction parseOptions(options) {\n    const prettyErrors = options.prettyErrors !== false;\n    const lineCounter$1 = options.lineCounter || (prettyErrors && new lineCounter.LineCounter()) || null;\n    return { lineCounter: lineCounter$1, prettyErrors };\n}\n/**\n * Parse the input as a stream of YAML documents.\n *\n * Documents should be separated from each other by `...` or `---` marker lines.\n *\n * @returns If an empty `docs` array is returned, it will be of type\n *   EmptyStream and contain additional stream information. In\n *   TypeScript, you should use `'empty' in docs` as a type guard for it.\n */\nfunction parseAllDocuments(source, options = {}) {\n    const { lineCounter, prettyErrors } = parseOptions(options);\n    const parser$1 = new parser.Parser(lineCounter?.addNewLine);\n    const composer$1 = new composer.Composer(options);\n    const docs = Array.from(composer$1.compose(parser$1.parse(source)));\n    if (prettyErrors && lineCounter)\n        for (const doc of docs) {\n            doc.errors.forEach(errors.prettifyError(source, lineCounter));\n            doc.warnings.forEach(errors.prettifyError(source, lineCounter));\n        }\n    if (docs.length > 0)\n        return docs;\n    return Object.assign([], { empty: true }, composer$1.streamInfo());\n}\n/** Parse an input string into a single YAML.Document */\nfunction parseDocument(source, options = {}) {\n    const { lineCounter, prettyErrors } = parseOptions(options);\n    const parser$1 = new parser.Parser(lineCounter?.addNewLine);\n    const composer$1 = new composer.Composer(options);\n    // `doc` is always set by compose.end(true) at the very latest\n    let doc = null;\n    for (const _doc of composer$1.compose(parser$1.parse(source), true, source.length)) {\n        if (!doc)\n            doc = _doc;\n        else if (doc.options.logLevel !== 'silent') {\n            doc.errors.push(new errors.YAMLParseError(_doc.range.slice(0, 2), 'MULTIPLE_DOCS', 'Source contains multiple documents; please use YAML.parseAllDocuments()'));\n            break;\n        }\n    }\n    if (prettyErrors && lineCounter) {\n        doc.errors.forEach(errors.prettifyError(source, lineCounter));\n        doc.warnings.forEach(errors.prettifyError(source, lineCounter));\n    }\n    return doc;\n}\nfunction parse(src, reviver, options) {\n    let _reviver = undefined;\n    if (typeof reviver === 'function') {\n        _reviver = reviver;\n    }\n    else if (options === undefined && reviver && typeof reviver === 'object') {\n        options = reviver;\n    }\n    const doc = parseDocument(src, options);\n    if (!doc)\n        return null;\n    doc.warnings.forEach(warning => log.warn(doc.options.logLevel, warning));\n    if (doc.errors.length > 0) {\n        if (doc.options.logLevel !== 'silent')\n            throw doc.errors[0];\n        else\n            doc.errors = [];\n    }\n    return doc.toJS(Object.assign({ reviver: _reviver }, options));\n}\nfunction stringify(value, replacer, options) {\n    let _replacer = null;\n    if (typeof replacer === 'function' || Array.isArray(replacer)) {\n        _replacer = replacer;\n    }\n    else if (options === undefined && replacer) {\n        options = replacer;\n    }\n    if (typeof options === 'string')\n        options = options.length;\n    if (typeof options === 'number') {\n        const indent = Math.round(options);\n        options = indent < 1 ? undefined : indent > 8 ? { indent: 8 } : { indent };\n    }\n    if (value === undefined) {\n        const { keepUndefined } = options ?? replacer ?? {};\n        if (!keepUndefined)\n            return undefined;\n    }\n    return new Document.Document(value, _replacer, options).toString(options);\n}\n\nexports.parse = parse;\nexports.parseAllDocuments = parseAllDocuments;\nexports.parseDocument = parseDocument;\nexports.stringify = stringify;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar map = require('./common/map.js');\nvar seq = require('./common/seq.js');\nvar string = require('./common/string.js');\nvar tags = require('./tags.js');\n\nconst sortMapEntriesByKey = (a, b) => a.key < b.key ? -1 : a.key > b.key ? 1 : 0;\nclass Schema {\n    constructor({ compat, customTags, merge, resolveKnownTags, schema, sortMapEntries, toStringDefaults }) {\n        this.compat = Array.isArray(compat)\n            ? tags.getTags(compat, 'compat')\n            : compat\n                ? tags.getTags(null, compat)\n                : null;\n        this.merge = !!merge;\n        this.name = (typeof schema === 'string' && schema) || 'core';\n        this.knownTags = resolveKnownTags ? tags.coreKnownTags : {};\n        this.tags = tags.getTags(customTags, this.name);\n        this.toStringOptions = toStringDefaults ?? null;\n        Object.defineProperty(this, identity.MAP, { value: map.map });\n        Object.defineProperty(this, identity.SCALAR, { value: string.string });\n        Object.defineProperty(this, identity.SEQ, { value: seq.seq });\n        // Used by createMap()\n        this.sortMapEntries =\n            typeof sortMapEntries === 'function'\n                ? sortMapEntries\n                : sortMapEntries === true\n                    ? sortMapEntriesByKey\n                    : null;\n    }\n    clone() {\n        const copy = Object.create(Schema.prototype, Object.getOwnPropertyDescriptors(this));\n        copy.tags = this.tags.slice();\n        return copy;\n    }\n}\n\nexports.Schema = Schema;\n","'use strict';\n\nvar identity = require('../../nodes/identity.js');\nvar YAMLMap = require('../../nodes/YAMLMap.js');\n\nconst map = {\n    collection: 'map',\n    default: true,\n    nodeClass: YAMLMap.YAMLMap,\n    tag: 'tag:yaml.org,2002:map',\n    resolve(map, onError) {\n        if (!identity.isMap(map))\n            onError('Expected a mapping for this tag');\n        return map;\n    },\n    createNode: (schema, obj, ctx) => YAMLMap.YAMLMap.from(schema, obj, ctx)\n};\n\nexports.map = map;\n","'use strict';\n\nvar Scalar = require('../../nodes/Scalar.js');\n\nconst nullTag = {\n    identify: value => value == null,\n    createNode: () => new Scalar.Scalar(null),\n    default: true,\n    tag: 'tag:yaml.org,2002:null',\n    test: /^(?:~|[Nn]ull|NULL)?$/,\n    resolve: () => new Scalar.Scalar(null),\n    stringify: ({ source }, ctx) => typeof source === 'string' && nullTag.test.test(source)\n        ? source\n        : ctx.options.nullStr\n};\n\nexports.nullTag = nullTag;\n","'use strict';\n\nvar identity = require('../../nodes/identity.js');\nvar YAMLSeq = require('../../nodes/YAMLSeq.js');\n\nconst seq = {\n    collection: 'seq',\n    default: true,\n    nodeClass: YAMLSeq.YAMLSeq,\n    tag: 'tag:yaml.org,2002:seq',\n    resolve(seq, onError) {\n        if (!identity.isSeq(seq))\n            onError('Expected a sequence for this tag');\n        return seq;\n    },\n    createNode: (schema, obj, ctx) => YAMLSeq.YAMLSeq.from(schema, obj, ctx)\n};\n\nexports.seq = seq;\n","'use strict';\n\nvar stringifyString = require('../../stringify/stringifyString.js');\n\nconst string = {\n    identify: value => typeof value === 'string',\n    default: true,\n    tag: 'tag:yaml.org,2002:str',\n    resolve: str => str,\n    stringify(item, ctx, onComment, onChompKeep) {\n        ctx = Object.assign({ actualString: true }, ctx);\n        return stringifyString.stringifyString(item, ctx, onComment, onChompKeep);\n    }\n};\n\nexports.string = string;\n","'use strict';\n\nvar Scalar = require('../../nodes/Scalar.js');\n\nconst boolTag = {\n    identify: value => typeof value === 'boolean',\n    default: true,\n    tag: 'tag:yaml.org,2002:bool',\n    test: /^(?:[Tt]rue|TRUE|[Ff]alse|FALSE)$/,\n    resolve: str => new Scalar.Scalar(str[0] === 't' || str[0] === 'T'),\n    stringify({ source, value }, ctx) {\n        if (source && boolTag.test.test(source)) {\n            const sv = source[0] === 't' || source[0] === 'T';\n            if (value === sv)\n                return source;\n        }\n        return value ? ctx.options.trueStr : ctx.options.falseStr;\n    }\n};\n\nexports.boolTag = boolTag;\n","'use strict';\n\nvar Scalar = require('../../nodes/Scalar.js');\nvar stringifyNumber = require('../../stringify/stringifyNumber.js');\n\nconst floatNaN = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    test: /^(?:[-+]?\\.(?:inf|Inf|INF|nan|NaN|NAN))$/,\n    resolve: str => str.slice(-3).toLowerCase() === 'nan'\n        ? NaN\n        : str[0] === '-'\n            ? Number.NEGATIVE_INFINITY\n            : Number.POSITIVE_INFINITY,\n    stringify: stringifyNumber.stringifyNumber\n};\nconst floatExp = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    format: 'EXP',\n    test: /^[-+]?(?:\\.[0-9]+|[0-9]+(?:\\.[0-9]*)?)[eE][-+]?[0-9]+$/,\n    resolve: str => parseFloat(str),\n    stringify(node) {\n        const num = Number(node.value);\n        return isFinite(num) ? num.toExponential() : stringifyNumber.stringifyNumber(node);\n    }\n};\nconst float = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    test: /^[-+]?(?:\\.[0-9]+|[0-9]+\\.[0-9]*)$/,\n    resolve(str) {\n        const node = new Scalar.Scalar(parseFloat(str));\n        const dot = str.indexOf('.');\n        if (dot !== -1 && str[str.length - 1] === '0')\n            node.minFractionDigits = str.length - dot - 1;\n        return node;\n    },\n    stringify: stringifyNumber.stringifyNumber\n};\n\nexports.float = float;\nexports.floatExp = floatExp;\nexports.floatNaN = floatNaN;\n","'use strict';\n\nvar stringifyNumber = require('../../stringify/stringifyNumber.js');\n\nconst intIdentify = (value) => typeof value === 'bigint' || Number.isInteger(value);\nconst intResolve = (str, offset, radix, { intAsBigInt }) => (intAsBigInt ? BigInt(str) : parseInt(str.substring(offset), radix));\nfunction intStringify(node, radix, prefix) {\n    const { value } = node;\n    if (intIdentify(value) && value >= 0)\n        return prefix + value.toString(radix);\n    return stringifyNumber.stringifyNumber(node);\n}\nconst intOct = {\n    identify: value => intIdentify(value) && value >= 0,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'OCT',\n    test: /^0o[0-7]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 2, 8, opt),\n    stringify: node => intStringify(node, 8, '0o')\n};\nconst int = {\n    identify: intIdentify,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    test: /^[-+]?[0-9]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 0, 10, opt),\n    stringify: stringifyNumber.stringifyNumber\n};\nconst intHex = {\n    identify: value => intIdentify(value) && value >= 0,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'HEX',\n    test: /^0x[0-9a-fA-F]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 2, 16, opt),\n    stringify: node => intStringify(node, 16, '0x')\n};\n\nexports.int = int;\nexports.intHex = intHex;\nexports.intOct = intOct;\n","'use strict';\n\nvar map = require('../common/map.js');\nvar _null = require('../common/null.js');\nvar seq = require('../common/seq.js');\nvar string = require('../common/string.js');\nvar bool = require('./bool.js');\nvar float = require('./float.js');\nvar int = require('./int.js');\n\nconst schema = [\n    map.map,\n    seq.seq,\n    string.string,\n    _null.nullTag,\n    bool.boolTag,\n    int.intOct,\n    int.int,\n    int.intHex,\n    float.floatNaN,\n    float.floatExp,\n    float.float\n];\n\nexports.schema = schema;\n","'use strict';\n\nvar Scalar = require('../../nodes/Scalar.js');\nvar map = require('../common/map.js');\nvar seq = require('../common/seq.js');\n\nfunction intIdentify(value) {\n    return typeof value === 'bigint' || Number.isInteger(value);\n}\nconst stringifyJSON = ({ value }) => JSON.stringify(value);\nconst jsonScalars = [\n    {\n        identify: value => typeof value === 'string',\n        default: true,\n        tag: 'tag:yaml.org,2002:str',\n        resolve: str => str,\n        stringify: stringifyJSON\n    },\n    {\n        identify: value => value == null,\n        createNode: () => new Scalar.Scalar(null),\n        default: true,\n        tag: 'tag:yaml.org,2002:null',\n        test: /^null$/,\n        resolve: () => null,\n        stringify: stringifyJSON\n    },\n    {\n        identify: value => typeof value === 'boolean',\n        default: true,\n        tag: 'tag:yaml.org,2002:bool',\n        test: /^true|false$/,\n        resolve: str => str === 'true',\n        stringify: stringifyJSON\n    },\n    {\n        identify: intIdentify,\n        default: true,\n        tag: 'tag:yaml.org,2002:int',\n        test: /^-?(?:0|[1-9][0-9]*)$/,\n        resolve: (str, _onError, { intAsBigInt }) => intAsBigInt ? BigInt(str) : parseInt(str, 10),\n        stringify: ({ value }) => intIdentify(value) ? value.toString() : JSON.stringify(value)\n    },\n    {\n        identify: value => typeof value === 'number',\n        default: true,\n        tag: 'tag:yaml.org,2002:float',\n        test: /^-?(?:0|[1-9][0-9]*)(?:\\.[0-9]*)?(?:[eE][-+]?[0-9]+)?$/,\n        resolve: str => parseFloat(str),\n        stringify: stringifyJSON\n    }\n];\nconst jsonError = {\n    default: true,\n    tag: '',\n    test: /^/,\n    resolve(str, onError) {\n        onError(`Unresolved plain scalar ${JSON.stringify(str)}`);\n        return str;\n    }\n};\nconst schema = [map.map, seq.seq].concat(jsonScalars, jsonError);\n\nexports.schema = schema;\n","'use strict';\n\nvar map = require('./common/map.js');\nvar _null = require('./common/null.js');\nvar seq = require('./common/seq.js');\nvar string = require('./common/string.js');\nvar bool = require('./core/bool.js');\nvar float = require('./core/float.js');\nvar int = require('./core/int.js');\nvar schema = require('./core/schema.js');\nvar schema$1 = require('./json/schema.js');\nvar binary = require('./yaml-1.1/binary.js');\nvar omap = require('./yaml-1.1/omap.js');\nvar pairs = require('./yaml-1.1/pairs.js');\nvar schema$2 = require('./yaml-1.1/schema.js');\nvar set = require('./yaml-1.1/set.js');\nvar timestamp = require('./yaml-1.1/timestamp.js');\n\nconst schemas = new Map([\n    ['core', schema.schema],\n    ['failsafe', [map.map, seq.seq, string.string]],\n    ['json', schema$1.schema],\n    ['yaml11', schema$2.schema],\n    ['yaml-1.1', schema$2.schema]\n]);\nconst tagsByName = {\n    binary: binary.binary,\n    bool: bool.boolTag,\n    float: float.float,\n    floatExp: float.floatExp,\n    floatNaN: float.floatNaN,\n    floatTime: timestamp.floatTime,\n    int: int.int,\n    intHex: int.intHex,\n    intOct: int.intOct,\n    intTime: timestamp.intTime,\n    map: map.map,\n    null: _null.nullTag,\n    omap: omap.omap,\n    pairs: pairs.pairs,\n    seq: seq.seq,\n    set: set.set,\n    timestamp: timestamp.timestamp\n};\nconst coreKnownTags = {\n    'tag:yaml.org,2002:binary': binary.binary,\n    'tag:yaml.org,2002:omap': omap.omap,\n    'tag:yaml.org,2002:pairs': pairs.pairs,\n    'tag:yaml.org,2002:set': set.set,\n    'tag:yaml.org,2002:timestamp': timestamp.timestamp\n};\nfunction getTags(customTags, schemaName) {\n    let tags = schemas.get(schemaName);\n    if (!tags) {\n        if (Array.isArray(customTags))\n            tags = [];\n        else {\n            const keys = Array.from(schemas.keys())\n                .filter(key => key !== 'yaml11')\n                .map(key => JSON.stringify(key))\n                .join(', ');\n            throw new Error(`Unknown schema \"${schemaName}\"; use one of ${keys} or define customTags array`);\n        }\n    }\n    if (Array.isArray(customTags)) {\n        for (const tag of customTags)\n            tags = tags.concat(tag);\n    }\n    else if (typeof customTags === 'function') {\n        tags = customTags(tags.slice());\n    }\n    return tags.map(tag => {\n        if (typeof tag !== 'string')\n            return tag;\n        const tagObj = tagsByName[tag];\n        if (tagObj)\n            return tagObj;\n        const keys = Object.keys(tagsByName)\n            .map(key => JSON.stringify(key))\n            .join(', ');\n        throw new Error(`Unknown custom tag \"${tag}\"; use one of ${keys}`);\n    });\n}\n\nexports.coreKnownTags = coreKnownTags;\nexports.getTags = getTags;\n","'use strict';\n\nvar Scalar = require('../../nodes/Scalar.js');\nvar stringifyString = require('../../stringify/stringifyString.js');\n\nconst binary = {\n    identify: value => value instanceof Uint8Array, // Buffer inherits from Uint8Array\n    default: false,\n    tag: 'tag:yaml.org,2002:binary',\n    /**\n     * Returns a Buffer in node and an Uint8Array in browsers\n     *\n     * To use the resulting buffer as an image, you'll want to do something like:\n     *\n     *   const blob = new Blob([buffer], { type: 'image/jpeg' })\n     *   document.querySelector('#photo').src = URL.createObjectURL(blob)\n     */\n    resolve(src, onError) {\n        if (typeof Buffer === 'function') {\n            return Buffer.from(src, 'base64');\n        }\n        else if (typeof atob === 'function') {\n            // On IE 11, atob() can't handle newlines\n            const str = atob(src.replace(/[\\n\\r]/g, ''));\n            const buffer = new Uint8Array(str.length);\n            for (let i = 0; i < str.length; ++i)\n                buffer[i] = str.charCodeAt(i);\n            return buffer;\n        }\n        else {\n            onError('This environment does not support reading binary tags; either Buffer or atob is required');\n            return src;\n        }\n    },\n    stringify({ comment, type, value }, ctx, onComment, onChompKeep) {\n        const buf = value; // checked earlier by binary.identify()\n        let str;\n        if (typeof Buffer === 'function') {\n            str =\n                buf instanceof Buffer\n                    ? buf.toString('base64')\n                    : Buffer.from(buf.buffer).toString('base64');\n        }\n        else if (typeof btoa === 'function') {\n            let s = '';\n            for (let i = 0; i < buf.length; ++i)\n                s += String.fromCharCode(buf[i]);\n            str = btoa(s);\n        }\n        else {\n            throw new Error('This environment does not support writing binary tags; either Buffer or btoa is required');\n        }\n        if (!type)\n            type = Scalar.Scalar.BLOCK_LITERAL;\n        if (type !== Scalar.Scalar.QUOTE_DOUBLE) {\n            const lineWidth = Math.max(ctx.options.lineWidth - ctx.indent.length, ctx.options.minContentWidth);\n            const n = Math.ceil(str.length / lineWidth);\n            const lines = new Array(n);\n            for (let i = 0, o = 0; i < n; ++i, o += lineWidth) {\n                lines[i] = str.substr(o, lineWidth);\n            }\n            str = lines.join(type === Scalar.Scalar.BLOCK_LITERAL ? '\\n' : ' ');\n        }\n        return stringifyString.stringifyString({ comment, type, value: str }, ctx, onComment, onChompKeep);\n    }\n};\n\nexports.binary = binary;\n","'use strict';\n\nvar Scalar = require('../../nodes/Scalar.js');\n\nfunction boolStringify({ value, source }, ctx) {\n    const boolObj = value ? trueTag : falseTag;\n    if (source && boolObj.test.test(source))\n        return source;\n    return value ? ctx.options.trueStr : ctx.options.falseStr;\n}\nconst trueTag = {\n    identify: value => value === true,\n    default: true,\n    tag: 'tag:yaml.org,2002:bool',\n    test: /^(?:Y|y|[Yy]es|YES|[Tt]rue|TRUE|[Oo]n|ON)$/,\n    resolve: () => new Scalar.Scalar(true),\n    stringify: boolStringify\n};\nconst falseTag = {\n    identify: value => value === false,\n    default: true,\n    tag: 'tag:yaml.org,2002:bool',\n    test: /^(?:N|n|[Nn]o|NO|[Ff]alse|FALSE|[Oo]ff|OFF)$/i,\n    resolve: () => new Scalar.Scalar(false),\n    stringify: boolStringify\n};\n\nexports.falseTag = falseTag;\nexports.trueTag = trueTag;\n","'use strict';\n\nvar Scalar = require('../../nodes/Scalar.js');\nvar stringifyNumber = require('../../stringify/stringifyNumber.js');\n\nconst floatNaN = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    test: /^[-+]?\\.(?:inf|Inf|INF|nan|NaN|NAN)$/,\n    resolve: (str) => str.slice(-3).toLowerCase() === 'nan'\n        ? NaN\n        : str[0] === '-'\n            ? Number.NEGATIVE_INFINITY\n            : Number.POSITIVE_INFINITY,\n    stringify: stringifyNumber.stringifyNumber\n};\nconst floatExp = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    format: 'EXP',\n    test: /^[-+]?(?:[0-9][0-9_]*)?(?:\\.[0-9_]*)?[eE][-+]?[0-9]+$/,\n    resolve: (str) => parseFloat(str.replace(/_/g, '')),\n    stringify(node) {\n        const num = Number(node.value);\n        return isFinite(num) ? num.toExponential() : stringifyNumber.stringifyNumber(node);\n    }\n};\nconst float = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    test: /^[-+]?(?:[0-9][0-9_]*)?\\.[0-9_]*$/,\n    resolve(str) {\n        const node = new Scalar.Scalar(parseFloat(str.replace(/_/g, '')));\n        const dot = str.indexOf('.');\n        if (dot !== -1) {\n            const f = str.substring(dot + 1).replace(/_/g, '');\n            if (f[f.length - 1] === '0')\n                node.minFractionDigits = f.length;\n        }\n        return node;\n    },\n    stringify: stringifyNumber.stringifyNumber\n};\n\nexports.float = float;\nexports.floatExp = floatExp;\nexports.floatNaN = floatNaN;\n","'use strict';\n\nvar stringifyNumber = require('../../stringify/stringifyNumber.js');\n\nconst intIdentify = (value) => typeof value === 'bigint' || Number.isInteger(value);\nfunction intResolve(str, offset, radix, { intAsBigInt }) {\n    const sign = str[0];\n    if (sign === '-' || sign === '+')\n        offset += 1;\n    str = str.substring(offset).replace(/_/g, '');\n    if (intAsBigInt) {\n        switch (radix) {\n            case 2:\n                str = `0b${str}`;\n                break;\n            case 8:\n                str = `0o${str}`;\n                break;\n            case 16:\n                str = `0x${str}`;\n                break;\n        }\n        const n = BigInt(str);\n        return sign === '-' ? BigInt(-1) * n : n;\n    }\n    const n = parseInt(str, radix);\n    return sign === '-' ? -1 * n : n;\n}\nfunction intStringify(node, radix, prefix) {\n    const { value } = node;\n    if (intIdentify(value)) {\n        const str = value.toString(radix);\n        return value < 0 ? '-' + prefix + str.substr(1) : prefix + str;\n    }\n    return stringifyNumber.stringifyNumber(node);\n}\nconst intBin = {\n    identify: intIdentify,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'BIN',\n    test: /^[-+]?0b[0-1_]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 2, 2, opt),\n    stringify: node => intStringify(node, 2, '0b')\n};\nconst intOct = {\n    identify: intIdentify,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'OCT',\n    test: /^[-+]?0[0-7_]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 1, 8, opt),\n    stringify: node => intStringify(node, 8, '0')\n};\nconst int = {\n    identify: intIdentify,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    test: /^[-+]?[0-9][0-9_]*$/,\n    resolve: (str, _onError, opt) => intResolve(str, 0, 10, opt),\n    stringify: stringifyNumber.stringifyNumber\n};\nconst intHex = {\n    identify: intIdentify,\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'HEX',\n    test: /^[-+]?0x[0-9a-fA-F_]+$/,\n    resolve: (str, _onError, opt) => intResolve(str, 2, 16, opt),\n    stringify: node => intStringify(node, 16, '0x')\n};\n\nexports.int = int;\nexports.intBin = intBin;\nexports.intHex = intHex;\nexports.intOct = intOct;\n","'use strict';\n\nvar identity = require('../../nodes/identity.js');\nvar toJS = require('../../nodes/toJS.js');\nvar YAMLMap = require('../../nodes/YAMLMap.js');\nvar YAMLSeq = require('../../nodes/YAMLSeq.js');\nvar pairs = require('./pairs.js');\n\nclass YAMLOMap extends YAMLSeq.YAMLSeq {\n    constructor() {\n        super();\n        this.add = YAMLMap.YAMLMap.prototype.add.bind(this);\n        this.delete = YAMLMap.YAMLMap.prototype.delete.bind(this);\n        this.get = YAMLMap.YAMLMap.prototype.get.bind(this);\n        this.has = YAMLMap.YAMLMap.prototype.has.bind(this);\n        this.set = YAMLMap.YAMLMap.prototype.set.bind(this);\n        this.tag = YAMLOMap.tag;\n    }\n    /**\n     * If `ctx` is given, the return type is actually `Map<unknown, unknown>`,\n     * but TypeScript won't allow widening the signature of a child method.\n     */\n    toJSON(_, ctx) {\n        if (!ctx)\n            return super.toJSON(_);\n        const map = new Map();\n        if (ctx?.onCreate)\n            ctx.onCreate(map);\n        for (const pair of this.items) {\n            let key, value;\n            if (identity.isPair(pair)) {\n                key = toJS.toJS(pair.key, '', ctx);\n                value = toJS.toJS(pair.value, key, ctx);\n            }\n            else {\n                key = toJS.toJS(pair, '', ctx);\n            }\n            if (map.has(key))\n                throw new Error('Ordered maps must not include duplicate keys');\n            map.set(key, value);\n        }\n        return map;\n    }\n    static from(schema, iterable, ctx) {\n        const pairs$1 = pairs.createPairs(schema, iterable, ctx);\n        const omap = new this();\n        omap.items = pairs$1.items;\n        return omap;\n    }\n}\nYAMLOMap.tag = 'tag:yaml.org,2002:omap';\nconst omap = {\n    collection: 'seq',\n    identify: value => value instanceof Map,\n    nodeClass: YAMLOMap,\n    default: false,\n    tag: 'tag:yaml.org,2002:omap',\n    resolve(seq, onError) {\n        const pairs$1 = pairs.resolvePairs(seq, onError);\n        const seenKeys = [];\n        for (const { key } of pairs$1.items) {\n            if (identity.isScalar(key)) {\n                if (seenKeys.includes(key.value)) {\n                    onError(`Ordered maps must not include duplicate keys: ${key.value}`);\n                }\n                else {\n                    seenKeys.push(key.value);\n                }\n            }\n        }\n        return Object.assign(new YAMLOMap(), pairs$1);\n    },\n    createNode: (schema, iterable, ctx) => YAMLOMap.from(schema, iterable, ctx)\n};\n\nexports.YAMLOMap = YAMLOMap;\nexports.omap = omap;\n","'use strict';\n\nvar identity = require('../../nodes/identity.js');\nvar Pair = require('../../nodes/Pair.js');\nvar Scalar = require('../../nodes/Scalar.js');\nvar YAMLSeq = require('../../nodes/YAMLSeq.js');\n\nfunction resolvePairs(seq, onError) {\n    if (identity.isSeq(seq)) {\n        for (let i = 0; i < seq.items.length; ++i) {\n            let item = seq.items[i];\n            if (identity.isPair(item))\n                continue;\n            else if (identity.isMap(item)) {\n                if (item.items.length > 1)\n                    onError('Each pair must have its own sequence indicator');\n                const pair = item.items[0] || new Pair.Pair(new Scalar.Scalar(null));\n                if (item.commentBefore)\n                    pair.key.commentBefore = pair.key.commentBefore\n                        ? `${item.commentBefore}\\n${pair.key.commentBefore}`\n                        : item.commentBefore;\n                if (item.comment) {\n                    const cn = pair.value ?? pair.key;\n                    cn.comment = cn.comment\n                        ? `${item.comment}\\n${cn.comment}`\n                        : item.comment;\n                }\n                item = pair;\n            }\n            seq.items[i] = identity.isPair(item) ? item : new Pair.Pair(item);\n        }\n    }\n    else\n        onError('Expected a sequence for this tag');\n    return seq;\n}\nfunction createPairs(schema, iterable, ctx) {\n    const { replacer } = ctx;\n    const pairs = new YAMLSeq.YAMLSeq(schema);\n    pairs.tag = 'tag:yaml.org,2002:pairs';\n    let i = 0;\n    if (iterable && Symbol.iterator in Object(iterable))\n        for (let it of iterable) {\n            if (typeof replacer === 'function')\n                it = replacer.call(iterable, String(i++), it);\n            let key, value;\n            if (Array.isArray(it)) {\n                if (it.length === 2) {\n                    key = it[0];\n                    value = it[1];\n                }\n                else\n                    throw new TypeError(`Expected [key, value] tuple: ${it}`);\n            }\n            else if (it && it instanceof Object) {\n                const keys = Object.keys(it);\n                if (keys.length === 1) {\n                    key = keys[0];\n                    value = it[key];\n                }\n                else {\n                    throw new TypeError(`Expected tuple with one key, not ${keys.length} keys`);\n                }\n            }\n            else {\n                key = it;\n            }\n            pairs.items.push(Pair.createPair(key, value, ctx));\n        }\n    return pairs;\n}\nconst pairs = {\n    collection: 'seq',\n    default: false,\n    tag: 'tag:yaml.org,2002:pairs',\n    resolve: resolvePairs,\n    createNode: createPairs\n};\n\nexports.createPairs = createPairs;\nexports.pairs = pairs;\nexports.resolvePairs = resolvePairs;\n","'use strict';\n\nvar map = require('../common/map.js');\nvar _null = require('../common/null.js');\nvar seq = require('../common/seq.js');\nvar string = require('../common/string.js');\nvar binary = require('./binary.js');\nvar bool = require('./bool.js');\nvar float = require('./float.js');\nvar int = require('./int.js');\nvar omap = require('./omap.js');\nvar pairs = require('./pairs.js');\nvar set = require('./set.js');\nvar timestamp = require('./timestamp.js');\n\nconst schema = [\n    map.map,\n    seq.seq,\n    string.string,\n    _null.nullTag,\n    bool.trueTag,\n    bool.falseTag,\n    int.intBin,\n    int.intOct,\n    int.int,\n    int.intHex,\n    float.floatNaN,\n    float.floatExp,\n    float.float,\n    binary.binary,\n    omap.omap,\n    pairs.pairs,\n    set.set,\n    timestamp.intTime,\n    timestamp.floatTime,\n    timestamp.timestamp\n];\n\nexports.schema = schema;\n","'use strict';\n\nvar identity = require('../../nodes/identity.js');\nvar Pair = require('../../nodes/Pair.js');\nvar YAMLMap = require('../../nodes/YAMLMap.js');\n\nclass YAMLSet extends YAMLMap.YAMLMap {\n    constructor(schema) {\n        super(schema);\n        this.tag = YAMLSet.tag;\n    }\n    add(key) {\n        let pair;\n        if (identity.isPair(key))\n            pair = key;\n        else if (key &&\n            typeof key === 'object' &&\n            'key' in key &&\n            'value' in key &&\n            key.value === null)\n            pair = new Pair.Pair(key.key, null);\n        else\n            pair = new Pair.Pair(key, null);\n        const prev = YAMLMap.findPair(this.items, pair.key);\n        if (!prev)\n            this.items.push(pair);\n    }\n    /**\n     * If `keepPair` is `true`, returns the Pair matching `key`.\n     * Otherwise, returns the value of that Pair's key.\n     */\n    get(key, keepPair) {\n        const pair = YAMLMap.findPair(this.items, key);\n        return !keepPair && identity.isPair(pair)\n            ? identity.isScalar(pair.key)\n                ? pair.key.value\n                : pair.key\n            : pair;\n    }\n    set(key, value) {\n        if (typeof value !== 'boolean')\n            throw new Error(`Expected boolean value for set(key, value) in a YAML set, not ${typeof value}`);\n        const prev = YAMLMap.findPair(this.items, key);\n        if (prev && !value) {\n            this.items.splice(this.items.indexOf(prev), 1);\n        }\n        else if (!prev && value) {\n            this.items.push(new Pair.Pair(key));\n        }\n    }\n    toJSON(_, ctx) {\n        return super.toJSON(_, ctx, Set);\n    }\n    toString(ctx, onComment, onChompKeep) {\n        if (!ctx)\n            return JSON.stringify(this);\n        if (this.hasAllNullValues(true))\n            return super.toString(Object.assign({}, ctx, { allNullValues: true }), onComment, onChompKeep);\n        else\n            throw new Error('Set items must all have null values');\n    }\n    static from(schema, iterable, ctx) {\n        const { replacer } = ctx;\n        const set = new this(schema);\n        if (iterable && Symbol.iterator in Object(iterable))\n            for (let value of iterable) {\n                if (typeof replacer === 'function')\n                    value = replacer.call(iterable, value, value);\n                set.items.push(Pair.createPair(value, null, ctx));\n            }\n        return set;\n    }\n}\nYAMLSet.tag = 'tag:yaml.org,2002:set';\nconst set = {\n    collection: 'map',\n    identify: value => value instanceof Set,\n    nodeClass: YAMLSet,\n    default: false,\n    tag: 'tag:yaml.org,2002:set',\n    createNode: (schema, iterable, ctx) => YAMLSet.from(schema, iterable, ctx),\n    resolve(map, onError) {\n        if (identity.isMap(map)) {\n            if (map.hasAllNullValues(true))\n                return Object.assign(new YAMLSet(), map);\n            else\n                onError('Set items must all have null values');\n        }\n        else\n            onError('Expected a mapping for this tag');\n        return map;\n    }\n};\n\nexports.YAMLSet = YAMLSet;\nexports.set = set;\n","'use strict';\n\nvar stringifyNumber = require('../../stringify/stringifyNumber.js');\n\n/** Internal types handle bigint as number, because TS can't figure it out. */\nfunction parseSexagesimal(str, asBigInt) {\n    const sign = str[0];\n    const parts = sign === '-' || sign === '+' ? str.substring(1) : str;\n    const num = (n) => asBigInt ? BigInt(n) : Number(n);\n    const res = parts\n        .replace(/_/g, '')\n        .split(':')\n        .reduce((res, p) => res * num(60) + num(p), num(0));\n    return (sign === '-' ? num(-1) * res : res);\n}\n/**\n * hhhh:mm:ss.sss\n *\n * Internal types handle bigint as number, because TS can't figure it out.\n */\nfunction stringifySexagesimal(node) {\n    let { value } = node;\n    let num = (n) => n;\n    if (typeof value === 'bigint')\n        num = n => BigInt(n);\n    else if (isNaN(value) || !isFinite(value))\n        return stringifyNumber.stringifyNumber(node);\n    let sign = '';\n    if (value < 0) {\n        sign = '-';\n        value *= num(-1);\n    }\n    const _60 = num(60);\n    const parts = [value % _60]; // seconds, including ms\n    if (value < 60) {\n        parts.unshift(0); // at least one : is required\n    }\n    else {\n        value = (value - parts[0]) / _60;\n        parts.unshift(value % _60); // minutes\n        if (value >= 60) {\n            value = (value - parts[0]) / _60;\n            parts.unshift(value); // hours\n        }\n    }\n    return (sign +\n        parts\n            .map(n => String(n).padStart(2, '0'))\n            .join(':')\n            .replace(/000000\\d*$/, '') // % 60 may introduce error\n    );\n}\nconst intTime = {\n    identify: value => typeof value === 'bigint' || Number.isInteger(value),\n    default: true,\n    tag: 'tag:yaml.org,2002:int',\n    format: 'TIME',\n    test: /^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+$/,\n    resolve: (str, _onError, { intAsBigInt }) => parseSexagesimal(str, intAsBigInt),\n    stringify: stringifySexagesimal\n};\nconst floatTime = {\n    identify: value => typeof value === 'number',\n    default: true,\n    tag: 'tag:yaml.org,2002:float',\n    format: 'TIME',\n    test: /^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+\\.[0-9_]*$/,\n    resolve: str => parseSexagesimal(str, false),\n    stringify: stringifySexagesimal\n};\nconst timestamp = {\n    identify: value => value instanceof Date,\n    default: true,\n    tag: 'tag:yaml.org,2002:timestamp',\n    // If the time zone is omitted, the timestamp is assumed to be specified in UTC. The time part\n    // may be omitted altogether, resulting in a date format. In such a case, the time part is\n    // assumed to be 00:00:00Z (start of day, UTC).\n    test: RegExp('^([0-9]{4})-([0-9]{1,2})-([0-9]{1,2})' + // YYYY-Mm-Dd\n        '(?:' + // time is optional\n        '(?:t|T|[ \\\\t]+)' + // t | T | whitespace\n        '([0-9]{1,2}):([0-9]{1,2}):([0-9]{1,2}(\\\\.[0-9]+)?)' + // Hh:Mm:Ss(.ss)?\n        '(?:[ \\\\t]*(Z|[-+][012]?[0-9](?::[0-9]{2})?))?' + // Z | +5 | -03:30\n        ')?$'),\n    resolve(str) {\n        const match = str.match(timestamp.test);\n        if (!match)\n            throw new Error('!!timestamp expects a date, starting with yyyy-mm-dd');\n        const [, year, month, day, hour, minute, second] = match.map(Number);\n        const millisec = match[7] ? Number((match[7] + '00').substr(1, 3)) : 0;\n        let date = Date.UTC(year, month - 1, day, hour || 0, minute || 0, second || 0, millisec);\n        const tz = match[8];\n        if (tz && tz !== 'Z') {\n            let d = parseSexagesimal(tz, false);\n            if (Math.abs(d) < 30)\n                d *= 60;\n            date -= 60000 * d;\n        }\n        return new Date(date);\n    },\n    stringify: ({ value }) => value.toISOString().replace(/((T00:00)?:00)?\\.000Z$/, '')\n};\n\nexports.floatTime = floatTime;\nexports.intTime = intTime;\nexports.timestamp = timestamp;\n","'use strict';\n\nconst FOLD_FLOW = 'flow';\nconst FOLD_BLOCK = 'block';\nconst FOLD_QUOTED = 'quoted';\n/**\n * Tries to keep input at up to `lineWidth` characters, splitting only on spaces\n * not followed by newlines or spaces unless `mode` is `'quoted'`. Lines are\n * terminated with `\\n` and started with `indent`.\n */\nfunction foldFlowLines(text, indent, mode = 'flow', { indentAtStart, lineWidth = 80, minContentWidth = 20, onFold, onOverflow } = {}) {\n    if (!lineWidth || lineWidth < 0)\n        return text;\n    const endStep = Math.max(1 + minContentWidth, 1 + lineWidth - indent.length);\n    if (text.length <= endStep)\n        return text;\n    const folds = [];\n    const escapedFolds = {};\n    let end = lineWidth - indent.length;\n    if (typeof indentAtStart === 'number') {\n        if (indentAtStart > lineWidth - Math.max(2, minContentWidth))\n            folds.push(0);\n        else\n            end = lineWidth - indentAtStart;\n    }\n    let split = undefined;\n    let prev = undefined;\n    let overflow = false;\n    let i = -1;\n    let escStart = -1;\n    let escEnd = -1;\n    if (mode === FOLD_BLOCK) {\n        i = consumeMoreIndentedLines(text, i, indent.length);\n        if (i !== -1)\n            end = i + endStep;\n    }\n    for (let ch; (ch = text[(i += 1)]);) {\n        if (mode === FOLD_QUOTED && ch === '\\\\') {\n            escStart = i;\n            switch (text[i + 1]) {\n                case 'x':\n                    i += 3;\n                    break;\n                case 'u':\n                    i += 5;\n                    break;\n                case 'U':\n                    i += 9;\n                    break;\n                default:\n                    i += 1;\n            }\n            escEnd = i;\n        }\n        if (ch === '\\n') {\n            if (mode === FOLD_BLOCK)\n                i = consumeMoreIndentedLines(text, i, indent.length);\n            end = i + indent.length + endStep;\n            split = undefined;\n        }\n        else {\n            if (ch === ' ' &&\n                prev &&\n                prev !== ' ' &&\n                prev !== '\\n' &&\n                prev !== '\\t') {\n                // space surrounded by non-space can be replaced with newline + indent\n                const next = text[i + 1];\n                if (next && next !== ' ' && next !== '\\n' && next !== '\\t')\n                    split = i;\n            }\n            if (i >= end) {\n                if (split) {\n                    folds.push(split);\n                    end = split + endStep;\n                    split = undefined;\n                }\n                else if (mode === FOLD_QUOTED) {\n                    // white-space collected at end may stretch past lineWidth\n                    while (prev === ' ' || prev === '\\t') {\n                        prev = ch;\n                        ch = text[(i += 1)];\n                        overflow = true;\n                    }\n                    // Account for newline escape, but don't break preceding escape\n                    const j = i > escEnd + 1 ? i - 2 : escStart - 1;\n                    // Bail out if lineWidth & minContentWidth are shorter than an escape string\n                    if (escapedFolds[j])\n                        return text;\n                    folds.push(j);\n                    escapedFolds[j] = true;\n                    end = j + endStep;\n                    split = undefined;\n                }\n                else {\n                    overflow = true;\n                }\n            }\n        }\n        prev = ch;\n    }\n    if (overflow && onOverflow)\n        onOverflow();\n    if (folds.length === 0)\n        return text;\n    if (onFold)\n        onFold();\n    let res = text.slice(0, folds[0]);\n    for (let i = 0; i < folds.length; ++i) {\n        const fold = folds[i];\n        const end = folds[i + 1] || text.length;\n        if (fold === 0)\n            res = `\\n${indent}${text.slice(0, end)}`;\n        else {\n            if (mode === FOLD_QUOTED && escapedFolds[fold])\n                res += `${text[fold]}\\\\`;\n            res += `\\n${indent}${text.slice(fold + 1, end)}`;\n        }\n    }\n    return res;\n}\n/**\n * Presumes `i + 1` is at the start of a line\n * @returns index of last newline in more-indented block\n */\nfunction consumeMoreIndentedLines(text, i, indent) {\n    let end = i;\n    let start = i + 1;\n    let ch = text[start];\n    while (ch === ' ' || ch === '\\t') {\n        if (i < start + indent) {\n            ch = text[++i];\n        }\n        else {\n            do {\n                ch = text[++i];\n            } while (ch && ch !== '\\n');\n            end = i;\n            start = i + 1;\n            ch = text[start];\n        }\n    }\n    return end;\n}\n\nexports.FOLD_BLOCK = FOLD_BLOCK;\nexports.FOLD_FLOW = FOLD_FLOW;\nexports.FOLD_QUOTED = FOLD_QUOTED;\nexports.foldFlowLines = foldFlowLines;\n","'use strict';\n\nvar anchors = require('../doc/anchors.js');\nvar identity = require('../nodes/identity.js');\nvar stringifyComment = require('./stringifyComment.js');\nvar stringifyString = require('./stringifyString.js');\n\nfunction createStringifyContext(doc, options) {\n    const opt = Object.assign({\n        blockQuote: true,\n        commentString: stringifyComment.stringifyComment,\n        defaultKeyType: null,\n        defaultStringType: 'PLAIN',\n        directives: null,\n        doubleQuotedAsJSON: false,\n        doubleQuotedMinMultiLineLength: 40,\n        falseStr: 'false',\n        flowCollectionPadding: true,\n        indentSeq: true,\n        lineWidth: 80,\n        minContentWidth: 20,\n        nullStr: 'null',\n        simpleKeys: false,\n        singleQuote: null,\n        trueStr: 'true',\n        verifyAliasOrder: true\n    }, doc.schema.toStringOptions, options);\n    let inFlow;\n    switch (opt.collectionStyle) {\n        case 'block':\n            inFlow = false;\n            break;\n        case 'flow':\n            inFlow = true;\n            break;\n        default:\n            inFlow = null;\n    }\n    return {\n        anchors: new Set(),\n        doc,\n        flowCollectionPadding: opt.flowCollectionPadding ? ' ' : '',\n        indent: '',\n        indentStep: typeof opt.indent === 'number' ? ' '.repeat(opt.indent) : '  ',\n        inFlow,\n        options: opt\n    };\n}\nfunction getTagObject(tags, item) {\n    if (item.tag) {\n        const match = tags.filter(t => t.tag === item.tag);\n        if (match.length > 0)\n            return match.find(t => t.format === item.format) ?? match[0];\n    }\n    let tagObj = undefined;\n    let obj;\n    if (identity.isScalar(item)) {\n        obj = item.value;\n        const match = tags.filter(t => t.identify?.(obj));\n        tagObj =\n            match.find(t => t.format === item.format) ?? match.find(t => !t.format);\n    }\n    else {\n        obj = item;\n        tagObj = tags.find(t => t.nodeClass && obj instanceof t.nodeClass);\n    }\n    if (!tagObj) {\n        const name = obj?.constructor?.name ?? typeof obj;\n        throw new Error(`Tag not resolved for ${name} value`);\n    }\n    return tagObj;\n}\n// needs to be called before value stringifier to allow for circular anchor refs\nfunction stringifyProps(node, tagObj, { anchors: anchors$1, doc }) {\n    if (!doc.directives)\n        return '';\n    const props = [];\n    const anchor = (identity.isScalar(node) || identity.isCollection(node)) && node.anchor;\n    if (anchor && anchors.anchorIsValid(anchor)) {\n        anchors$1.add(anchor);\n        props.push(`&${anchor}`);\n    }\n    const tag = node.tag ? node.tag : tagObj.default ? null : tagObj.tag;\n    if (tag)\n        props.push(doc.directives.tagString(tag));\n    return props.join(' ');\n}\nfunction stringify(item, ctx, onComment, onChompKeep) {\n    if (identity.isPair(item))\n        return item.toString(ctx, onComment, onChompKeep);\n    if (identity.isAlias(item)) {\n        if (ctx.doc.directives)\n            return item.toString(ctx);\n        if (ctx.resolvedAliases?.has(item)) {\n            throw new TypeError(`Cannot stringify circular structure without alias nodes`);\n        }\n        else {\n            if (ctx.resolvedAliases)\n                ctx.resolvedAliases.add(item);\n            else\n                ctx.resolvedAliases = new Set([item]);\n            item = item.resolve(ctx.doc);\n        }\n    }\n    let tagObj = undefined;\n    const node = identity.isNode(item)\n        ? item\n        : ctx.doc.createNode(item, { onTagObj: o => (tagObj = o) });\n    if (!tagObj)\n        tagObj = getTagObject(ctx.doc.schema.tags, node);\n    const props = stringifyProps(node, tagObj, ctx);\n    if (props.length > 0)\n        ctx.indentAtStart = (ctx.indentAtStart ?? 0) + props.length + 1;\n    const str = typeof tagObj.stringify === 'function'\n        ? tagObj.stringify(node, ctx, onComment, onChompKeep)\n        : identity.isScalar(node)\n            ? stringifyString.stringifyString(node, ctx, onComment, onChompKeep)\n            : node.toString(ctx, onComment, onChompKeep);\n    if (!props)\n        return str;\n    return identity.isScalar(node) || str[0] === '{' || str[0] === '['\n        ? `${props} ${str}`\n        : `${props}\\n${ctx.indent}${str}`;\n}\n\nexports.createStringifyContext = createStringifyContext;\nexports.stringify = stringify;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar stringify = require('./stringify.js');\nvar stringifyComment = require('./stringifyComment.js');\n\nfunction stringifyCollection(collection, ctx, options) {\n    const flow = ctx.inFlow ?? collection.flow;\n    const stringify = flow ? stringifyFlowCollection : stringifyBlockCollection;\n    return stringify(collection, ctx, options);\n}\nfunction stringifyBlockCollection({ comment, items }, ctx, { blockItemPrefix, flowChars, itemIndent, onChompKeep, onComment }) {\n    const { indent, options: { commentString } } = ctx;\n    const itemCtx = Object.assign({}, ctx, { indent: itemIndent, type: null });\n    let chompKeep = false; // flag for the preceding node's status\n    const lines = [];\n    for (let i = 0; i < items.length; ++i) {\n        const item = items[i];\n        let comment = null;\n        if (identity.isNode(item)) {\n            if (!chompKeep && item.spaceBefore)\n                lines.push('');\n            addCommentBefore(ctx, lines, item.commentBefore, chompKeep);\n            if (item.comment)\n                comment = item.comment;\n        }\n        else if (identity.isPair(item)) {\n            const ik = identity.isNode(item.key) ? item.key : null;\n            if (ik) {\n                if (!chompKeep && ik.spaceBefore)\n                    lines.push('');\n                addCommentBefore(ctx, lines, ik.commentBefore, chompKeep);\n            }\n        }\n        chompKeep = false;\n        let str = stringify.stringify(item, itemCtx, () => (comment = null), () => (chompKeep = true));\n        if (comment)\n            str += stringifyComment.lineComment(str, itemIndent, commentString(comment));\n        if (chompKeep && comment)\n            chompKeep = false;\n        lines.push(blockItemPrefix + str);\n    }\n    let str;\n    if (lines.length === 0) {\n        str = flowChars.start + flowChars.end;\n    }\n    else {\n        str = lines[0];\n        for (let i = 1; i < lines.length; ++i) {\n            const line = lines[i];\n            str += line ? `\\n${indent}${line}` : '\\n';\n        }\n    }\n    if (comment) {\n        str += '\\n' + stringifyComment.indentComment(commentString(comment), indent);\n        if (onComment)\n            onComment();\n    }\n    else if (chompKeep && onChompKeep)\n        onChompKeep();\n    return str;\n}\nfunction stringifyFlowCollection({ items }, ctx, { flowChars, itemIndent }) {\n    const { indent, indentStep, flowCollectionPadding: fcPadding, options: { commentString } } = ctx;\n    itemIndent += indentStep;\n    const itemCtx = Object.assign({}, ctx, {\n        indent: itemIndent,\n        inFlow: true,\n        type: null\n    });\n    let reqNewline = false;\n    let linesAtValue = 0;\n    const lines = [];\n    for (let i = 0; i < items.length; ++i) {\n        const item = items[i];\n        let comment = null;\n        if (identity.isNode(item)) {\n            if (item.spaceBefore)\n                lines.push('');\n            addCommentBefore(ctx, lines, item.commentBefore, false);\n            if (item.comment)\n                comment = item.comment;\n        }\n        else if (identity.isPair(item)) {\n            const ik = identity.isNode(item.key) ? item.key : null;\n            if (ik) {\n                if (ik.spaceBefore)\n                    lines.push('');\n                addCommentBefore(ctx, lines, ik.commentBefore, false);\n                if (ik.comment)\n                    reqNewline = true;\n            }\n            const iv = identity.isNode(item.value) ? item.value : null;\n            if (iv) {\n                if (iv.comment)\n                    comment = iv.comment;\n                if (iv.commentBefore)\n                    reqNewline = true;\n            }\n            else if (item.value == null && ik?.comment) {\n                comment = ik.comment;\n            }\n        }\n        if (comment)\n            reqNewline = true;\n        let str = stringify.stringify(item, itemCtx, () => (comment = null));\n        if (i < items.length - 1)\n            str += ',';\n        if (comment)\n            str += stringifyComment.lineComment(str, itemIndent, commentString(comment));\n        if (!reqNewline && (lines.length > linesAtValue || str.includes('\\n')))\n            reqNewline = true;\n        lines.push(str);\n        linesAtValue = lines.length;\n    }\n    const { start, end } = flowChars;\n    if (lines.length === 0) {\n        return start + end;\n    }\n    else {\n        if (!reqNewline) {\n            const len = lines.reduce((sum, line) => sum + line.length + 2, 2);\n            reqNewline = ctx.options.lineWidth > 0 && len > ctx.options.lineWidth;\n        }\n        if (reqNewline) {\n            let str = start;\n            for (const line of lines)\n                str += line ? `\\n${indentStep}${indent}${line}` : '\\n';\n            return `${str}\\n${indent}${end}`;\n        }\n        else {\n            return `${start}${fcPadding}${lines.join(' ')}${fcPadding}${end}`;\n        }\n    }\n}\nfunction addCommentBefore({ indent, options: { commentString } }, lines, comment, chompKeep) {\n    if (comment && chompKeep)\n        comment = comment.replace(/^\\n+/, '');\n    if (comment) {\n        const ic = stringifyComment.indentComment(commentString(comment), indent);\n        lines.push(ic.trimStart()); // Avoid double indent on first line\n    }\n}\n\nexports.stringifyCollection = stringifyCollection;\n","'use strict';\n\n/**\n * Stringifies a comment.\n *\n * Empty comment lines are left empty,\n * lines consisting of a single space are replaced by `#`,\n * and all other lines are prefixed with a `#`.\n */\nconst stringifyComment = (str) => str.replace(/^(?!$)(?: $)?/gm, '#');\nfunction indentComment(comment, indent) {\n    if (/^\\n+$/.test(comment))\n        return comment.substring(1);\n    return indent ? comment.replace(/^(?! *$)/gm, indent) : comment;\n}\nconst lineComment = (str, indent, comment) => str.endsWith('\\n')\n    ? indentComment(comment, indent)\n    : comment.includes('\\n')\n        ? '\\n' + indentComment(comment, indent)\n        : (str.endsWith(' ') ? '' : ' ') + comment;\n\nexports.indentComment = indentComment;\nexports.lineComment = lineComment;\nexports.stringifyComment = stringifyComment;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar stringify = require('./stringify.js');\nvar stringifyComment = require('./stringifyComment.js');\n\nfunction stringifyDocument(doc, options) {\n    const lines = [];\n    let hasDirectives = options.directives === true;\n    if (options.directives !== false && doc.directives) {\n        const dir = doc.directives.toString(doc);\n        if (dir) {\n            lines.push(dir);\n            hasDirectives = true;\n        }\n        else if (doc.directives.docStart)\n            hasDirectives = true;\n    }\n    if (hasDirectives)\n        lines.push('---');\n    const ctx = stringify.createStringifyContext(doc, options);\n    const { commentString } = ctx.options;\n    if (doc.commentBefore) {\n        if (lines.length !== 1)\n            lines.unshift('');\n        const cs = commentString(doc.commentBefore);\n        lines.unshift(stringifyComment.indentComment(cs, ''));\n    }\n    let chompKeep = false;\n    let contentComment = null;\n    if (doc.contents) {\n        if (identity.isNode(doc.contents)) {\n            if (doc.contents.spaceBefore && hasDirectives)\n                lines.push('');\n            if (doc.contents.commentBefore) {\n                const cs = commentString(doc.contents.commentBefore);\n                lines.push(stringifyComment.indentComment(cs, ''));\n            }\n            // top-level block scalars need to be indented if followed by a comment\n            ctx.forceBlockIndent = !!doc.comment;\n            contentComment = doc.contents.comment;\n        }\n        const onChompKeep = contentComment ? undefined : () => (chompKeep = true);\n        let body = stringify.stringify(doc.contents, ctx, () => (contentComment = null), onChompKeep);\n        if (contentComment)\n            body += stringifyComment.lineComment(body, '', commentString(contentComment));\n        if ((body[0] === '|' || body[0] === '>') &&\n            lines[lines.length - 1] === '---') {\n            // Top-level block scalars with a preceding doc marker ought to use the\n            // same line for their header.\n            lines[lines.length - 1] = `--- ${body}`;\n        }\n        else\n            lines.push(body);\n    }\n    else {\n        lines.push(stringify.stringify(doc.contents, ctx));\n    }\n    if (doc.directives?.docEnd) {\n        if (doc.comment) {\n            const cs = commentString(doc.comment);\n            if (cs.includes('\\n')) {\n                lines.push('...');\n                lines.push(stringifyComment.indentComment(cs, ''));\n            }\n            else {\n                lines.push(`... ${cs}`);\n            }\n        }\n        else {\n            lines.push('...');\n        }\n    }\n    else {\n        let dc = doc.comment;\n        if (dc && chompKeep)\n            dc = dc.replace(/^\\n+/, '');\n        if (dc) {\n            if ((!chompKeep || contentComment) && lines[lines.length - 1] !== '')\n                lines.push('');\n            lines.push(stringifyComment.indentComment(commentString(dc), ''));\n        }\n    }\n    return lines.join('\\n') + '\\n';\n}\n\nexports.stringifyDocument = stringifyDocument;\n","'use strict';\n\nfunction stringifyNumber({ format, minFractionDigits, tag, value }) {\n    if (typeof value === 'bigint')\n        return String(value);\n    const num = typeof value === 'number' ? value : Number(value);\n    if (!isFinite(num))\n        return isNaN(num) ? '.nan' : num < 0 ? '-.inf' : '.inf';\n    let n = JSON.stringify(value);\n    if (!format &&\n        minFractionDigits &&\n        (!tag || tag === 'tag:yaml.org,2002:float') &&\n        /^\\d/.test(n)) {\n        let i = n.indexOf('.');\n        if (i < 0) {\n            i = n.length;\n            n += '.';\n        }\n        let d = minFractionDigits - (n.length - i - 1);\n        while (d-- > 0)\n            n += '0';\n    }\n    return n;\n}\n\nexports.stringifyNumber = stringifyNumber;\n","'use strict';\n\nvar identity = require('../nodes/identity.js');\nvar Scalar = require('../nodes/Scalar.js');\nvar stringify = require('./stringify.js');\nvar stringifyComment = require('./stringifyComment.js');\n\nfunction stringifyPair({ key, value }, ctx, onComment, onChompKeep) {\n    const { allNullValues, doc, indent, indentStep, options: { commentString, indentSeq, simpleKeys } } = ctx;\n    let keyComment = (identity.isNode(key) && key.comment) || null;\n    if (simpleKeys) {\n        if (keyComment) {\n            throw new Error('With simple keys, key nodes cannot have comments');\n        }\n        if (identity.isCollection(key)) {\n            const msg = 'With simple keys, collection cannot be used as a key value';\n            throw new Error(msg);\n        }\n    }\n    let explicitKey = !simpleKeys &&\n        (!key ||\n            (keyComment && value == null && !ctx.inFlow) ||\n            identity.isCollection(key) ||\n            (identity.isScalar(key)\n                ? key.type === Scalar.Scalar.BLOCK_FOLDED || key.type === Scalar.Scalar.BLOCK_LITERAL\n                : typeof key === 'object'));\n    ctx = Object.assign({}, ctx, {\n        allNullValues: false,\n        implicitKey: !explicitKey && (simpleKeys || !allNullValues),\n        indent: indent + indentStep\n    });\n    let keyCommentDone = false;\n    let chompKeep = false;\n    let str = stringify.stringify(key, ctx, () => (keyCommentDone = true), () => (chompKeep = true));\n    if (!explicitKey && !ctx.inFlow && str.length > 1024) {\n        if (simpleKeys)\n            throw new Error('With simple keys, single line scalar must not span more than 1024 characters');\n        explicitKey = true;\n    }\n    if (ctx.inFlow) {\n        if (allNullValues || value == null) {\n            if (keyCommentDone && onComment)\n                onComment();\n            return str === '' ? '?' : explicitKey ? `? ${str}` : str;\n        }\n    }\n    else if ((allNullValues && !simpleKeys) || (value == null && explicitKey)) {\n        str = `? ${str}`;\n        if (keyComment && !keyCommentDone) {\n            str += stringifyComment.lineComment(str, ctx.indent, commentString(keyComment));\n        }\n        else if (chompKeep && onChompKeep)\n            onChompKeep();\n        return str;\n    }\n    if (keyCommentDone)\n        keyComment = null;\n    if (explicitKey) {\n        if (keyComment)\n            str += stringifyComment.lineComment(str, ctx.indent, commentString(keyComment));\n        str = `? ${str}\\n${indent}:`;\n    }\n    else {\n        str = `${str}:`;\n        if (keyComment)\n            str += stringifyComment.lineComment(str, ctx.indent, commentString(keyComment));\n    }\n    let vsb, vcb, valueComment;\n    if (identity.isNode(value)) {\n        vsb = !!value.spaceBefore;\n        vcb = value.commentBefore;\n        valueComment = value.comment;\n    }\n    else {\n        vsb = false;\n        vcb = null;\n        valueComment = null;\n        if (value && typeof value === 'object')\n            value = doc.createNode(value);\n    }\n    ctx.implicitKey = false;\n    if (!explicitKey && !keyComment && identity.isScalar(value))\n        ctx.indentAtStart = str.length + 1;\n    chompKeep = false;\n    if (!indentSeq &&\n        indentStep.length >= 2 &&\n        !ctx.inFlow &&\n        !explicitKey &&\n        identity.isSeq(value) &&\n        !value.flow &&\n        !value.tag &&\n        !value.anchor) {\n        // If indentSeq === false, consider '- ' as part of indentation where possible\n        ctx.indent = ctx.indent.substring(2);\n    }\n    let valueCommentDone = false;\n    const valueStr = stringify.stringify(value, ctx, () => (valueCommentDone = true), () => (chompKeep = true));\n    let ws = ' ';\n    if (keyComment || vsb || vcb) {\n        ws = vsb ? '\\n' : '';\n        if (vcb) {\n            const cs = commentString(vcb);\n            ws += `\\n${stringifyComment.indentComment(cs, ctx.indent)}`;\n        }\n        if (valueStr === '' && !ctx.inFlow) {\n            if (ws === '\\n')\n                ws = '\\n\\n';\n        }\n        else {\n            ws += `\\n${ctx.indent}`;\n        }\n    }\n    else if (!explicitKey && identity.isCollection(value)) {\n        const vs0 = valueStr[0];\n        const nl0 = valueStr.indexOf('\\n');\n        const hasNewline = nl0 !== -1;\n        const flow = ctx.inFlow ?? value.flow ?? value.items.length === 0;\n        if (hasNewline || !flow) {\n            let hasPropsLine = false;\n            if (hasNewline && (vs0 === '&' || vs0 === '!')) {\n                let sp0 = valueStr.indexOf(' ');\n                if (vs0 === '&' &&\n                    sp0 !== -1 &&\n                    sp0 < nl0 &&\n                    valueStr[sp0 + 1] === '!') {\n                    sp0 = valueStr.indexOf(' ', sp0 + 1);\n                }\n                if (sp0 === -1 || nl0 < sp0)\n                    hasPropsLine = true;\n            }\n            if (!hasPropsLine)\n                ws = `\\n${ctx.indent}`;\n        }\n    }\n    else if (valueStr === '' || valueStr[0] === '\\n') {\n        ws = '';\n    }\n    str += ws + valueStr;\n    if (ctx.inFlow) {\n        if (valueCommentDone && onComment)\n            onComment();\n    }\n    else if (valueComment && !valueCommentDone) {\n        str += stringifyComment.lineComment(str, ctx.indent, commentString(valueComment));\n    }\n    else if (chompKeep && onChompKeep) {\n        onChompKeep();\n    }\n    return str;\n}\n\nexports.stringifyPair = stringifyPair;\n","'use strict';\n\nvar Scalar = require('../nodes/Scalar.js');\nvar foldFlowLines = require('./foldFlowLines.js');\n\nconst getFoldOptions = (ctx, isBlock) => ({\n    indentAtStart: isBlock ? ctx.indent.length : ctx.indentAtStart,\n    lineWidth: ctx.options.lineWidth,\n    minContentWidth: ctx.options.minContentWidth\n});\n// Also checks for lines starting with %, as parsing the output as YAML 1.1 will\n// presume that's starting a new document.\nconst containsDocumentMarker = (str) => /^(%|---|\\.\\.\\.)/m.test(str);\nfunction lineLengthOverLimit(str, lineWidth, indentLength) {\n    if (!lineWidth || lineWidth < 0)\n        return false;\n    const limit = lineWidth - indentLength;\n    const strLen = str.length;\n    if (strLen <= limit)\n        return false;\n    for (let i = 0, start = 0; i < strLen; ++i) {\n        if (str[i] === '\\n') {\n            if (i - start > limit)\n                return true;\n            start = i + 1;\n            if (strLen - start <= limit)\n                return false;\n        }\n    }\n    return true;\n}\nfunction doubleQuotedString(value, ctx) {\n    const json = JSON.stringify(value);\n    if (ctx.options.doubleQuotedAsJSON)\n        return json;\n    const { implicitKey } = ctx;\n    const minMultiLineLength = ctx.options.doubleQuotedMinMultiLineLength;\n    const indent = ctx.indent || (containsDocumentMarker(value) ? '  ' : '');\n    let str = '';\n    let start = 0;\n    for (let i = 0, ch = json[i]; ch; ch = json[++i]) {\n        if (ch === ' ' && json[i + 1] === '\\\\' && json[i + 2] === 'n') {\n            // space before newline needs to be escaped to not be folded\n            str += json.slice(start, i) + '\\\\ ';\n            i += 1;\n            start = i;\n            ch = '\\\\';\n        }\n        if (ch === '\\\\')\n            switch (json[i + 1]) {\n                case 'u':\n                    {\n                        str += json.slice(start, i);\n                        const code = json.substr(i + 2, 4);\n                        switch (code) {\n                            case '0000':\n                                str += '\\\\0';\n                                break;\n                            case '0007':\n                                str += '\\\\a';\n                                break;\n                            case '000b':\n                                str += '\\\\v';\n                                break;\n                            case '001b':\n                                str += '\\\\e';\n                                break;\n                            case '0085':\n                                str += '\\\\N';\n                                break;\n                            case '00a0':\n                                str += '\\\\_';\n                                break;\n                            case '2028':\n                                str += '\\\\L';\n                                break;\n                            case '2029':\n                                str += '\\\\P';\n                                break;\n                            default:\n                                if (code.substr(0, 2) === '00')\n                                    str += '\\\\x' + code.substr(2);\n                                else\n                                    str += json.substr(i, 6);\n                        }\n                        i += 5;\n                        start = i + 1;\n                    }\n                    break;\n                case 'n':\n                    if (implicitKey ||\n                        json[i + 2] === '\"' ||\n                        json.length < minMultiLineLength) {\n                        i += 1;\n                    }\n                    else {\n                        // folding will eat first newline\n                        str += json.slice(start, i) + '\\n\\n';\n                        while (json[i + 2] === '\\\\' &&\n                            json[i + 3] === 'n' &&\n                            json[i + 4] !== '\"') {\n                            str += '\\n';\n                            i += 2;\n                        }\n                        str += indent;\n                        // space after newline needs to be escaped to not be folded\n                        if (json[i + 2] === ' ')\n                            str += '\\\\';\n                        i += 1;\n                        start = i + 1;\n                    }\n                    break;\n                default:\n                    i += 1;\n            }\n    }\n    str = start ? str + json.slice(start) : json;\n    return implicitKey\n        ? str\n        : foldFlowLines.foldFlowLines(str, indent, foldFlowLines.FOLD_QUOTED, getFoldOptions(ctx, false));\n}\nfunction singleQuotedString(value, ctx) {\n    if (ctx.options.singleQuote === false ||\n        (ctx.implicitKey && value.includes('\\n')) ||\n        /[ \\t]\\n|\\n[ \\t]/.test(value) // single quoted string can't have leading or trailing whitespace around newline\n    )\n        return doubleQuotedString(value, ctx);\n    const indent = ctx.indent || (containsDocumentMarker(value) ? '  ' : '');\n    const res = \"'\" + value.replace(/'/g, \"''\").replace(/\\n+/g, `$&\\n${indent}`) + \"'\";\n    return ctx.implicitKey\n        ? res\n        : foldFlowLines.foldFlowLines(res, indent, foldFlowLines.FOLD_FLOW, getFoldOptions(ctx, false));\n}\nfunction quotedString(value, ctx) {\n    const { singleQuote } = ctx.options;\n    let qs;\n    if (singleQuote === false)\n        qs = doubleQuotedString;\n    else {\n        const hasDouble = value.includes('\"');\n        const hasSingle = value.includes(\"'\");\n        if (hasDouble && !hasSingle)\n            qs = singleQuotedString;\n        else if (hasSingle && !hasDouble)\n            qs = doubleQuotedString;\n        else\n            qs = singleQuote ? singleQuotedString : doubleQuotedString;\n    }\n    return qs(value, ctx);\n}\n// The negative lookbehind avoids a polynomial search,\n// but isn't supported yet on Safari: https://caniuse.com/js-regexp-lookbehind\nlet blockEndNewlines;\ntry {\n    blockEndNewlines = new RegExp('(^|(?<!\\n))\\n+(?!\\n|$)', 'g');\n}\ncatch {\n    blockEndNewlines = /\\n+(?!\\n|$)/g;\n}\nfunction blockString({ comment, type, value }, ctx, onComment, onChompKeep) {\n    const { blockQuote, commentString, lineWidth } = ctx.options;\n    // 1. Block can't end in whitespace unless the last line is non-empty.\n    // 2. Strings consisting of only whitespace are best rendered explicitly.\n    if (!blockQuote || /\\n[\\t ]+$/.test(value) || /^\\s*$/.test(value)) {\n        return quotedString(value, ctx);\n    }\n    const indent = ctx.indent ||\n        (ctx.forceBlockIndent || containsDocumentMarker(value) ? '  ' : '');\n    const literal = blockQuote === 'literal'\n        ? true\n        : blockQuote === 'folded' || type === Scalar.Scalar.BLOCK_FOLDED\n            ? false\n            : type === Scalar.Scalar.BLOCK_LITERAL\n                ? true\n                : !lineLengthOverLimit(value, lineWidth, indent.length);\n    if (!value)\n        return literal ? '|\\n' : '>\\n';\n    // determine chomping from whitespace at value end\n    let chomp;\n    let endStart;\n    for (endStart = value.length; endStart > 0; --endStart) {\n        const ch = value[endStart - 1];\n        if (ch !== '\\n' && ch !== '\\t' && ch !== ' ')\n            break;\n    }\n    let end = value.substring(endStart);\n    const endNlPos = end.indexOf('\\n');\n    if (endNlPos === -1) {\n        chomp = '-'; // strip\n    }\n    else if (value === end || endNlPos !== end.length - 1) {\n        chomp = '+'; // keep\n        if (onChompKeep)\n            onChompKeep();\n    }\n    else {\n        chomp = ''; // clip\n    }\n    if (end) {\n        value = value.slice(0, -end.length);\n        if (end[end.length - 1] === '\\n')\n            end = end.slice(0, -1);\n        end = end.replace(blockEndNewlines, `$&${indent}`);\n    }\n    // determine indent indicator from whitespace at value start\n    let startWithSpace = false;\n    let startEnd;\n    let startNlPos = -1;\n    for (startEnd = 0; startEnd < value.length; ++startEnd) {\n        const ch = value[startEnd];\n        if (ch === ' ')\n            startWithSpace = true;\n        else if (ch === '\\n')\n            startNlPos = startEnd;\n        else\n            break;\n    }\n    let start = value.substring(0, startNlPos < startEnd ? startNlPos + 1 : startEnd);\n    if (start) {\n        value = value.substring(start.length);\n        start = start.replace(/\\n+/g, `$&${indent}`);\n    }\n    const indentSize = indent ? '2' : '1'; // root is at -1\n    let header = (literal ? '|' : '>') + (startWithSpace ? indentSize : '') + chomp;\n    if (comment) {\n        header += ' ' + commentString(comment.replace(/ ?[\\r\\n]+/g, ' '));\n        if (onComment)\n            onComment();\n    }\n    if (literal) {\n        value = value.replace(/\\n+/g, `$&${indent}`);\n        return `${header}\\n${indent}${start}${value}${end}`;\n    }\n    value = value\n        .replace(/\\n+/g, '\\n$&')\n        .replace(/(?:^|\\n)([\\t ].*)(?:([\\n\\t ]*)\\n(?![\\n\\t ]))?/g, '$1$2') // more-indented lines aren't folded\n        //                ^ more-ind. ^ empty     ^ capture next empty lines only at end of indent\n        .replace(/\\n+/g, `$&${indent}`);\n    const body = foldFlowLines.foldFlowLines(`${start}${value}${end}`, indent, foldFlowLines.FOLD_BLOCK, getFoldOptions(ctx, true));\n    return `${header}\\n${indent}${body}`;\n}\nfunction plainString(item, ctx, onComment, onChompKeep) {\n    const { type, value } = item;\n    const { actualString, implicitKey, indent, indentStep, inFlow } = ctx;\n    if ((implicitKey && value.includes('\\n')) ||\n        (inFlow && /[[\\]{},]/.test(value))) {\n        return quotedString(value, ctx);\n    }\n    if (!value ||\n        /^[\\n\\t ,[\\]{}#&*!|>'\"%@`]|^[?-]$|^[?-][ \\t]|[\\n:][ \\t]|[ \\t]\\n|[\\n\\t ]#|[\\n\\t :]$/.test(value)) {\n        // not allowed:\n        // - empty string, '-' or '?'\n        // - start with an indicator character (except [?:-]) or /[?-] /\n        // - '\\n ', ': ' or ' \\n' anywhere\n        // - '#' not preceded by a non-space char\n        // - end with ' ' or ':'\n        return implicitKey || inFlow || !value.includes('\\n')\n            ? quotedString(value, ctx)\n            : blockString(item, ctx, onComment, onChompKeep);\n    }\n    if (!implicitKey &&\n        !inFlow &&\n        type !== Scalar.Scalar.PLAIN &&\n        value.includes('\\n')) {\n        // Where allowed & type not set explicitly, prefer block style for multiline strings\n        return blockString(item, ctx, onComment, onChompKeep);\n    }\n    if (containsDocumentMarker(value)) {\n        if (indent === '') {\n            ctx.forceBlockIndent = true;\n            return blockString(item, ctx, onComment, onChompKeep);\n        }\n        else if (implicitKey && indent === indentStep) {\n            return quotedString(value, ctx);\n        }\n    }\n    const str = value.replace(/\\n+/g, `$&\\n${indent}`);\n    // Verify that output will be parsed as a string, as e.g. plain numbers and\n    // booleans get parsed with those types in v1.2 (e.g. '42', 'true' & '0.9e-3'),\n    // and others in v1.1.\n    if (actualString) {\n        const test = (tag) => tag.default && tag.tag !== 'tag:yaml.org,2002:str' && tag.test?.test(str);\n        const { compat, tags } = ctx.doc.schema;\n        if (tags.some(test) || compat?.some(test))\n            return quotedString(value, ctx);\n    }\n    return implicitKey\n        ? str\n        : foldFlowLines.foldFlowLines(str, indent, foldFlowLines.FOLD_FLOW, getFoldOptions(ctx, false));\n}\nfunction stringifyString(item, ctx, onComment, onChompKeep) {\n    const { implicitKey, inFlow } = ctx;\n    const ss = typeof item.value === 'string'\n        ? item\n        : Object.assign({}, item, { value: String(item.value) });\n    let { type } = item;\n    if (type !== Scalar.Scalar.QUOTE_DOUBLE) {\n        // force double quotes on control characters & unpaired surrogates\n        if (/[\\x00-\\x08\\x0b-\\x1f\\x7f-\\x9f\\u{D800}-\\u{DFFF}]/u.test(ss.value))\n            type = Scalar.Scalar.QUOTE_DOUBLE;\n    }\n    const _stringify = (_type) => {\n        switch (_type) {\n            case Scalar.Scalar.BLOCK_FOLDED:\n            case Scalar.Scalar.BLOCK_LITERAL:\n                return implicitKey || inFlow\n                    ? quotedString(ss.value, ctx) // blocks are not valid inside flow containers\n                    : blockString(ss, ctx, onComment, onChompKeep);\n            case Scalar.Scalar.QUOTE_DOUBLE:\n                return doubleQuotedString(ss.value, ctx);\n            case Scalar.Scalar.QUOTE_SINGLE:\n                return singleQuotedString(ss.value, ctx);\n            case Scalar.Scalar.PLAIN:\n                return plainString(ss, ctx, onComment, onChompKeep);\n            default:\n                return null;\n        }\n    };\n    let res = _stringify(type);\n    if (res === null) {\n        const { defaultKeyType, defaultStringType } = ctx.options;\n        const t = (implicitKey && defaultKeyType) || defaultStringType;\n        res = _stringify(t);\n        if (res === null)\n            throw new Error(`Unsupported default string type ${t}`);\n    }\n    return res;\n}\n\nexports.stringifyString = stringifyString;\n","'use strict';\n\nvar identity = require('./nodes/identity.js');\n\nconst BREAK = Symbol('break visit');\nconst SKIP = Symbol('skip children');\nconst REMOVE = Symbol('remove node');\n/**\n * Apply a visitor to an AST node or document.\n *\n * Walks through the tree (depth-first) starting from `node`, calling a\n * `visitor` function with three arguments:\n *   - `key`: For sequence values and map `Pair`, the node's index in the\n *     collection. Within a `Pair`, `'key'` or `'value'`, correspondingly.\n *     `null` for the root node.\n *   - `node`: The current node.\n *   - `path`: The ancestry of the current node.\n *\n * The return value of the visitor may be used to control the traversal:\n *   - `undefined` (default): Do nothing and continue\n *   - `visit.SKIP`: Do not visit the children of this node, continue with next\n *     sibling\n *   - `visit.BREAK`: Terminate traversal completely\n *   - `visit.REMOVE`: Remove the current node, then continue with the next one\n *   - `Node`: Replace the current node, then continue by visiting it\n *   - `number`: While iterating the items of a sequence or map, set the index\n *     of the next step. This is useful especially if the index of the current\n *     node has changed.\n *\n * If `visitor` is a single function, it will be called with all values\n * encountered in the tree, including e.g. `null` values. Alternatively,\n * separate visitor functions may be defined for each `Map`, `Pair`, `Seq`,\n * `Alias` and `Scalar` node. To define the same visitor function for more than\n * one node type, use the `Collection` (map and seq), `Value` (map, seq & scalar)\n * and `Node` (alias, map, seq & scalar) targets. Of all these, only the most\n * specific defined one will be used for each node.\n */\nfunction visit(node, visitor) {\n    const visitor_ = initVisitor(visitor);\n    if (identity.isDocument(node)) {\n        const cd = visit_(null, node.contents, visitor_, Object.freeze([node]));\n        if (cd === REMOVE)\n            node.contents = null;\n    }\n    else\n        visit_(null, node, visitor_, Object.freeze([]));\n}\n// Without the `as symbol` casts, TS declares these in the `visit`\n// namespace using `var`, but then complains about that because\n// `unique symbol` must be `const`.\n/** Terminate visit traversal completely */\nvisit.BREAK = BREAK;\n/** Do not visit the children of the current node */\nvisit.SKIP = SKIP;\n/** Remove the current node */\nvisit.REMOVE = REMOVE;\nfunction visit_(key, node, visitor, path) {\n    const ctrl = callVisitor(key, node, visitor, path);\n    if (identity.isNode(ctrl) || identity.isPair(ctrl)) {\n        replaceNode(key, path, ctrl);\n        return visit_(key, ctrl, visitor, path);\n    }\n    if (typeof ctrl !== 'symbol') {\n        if (identity.isCollection(node)) {\n            path = Object.freeze(path.concat(node));\n            for (let i = 0; i < node.items.length; ++i) {\n                const ci = visit_(i, node.items[i], visitor, path);\n                if (typeof ci === 'number')\n                    i = ci - 1;\n                else if (ci === BREAK)\n                    return BREAK;\n                else if (ci === REMOVE) {\n                    node.items.splice(i, 1);\n                    i -= 1;\n                }\n            }\n        }\n        else if (identity.isPair(node)) {\n            path = Object.freeze(path.concat(node));\n            const ck = visit_('key', node.key, visitor, path);\n            if (ck === BREAK)\n                return BREAK;\n            else if (ck === REMOVE)\n                node.key = null;\n            const cv = visit_('value', node.value, visitor, path);\n            if (cv === BREAK)\n                return BREAK;\n            else if (cv === REMOVE)\n                node.value = null;\n        }\n    }\n    return ctrl;\n}\n/**\n * Apply an async visitor to an AST node or document.\n *\n * Walks through the tree (depth-first) starting from `node`, calling a\n * `visitor` function with three arguments:\n *   - `key`: For sequence values and map `Pair`, the node's index in the\n *     collection. Within a `Pair`, `'key'` or `'value'`, correspondingly.\n *     `null` for the root node.\n *   - `node`: The current node.\n *   - `path`: The ancestry of the current node.\n *\n * The return value of the visitor may be used to control the traversal:\n *   - `Promise`: Must resolve to one of the following values\n *   - `undefined` (default): Do nothing and continue\n *   - `visit.SKIP`: Do not visit the children of this node, continue with next\n *     sibling\n *   - `visit.BREAK`: Terminate traversal completely\n *   - `visit.REMOVE`: Remove the current node, then continue with the next one\n *   - `Node`: Replace the current node, then continue by visiting it\n *   - `number`: While iterating the items of a sequence or map, set the index\n *     of the next step. This is useful especially if the index of the current\n *     node has changed.\n *\n * If `visitor` is a single function, it will be called with all values\n * encountered in the tree, including e.g. `null` values. Alternatively,\n * separate visitor functions may be defined for each `Map`, `Pair`, `Seq`,\n * `Alias` and `Scalar` node. To define the same visitor function for more than\n * one node type, use the `Collection` (map and seq), `Value` (map, seq & scalar)\n * and `Node` (alias, map, seq & scalar) targets. Of all these, only the most\n * specific defined one will be used for each node.\n */\nasync function visitAsync(node, visitor) {\n    const visitor_ = initVisitor(visitor);\n    if (identity.isDocument(node)) {\n        const cd = await visitAsync_(null, node.contents, visitor_, Object.freeze([node]));\n        if (cd === REMOVE)\n            node.contents = null;\n    }\n    else\n        await visitAsync_(null, node, visitor_, Object.freeze([]));\n}\n// Without the `as symbol` casts, TS declares these in the `visit`\n// namespace using `var`, but then complains about that because\n// `unique symbol` must be `const`.\n/** Terminate visit traversal completely */\nvisitAsync.BREAK = BREAK;\n/** Do not visit the children of the current node */\nvisitAsync.SKIP = SKIP;\n/** Remove the current node */\nvisitAsync.REMOVE = REMOVE;\nasync function visitAsync_(key, node, visitor, path) {\n    const ctrl = await callVisitor(key, node, visitor, path);\n    if (identity.isNode(ctrl) || identity.isPair(ctrl)) {\n        replaceNode(key, path, ctrl);\n        return visitAsync_(key, ctrl, visitor, path);\n    }\n    if (typeof ctrl !== 'symbol') {\n        if (identity.isCollection(node)) {\n            path = Object.freeze(path.concat(node));\n            for (let i = 0; i < node.items.length; ++i) {\n                const ci = await visitAsync_(i, node.items[i], visitor, path);\n                if (typeof ci === 'number')\n                    i = ci - 1;\n                else if (ci === BREAK)\n                    return BREAK;\n                else if (ci === REMOVE) {\n                    node.items.splice(i, 1);\n                    i -= 1;\n                }\n            }\n        }\n        else if (identity.isPair(node)) {\n            path = Object.freeze(path.concat(node));\n            const ck = await visitAsync_('key', node.key, visitor, path);\n            if (ck === BREAK)\n                return BREAK;\n            else if (ck === REMOVE)\n                node.key = null;\n            const cv = await visitAsync_('value', node.value, visitor, path);\n            if (cv === BREAK)\n                return BREAK;\n            else if (cv === REMOVE)\n                node.value = null;\n        }\n    }\n    return ctrl;\n}\nfunction initVisitor(visitor) {\n    if (typeof visitor === 'object' &&\n        (visitor.Collection || visitor.Node || visitor.Value)) {\n        return Object.assign({\n            Alias: visitor.Node,\n            Map: visitor.Node,\n            Scalar: visitor.Node,\n            Seq: visitor.Node\n        }, visitor.Value && {\n            Map: visitor.Value,\n            Scalar: visitor.Value,\n            Seq: visitor.Value\n        }, visitor.Collection && {\n            Map: visitor.Collection,\n            Seq: visitor.Collection\n        }, visitor);\n    }\n    return visitor;\n}\nfunction callVisitor(key, node, visitor, path) {\n    if (typeof visitor === 'function')\n        return visitor(key, node, path);\n    if (identity.isMap(node))\n        return visitor.Map?.(key, node, path);\n    if (identity.isSeq(node))\n        return visitor.Seq?.(key, node, path);\n    if (identity.isPair(node))\n        return visitor.Pair?.(key, node, path);\n    if (identity.isScalar(node))\n        return visitor.Scalar?.(key, node, path);\n    if (identity.isAlias(node))\n        return visitor.Alias?.(key, node, path);\n    return undefined;\n}\nfunction replaceNode(key, path, node) {\n    const parent = path[path.length - 1];\n    if (identity.isCollection(parent)) {\n        parent.items[key] = node;\n    }\n    else if (identity.isPair(parent)) {\n        if (key === 'key')\n            parent.key = node;\n        else\n            parent.value = node;\n    }\n    else if (identity.isDocument(parent)) {\n        parent.contents = node;\n    }\n    else {\n        const pt = identity.isAlias(parent) ? 'alias' : 'scalar';\n        throw new Error(`Cannot replace node with ${pt} parent`);\n    }\n}\n\nexports.visit = visit;\nexports.visitAsync = visitAsync;\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\tvar threw = true;\n\ttry {\n\t\t__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\t\tthrew = false;\n\t} finally {\n\t\tif(threw) delete __webpack_module_cache__[moduleId];\n\t}\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// getDefaultExport function for compatibility with non-harmony modules\n__webpack_require__.n = (module) => {\n\tvar getter = module && module.__esModule ?\n\t\t() => (module['default']) :\n\t\t() => (module);\n\t__webpack_require__.d(getter, { a: getter });\n\treturn getter;\n};","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","\nif (typeof __webpack_require__ !== 'undefined') __webpack_require__.ab = new URL('.', import.meta.url).pathname.slice(import.meta.url.match(/^file:\\/\\/\\/\\w:/) ? 1 : 0, -1) + \"/\";","var __defProp = Object.defineProperty;\nvar __name = (target, value) => __defProp(target, \"name\", { value, configurable: true });\n\n// src/IntStream.ts\nvar IntStream;\n((IntStream2) => {\n  IntStream2.EOF = -1;\n  IntStream2.UNKNOWN_SOURCE_NAME = \"<unknown>\";\n})(IntStream || (IntStream = {}));\n\n// src/Token.ts\nvar Token;\n((Token2) => {\n  Token2.INVALID_TYPE = 0;\n  Token2.EPSILON = -2;\n  Token2.MIN_USER_TOKEN_TYPE = 1;\n  Token2.EOF = IntStream.EOF;\n  Token2.DEFAULT_CHANNEL = 0;\n  Token2.HIDDEN_CHANNEL = 1;\n  Token2.MIN_USER_CHANNEL_VALUE = 2;\n})(Token || (Token = {}));\nvar isToken = /* @__PURE__ */ __name((candidate) => {\n  const token = candidate;\n  return token.tokenSource !== void 0 && token.channel !== void 0;\n}, \"isToken\");\n\n// src/misc/Interval.ts\nvar Interval = class _Interval {\n  static {\n    __name(this, \"Interval\");\n  }\n  static INVALID_INTERVAL = new _Interval(-1, -2);\n  static INTERVAL_POOL_MAX_VALUE = 1e3;\n  start;\n  stop;\n  static #cache = [];\n  #cachedHashCode;\n  constructor(start, stop) {\n    this.start = start;\n    this.stop = stop;\n    this.#cachedHashCode = Math.imul(651 + start, 31) + stop;\n  }\n  /**\n   * Creates a new interval from the given values.\n   *\n   * Interval objects are used readonly so share all with the\n   * same single value a==b up to some max size. Use an array as a perfect hash.\n   * Return shared object for 0..INTERVAL_POOL_MAX_VALUE or a new\n   * Interval object with a..a in it.  On Java.g4, 218623 IntervalSets\n   * have a..a (set with 1 element).\n   *\n   * @param a The start of the interval.\n   * @param b The end of the interval (inclusive).\n   *\n   * @returns A cached or new interval.\n   */\n  static of(a, b) {\n    if (a !== b || a < 0 || a > _Interval.INTERVAL_POOL_MAX_VALUE) {\n      return new _Interval(a, b);\n    }\n    if (!_Interval.#cache[a]) {\n      _Interval.#cache[a] = new _Interval(a, a);\n    }\n    return _Interval.#cache[a];\n  }\n  equals(o) {\n    return this.start === o.start && this.stop === o.stop;\n  }\n  hashCode() {\n    return this.#cachedHashCode;\n  }\n  /** Does this start completely before other? Disjoint */\n  startsBeforeDisjoint(other) {\n    return this.start < other.start && this.stop < other.start;\n  }\n  /** Does this start at or before other? Nondisjoint */\n  startsBeforeNonDisjoint(other) {\n    return this.start <= other.start && this.stop >= other.start;\n  }\n  /** Does this.start start after other.stop? May or may not be disjoint */\n  startsAfter(other) {\n    return this.start > other.start;\n  }\n  /** Does this start completely after other? Disjoint */\n  startsAfterDisjoint(other) {\n    return this.start > other.stop;\n  }\n  /** Does this start after other? NonDisjoint */\n  startsAfterNonDisjoint(other) {\n    return this.start > other.start && this.start <= other.stop;\n  }\n  /** Are both ranges disjoint? I.e., no overlap? */\n  disjoint(other) {\n    return this.startsBeforeDisjoint(other) || this.startsAfterDisjoint(other);\n  }\n  /** Are two intervals adjacent such as 0..41 and 42..42? */\n  adjacent(other) {\n    return this.start === other.stop + 1 || this.stop === other.start - 1;\n  }\n  properlyContains(other) {\n    return other.start >= this.start && other.stop <= this.stop;\n  }\n  /** Return the interval computed from combining this and other */\n  union(other) {\n    return _Interval.of(Math.min(this.start, other.start), Math.max(this.stop, other.stop));\n  }\n  /** Return the interval in common between this and o */\n  intersection(other) {\n    return _Interval.of(Math.max(this.start, other.start), Math.min(this.stop, other.stop));\n  }\n  /**\n   * Return the interval with elements from this not in other;\n   *  other must not be totally enclosed (properly contained)\n   *  within this, which would result in two disjoint intervals\n   *  instead of the single one returned by this method.\n   */\n  differenceNotProperlyContained(other) {\n    let diff = null;\n    if (other.startsBeforeNonDisjoint(this)) {\n      diff = _Interval.of(Math.max(this.start, other.stop + 1), this.stop);\n    } else if (other.startsAfterNonDisjoint(this)) {\n      diff = _Interval.of(this.start, other.start - 1);\n    }\n    return diff;\n  }\n  toString() {\n    if (this.start === this.stop) {\n      return this.start.toString();\n    } else {\n      return this.start.toString() + \"..\" + this.stop.toString();\n    }\n  }\n  get length() {\n    if (this.stop < this.start) {\n      return 0;\n    }\n    return this.stop - this.start + 1;\n  }\n};\n\n// src/Vocabulary.ts\nvar Vocabulary = class _Vocabulary {\n  static {\n    __name(this, \"Vocabulary\");\n  }\n  static EMPTY_NAMES = [];\n  /**\n   * Gets an empty {@link Vocabulary} instance.\n   *\n   *\n   * No literal or symbol names are assigned to token types, so\n   * {@link #getDisplayName(int)} returns the numeric value for all tokens\n   * except {@link Token#EOF}.\n   */\n  static EMPTY_VOCABULARY = new _Vocabulary(_Vocabulary.EMPTY_NAMES, _Vocabulary.EMPTY_NAMES, _Vocabulary.EMPTY_NAMES);\n  maxTokenType;\n  literalNames;\n  symbolicNames;\n  displayNames;\n  /**\n   * Constructs a new instance of {@link Vocabulary} from the specified\n   * literal, symbolic, and display token names.\n   *\n   * @param literalNames The literal names assigned to tokens, or `null`\n   * if no literal names are assigned.\n   * @param symbolicNames The symbolic names assigned to tokens, or\n   * `null` if no symbolic names are assigned.\n   * @param displayNames The display names assigned to tokens, or `null`\n   * to use the values in `literalNames` and `symbolicNames` as\n   * the source of display names, as described in\n   * {@link #getDisplayName(int)}.\n   */\n  constructor(literalNames, symbolicNames, displayNames) {\n    this.literalNames = literalNames ?? _Vocabulary.EMPTY_NAMES;\n    this.symbolicNames = symbolicNames ?? _Vocabulary.EMPTY_NAMES;\n    this.displayNames = displayNames ?? _Vocabulary.EMPTY_NAMES;\n    this.maxTokenType = Math.max(this.displayNames.length, Math.max(\n      this.literalNames.length,\n      this.symbolicNames.length\n    )) - 1;\n  }\n  /**\n   * Returns a {@link Vocabulary} instance from the specified set of token\n   * names. This method acts as a compatibility layer for the single\n   * `tokenNames` array generated by previous releases of ANTLR.\n   *\n   * The resulting vocabulary instance returns `null` for\n   * {@link getLiteralName getLiteralName(int)} and {@link getSymbolicName getSymbolicName(int)}, and the\n   * value from `tokenNames` for the display names.\n   *\n   * @param tokenNames The token names, or `null` if no token names are\n   * available.\n   * @returns A {@link Vocabulary} instance which uses `tokenNames` for\n   * the display names of tokens.\n   */\n  static fromTokenNames(tokenNames) {\n    if (tokenNames == null || tokenNames.length === 0) {\n      return _Vocabulary.EMPTY_VOCABULARY;\n    }\n    const literalNames = [...tokenNames];\n    const symbolicNames = [...tokenNames];\n    for (let i = 0; i < tokenNames.length; i++) {\n      const tokenName = tokenNames[i];\n      if (tokenName == null) {\n        continue;\n      }\n      if (tokenName?.length > 0) {\n        const firstChar = tokenName.charAt(0);\n        if (firstChar === \"'\") {\n          symbolicNames[i] = null;\n          continue;\n        } else if (firstChar.toUpperCase() === firstChar) {\n          literalNames[i] = null;\n          continue;\n        }\n      }\n      literalNames[i] = null;\n      symbolicNames[i] = null;\n    }\n    return new _Vocabulary(literalNames, symbolicNames, tokenNames);\n  }\n  getMaxTokenType() {\n    return this.maxTokenType;\n  }\n  getLiteralName(tokenType) {\n    if (tokenType >= 0 && tokenType < this.literalNames.length) {\n      return this.literalNames[tokenType];\n    }\n    return null;\n  }\n  getSymbolicName(tokenType) {\n    if (tokenType >= 0 && tokenType < this.symbolicNames.length) {\n      return this.symbolicNames[tokenType];\n    }\n    if (tokenType === Token.EOF) {\n      return \"EOF\";\n    }\n    return null;\n  }\n  getDisplayName(tokenType) {\n    if (tokenType >= 0 && tokenType < this.displayNames.length) {\n      const displayName = this.displayNames[tokenType];\n      if (displayName != null) {\n        return displayName;\n      }\n    }\n    const literalName = this.getLiteralName(tokenType);\n    if (literalName != null) {\n      return literalName;\n    }\n    const symbolicName = this.getSymbolicName(tokenType);\n    if (symbolicName != null) {\n      return symbolicName;\n    }\n    return `${tokenType}`;\n  }\n  getLiteralNames() {\n    return this.literalNames;\n  }\n  getSymbolicNames() {\n    return this.symbolicNames;\n  }\n  getDisplayNames() {\n    return this.displayNames;\n  }\n};\n\n// src/utils/MurmurHash.ts\nvar c1 = 3432918353;\nvar c2 = 461845907;\nvar r1 = 15;\nvar r2 = 13;\nvar m = 5;\nvar n = 3864292196;\nvar MurmurHash = class _MurmurHash {\n  static {\n    __name(this, \"MurmurHash\");\n  }\n  static #defaultSeed = 701;\n  constructor() {\n  }\n  /**\n   * Initialize the hash using the specified {@code seed}.\n   *\n   * @param seed the seed\n   *\n   * @returns the intermediate hash value\n   */\n  static initialize(seed = _MurmurHash.#defaultSeed) {\n    return seed;\n  }\n  static updateFromComparable(hash, value) {\n    return this.update(hash, value?.hashCode() ?? 0);\n  }\n  /**\n   * Update the intermediate hash value for the next input {@code value}.\n   *\n   * @param hash The intermediate hash value.\n   * @param value the value to add to the current hash.\n   *\n   * @returns the updated intermediate hash value\n   */\n  static update(hash, value) {\n    value = Math.imul(value, c1);\n    value = value << r1 | value >>> 32 - r1;\n    value = Math.imul(value, c2);\n    hash = hash ^ value;\n    hash = hash << r2 | hash >>> 32 - r2;\n    hash = Math.imul(hash, m) + n;\n    return hash;\n  }\n  /**\n   * Apply the final computation steps to the intermediate value {@code hash}\n   * to form the final result of the MurmurHash 3 hash function.\n   *\n   * @param hash The intermediate hash value.\n   * @param entryCount The number of values added to the hash.\n   *\n   * @returns the final hash result\n   */\n  static finish = (hash, entryCount) => {\n    hash ^= entryCount * 4;\n    hash ^= hash >>> 16;\n    hash = Math.imul(hash, 2246822507);\n    hash ^= hash >>> 13;\n    hash = Math.imul(hash, 3266489909);\n    hash ^= hash >>> 16;\n    return hash;\n  };\n  /**\n   * An all-in-one convenience method to compute a hash for a single value.\n   *\n   * @param value The value to hash.\n   * @param seed The seed for the hash value.\n   *\n   * @returns The computed hash.\n   */\n  static hashCode = (value, seed) => {\n    return _MurmurHash.finish(_MurmurHash.update(seed ?? _MurmurHash.#defaultSeed, value), 1);\n  };\n};\n\n// src/misc/IntervalSet.ts\nvar IntervalSet = class _IntervalSet {\n  static {\n    __name(this, \"IntervalSet\");\n  }\n  /** The list of sorted, disjoint intervals. */\n  #intervals = [];\n  #cachedHashCode;\n  constructor(set) {\n    if (set) {\n      this.addSet(set);\n    }\n  }\n  /** Create a set with all ints within range [a..b] (inclusive) */\n  static of(a, b) {\n    const s = new _IntervalSet();\n    s.addRange(a, b);\n    return s;\n  }\n  [Symbol.iterator]() {\n    return this.#intervals[Symbol.iterator]();\n  }\n  get(index) {\n    return this.#intervals[index];\n  }\n  /**\n   * Returns the minimum value contained in the set if not isNil().\n   *\n   * @returns the minimum value contained in the set.\n   */\n  get minElement() {\n    if (this.#intervals.length === 0) {\n      return Token.INVALID_TYPE;\n    }\n    return this.#intervals[0].start;\n  }\n  /**\n   * Returns the maximum value contained in the set if not isNil().\n   *\n   * @returns the maximum value contained in the set.\n   */\n  get maxElement() {\n    if (this.#intervals.length === 0) {\n      return Token.INVALID_TYPE;\n    }\n    return this.#intervals[this.#intervals.length - 1].stop;\n  }\n  clear() {\n    this.#cachedHashCode = void 0;\n    this.#intervals = [];\n  }\n  /**\n   * Add a single element to the set.  An isolated element is stored\n   *  as a range el..el.\n   */\n  addOne(v) {\n    this.addInterval(new Interval(v, v));\n  }\n  /**\n   * Add interval; i.e., add all integers from a to b to set.\n   *  If b < a, do nothing.\n   *  Keep list in sorted order (by left range value).\n   *  If overlap, combine ranges. For example,\n   *  If this is {1..5, 10..20}, adding 6..7 yields\n   *  {1..5, 6..7, 10..20}. Adding 4..8 yields {1..8, 10..20}.\n   */\n  addRange(l, h) {\n    this.addInterval(new Interval(l, h));\n  }\n  addInterval(addition) {\n    this.#cachedHashCode = void 0;\n    if (this.#intervals.length === 0) {\n      this.#intervals.push(addition);\n    } else {\n      for (let pos = 0; pos < this.#intervals.length; pos++) {\n        const existing = this.#intervals[pos];\n        if (addition.equals(existing)) {\n          return;\n        }\n        if (addition.adjacent(existing) || !addition.disjoint(existing)) {\n          const bigger = addition.union(existing);\n          this.#intervals[pos] = bigger;\n          for (let sub = pos + 1; sub < this.#intervals.length; ) {\n            const next = this.#intervals[sub];\n            if (!bigger.adjacent(next) && bigger.disjoint(next)) {\n              break;\n            }\n            this.#intervals.splice(sub, 1);\n            this.#intervals[pos] = bigger.union(next);\n          }\n          return;\n        }\n        if (addition.startsBeforeDisjoint(existing)) {\n          this.#intervals.splice(pos, 0, addition);\n          return;\n        }\n      }\n      this.#intervals.push(addition);\n    }\n  }\n  addSet(other) {\n    other.#intervals.forEach((toAdd) => {\n      return this.addInterval(toAdd);\n    }, this);\n    return this;\n  }\n  complementWithVocabulary(vocabulary) {\n    const result = new _IntervalSet();\n    if (!vocabulary) {\n      return result;\n    }\n    if (vocabulary.length === 0) {\n      return result;\n    }\n    result.addSet(vocabulary);\n    return result.subtract(this);\n  }\n  complement(minElement, maxElement) {\n    const result = new _IntervalSet();\n    result.addInterval(new Interval(minElement, maxElement));\n    return result.subtract(this);\n  }\n  /** combine all sets in the array returned the or'd value */\n  or(sets) {\n    const result = new _IntervalSet();\n    result.addSet(this);\n    sets.forEach((set) => {\n      return result.addSet(set);\n    });\n    return result;\n  }\n  and(other) {\n    if (other.length === 0) {\n      return new _IntervalSet();\n    }\n    const myIntervals = this.#intervals;\n    const theirIntervals = other.#intervals;\n    let intersection;\n    const mySize = myIntervals.length;\n    const theirSize = theirIntervals.length;\n    let i = 0;\n    let j = 0;\n    while (i < mySize && j < theirSize) {\n      const mine = myIntervals[i];\n      const theirs = theirIntervals[j];\n      if (mine.startsBeforeDisjoint(theirs)) {\n        i++;\n      } else if (theirs.startsBeforeDisjoint(mine)) {\n        j++;\n      } else if (mine.properlyContains(theirs)) {\n        if (!intersection) {\n          intersection = new _IntervalSet();\n        }\n        intersection.addInterval(mine.intersection(theirs));\n        j++;\n      } else if (theirs.properlyContains(mine)) {\n        if (!intersection) {\n          intersection = new _IntervalSet();\n        }\n        intersection.addInterval(mine.intersection(theirs));\n        i++;\n      } else if (!mine.disjoint(theirs)) {\n        if (!intersection) {\n          intersection = new _IntervalSet();\n        }\n        intersection.addInterval(mine.intersection(theirs));\n        if (mine.startsAfterNonDisjoint(theirs)) {\n          j++;\n        } else if (theirs.startsAfterNonDisjoint(mine)) {\n          i++;\n        }\n      }\n    }\n    if (!intersection) {\n      return new _IntervalSet();\n    }\n    return intersection;\n  }\n  /**\n   * Compute the set difference between two interval sets. The specific\n   * operation is `left - right`. If either of the input sets is\n   * `null`, it is treated as though it was an empty set.\n   */\n  subtract(other) {\n    if (this.length === 0) {\n      return new _IntervalSet();\n    }\n    const result = new _IntervalSet(this);\n    if (other.length === 0) {\n      return result;\n    }\n    let resultI = 0;\n    let rightI = 0;\n    while (resultI < result.#intervals.length && rightI < other.#intervals.length) {\n      const resultInterval = result.#intervals[resultI];\n      const rightInterval = other.#intervals[rightI];\n      if (rightInterval.stop < resultInterval.start) {\n        rightI++;\n        continue;\n      }\n      if (rightInterval.start > resultInterval.stop) {\n        resultI++;\n        continue;\n      }\n      let beforeCurrent;\n      let afterCurrent;\n      if (rightInterval.start > resultInterval.start) {\n        beforeCurrent = new Interval(resultInterval.start, rightInterval.start - 1);\n      }\n      if (rightInterval.stop < resultInterval.stop) {\n        afterCurrent = new Interval(rightInterval.stop + 1, resultInterval.stop);\n      }\n      if (beforeCurrent) {\n        if (afterCurrent) {\n          result.#intervals[resultI] = beforeCurrent;\n          result.#intervals.splice(resultI + 1, 0, afterCurrent);\n          resultI++;\n          rightI++;\n        } else {\n          result.#intervals[resultI] = beforeCurrent;\n          resultI++;\n        }\n      } else {\n        if (afterCurrent) {\n          result.#intervals[resultI] = afterCurrent;\n          rightI++;\n        } else {\n          result.#intervals.splice(resultI, 1);\n        }\n      }\n    }\n    return result;\n  }\n  contains(el) {\n    const n2 = this.#intervals.length;\n    let l = 0;\n    let r = n2 - 1;\n    while (l <= r) {\n      const m2 = Math.floor((l + r) / 2);\n      const interval = this.#intervals[m2];\n      if (interval.stop < el) {\n        l = m2 + 1;\n      } else if (interval.start > el) {\n        r = m2 - 1;\n      } else {\n        return true;\n      }\n    }\n    return false;\n  }\n  removeRange(toRemove) {\n    this.#cachedHashCode = void 0;\n    if (toRemove.start === toRemove.stop) {\n      this.removeOne(toRemove.start);\n    } else if (this.#intervals !== null) {\n      let pos = 0;\n      for (const existing of this.#intervals) {\n        if (toRemove.stop <= existing.start) {\n          return;\n        } else if (toRemove.start > existing.start && toRemove.stop < existing.stop) {\n          this.#intervals[pos] = new Interval(existing.start, toRemove.start);\n          const x = new Interval(toRemove.stop, existing.stop);\n          this.#intervals.splice(pos, 0, x);\n          return;\n        } else if (toRemove.start <= existing.start && toRemove.stop >= existing.stop) {\n          this.#intervals.splice(pos, 1);\n          pos = pos - 1;\n        } else if (toRemove.start < existing.stop) {\n          this.#intervals[pos] = new Interval(existing.start, toRemove.start);\n        } else if (toRemove.stop < existing.stop) {\n          this.#intervals[pos] = new Interval(toRemove.stop, existing.stop);\n        }\n        pos += 1;\n      }\n    }\n  }\n  removeOne(value) {\n    this.#cachedHashCode = void 0;\n    for (let i = 0; i < this.#intervals.length; i++) {\n      const existing = this.#intervals[i];\n      if (value < existing.start) {\n        return;\n      } else if (value === existing.start && value === existing.stop) {\n        this.#intervals.splice(i, 1);\n        return;\n      } else if (value === existing.start) {\n        this.#intervals[i] = new Interval(existing.start + 1, existing.stop);\n        return;\n      } else if (value === existing.stop) {\n        this.#intervals[i] = new Interval(existing.start, existing.stop);\n        return;\n      } else if (value < existing.stop) {\n        const replace = new Interval(existing.start, value);\n        this.#intervals[i] = new Interval(value + 1, existing.stop);\n        this.#intervals.splice(i, 0, replace);\n        return;\n      }\n    }\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      for (const interval of this.#intervals) {\n        hash = MurmurHash.update(hash, interval.start);\n        hash = MurmurHash.update(hash, interval.stop);\n      }\n      this.#cachedHashCode = MurmurHash.finish(hash, this.#intervals.length * 2);\n    }\n    return this.#cachedHashCode;\n  }\n  /**\n   * Are two IntervalSets equal? Because all intervals are sorted and disjoint, equals is a simple linear walk over\n   * both lists to make sure they are the same. Interval.equals() is used by the List.equals() method to check\n   * the ranges.\n   */\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (this.#intervals.length !== other.#intervals.length) {\n      return false;\n    }\n    for (let i = 0; i < this.#intervals.length; i++) {\n      if (!this.#intervals[i].equals(other.#intervals[i])) {\n        return false;\n      }\n    }\n    return true;\n  }\n  toString(elementsAreChar) {\n    if (this.#intervals.length === 0) {\n      return \"{}\";\n    }\n    let result = \"\";\n    if (this.length > 1) {\n      result += \"{\";\n    }\n    for (let i = 0; i < this.#intervals.length; ++i) {\n      const interval = this.#intervals[i];\n      const start = interval.start;\n      const stop = interval.stop;\n      if (start === stop) {\n        if (start === Token.EOF) {\n          result += \"<EOF>\";\n        } else if (elementsAreChar) {\n          result += \"'\" + String.fromCodePoint(start) + \"'\";\n        } else {\n          result += start;\n        }\n      } else {\n        if (elementsAreChar) {\n          result += \"'\" + String.fromCodePoint(start) + \"'..'\" + String.fromCodePoint(stop) + \"'\";\n        } else {\n          result += start + \"..\" + stop;\n        }\n      }\n      if (i < this.#intervals.length - 1) {\n        result += \", \";\n      }\n    }\n    if (this.length > 1) {\n      result += \"}\";\n    }\n    return result;\n  }\n  toStringWithVocabulary(vocabulary) {\n    if (this.#intervals.length === 0) {\n      return \"{}\";\n    }\n    let result = \"\";\n    if (this.length > 1) {\n      result += \"{\";\n    }\n    for (let i = 0; i < this.#intervals.length; ++i) {\n      const interval = this.#intervals[i];\n      const start = interval.start;\n      const stop = interval.stop;\n      if (start === stop) {\n        if (start === Token.EOF) {\n          result += \"<EOF>\";\n        } else {\n          result += this.elementName(vocabulary, start);\n        }\n      } else {\n        for (let i2 = start; i2 <= stop; ++i2) {\n          if (i2 > start) {\n            result += \", \";\n          }\n          result += this.elementName(vocabulary, i2);\n        }\n      }\n      if (i < this.#intervals.length - 1) {\n        result += \", \";\n      }\n    }\n    if (this.length > 1) {\n      result += \"}\";\n    }\n    return result;\n  }\n  toStringWithRuleNames(ruleNames) {\n    if (this.#intervals.length === 0) {\n      return \"{}\";\n    }\n    let result = \"\";\n    if (this.length > 1) {\n      result += \"{\";\n    }\n    const vocabulary = Vocabulary.fromTokenNames(ruleNames);\n    for (let i = 0; i < this.#intervals.length; ++i) {\n      const interval = this.#intervals[i];\n      const start = interval.start;\n      const stop = interval.stop;\n      if (start === stop) {\n        if (start === Token.EOF) {\n          result += \"<EOF>\";\n        } else {\n          result += this.elementName(vocabulary, start);\n        }\n      } else {\n        for (let i2 = start; i2 <= stop; ++i2) {\n          if (i2 > start) {\n            result += \", \";\n          }\n          result += this.elementName(vocabulary, i2);\n        }\n      }\n      if (i < this.#intervals.length - 1) {\n        result += \", \";\n      }\n    }\n    if (this.length > 1) {\n      result += \"}\";\n    }\n    return result;\n  }\n  toArray() {\n    const data = [];\n    for (const interval of this.#intervals) {\n      for (let j = interval.start; j <= interval.stop; j++) {\n        data.push(j);\n      }\n    }\n    return data;\n  }\n  get length() {\n    let result = 0;\n    const intervalCount = this.#intervals.length;\n    if (intervalCount === 1) {\n      const firstInterval = this.#intervals[0];\n      return firstInterval.stop - firstInterval.start + 1;\n    }\n    for (const interval of this.#intervals) {\n      result += interval.length;\n    }\n    return result;\n  }\n  elementName(vocabulary, token) {\n    if (token === Token.EOF) {\n      return \"<EOF>\";\n    }\n    if (token === Token.EPSILON) {\n      return \"<EPSILON>\";\n    }\n    return vocabulary.getDisplayName(token);\n  }\n};\n\n// src/atn/Transition.ts\nvar Transition = class {\n  static {\n    __name(this, \"Transition\");\n  }\n  static INVALID = 0;\n  static EPSILON = 1;\n  static RANGE = 2;\n  static RULE = 3;\n  static PREDICATE = 4;\n  // e.g., {isType(input.LT(1))}\n  static ATOM = 5;\n  static ACTION = 6;\n  static SET = 7;\n  // ~(A|B) or ~atom, wildcard, which convert to next\n  static NOT_SET = 8;\n  static WILDCARD = 9;\n  static PRECEDENCE = 10;\n  /** The target of this transition. */\n  target;\n  constructor(target) {\n    this.target = target;\n  }\n  /**\n   * Determines if the transition is an \"epsilon\" transition.\n   *\n   * The default implementation returns `false`.\n   *\n   * @returns `true` if traversing this transition in the ATN does not\n   * consume an input symbol; otherwise, `false` if traversing this\n   * transition consumes (matches) an input symbol.\n   */\n  get isEpsilon() {\n    return false;\n  }\n  get label() {\n    return null;\n  }\n};\n\n// src/atn/SetTransition.ts\nvar SetTransition = class extends Transition {\n  static {\n    __name(this, \"SetTransition\");\n  }\n  set;\n  constructor(target, set) {\n    super(target);\n    if (set) {\n      this.set = set;\n    } else {\n      this.set = IntervalSet.of(Token.INVALID_TYPE, Token.INVALID_TYPE);\n    }\n  }\n  get transitionType() {\n    return Transition.SET;\n  }\n  get label() {\n    return this.set;\n  }\n  matches(symbol, _minVocabSymbol, _maxVocabSymbol) {\n    return this.set.contains(symbol);\n  }\n  toString() {\n    return this.set.toString();\n  }\n};\n\n// src/atn/NotSetTransition.ts\nvar NotSetTransition = class extends SetTransition {\n  static {\n    __name(this, \"NotSetTransition\");\n  }\n  get transitionType() {\n    return Transition.NOT_SET;\n  }\n  matches(symbol, minVocabSymbol, maxVocabSymbol) {\n    return symbol >= minVocabSymbol && symbol <= maxVocabSymbol && !super.matches(symbol, minVocabSymbol, maxVocabSymbol);\n  }\n  toString() {\n    return \"~\" + super.toString();\n  }\n};\n\n// src/atn/PredictionContext.ts\nvar PredictionContext = class _PredictionContext {\n  static {\n    __name(this, \"PredictionContext\");\n  }\n  /**\n   * Represents `$` in an array in full context mode, when `$`\n   * doesn't mean wildcard: `$ + x = [$,x]`. Here,\n   * `$` = {@link EMPTY_RETURN_STATE}.\n   */\n  static EMPTY_RETURN_STATE = 2147483647;\n  // TODO: Temporarily here. Should be moved to EmptyPredictionContext. It's initialized in that context class.\n  static EMPTY;\n  static traceATNSimulator = false;\n  #cachedHashCode;\n  constructor(cachedHashCode) {\n    this.#cachedHashCode = cachedHashCode;\n  }\n  static calculateEmptyHashCode() {\n    let hash = MurmurHash.initialize(31);\n    hash = MurmurHash.finish(hash, 0);\n    return hash;\n  }\n  static calculateHashCodeSingle(parent, returnState) {\n    let hash = MurmurHash.initialize(31);\n    hash = MurmurHash.updateFromComparable(hash, parent);\n    hash = MurmurHash.update(hash, returnState);\n    hash = MurmurHash.finish(hash, 2);\n    return hash;\n  }\n  static calculateHashCodeList(parents, returnStates) {\n    let hash = MurmurHash.initialize(31);\n    for (const parent of parents) {\n      hash = MurmurHash.updateFromComparable(hash, parent);\n    }\n    for (const returnState of returnStates) {\n      hash = MurmurHash.update(hash, returnState);\n    }\n    hash = MurmurHash.finish(hash, 2 * parents.length);\n    return hash;\n  }\n  isEmpty() {\n    return false;\n  }\n  hasEmptyPath() {\n    return this.getReturnState(this.length - 1) === _PredictionContext.EMPTY_RETURN_STATE;\n  }\n  hashCode() {\n    return this.#cachedHashCode;\n  }\n  toString(_recog) {\n    return \"\";\n  }\n};\n\n// src/utils/helpers.ts\nvar isComparable = /* @__PURE__ */ __name((candidate) => {\n  return typeof candidate.equals === \"function\";\n}, \"isComparable\");\nvar valueToString = /* @__PURE__ */ __name((v) => {\n  return v === null ? \"null\" : v;\n}, \"valueToString\");\nvar arrayToString = /* @__PURE__ */ __name((value) => {\n  return Array.isArray(value) ? \"[\" + value.map(valueToString).join(\", \") + \"]\" : \"null\";\n}, \"arrayToString\");\nvar equalArrays = /* @__PURE__ */ __name((a, b) => {\n  if (a === b) {\n    return true;\n  }\n  if (a.length !== b.length) {\n    return false;\n  }\n  for (let i = 0; i < a.length; i++) {\n    const left = a[i];\n    const right = b[i];\n    if (left === right) {\n      continue;\n    }\n    if (!left || !left.equals(right)) {\n      return false;\n    }\n  }\n  return true;\n}, \"equalArrays\");\nvar equalNumberArrays = /* @__PURE__ */ __name((a, b) => {\n  if (a === b) {\n    return true;\n  }\n  if (a.length !== b.length) {\n    return false;\n  }\n  for (let i = 0; i < a.length; i++) {\n    if (a[i] !== b[i]) {\n      return false;\n    }\n  }\n  return true;\n}, \"equalNumberArrays\");\nvar escapeWhitespace = /* @__PURE__ */ __name((s, escapeSpaces = false) => {\n  s = s.replace(/\\t/g, \"\\\\t\").replace(/\\n/g, \"\\\\n\").replace(/\\r/g, \"\\\\r\");\n  if (escapeSpaces) {\n    s = s.replace(/ /g, \"\\xB7\");\n  }\n  return s;\n}, \"escapeWhitespace\");\n\n// src/atn/ArrayPredictionContext.ts\nvar ArrayPredictionContext = class _ArrayPredictionContext extends PredictionContext {\n  static {\n    __name(this, \"ArrayPredictionContext\");\n  }\n  parents = [];\n  returnStates = [];\n  constructor(parents, returnStates) {\n    super(PredictionContext.calculateHashCodeList(parents, returnStates));\n    this.parents = parents;\n    this.returnStates = returnStates;\n    return this;\n  }\n  isEmpty() {\n    return this.returnStates[0] === PredictionContext.EMPTY_RETURN_STATE;\n  }\n  get length() {\n    return this.returnStates.length;\n  }\n  getParent(index) {\n    return this.parents[index];\n  }\n  getReturnState(index) {\n    return this.returnStates[index];\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _ArrayPredictionContext) || this.hashCode() !== other.hashCode()) {\n      return false;\n    }\n    return equalNumberArrays(this.returnStates, other.returnStates) && equalArrays(this.parents, other.parents);\n  }\n  toString() {\n    if (this.isEmpty()) {\n      return \"[]\";\n    }\n    const entries = [];\n    for (let i = 0; i < this.returnStates.length; i++) {\n      if (this.returnStates[i] === PredictionContext.EMPTY_RETURN_STATE) {\n        entries.push(\"$\");\n        continue;\n      }\n      entries.push(this.returnStates[i].toString());\n      if (this.parents[i]) {\n        entries.push(this.parents[i].toString());\n      } else {\n        entries.push(\"null\");\n      }\n    }\n    return `[${entries.join(\", \")}]`;\n  }\n};\n\n// src/atn/SingletonPredictionContext.ts\nvar SingletonPredictionContext = class _SingletonPredictionContext extends PredictionContext {\n  static {\n    __name(this, \"SingletonPredictionContext\");\n  }\n  parent;\n  returnState;\n  constructor(parent, returnState) {\n    super(\n      parent ? PredictionContext.calculateHashCodeSingle(parent, returnState) : PredictionContext.calculateEmptyHashCode()\n    );\n    this.parent = parent ?? null;\n    this.returnState = returnState;\n  }\n  static create(parent, returnState) {\n    if (returnState === PredictionContext.EMPTY_RETURN_STATE && parent === null) {\n      return PredictionContext.EMPTY;\n    } else {\n      return new _SingletonPredictionContext(parent, returnState);\n    }\n  }\n  getParent(_index) {\n    return this.parent;\n  }\n  getReturnState(_index) {\n    return this.returnState;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _SingletonPredictionContext)) {\n      return false;\n    }\n    if (this.hashCode() !== other.hashCode()) {\n      return false;\n    }\n    if (this.returnState !== other.returnState) {\n      return false;\n    }\n    if (this.parent == null) {\n      return other.parent == null;\n    }\n    return this.parent.equals(other.parent);\n  }\n  toString() {\n    const up = this.parent === null ? \"\" : this.parent.toString();\n    if (up.length === 0) {\n      if (this.returnState === PredictionContext.EMPTY_RETURN_STATE) {\n        return \"$\";\n      }\n      return \"\" + this.returnState;\n    } else {\n      return \"\" + this.returnState + \" \" + up;\n    }\n  }\n  get length() {\n    return 1;\n  }\n};\n\n// src/atn/EmptyPredictionContext.ts\nvar EmptyPredictionContext = class _EmptyPredictionContext extends SingletonPredictionContext {\n  static {\n    __name(this, \"EmptyPredictionContext\");\n  }\n  /**\n   * Represents `$` in local context prediction, which means wildcard.\n   * `*+x = *`.\n   */\n  static instance = new _EmptyPredictionContext();\n  constructor() {\n    super(void 0, PredictionContext.EMPTY_RETURN_STATE);\n  }\n  isEmpty() {\n    return true;\n  }\n  getParent() {\n    return null;\n  }\n  getReturnState() {\n    return this.returnState;\n  }\n  equals(other) {\n    return this === other;\n  }\n  toString() {\n    return \"$\";\n  }\n  static {\n    PredictionContext.EMPTY = new _EmptyPredictionContext();\n  }\n};\n\n// src/tree/TerminalNode.ts\nvar TerminalNode = class {\n  static {\n    __name(this, \"TerminalNode\");\n  }\n  parent = null;\n  symbol;\n  constructor(symbol) {\n    this.symbol = symbol;\n  }\n  getChild(_i) {\n    return null;\n  }\n  getSymbol() {\n    return this.symbol;\n  }\n  getPayload() {\n    return this.symbol;\n  }\n  getSourceInterval() {\n    if (this.symbol === null) {\n      return Interval.INVALID_INTERVAL;\n    }\n    const tokenIndex = this.symbol.tokenIndex;\n    return new Interval(tokenIndex, tokenIndex);\n  }\n  getChildCount() {\n    return 0;\n  }\n  accept(visitor) {\n    return visitor.visitTerminal(this);\n  }\n  getText() {\n    return this.symbol?.text ?? \"\";\n  }\n  toString() {\n    if (this.symbol?.type === Token.EOF) {\n      return \"<EOF>\";\n    } else {\n      return this.symbol?.text ?? \"\";\n    }\n  }\n  toStringTree() {\n    return this.toString();\n  }\n};\n\n// src/tree/ErrorNode.ts\nvar ErrorNode = class extends TerminalNode {\n  static {\n    __name(this, \"ErrorNode\");\n  }\n  accept(visitor) {\n    return visitor.visitErrorNode(this);\n  }\n};\n\n// src/tree/Trees.ts\nvar Trees = class _Trees {\n  static {\n    __name(this, \"Trees\");\n  }\n  /**\n   * Print out a whole tree in LISP form. {@link getNodeText} is used on the\n   * node payloads to get the text for the nodes.  Detect\n   * parse trees and extract data appropriately.\n   */\n  static toStringTree(tree, ruleNames, recog) {\n    ruleNames = ruleNames ?? null;\n    recog = recog ?? null;\n    if (recog !== null) {\n      ruleNames = recog.ruleNames;\n    }\n    let s = _Trees.getNodeText(tree, ruleNames);\n    s = escapeWhitespace(s, false);\n    const c = tree.getChildCount();\n    if (c === 0) {\n      return s;\n    }\n    let res = \"(\" + s + \" \";\n    if (c > 0) {\n      s = _Trees.toStringTree(tree.getChild(0), ruleNames);\n      res = res.concat(s);\n    }\n    for (let i = 1; i < c; i++) {\n      s = _Trees.toStringTree(tree.getChild(i), ruleNames);\n      res = res.concat(\" \" + s);\n    }\n    res = res.concat(\")\");\n    return res;\n  }\n  static getNodeText(t, ruleNames, recog) {\n    ruleNames = ruleNames ?? null;\n    recog = recog ?? null;\n    if (recog !== null) {\n      ruleNames = recog.ruleNames;\n    }\n    if (ruleNames !== null) {\n      if (t instanceof ParserRuleContext) {\n        const context = t.ruleContext;\n        const altNumber = context.getAltNumber();\n        if (altNumber !== 0) {\n          return ruleNames[t.ruleIndex] + \":\" + altNumber;\n        }\n        return ruleNames[t.ruleIndex];\n      } else if (t instanceof ErrorNode) {\n        return t.toString();\n      } else if (t instanceof TerminalNode) {\n        if (t.symbol !== null) {\n          return t.symbol.text;\n        }\n      }\n    }\n    const payload = t.getPayload();\n    if (isToken(payload)) {\n      return payload.text;\n    }\n    return String(t.getPayload());\n  }\n  /**\n   * Return ordered list of all children of this node\n   */\n  static getChildren(t) {\n    const list = [];\n    for (let i = 0; i < t.getChildCount(); i++) {\n      list.push(t.getChild(i));\n    }\n    return list;\n  }\n  /**\n   * Return a list of all ancestors of this node.  The first node of\n   * list is the root and the last is the parent of this node.\n   */\n  static getAncestors(t) {\n    if (t.parent === null) {\n      return [];\n    }\n    let ancestors = [];\n    let p = t.parent;\n    while (p !== null) {\n      ancestors = [p].concat(ancestors);\n      p = p.parent;\n    }\n    return ancestors;\n  }\n  static findAllTokenNodes(t, ttype) {\n    return _Trees.findAllNodes(t, ttype, true);\n  }\n  static findAllRuleNodes(t, ruleIndex) {\n    return _Trees.findAllNodes(t, ruleIndex, false);\n  }\n  static findAllNodes(t, index, findTokens) {\n    const nodes = [];\n    _Trees.doFindAllNodes(t, index, findTokens, nodes);\n    return nodes;\n  }\n  static descendants(t) {\n    let nodes = [t];\n    for (let i = 0; i < t.getChildCount(); i++) {\n      nodes = nodes.concat(_Trees.descendants(t.getChild(i)));\n    }\n    return nodes;\n  }\n  static doFindAllNodes(t, index, findTokens, nodes) {\n    if (findTokens && t instanceof TerminalNode) {\n      if (t.symbol?.type === index) {\n        nodes.push(t);\n      }\n    } else if (!findTokens && t instanceof ParserRuleContext) {\n      if (t.ruleIndex === index) {\n        nodes.push(t);\n      }\n    }\n    for (let i = 0; i < t.getChildCount(); i++) {\n      _Trees.doFindAllNodes(t.getChild(i), index, findTokens, nodes);\n    }\n  }\n};\n\n// src/ParserRuleContext.ts\nvar ParserRuleContext = class _ParserRuleContext {\n  static {\n    __name(this, \"ParserRuleContext\");\n  }\n  static empty = new _ParserRuleContext(null);\n  start = null;\n  stop = null;\n  children = [];\n  /**\n   * What state invoked the rule associated with this context?\n   *  The \"return address\" is the followState of invokingState\n   *  If parent is null, this should be -1 this context object represents\n   *  the start rule.\n   */\n  invokingState;\n  #parent;\n  /**\n   * A rule context is a record of a single rule invocation. It knows\n   * which context invoked it, if any. If there is no parent context, then\n   * naturally the invoking state is not valid.  The parent link\n   * provides a chain upwards from the current rule invocation to the root\n   * of the invocation tree, forming a stack. We actually carry no\n   * information about the rule associated with this context (except\n   * when parsing). We keep only the state number of the invoking state from\n   * the ATN submachine that invoked this. Contrast this with the s\n   * pointer inside ParserRuleContext that tracks the current state\n   * being \"executed\" for the current rule.\n   *\n   * The parent contexts are useful for computing lookahead sets and\n   * getting error information.\n   *\n   * These objects are used during parsing and prediction.\n   * For the special case of parsers, we use the subclass\n   * ParserRuleContext.\n   */\n  constructor(parent, invokingStateNumber = -1) {\n    this.#parent = parent;\n    this.invokingState = invokingStateNumber;\n  }\n  /** Copy a context */\n  copyFrom(ctx) {\n    this.#parent = ctx.#parent;\n    this.invokingState = ctx.invokingState;\n    this.children.slice(0, this.children.length);\n    this.start = ctx.start;\n    this.stop = ctx.stop;\n    if (ctx.children) {\n      ctx.children.forEach((child) => {\n        if (child instanceof ErrorNode) {\n          this.children.push(child);\n          child.parent = this;\n        }\n      });\n    }\n  }\n  // Double dispatch methods for listeners\n  enterRule(_listener) {\n  }\n  exitRule(_listener) {\n  }\n  addChild(child) {\n    this.children.push(child);\n    return child;\n  }\n  /**\n   * Used by enterOuterAlt to toss out a RuleContext previously added as\n   * we entered a rule. If we have label, we will need to remove\n   * generic ruleContext object.\n   */\n  removeLastChild() {\n    this.children.pop();\n  }\n  addTokenNode(token) {\n    const node = new TerminalNode(token);\n    this.children.push(node);\n    node.parent = this;\n    return node;\n  }\n  addErrorNode(errorNode) {\n    errorNode.parent = this;\n    this.children.push(errorNode);\n    return errorNode;\n  }\n  getChild(i, type) {\n    if (i < 0 || i >= this.children.length) {\n      return null;\n    }\n    if (!type) {\n      return this.children[i];\n    }\n    for (const child of this.children) {\n      if (child instanceof type) {\n        if (i === 0) {\n          return child;\n        } else {\n          i -= 1;\n        }\n      }\n    }\n    return null;\n  }\n  getToken(ttype, i) {\n    if (i < 0 || i >= this.children.length) {\n      return null;\n    }\n    for (const child of this.children) {\n      if (\"symbol\" in child) {\n        if (child.symbol?.type === ttype) {\n          if (i === 0) {\n            return child;\n          } else {\n            i -= 1;\n          }\n        }\n      }\n    }\n    return null;\n  }\n  getTokens(ttype) {\n    const tokens = [];\n    for (const child of this.children) {\n      if (\"symbol\" in child) {\n        if (child.symbol?.type === ttype) {\n          tokens.push(child);\n        }\n      }\n    }\n    return tokens;\n  }\n  // XXX: base the child type selection on the rule index, not the class.\n  getRuleContext(index, ctxType) {\n    return this.getChild(index, ctxType);\n  }\n  // XXX: base the child type selection on the rule index, not the class.\n  getRuleContexts(ctxType) {\n    const contexts = [];\n    for (const child of this.children) {\n      if (child instanceof ctxType) {\n        contexts.push(child);\n      }\n    }\n    return contexts;\n  }\n  getChildCount() {\n    return this.children.length;\n  }\n  getSourceInterval() {\n    if (this.start === null || this.stop === null) {\n      return Interval.INVALID_INTERVAL;\n    } else {\n      return new Interval(this.start.tokenIndex, this.stop.tokenIndex);\n    }\n  }\n  get parent() {\n    return this.#parent;\n  }\n  set parent(parent) {\n    this.#parent = parent;\n  }\n  depth() {\n    let n2 = 0;\n    let p = this;\n    while (p !== null) {\n      p = p.parent;\n      n2 += 1;\n    }\n    return n2;\n  }\n  /**\n   * A context is empty if there is no invoking state; meaning nobody call\n   * current context.\n   */\n  isEmpty() {\n    return this.invokingState === -1;\n  }\n  get ruleContext() {\n    return this;\n  }\n  get ruleIndex() {\n    return -1;\n  }\n  getPayload() {\n    return this;\n  }\n  getText() {\n    if (this.children.length === 0) {\n      return \"\";\n    }\n    return this.children.map((child) => {\n      return child.getText();\n    }).join(\"\");\n  }\n  /**\n   * For rule associated with this parse tree internal node, return\n   * the outer alternative number used to match the input. Default\n   * implementation does not compute nor store this alt num. Create\n   * a subclass of ParserRuleContext with backing field and set\n   * option contextSuperClass.\n   * to set it.\n   */\n  getAltNumber() {\n    return ATN.INVALID_ALT_NUMBER;\n  }\n  /**\n   * Set the outer alternative number for this context node. Default\n   * implementation does nothing to avoid backing field overhead for\n   * trees that don't need it.  Create\n   * a subclass of ParserRuleContext with backing field and set\n   * option contextSuperClass.\n   */\n  setAltNumber(_altNumber) {\n  }\n  accept(visitor) {\n    return visitor.visitChildren(this);\n  }\n  toStringTree(...args) {\n    if (args.length === 1) {\n      return Trees.toStringTree(this, null, args[0]);\n    }\n    return Trees.toStringTree(this, args[0], args[1]);\n  }\n  toString(ruleNames, stop) {\n    ruleNames = ruleNames ?? null;\n    stop = stop ?? null;\n    let p = this;\n    let s = \"[\";\n    while (p !== null && p !== stop) {\n      if (ruleNames === null) {\n        if (!p.isEmpty()) {\n          s += p.invokingState;\n        }\n      } else {\n        const ri = p.ruleIndex;\n        const ruleName = ri >= 0 && ri < ruleNames.length ? ruleNames[ri] : \"\" + ri;\n        s += ruleName;\n      }\n      if (p.parent !== null && (ruleNames !== null || !p.parent.isEmpty())) {\n        s += \" \";\n      }\n      p = p.parent;\n    }\n    s += \"]\";\n    return s;\n  }\n};\n\n// src/misc/ObjectEqualityComparator.ts\nvar ObjectEqualityComparator = class _ObjectEqualityComparator {\n  static {\n    __name(this, \"ObjectEqualityComparator\");\n  }\n  static instance = new _ObjectEqualityComparator();\n  hashCode(obj) {\n    if (obj == null) {\n      return 0;\n    }\n    return obj.hashCode();\n  }\n  equals(a, b) {\n    if (a == null) {\n      return b == null;\n    }\n    return a.equals(b);\n  }\n};\n\n// src/misc/DefaultEqualityComparator.ts\nvar DefaultEqualityComparator = class _DefaultEqualityComparator {\n  static {\n    __name(this, \"DefaultEqualityComparator\");\n  }\n  static instance = new _DefaultEqualityComparator();\n  hashCode(obj) {\n    if (obj == null) {\n      return 0;\n    }\n    return ObjectEqualityComparator.instance.hashCode(obj);\n  }\n  equals(a, b) {\n    if (a == null) {\n      return b == null;\n    }\n    if (typeof a === \"string\" || typeof a === \"number\") {\n      return a === b;\n    }\n    return ObjectEqualityComparator.instance.equals(a, b);\n  }\n};\n\n// src/misc/HashSet.ts\nvar HashSet = class _HashSet {\n  static {\n    __name(this, \"HashSet\");\n  }\n  static #defaultLoadFactor = 0.75;\n  static #initialCapacity = 16;\n  // must be power of 2\n  #comparator;\n  #buckets;\n  /** How many elements in set */\n  #itemCount = 0;\n  #threshold;\n  constructor(comparatorOrSet, initialCapacity = _HashSet.#initialCapacity) {\n    if (comparatorOrSet instanceof _HashSet) {\n      this.#comparator = comparatorOrSet.#comparator;\n      this.#buckets = comparatorOrSet.#buckets.slice(0);\n      for (let i = 0; i < this.#buckets.length; i++) {\n        const bucket = this.#buckets[i];\n        if (bucket) {\n          this.#buckets[i] = bucket.slice(0);\n        }\n      }\n      this.#itemCount = comparatorOrSet.#itemCount;\n      this.#threshold = comparatorOrSet.#threshold;\n    } else {\n      this.#comparator = comparatorOrSet ?? DefaultEqualityComparator.instance;\n      this.#buckets = this.createBuckets(initialCapacity);\n      this.#threshold = Math.floor(_HashSet.#initialCapacity * _HashSet.#defaultLoadFactor);\n    }\n  }\n  /**\n   * Add `o` to set if not there; return existing value if already\n   * there. This method performs the same operation as {@link #add} aside from\n   * the return value.\n   *\n   * @param o the object to add to the set.\n   *\n   * @returns An existing element that equals to `o` if already in set, otherwise `o`.\n   */\n  getOrAdd(o) {\n    if (this.#itemCount > this.#threshold) {\n      this.expand();\n    }\n    const b = this.getBucket(o);\n    let bucket = this.#buckets[b];\n    if (!bucket) {\n      bucket = [o];\n      this.#buckets[b] = bucket;\n      ++this.#itemCount;\n      return o;\n    }\n    for (const existing of bucket) {\n      if (this.#comparator.equals(existing, o)) {\n        return existing;\n      }\n    }\n    bucket.push(o);\n    ++this.#itemCount;\n    return o;\n  }\n  get(o) {\n    if (o == null) {\n      return o;\n    }\n    const b = this.getBucket(o);\n    const bucket = this.#buckets[b];\n    if (!bucket) {\n      return void 0;\n    }\n    for (const e of bucket) {\n      if (this.#comparator.equals(e, o)) {\n        return e;\n      }\n    }\n    return void 0;\n  }\n  hashCode() {\n    let hash = MurmurHash.initialize();\n    for (const bucket of this.#buckets) {\n      if (bucket == null) {\n        continue;\n      }\n      for (const o of bucket) {\n        if (o == null) {\n          break;\n        }\n        hash = MurmurHash.update(hash, this.#comparator.hashCode(o));\n      }\n    }\n    hash = MurmurHash.finish(hash, this.size);\n    return hash;\n  }\n  equals(o) {\n    if (o === this) {\n      return true;\n    }\n    if (!(o instanceof _HashSet)) {\n      return false;\n    }\n    if (o.size !== this.size) {\n      return false;\n    }\n    return this.containsAll(o);\n  }\n  add(t) {\n    const existing = this.getOrAdd(t);\n    return existing === t;\n  }\n  contains(o) {\n    return this.containsFast(o);\n  }\n  containsFast(obj) {\n    if (obj == null) {\n      return false;\n    }\n    return this.get(obj) !== void 0;\n  }\n  *[Symbol.iterator]() {\n    yield* this.toArray();\n  }\n  toArray() {\n    const a = new Array(this.size);\n    let i = 0;\n    for (const bucket of this.#buckets) {\n      if (bucket == null) {\n        continue;\n      }\n      for (const o of bucket) {\n        if (o == null) {\n          break;\n        }\n        a[i++] = o;\n      }\n    }\n    return a;\n  }\n  containsAll(collection) {\n    if (collection instanceof _HashSet) {\n      for (const bucket of collection.#buckets) {\n        if (bucket == null) {\n          continue;\n        }\n        for (const o of bucket) {\n          if (o == null) {\n            break;\n          }\n          if (!this.containsFast(o)) {\n            return false;\n          }\n        }\n      }\n    } else {\n      for (const o of collection) {\n        if (!this.containsFast(o)) {\n          return false;\n        }\n      }\n    }\n    return true;\n  }\n  addAll(c) {\n    let changed = false;\n    for (const o of c) {\n      const existing = this.getOrAdd(o);\n      if (existing !== o) {\n        changed = true;\n      }\n    }\n    return changed;\n  }\n  clear() {\n    this.#buckets = this.createBuckets(_HashSet.#initialCapacity);\n    this.#itemCount = 0;\n    this.#threshold = Math.floor(_HashSet.#initialCapacity * _HashSet.#defaultLoadFactor);\n  }\n  toString() {\n    if (this.size === 0) {\n      return \"{}\";\n    }\n    let buf = \"{\";\n    let first = true;\n    for (const bucket of this.#buckets) {\n      if (bucket == null) {\n        continue;\n      }\n      for (const o of bucket) {\n        if (o == null) {\n          break;\n        }\n        if (first) {\n          first = false;\n        } else {\n          buf += \", \";\n        }\n        buf += o.toString();\n      }\n    }\n    buf += \"}\";\n    return buf;\n  }\n  toTableString() {\n    let buf = \"\";\n    for (const bucket of this.#buckets) {\n      if (bucket == null) {\n        buf += \"null\\n\";\n        continue;\n      }\n      buf += \"[\";\n      let first = true;\n      for (const o of bucket) {\n        if (first) {\n          first = false;\n        } else {\n          buf += \" \";\n        }\n        if (o == null) {\n          buf += \"_\";\n        } else {\n          buf += o.toString();\n        }\n      }\n      buf += \"]\\n\";\n    }\n    return buf;\n  }\n  getBucket(o) {\n    const hash = this.#comparator.hashCode(o);\n    const b = hash & this.#buckets.length - 1;\n    return b;\n  }\n  expand() {\n    const old = this.#buckets;\n    const newCapacity = this.#buckets.length * 2;\n    const newTable = this.createBuckets(newCapacity);\n    this.#buckets = newTable;\n    this.#threshold = Math.floor(newCapacity * _HashSet.#defaultLoadFactor);\n    for (const bucket of old) {\n      if (!bucket) {\n        continue;\n      }\n      for (const o of bucket) {\n        const b = this.getBucket(o);\n        let newBucket = this.#buckets[b];\n        if (!newBucket) {\n          newBucket = [];\n          this.#buckets[b] = newBucket;\n        }\n        newBucket.push(o);\n      }\n    }\n  }\n  get size() {\n    return this.#itemCount;\n  }\n  get isEmpty() {\n    return this.#itemCount === 0;\n  }\n  /**\n   * Return an array of `T[]` with length `capacity`.\n   *\n   * @param capacity the length of the array to return\n   * @returns the newly constructed array\n   */\n  createBuckets(capacity) {\n    return new Array(capacity);\n  }\n};\n\n// src/misc/MapKeyEqualityOperator.ts\nvar MapKeyEqualityComparator = class {\n  static {\n    __name(this, \"MapKeyEqualityComparator\");\n  }\n  keyComparator;\n  constructor(keyComparator) {\n    this.keyComparator = keyComparator;\n  }\n  hashCode(obj) {\n    return this.keyComparator.hashCode(obj.key);\n  }\n  equals(a, b) {\n    return this.keyComparator.equals(a.key, b.key);\n  }\n};\n\n// src/misc/HashMap.ts\nvar HashMap = class _HashMap {\n  static {\n    __name(this, \"HashMap\");\n  }\n  backingStore;\n  constructor(keyComparer) {\n    if (keyComparer instanceof _HashMap) {\n      this.backingStore = new HashSet(keyComparer.backingStore);\n    } else {\n      this.backingStore = new HashSet(new MapKeyEqualityComparator(keyComparer));\n    }\n  }\n  clear() {\n    this.backingStore.clear();\n  }\n  containsKey(key) {\n    return this.backingStore.contains({ key });\n  }\n  get(key) {\n    const bucket = this.backingStore.get({ key });\n    if (!bucket) {\n      return void 0;\n    }\n    return bucket.value;\n  }\n  get isEmpty() {\n    return this.backingStore.isEmpty;\n  }\n  /**\n   * Sets the value for a key in the map. If the key is not present in the map, it is added.\n   * If the key is present, the value is updated and the old value is returned.\n   *\n   * @param key The key to set.\n   * @param value The value to set.\n   *\n   * @returns The old value for the key, if present.\n   */\n  set(key, value) {\n    const element = this.backingStore.get({ key, value });\n    let result;\n    if (!element) {\n      this.backingStore.add({ key, value });\n    } else {\n      result = element.value;\n      element.value = value;\n    }\n    return result;\n  }\n  /**\n   * Sets the value for a key in the map if the key is not already present. Otherwise the value is not changed and\n   * the old value is returned.\n   *\n   * @param key The key to set.\n   * @param value The value to set.\n   *\n   * @returns The current value for the key, if present.\n   */\n  setIfAbsent(key, value) {\n    const element = this.backingStore.get({ key, value });\n    let result;\n    if (!element) {\n      this.backingStore.add({ key, value });\n    } else {\n      result = element.value;\n    }\n    return result;\n  }\n  values() {\n    return this.backingStore.toArray().map((bucket) => {\n      return bucket.value;\n    });\n  }\n  get size() {\n    return this.backingStore.size;\n  }\n  hashCode() {\n    return this.backingStore.hashCode();\n  }\n  equals(o) {\n    return this.backingStore.equals(o.backingStore);\n  }\n};\n\n// src/atn/PredictionContextUtils.ts\nvar predictionContextFromRuleContext = /* @__PURE__ */ __name((atn, outerContext) => {\n  if (!outerContext) {\n    outerContext = ParserRuleContext.empty;\n  }\n  if (!outerContext.parent || outerContext === ParserRuleContext.empty) {\n    return PredictionContext.EMPTY;\n  }\n  const parent = predictionContextFromRuleContext(atn, outerContext.parent);\n  const state = atn.states[outerContext.invokingState];\n  const transition = state.transitions[0];\n  return SingletonPredictionContext.create(parent, transition.followState.stateNumber);\n}, \"predictionContextFromRuleContext\");\nvar getCachedPredictionContext = /* @__PURE__ */ __name((context, contextCache, visited) => {\n  if (context.isEmpty()) {\n    return context;\n  }\n  let existing = visited.get(context);\n  if (existing) {\n    return existing;\n  }\n  existing = contextCache.get(context);\n  if (existing) {\n    visited.set(context, existing);\n    return existing;\n  }\n  let changed = false;\n  let parents = [];\n  for (let i = 0; i < parents.length; i++) {\n    const parent = getCachedPredictionContext(context.getParent(i), contextCache, visited);\n    if (changed || parent !== context.getParent(i)) {\n      if (!changed) {\n        parents = [];\n        for (let j = 0; j < context.length; j++) {\n          parents[j] = context.getParent(j);\n        }\n        changed = true;\n      }\n      parents[i] = parent;\n    }\n  }\n  if (!changed) {\n    contextCache.add(context);\n    visited.set(context, context);\n    return context;\n  }\n  let updated;\n  if (parents.length === 0) {\n    updated = PredictionContext.EMPTY;\n  } else if (parents.length === 1) {\n    updated = SingletonPredictionContext.create(parents[0] ?? void 0, context.getReturnState(0));\n  } else {\n    updated = new ArrayPredictionContext(parents, context.returnStates);\n  }\n  contextCache.add(updated);\n  visited.set(updated, updated);\n  visited.set(context, updated);\n  return updated;\n}, \"getCachedPredictionContext\");\nvar merge = /* @__PURE__ */ __name((a, b, rootIsWildcard, mergeCache) => {\n  if (a === b) {\n    return a;\n  }\n  if (a instanceof SingletonPredictionContext && b instanceof SingletonPredictionContext) {\n    return mergeSingletons(a, b, rootIsWildcard, mergeCache);\n  }\n  if (rootIsWildcard) {\n    if (a instanceof EmptyPredictionContext) {\n      return a;\n    }\n    if (b instanceof EmptyPredictionContext) {\n      return b;\n    }\n  }\n  if (a instanceof SingletonPredictionContext) {\n    a = new ArrayPredictionContext([a.parent], [a.returnState]);\n  }\n  if (b instanceof SingletonPredictionContext) {\n    b = new ArrayPredictionContext([b.parent], [b.returnState]);\n  }\n  return mergeArrays(a, b, rootIsWildcard, mergeCache);\n}, \"merge\");\nvar mergeArrays = /* @__PURE__ */ __name((a, b, rootIsWildcard, mergeCache) => {\n  if (mergeCache) {\n    let previous = mergeCache.get(a, b);\n    if (previous) {\n      return previous;\n    }\n    previous = mergeCache.get(b, a);\n    if (previous) {\n      return previous;\n    }\n  }\n  let i = 0;\n  let j = 0;\n  let k = 0;\n  let mergedReturnStates = new Array(a.returnStates.length + b.returnStates.length).fill(0);\n  let mergedParents = new Array(a.returnStates.length + b.returnStates.length).fill(null);\n  while (i < a.returnStates.length && j < b.returnStates.length) {\n    const aParent = a.parents[i];\n    const bParent = b.parents[j];\n    if (a.returnStates[i] === b.returnStates[j]) {\n      const payload = a.returnStates[i];\n      const bothDollars = payload === PredictionContext.EMPTY_RETURN_STATE && aParent === null && bParent === null;\n      const axAx = aParent !== null && bParent !== null && aParent === bParent;\n      if (bothDollars || axAx) {\n        mergedParents[k] = aParent;\n        mergedReturnStates[k] = payload;\n      } else {\n        mergedParents[k] = merge(aParent, bParent, rootIsWildcard, mergeCache);\n        mergedReturnStates[k] = payload;\n      }\n      i += 1;\n      j += 1;\n    } else if (a.returnStates[i] < b.returnStates[j]) {\n      mergedParents[k] = aParent;\n      mergedReturnStates[k] = a.returnStates[i];\n      i += 1;\n    } else {\n      mergedParents[k] = bParent;\n      mergedReturnStates[k] = b.returnStates[j];\n      j += 1;\n    }\n    k += 1;\n  }\n  if (i < a.returnStates.length) {\n    for (let p = i; p < a.returnStates.length; p++) {\n      mergedParents[k] = a.parents[p];\n      mergedReturnStates[k] = a.returnStates[p];\n      k += 1;\n    }\n  } else {\n    for (let p = j; p < b.returnStates.length; p++) {\n      mergedParents[k] = b.parents[p];\n      mergedReturnStates[k] = b.returnStates[p];\n      k += 1;\n    }\n  }\n  if (k < mergedParents.length) {\n    if (k === 1) {\n      const aNew = SingletonPredictionContext.create(mergedParents[0] ?? void 0, mergedReturnStates[0]);\n      if (mergeCache !== null) {\n        mergeCache.set(a, b, aNew);\n      }\n      return aNew;\n    }\n    mergedParents = mergedParents.slice(0, k);\n    mergedReturnStates = mergedReturnStates.slice(0, k);\n  }\n  const merged = new ArrayPredictionContext(mergedParents, mergedReturnStates);\n  if (merged.equals(a)) {\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, a);\n    }\n    if (PredictionContext.traceATNSimulator) {\n      console.log(\"mergeArrays a=\" + a + \",b=\" + b + \" -> a\");\n    }\n    return a;\n  }\n  if (merged.equals(b)) {\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, b);\n    }\n    return b;\n  }\n  combineCommonParents(mergedParents);\n  if (mergeCache !== null) {\n    mergeCache.set(a, b, merged);\n  }\n  if (PredictionContext.traceATNSimulator) {\n    console.log(\"mergeArrays a=\" + a + \",b=\" + b + \" -> \" + merged);\n  }\n  return merged;\n}, \"mergeArrays\");\nvar combineCommonParents = /* @__PURE__ */ __name((parents) => {\n  const uniqueParents = new HashMap(ObjectEqualityComparator.instance);\n  for (const parent of parents) {\n    if (parent) {\n      if (!uniqueParents.containsKey(parent)) {\n        uniqueParents.set(parent, parent);\n      }\n    }\n  }\n  for (let q = 0; q < parents.length; q++) {\n    if (parents[q]) {\n      parents[q] = uniqueParents.get(parents[q]) ?? null;\n    }\n  }\n}, \"combineCommonParents\");\nvar mergeSingletons = /* @__PURE__ */ __name((a, b, rootIsWildcard, mergeCache) => {\n  if (mergeCache !== null) {\n    let previous = mergeCache.get(a, b);\n    if (previous !== null) {\n      return previous;\n    }\n    previous = mergeCache.get(b, a);\n    if (previous !== null) {\n      return previous;\n    }\n  }\n  const rootMerge = mergeRoot(a, b, rootIsWildcard);\n  if (rootMerge !== null) {\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, rootMerge);\n    }\n    return rootMerge;\n  }\n  if (a.returnState === b.returnState) {\n    const parent = merge(a.parent, b.parent, rootIsWildcard, mergeCache);\n    if (parent === a.parent) {\n      return a;\n    }\n    if (parent === b.parent) {\n      return b;\n    }\n    const spc = SingletonPredictionContext.create(parent, a.returnState);\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, spc);\n    }\n    return spc;\n  } else {\n    let singleParent = null;\n    if (a === b || a.parent !== null && a.parent === b.parent) {\n      singleParent = a.parent;\n    }\n    if (singleParent !== null) {\n      const payloads2 = [a.returnState, b.returnState];\n      if (a.returnState > b.returnState) {\n        payloads2[0] = b.returnState;\n        payloads2[1] = a.returnState;\n      }\n      const parents2 = [singleParent, singleParent];\n      const apc = new ArrayPredictionContext(parents2, payloads2);\n      if (mergeCache !== null) {\n        mergeCache.set(a, b, apc);\n      }\n      return apc;\n    }\n    const payloads = [a.returnState, b.returnState];\n    let parents = [a.parent, b.parent];\n    if (a.returnState > b.returnState) {\n      payloads[0] = b.returnState;\n      payloads[1] = a.returnState;\n      parents = [b.parent, a.parent];\n    }\n    const aNew = new ArrayPredictionContext(parents, payloads);\n    if (mergeCache !== null) {\n      mergeCache.set(a, b, aNew);\n    }\n    return aNew;\n  }\n}, \"mergeSingletons\");\nvar mergeRoot = /* @__PURE__ */ __name((a, b, rootIsWildcard) => {\n  if (rootIsWildcard) {\n    if (a === PredictionContext.EMPTY || b === PredictionContext.EMPTY) {\n      return PredictionContext.EMPTY;\n    }\n  } else {\n    if (a === PredictionContext.EMPTY && b === PredictionContext.EMPTY) {\n      return PredictionContext.EMPTY;\n    }\n    if (a === PredictionContext.EMPTY) {\n      const payloads = [\n        b.returnState,\n        PredictionContext.EMPTY_RETURN_STATE\n      ];\n      const parents = [b.parent, null];\n      return new ArrayPredictionContext(parents, payloads);\n    }\n    if (b === PredictionContext.EMPTY) {\n      const payloads = [a.returnState, PredictionContext.EMPTY_RETURN_STATE];\n      const parents = [a.parent, null];\n      return new ArrayPredictionContext(parents, payloads);\n    }\n  }\n  return null;\n}, \"mergeRoot\");\n\n// src/misc/BitSet.ts\nvar BitSet = class {\n  static {\n    __name(this, \"BitSet\");\n  }\n  data;\n  /**\n   * Creates a new bit set. All bits are initially `false`.\n   *\n   * @param data Optional initial data.\n   */\n  constructor(data) {\n    if (data) {\n      this.data = new Uint32Array(data.map((value) => {\n        return value >>> 0;\n      }));\n    } else {\n      this.data = new Uint32Array(1);\n    }\n  }\n  /**\n   * @returns an iterator over all set bits.\n   */\n  [Symbol.iterator]() {\n    const length = this.data.length;\n    let currentIndex = 0;\n    let currentWord = this.data[currentIndex];\n    const words = this.data;\n    return {\n      [Symbol.iterator]() {\n        return this;\n      },\n      next: () => {\n        while (currentIndex < length) {\n          if (currentWord !== 0) {\n            const t = currentWord & -currentWord;\n            const value = (currentIndex << 5) + this.bitCount(t - 1);\n            currentWord ^= t;\n            return { done: false, value };\n          } else {\n            currentIndex++;\n            if (currentIndex < length) {\n              currentWord = words[currentIndex];\n            }\n          }\n        }\n        return { done: true, value: void 0 };\n      }\n    };\n  }\n  /**\n   * Sets a single bit or all of the bits in this `BitSet` to `false`.\n   *\n   * @param index the index of the bit to be cleared, or undefined to clear all bits.\n   */\n  clear(index) {\n    if (index === void 0) {\n      this.data = new Uint32Array();\n    } else {\n      this.resize(index);\n      this.data[index >>> 5] &= ~(1 << index);\n    }\n  }\n  /**\n   * Performs a logical **OR** of this bit set with the bit set argument. This bit set is modified so that a bit in it\n   * has the value `true` if and only if it either already had the value `true` or the corresponding bit in the bit\n   * set argument has the value `true`.\n   *\n   * @param set the bit set to be ORed with.\n   */\n  or(set) {\n    const minCount = Math.min(this.data.length, set.data.length);\n    for (let k = 0; k < minCount; ++k) {\n      this.data[k] |= set.data[k];\n    }\n    if (this.data.length < set.data.length) {\n      this.resize((set.data.length << 5) - 1);\n      const c = set.data.length;\n      for (let k = minCount; k < c; ++k) {\n        this.data[k] = set.data[k];\n      }\n    }\n  }\n  /**\n   * Returns the value of the bit with the specified index. The value is `true` if the bit with the index `bitIndex`\n   * is currently set in this `BitSet`; otherwise, the result is `false`.\n   *\n   * @param index the bit index\n   *\n   * @returns the value of the bit with the specified index.\n   */\n  get(index) {\n    if (index < 0) {\n      throw new RangeError(\"index cannot be negative\");\n    }\n    const slot = index >>> 5;\n    if (slot >= this.data.length) {\n      return false;\n    }\n    return (this.data[slot] & 1 << index % 32) !== 0;\n  }\n  /**\n   * @returns the number of set bits.\n   */\n  get length() {\n    let result = 0;\n    const c = this.data.length;\n    const w = this.data;\n    for (let i = 0; i < c; i++) {\n      result += this.bitCount(w[i]);\n    }\n    return result;\n  }\n  /**\n   * @returns an array with indices of set bits.\n   */\n  values() {\n    const result = new Array(this.length);\n    let pos = 0;\n    const length = this.data.length;\n    for (let k = 0; k < length; ++k) {\n      let w = this.data[k];\n      while (w !== 0) {\n        const t = w & -w;\n        result[pos++] = (k << 5) + this.bitCount(t - 1);\n        w ^= t;\n      }\n    }\n    return result;\n  }\n  /**\n   * @returns the index of the first bit that is set to `true` that occurs on or after the specified starting index.\n   * If no such bit exists then undefined is returned.\n   *\n   * @param fromIndex the index to start checking from (inclusive)\n   */\n  nextSetBit(fromIndex) {\n    if (fromIndex < 0) {\n      throw new RangeError(\"index cannot be negative\");\n    }\n    for (const index of this) {\n      if (index > fromIndex) {\n        return index;\n      }\n    }\n    return void 0;\n  }\n  /**\n   * Sets the bit at the specified index to `true`.\n   *\n   * @param index a bit index\n   */\n  set(index) {\n    if (index < 0) {\n      throw new RangeError(\"index cannot be negative\");\n    }\n    this.resize(index);\n    this.data[index >>> 5] |= 1 << index % 32;\n  }\n  /**\n   * @returns a string representation of this bit set.\n   */\n  toString() {\n    return \"{\" + this.values().join(\", \") + \"}\";\n  }\n  resize(index) {\n    const count = index + 32 >>> 5;\n    if (count <= this.data.length) {\n      return;\n    }\n    const data = new Uint32Array(count);\n    data.set(this.data);\n    data.fill(0, this.data.length);\n    this.data = data;\n  }\n  bitCount(v) {\n    v = v - (v >> 1 & 1431655765);\n    v = (v & 858993459) + (v >> 2 & 858993459);\n    v = v + (v >> 4) & 252645135;\n    v = v + (v >> 8);\n    v = v + (v >> 16);\n    return v & 63;\n  }\n};\n\n// src/atn/ATNState.ts\nvar ATNState = class _ATNState {\n  static {\n    __name(this, \"ATNState\");\n  }\n  static INVALID_STATE_NUMBER = -1;\n  static INVALID_TYPE = 0;\n  static BASIC = 1;\n  static RULE_START = 2;\n  static BLOCK_START = 3;\n  static PLUS_BLOCK_START = 4;\n  static STAR_BLOCK_START = 5;\n  static TOKEN_START = 6;\n  static RULE_STOP = 7;\n  static BLOCK_END = 8;\n  static STAR_LOOP_BACK = 9;\n  static STAR_LOOP_ENTRY = 10;\n  static PLUS_LOOP_BACK = 11;\n  static LOOP_END = 12;\n  static stateType = _ATNState.INVALID_STATE_NUMBER;\n  stateNumber = 0;\n  ruleIndex = 0;\n  // at runtime, we don't have Rule objects\n  epsilonOnlyTransitions = false;\n  /** Used to cache lookahead during parsing, not used during construction */\n  nextTokenWithinRule;\n  /** Track the transitions emanating from this ATN state. */\n  transitions = [];\n  hashCode() {\n    return this.stateNumber;\n  }\n  equals(other) {\n    return this.stateNumber === other.stateNumber;\n  }\n  toString() {\n    return `${this.stateNumber}`;\n  }\n  addTransitionAtIndex(index, transition) {\n    if (this.transitions.length === 0) {\n      this.epsilonOnlyTransitions = transition.isEpsilon;\n    } else if (this.epsilonOnlyTransitions !== transition.isEpsilon) {\n      this.epsilonOnlyTransitions = false;\n    }\n    this.transitions.splice(index, 1, transition);\n  }\n  addTransition(transition) {\n    if (this.transitions.length === 0) {\n      this.epsilonOnlyTransitions = transition.isEpsilon;\n    } else if (this.epsilonOnlyTransitions !== transition.isEpsilon) {\n      this.epsilonOnlyTransitions = false;\n    }\n    this.transitions.push(transition);\n  }\n  setTransition(i, e) {\n    this.transitions.splice(i, 1, e);\n  }\n  removeTransition(index) {\n    const t = this.transitions.splice(index, 1);\n    return t[0];\n  }\n};\n\n// src/atn/SemanticContext.ts\nvar SemanticContext = class _SemanticContext {\n  static {\n    __name(this, \"SemanticContext\");\n  }\n  cachedHashCode;\n  static andContext(a, b) {\n    if (a === null || a === _SemanticContext.NONE) {\n      return b;\n    }\n    if (b === null || b === _SemanticContext.NONE) {\n      return a;\n    }\n    const result = new AND(a, b);\n    if (result.operands.length === 1) {\n      return result.operands[0];\n    }\n    return result;\n  }\n  static orContext(a, b) {\n    if (a === null) {\n      return b;\n    }\n    if (b === null) {\n      return a;\n    }\n    if (a === _SemanticContext.NONE || b === _SemanticContext.NONE) {\n      return _SemanticContext.NONE;\n    }\n    const result = new OR(a, b);\n    if (result.operands.length === 1) {\n      return result.operands[0];\n    } else {\n      return result;\n    }\n  }\n  static filterPrecedencePredicates(set) {\n    const result = [];\n    for (const context of set) {\n      if (context instanceof _SemanticContext.PrecedencePredicate) {\n        result.push(context);\n      }\n    }\n    return result;\n  }\n  /**\n   * Evaluate the precedence predicates for the context and reduce the result.\n   *\n   * @param _parser The parser instance.\n   * @param _parserCallStack The current parser context object.\n   * @returns The simplified semantic context after precedence predicates are\n   * evaluated, which will be one of the following values.\n   * - {@link NONE}: if the predicate simplifies to `true` after\n   * precedence predicates are evaluated.\n   * - `null`: if the predicate simplifies to `false` after\n   * precedence predicates are evaluated.\n   * - `this`: if the semantic context is not changed as a result of\n   * precedence predicate evaluation.\n   * - A non-`null` {@link SemanticContext}: the new simplified\n   * semantic context after precedence predicates are evaluated.\n   */\n  evalPrecedence(_parser, _parserCallStack) {\n    return this;\n  }\n};\nvar AND = class _AND extends SemanticContext {\n  static {\n    __name(this, \"AND\");\n  }\n  operands;\n  /**\n   * A semantic context which is true whenever none of the contained contexts\n   * is false\n   */\n  constructor(a, b) {\n    super();\n    const operands = new HashSet();\n    if (a instanceof _AND) {\n      a.operands.forEach((o) => {\n        operands.add(o);\n      });\n    } else {\n      operands.add(a);\n    }\n    if (b instanceof _AND) {\n      b.operands.forEach((o) => {\n        operands.add(o);\n      });\n    } else {\n      operands.add(b);\n    }\n    const precedencePredicates = SemanticContext.filterPrecedencePredicates(operands);\n    if (precedencePredicates.length > 0) {\n      let reduced = null;\n      precedencePredicates.forEach((p) => {\n        if (reduced === null || p.precedence < reduced.precedence) {\n          reduced = p;\n        }\n      });\n      if (reduced) {\n        operands.add(reduced);\n      }\n    }\n    this.operands = operands.toArray();\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _AND)) {\n      return false;\n    }\n    return equalArrays(this.operands, other.operands);\n  }\n  hashCode() {\n    if (this.cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      for (const operand of this.operands) {\n        hash = MurmurHash.updateFromComparable(hash, operand);\n      }\n      hash = MurmurHash.update(hash, 3813686060);\n      this.cachedHashCode = MurmurHash.finish(hash, this.operands.length + 1);\n    }\n    return this.cachedHashCode;\n  }\n  /**\n   * {@inheritDoc}\n   *\n   *\n   * The evaluation of predicates by this context is short-circuiting, but\n   * unordered.\n   */\n  evaluate(parser, parserCallStack) {\n    for (const operand of this.operands) {\n      if (!operand.evaluate(parser, parserCallStack)) {\n        return false;\n      }\n    }\n    return true;\n  }\n  evalPrecedence(parser, parserCallStack) {\n    let differs = false;\n    const operands = [];\n    for (const context of this.operands) {\n      const evaluated = context.evalPrecedence(parser, parserCallStack);\n      differs ||= evaluated !== context;\n      if (evaluated === null) {\n        return null;\n      } else if (evaluated !== SemanticContext.NONE) {\n        operands.push(evaluated);\n      }\n    }\n    if (!differs) {\n      return this;\n    }\n    if (operands.length === 0) {\n      return SemanticContext.NONE;\n    }\n    let result = null;\n    operands.forEach((o) => {\n      result = result === null ? o : SemanticContext.andContext(result, o);\n    });\n    return result;\n  }\n  toString() {\n    const s = this.operands.map((o) => {\n      return o.toString();\n    });\n    return (s.length > 3 ? s.slice(3) : s).join(\"&&\");\n  }\n};\nvar OR = class _OR extends SemanticContext {\n  static {\n    __name(this, \"OR\");\n  }\n  operands;\n  /**\n   * A semantic context which is true whenever at least one of the contained\n   * contexts is true\n   */\n  constructor(a, b) {\n    super();\n    const operands = new HashSet();\n    if (a instanceof _OR) {\n      a.operands.forEach((o) => {\n        operands.add(o);\n      });\n    } else {\n      operands.add(a);\n    }\n    if (b instanceof _OR) {\n      b.operands.forEach((o) => {\n        operands.add(o);\n      });\n    } else {\n      operands.add(b);\n    }\n    const precedencePredicates = SemanticContext.filterPrecedencePredicates(operands);\n    if (precedencePredicates.length > 0) {\n      const s = precedencePredicates.sort((a2, b2) => {\n        return a2.compareTo(b2);\n      });\n      const reduced = s[s.length - 1];\n      operands.add(reduced);\n    }\n    this.operands = operands.toArray();\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    } else if (!(other instanceof _OR)) {\n      return false;\n    } else {\n      return equalArrays(this.operands, other.operands);\n    }\n  }\n  hashCode() {\n    if (this.cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      for (const operand of this.operands) {\n        hash = MurmurHash.updateFromComparable(hash, operand);\n      }\n      hash = MurmurHash.update(hash, 3383313031);\n      this.cachedHashCode = MurmurHash.finish(hash, this.operands.length + 1);\n    }\n    return this.cachedHashCode;\n  }\n  /**\n   * The evaluation of predicates by this context is short-circuiting, but unordered.\n   */\n  evaluate(parser, parserCallStack) {\n    for (const operand of this.operands) {\n      if (operand.evaluate(parser, parserCallStack)) {\n        return true;\n      }\n    }\n    return false;\n  }\n  evalPrecedence(parser, parserCallStack) {\n    let differs = false;\n    const operands = [];\n    for (const context of this.operands) {\n      const evaluated = context.evalPrecedence(parser, parserCallStack);\n      differs ||= evaluated !== context;\n      if (evaluated === SemanticContext.NONE) {\n        return SemanticContext.NONE;\n      } else if (evaluated !== null) {\n        operands.push(evaluated);\n      }\n    }\n    if (!differs) {\n      return this;\n    }\n    if (operands.length === 0) {\n      return null;\n    }\n    let result = null;\n    operands.forEach((o) => {\n      result = result === null ? o : SemanticContext.orContext(result, o);\n    });\n    return result;\n  }\n  toString() {\n    const s = this.operands.map((o) => {\n      return o.toString();\n    });\n    return (s.length > 3 ? s.slice(3) : s).join(\"||\");\n  }\n};\n((SemanticContext2) => {\n  class Predicate extends SemanticContext2 {\n    static {\n      __name(this, \"Predicate\");\n    }\n    ruleIndex;\n    predIndex;\n    isCtxDependent;\n    // e.g., $i ref in pred\n    constructor(ruleIndex, predIndex, isCtxDependent) {\n      super();\n      this.ruleIndex = ruleIndex ?? -1;\n      this.predIndex = predIndex ?? -1;\n      this.isCtxDependent = isCtxDependent ?? false;\n    }\n    evaluate(parser, outerContext) {\n      const localctx = this.isCtxDependent ? outerContext : null;\n      return parser.sempred(localctx, this.ruleIndex, this.predIndex);\n    }\n    hashCode() {\n      if (this.cachedHashCode === void 0) {\n        let hashCode = MurmurHash.initialize();\n        hashCode = MurmurHash.update(hashCode, this.ruleIndex);\n        hashCode = MurmurHash.update(hashCode, this.predIndex);\n        hashCode = MurmurHash.update(hashCode, this.isCtxDependent ? 1 : 0);\n        hashCode = MurmurHash.finish(hashCode, 3);\n        this.cachedHashCode = hashCode;\n      }\n      return this.cachedHashCode;\n    }\n    equals(other) {\n      if (this === other) {\n        return true;\n      }\n      return this.ruleIndex === other.ruleIndex && this.predIndex === other.predIndex && this.isCtxDependent === other.isCtxDependent;\n    }\n    toString() {\n      return \"{\" + this.ruleIndex + \":\" + this.predIndex + \"}?\";\n    }\n  }\n  SemanticContext2.Predicate = Predicate;\n  class PrecedencePredicate extends SemanticContext2 {\n    static {\n      __name(this, \"PrecedencePredicate\");\n    }\n    precedence;\n    constructor(precedence) {\n      super();\n      this.precedence = precedence ?? 0;\n    }\n    evaluate(parser, outerContext) {\n      return parser.precpred(outerContext, this.precedence);\n    }\n    evalPrecedence(parser, outerContext) {\n      if (parser.precpred(outerContext ?? null, this.precedence)) {\n        return SemanticContext2.NONE;\n      }\n      return null;\n    }\n    compareTo(other) {\n      return this.precedence - other.precedence;\n    }\n    hashCode() {\n      return 31 + this.precedence;\n    }\n    equals(other) {\n      if (this === other) {\n        return true;\n      }\n      return this.precedence === other.precedence;\n    }\n    toString() {\n      return \"{\" + this.precedence + \">=prec}?\";\n    }\n  }\n  SemanticContext2.PrecedencePredicate = PrecedencePredicate;\n  SemanticContext2.NONE = new Predicate();\n})(SemanticContext || (SemanticContext = {}));\n\n// src/atn/ATNConfig.ts\nvar ATNConfig = class _ATNConfig {\n  static {\n    __name(this, \"ATNConfig\");\n  }\n  /** The ATN state associated with this configuration */\n  state;\n  /** What alt (or lexer rule) is predicted by this configuration */\n  alt;\n  /**\n   * We cannot execute predicates dependent upon local context unless\n   * we know for sure we are in the correct context. Because there is\n   * no way to do this efficiently, we simply cannot evaluate\n   * dependent predicates unless we are in the rule that initially\n   * invokes the ATN simulator.\n   *\n   * closure() tracks the depth of how far we dip into the outer context:\n   * depth > 0.\n   */\n  reachesIntoOuterContext = false;\n  // Not used in hash code.\n  precedenceFilterSuppressed = false;\n  // Not used in hash code.\n  get semanticContext() {\n    return this.#semanticContext;\n  }\n  cachedHashCode;\n  // Shared with LexerATNConfig.\n  /**\n   * The syntactic context is a graph-structured stack node whose\n   * path(s) to the root is the rule invocation(s)\n   * chain used to arrive at the state.  The semantic context is\n   * the tree of semantic predicates encountered before reaching\n   * an ATN state\n   */\n  #context = null;\n  #semanticContext;\n  /** Never create config classes directly. Use the factory methods below. */\n  constructor(c, state, context, semanticContext) {\n    this.state = state;\n    this.alt = c.alt;\n    this.context = context;\n    this.#semanticContext = semanticContext ?? SemanticContext.NONE;\n    this.reachesIntoOuterContext = c.reachesIntoOuterContext;\n    if (c.precedenceFilterSuppressed !== void 0) {\n      this.precedenceFilterSuppressed = c.precedenceFilterSuppressed;\n    }\n  }\n  static duplicate(old, semanticContext) {\n    return new _ATNConfig(old, old.state, old.context, semanticContext ?? old.semanticContext);\n  }\n  static createWithContext(state, alt, context, semanticContext) {\n    return new _ATNConfig({ alt }, state, context, semanticContext);\n  }\n  static createWithConfig(state, config, context) {\n    return new _ATNConfig(config, state, context ?? config.context, config.semanticContext);\n  }\n  static createWithSemanticContext(state, c, semanticContext) {\n    return new _ATNConfig(c, state ?? c.state, c.context, semanticContext);\n  }\n  hashCode() {\n    if (this.cachedHashCode === void 0) {\n      let hashCode = MurmurHash.initialize(7);\n      hashCode = MurmurHash.update(hashCode, this.state.stateNumber);\n      hashCode = MurmurHash.update(hashCode, this.alt);\n      hashCode = MurmurHash.updateFromComparable(hashCode, this.#context);\n      hashCode = MurmurHash.updateFromComparable(hashCode, this.semanticContext);\n      hashCode = MurmurHash.finish(hashCode, 4);\n      this.cachedHashCode = hashCode;\n    }\n    return this.cachedHashCode;\n  }\n  /**\n   * The stack of invoking states leading to the rule/states associated\n   * with this config.  We track only those contexts pushed during\n   * execution of the ATN simulator.\n   */\n  get context() {\n    return this.#context;\n  }\n  set context(context) {\n    this.#context = context;\n    this.cachedHashCode = void 0;\n  }\n  /**\n   * An ATN configuration is equal to another if both have\n   * the same state, they predict the same alternative, and\n   * syntactic/semantic contexts are the same.\n   */\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    return this.state.stateNumber === other.state.stateNumber && this.alt === other.alt && (this.context === null ? other.context === null : this.context.equals(other.context)) && this.semanticContext.equals(other.semanticContext) && this.precedenceFilterSuppressed === other.precedenceFilterSuppressed;\n  }\n  toString(_recog, showAlt = true) {\n    let alt = \"\";\n    if (showAlt) {\n      alt = \",\" + this.alt;\n    }\n    return \"(\" + this.state + alt + (this.context !== null ? \",[\" + this.context.toString() + \"]\" : \"\") + (this.semanticContext !== SemanticContext.NONE ? \",\" + this.semanticContext.toString() : \"\") + (this.reachesIntoOuterContext ? \",up=\" + this.reachesIntoOuterContext : \"\") + \")\";\n  }\n};\n\n// src/atn/LL1Analyzer.ts\nvar LL1Analyzer = class _LL1Analyzer {\n  static {\n    __name(this, \"LL1Analyzer\");\n  }\n  /**\n   * Special value added to the lookahead sets to indicate that we hit\n   * a predicate during analysis if `seeThruPreds==false`.\n   */\n  static hitPredicate = Token.INVALID_TYPE;\n  #atn;\n  /**\n   * Calculates the SLL(1) expected lookahead set for each outgoing transition\n   * of an {@link ATNState}. The returned array has one element for each\n   * outgoing transition in `s`. If the closure from transition\n   * _i_ leads to a semantic predicate before matching a symbol, the\n   * element at index *i* of the result will be `null`.\n   *\n   * @param s the ATN state\n   * @returns the expected symbols for each outgoing transition of `s`.\n   */\n  getDecisionLookahead(s) {\n    if (!s) {\n      return void 0;\n    }\n    const count = s.transitions.length;\n    const look = new Array(count);\n    for (let alt = 0; alt < count; alt++) {\n      const set = new IntervalSet();\n      const lookBusy = new HashSet();\n      this.doLook(\n        s.transitions[alt].target,\n        void 0,\n        PredictionContext.EMPTY,\n        set,\n        lookBusy,\n        new BitSet(),\n        false,\n        false\n      );\n      if (set.length > 0 && !set.contains(_LL1Analyzer.hitPredicate)) {\n        look[alt] = set;\n      }\n    }\n    return look;\n  }\n  /**\n   * Compute set of tokens that can follow `s` in the ATN in the\n   * specified `ctx`.\n   *\n   * If `ctx` is `null` and the end of the rule containing\n   * `s` is reached, {@link Token//EPSILON} is added to the result set.\n   * If `ctx` is not `null` and the end of the outermost rule is\n   * reached, {@link Token//EOF} is added to the result set.\n   *\n   * @param atn the ATN\n   * @param s the ATN state\n   * @param stopState the ATN state to stop at. This can be a\n   * {@link BlockEndState} to detect epsilon paths through a closure.\n   * @param ctx the complete parser context, or `null` if the context\n   * should be ignored\n   *\n   * @returns The set of tokens that can follow `s` in the ATN in the\n   * specified `ctx`.\n   */\n  look(atn, s, stopState, ctx) {\n    this.#atn = atn;\n    const r = new IntervalSet();\n    const lookContext = ctx ? predictionContextFromRuleContext(atn, ctx) : null;\n    this.doLook(s, stopState, lookContext, r, new HashSet(), new BitSet(), true, true);\n    return r;\n  }\n  /**\n   * Compute set of tokens that can follow `s` in the ATN in the\n   * specified `ctx`.\n   *\n   * If `ctx` is `null` and `stopState` or the end of the\n   * rule containing `s` is reached, {@link Token//EPSILON} is added to\n   * the result set. If `ctx` is not `null` and `addEOF` is\n   * `true` and `stopState` or the end of the outermost rule is\n   * reached, {@link Token//EOF} is added to the result set.\n   *\n   * @param s the ATN state.\n   * @param stopState the ATN state to stop at. This can be a\n   * {@link BlockEndState} to detect epsilon paths through a closure.\n   * @param ctx The outer context, or `null` if the outer context should\n   * not be used.\n   * @param look The result lookahead set.\n   * @param lookBusy A set used for preventing epsilon closures in the ATN\n   * from causing a stack overflow. Outside code should pass\n   * `new CustomizedSet<ATNConfig>` for this argument.\n   * @param calledRuleStack A set used for preventing left recursion in the\n   * ATN from causing a stack overflow. Outside code should pass\n   * `new BitSet()` for this argument.\n   * @param seeThruPreds `true` to true semantic predicates as\n   * implicitly `true` and \"see through them\", otherwise `false`\n   * to treat semantic predicates as opaque and add {@link hitPredicate} to the\n   * result if one is encountered.\n   * @param addEOF Add {@link Token//EOF} to the result if the end of the\n   * outermost context is reached. This parameter has no effect if `ctx`\n   * is `null`.\n   */\n  doLook(s, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF) {\n    const c = ATNConfig.createWithContext(s, 0, ctx);\n    if (lookBusy.get(c)) {\n      return;\n    }\n    lookBusy.add(c);\n    if (s === stopState) {\n      if (!ctx) {\n        look.addOne(Token.EPSILON);\n        return;\n      } else if (ctx.isEmpty() && addEOF) {\n        look.addOne(Token.EOF);\n        return;\n      }\n    }\n    if (s.constructor.stateType === ATNState.RULE_STOP) {\n      if (!ctx) {\n        look.addOne(Token.EPSILON);\n        return;\n      } else if (ctx.isEmpty() && addEOF) {\n        look.addOne(Token.EOF);\n        return;\n      }\n      if (ctx !== PredictionContext.EMPTY) {\n        const removed = calledRuleStack.get(s.ruleIndex);\n        try {\n          calledRuleStack.clear(s.ruleIndex);\n          for (let i = 0; i < ctx.length; i++) {\n            const returnState = this.#atn.states[ctx.getReturnState(i)];\n            this.doLook(\n              returnState,\n              stopState,\n              ctx.getParent(i),\n              look,\n              lookBusy,\n              calledRuleStack,\n              seeThruPreds,\n              addEOF\n            );\n          }\n        } finally {\n          if (removed) {\n            calledRuleStack.set(s.ruleIndex);\n          }\n        }\n        return;\n      }\n    }\n    for (const t of s.transitions) {\n      switch (t.transitionType) {\n        case Transition.RULE: {\n          if (calledRuleStack.get(t.target.ruleIndex)) {\n            continue;\n          }\n          const newContext = SingletonPredictionContext.create(\n            ctx ?? void 0,\n            t.followState.stateNumber\n          );\n          try {\n            calledRuleStack.set(t.target.ruleIndex);\n            this.doLook(\n              t.target,\n              stopState,\n              newContext,\n              look,\n              lookBusy,\n              calledRuleStack,\n              seeThruPreds,\n              addEOF\n            );\n          } finally {\n            calledRuleStack.clear(t.target.ruleIndex);\n          }\n          break;\n        }\n        case Transition.PREDICATE:\n        case Transition.PRECEDENCE: {\n          if (seeThruPreds) {\n            this.doLook(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n          } else {\n            look.addOne(_LL1Analyzer.hitPredicate);\n          }\n          break;\n        }\n        case Transition.WILDCARD: {\n          look.addRange(Token.MIN_USER_TOKEN_TYPE, this.#atn.maxTokenType);\n          break;\n        }\n        default: {\n          if (t.isEpsilon) {\n            this.doLook(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n          } else {\n            let set = t.label;\n            if (set) {\n              if (t instanceof NotSetTransition) {\n                set = set.complement(Token.MIN_USER_TOKEN_TYPE, this.#atn.maxTokenType);\n              }\n              look.addSet(set);\n            }\n          }\n          break;\n        }\n      }\n    }\n  }\n};\n\n// src/atn/ATN.ts\nvar ATN = class _ATN {\n  static {\n    __name(this, \"ATN\");\n  }\n  static INVALID_ALT_NUMBER = 0;\n  /** Represents the type of recognizer an ATN applies to */\n  static LEXER = 0;\n  static PARSER = 1;\n  /**\n   * Used for runtime deserialization of ATNs from strings\n   * The type of the ATN.\n   */\n  grammarType;\n  /** The maximum value for any symbol recognized by a transition in the ATN. */\n  maxTokenType;\n  states = [];\n  /**\n   * Each subrule/rule is a decision point and we must track them so we\n   * can go back later and build DFA predictors for them.  This includes\n   * all the rules, subrules, optional blocks, ()+, ()* etc...\n   */\n  decisionToState = [];\n  /** Maps from rule index to starting state number. */\n  ruleToStartState = [];\n  // Initialized by the ATN deserializer.\n  /** Maps from rule index to stop state number. */\n  ruleToStopState = [];\n  // Initialized by the ATN deserializer.\n  modeNameToStartState = /* @__PURE__ */ new Map();\n  /**\n   * For lexer ATNs, this maps the rule index to the resulting token type.\n   * For parser ATNs, this maps the rule index to the generated bypass token\n   * type if the {@link ATNDeserializationOptions//isGenerateRuleBypassTransitions}\n   * deserialization option was specified; otherwise, this is `null`\n   */\n  ruleToTokenType = [];\n  // Initialized by the ATN deserializer.\n  /**\n   * For lexer ATNs, this is an array of {@link LexerAction} objects which may\n   * be referenced by action transitions in the ATN\n   */\n  lexerActions = [];\n  modeToStartState = [];\n  static #analyzer = new LL1Analyzer();\n  constructor(grammarType, maxTokenType) {\n    this.grammarType = grammarType;\n    this.maxTokenType = maxTokenType;\n  }\n  /**\n   * Compute the set of valid tokens that can occur starting in state `s`.\n   * If `ctx` is null, the set of tokens will not include what can follow\n   * the rule surrounding `s`. In other words, the set will be\n   * restricted to tokens reachable staying within `s`'s rule.\n   */\n  nextTokens(atnState, ctx) {\n    if (!ctx && atnState.nextTokenWithinRule) {\n      return atnState.nextTokenWithinRule;\n    }\n    const next = _ATN.#analyzer.look(this, atnState, void 0, ctx);\n    if (!ctx) {\n      atnState.nextTokenWithinRule = next;\n    }\n    return next;\n  }\n  addState(state) {\n    if (state) {\n      state.stateNumber = this.states.length;\n    }\n    this.states.push(state);\n  }\n  removeState(state) {\n    this.states[state.stateNumber] = null;\n  }\n  defineDecisionState(s) {\n    this.decisionToState.push(s);\n    s.decision = this.decisionToState.length - 1;\n    return s.decision;\n  }\n  getDecisionState(decision) {\n    if (this.decisionToState.length === 0) {\n      return null;\n    } else {\n      return this.decisionToState[decision];\n    }\n  }\n  getNumberOfDecisions() {\n    return this.decisionToState.length;\n  }\n  /**\n   * Computes the set of input symbols which could follow ATN state number\n   * `stateNumber` in the specified full `context`. This method\n   * considers the complete parser context, but does not evaluate semantic\n   * predicates (i.e. all predicates encountered during the calculation are\n   * assumed true). If a path in the ATN exists from the starting state to the\n   * {@link RuleStopState} of the outermost context without matching any\n   * symbols, {@link Token//EOF} is added to the returned set.\n   *\n   * If `context` is `null`, it is treated as\n   * {@link ParserRuleContext//EMPTY}.\n   *\n   * @param stateNumber the ATN state number\n   * @param context the full parse context\n   *\n   * @returns {IntervalSet} The set of potentially valid input symbols which could follow the\n   * specified state in the specified context.\n   *\n   * @throws IllegalArgumentException if the ATN does not contain a state with\n   * number `stateNumber`\n   */\n  getExpectedTokens(stateNumber, context) {\n    if (stateNumber < 0 || stateNumber >= this.states.length) {\n      throw new Error(\"Invalid state number.\");\n    }\n    const s = this.states[stateNumber];\n    let following = this.nextTokens(s);\n    if (!following.contains(Token.EPSILON)) {\n      return following;\n    }\n    let ctx = context;\n    const expected = new IntervalSet();\n    expected.addSet(following);\n    expected.removeOne(Token.EPSILON);\n    while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n      const invokingState = this.states[ctx.invokingState];\n      const rt = invokingState.transitions[0];\n      following = this.nextTokens(rt.followState);\n      expected.addSet(following);\n      expected.removeOne(Token.EPSILON);\n      ctx = ctx.parent;\n    }\n    if (following.contains(Token.EPSILON)) {\n      expected.addOne(Token.EOF);\n    }\n    return expected;\n  }\n};\n\n// src/atn/ATNConfigSet.ts\nvar KeyTypeEqualityComparer = class _KeyTypeEqualityComparer {\n  static {\n    __name(this, \"KeyTypeEqualityComparer\");\n  }\n  static instance = new _KeyTypeEqualityComparer();\n  hashCode(config) {\n    let hashCode = 7;\n    hashCode = 31 * hashCode + config.state.stateNumber;\n    hashCode = 31 * hashCode + config.alt;\n    hashCode = 31 * hashCode + config.semanticContext.hashCode();\n    return hashCode;\n  }\n  equals(a, b) {\n    if (a === b) {\n      return true;\n    }\n    return a.state.stateNumber === b.state.stateNumber && a.alt === b.alt && a.semanticContext.equals(b.semanticContext);\n  }\n};\nvar ATNConfigSet = class {\n  static {\n    __name(this, \"ATNConfigSet\");\n  }\n  /**\n   * The reason that we need this is because we don't want the hash map to use\n   * the standard hash code and equals. We need all configurations with the\n   * same\n   * `(s,i,_,semctx)` to be equal. Unfortunately, this key effectively\n   * doubles\n   * the number of objects associated with ATNConfigs. The other solution is\n   * to\n   * use a hash table that lets us specify the equals/hashCode operation.\n   * All configs but hashed by (s, i, _, pi) not including context. Wiped out\n   * when we go readonly as this set becomes a DFA state\n   */\n  configLookup = new HashSet(KeyTypeEqualityComparer.instance);\n  // Track the elements as they are added to the set; supports get(i).\n  configs = [];\n  uniqueAlt = 0;\n  /**\n   * Used in parser and lexer. In lexer, it indicates we hit a pred\n   * while computing a closure operation. Don't make a DFA state from this\n   */\n  hasSemanticContext = false;\n  dipsIntoOuterContext = false;\n  /**\n   * Indicates that this configuration set is part of a full context\n   * LL prediction. It will be used to determine how to merge $. With SLL\n   * it's a wildcard whereas it is not for LL context merge\n   */\n  fullCtx = false;\n  /**\n   * Indicates that the set of configurations is read-only. Do not\n   * allow any code to manipulate the set; DFA states will point at\n   * the sets and they must not change. This does not protect the other\n   * fields; in particular, conflictingAlts is set after\n   * we've made this readonly\n   */\n  readOnly = false;\n  conflictingAlts = null;\n  /**\n   * Tracks the first config that has a rule stop state. Avoids frequent linear search for that, when adding\n   * a DFA state in the lexer ATN simulator.\n   */\n  firstStopState;\n  #cachedHashCode = -1;\n  constructor(fullCtxOrOldSet) {\n    if (fullCtxOrOldSet !== void 0) {\n      if (typeof fullCtxOrOldSet === \"boolean\") {\n        this.fullCtx = fullCtxOrOldSet ?? true;\n      } else {\n        const old = fullCtxOrOldSet;\n        this.addAll(old.configs);\n        this.uniqueAlt = old.uniqueAlt;\n        this.conflictingAlts = old.conflictingAlts;\n        this.hasSemanticContext = old.hasSemanticContext;\n        this.dipsIntoOuterContext = old.dipsIntoOuterContext;\n      }\n    }\n  }\n  [Symbol.iterator]() {\n    return this.configs[Symbol.iterator]();\n  }\n  /**\n   * Adding a new config means merging contexts with existing configs for\n   * `(s, i, pi, _)`, where `s` is the {@link ATNConfig.state}, `i` is the {@link ATNConfig.alt}, and\n   * `pi` is the {@link ATNConfig.semanticContext}. We use `(s,i,pi)` as key.\n   *\n   * This method updates {@link dipsIntoOuterContext} and\n   * {@link hasSemanticContext} when necessary.\n   */\n  add(config, mergeCache = null) {\n    if (this.readOnly) {\n      throw new Error(\"This set is readonly\");\n    }\n    if (!this.firstStopState && config.state.constructor.stateType === ATNState.RULE_STOP) {\n      this.firstStopState = config;\n    }\n    this.hasSemanticContext ||= config.semanticContext !== SemanticContext.NONE;\n    this.dipsIntoOuterContext ||= config.reachesIntoOuterContext;\n    const existing = this.configLookup.getOrAdd(config);\n    if (existing === config) {\n      this.#cachedHashCode = -1;\n      this.configs.push(config);\n      return;\n    }\n    const rootIsWildcard = !this.fullCtx;\n    const merged = merge(existing.context, config.context, rootIsWildcard, mergeCache);\n    existing.reachesIntoOuterContext ||= config.reachesIntoOuterContext;\n    existing.precedenceFilterSuppressed ||= config.precedenceFilterSuppressed;\n    existing.context = merged;\n  }\n  /** Return a List holding list of configs */\n  get elements() {\n    return this.configs;\n  }\n  /**\n   * Gets the complete set of represented alternatives for the configuration set.\n   *\n   * @returns the set of represented alternatives in this configuration set\n   */\n  getAlts() {\n    const alts = new BitSet();\n    for (const config of this.configs) {\n      alts.set(config.alt);\n    }\n    return alts;\n  }\n  getPredicates() {\n    const preds = [];\n    for (const config of this.configs) {\n      if (config.semanticContext !== SemanticContext.NONE) {\n        preds.push(config.semanticContext);\n      }\n    }\n    return preds;\n  }\n  getStates() {\n    const states = new HashSet();\n    for (const config of this.configs) {\n      states.add(config.state);\n    }\n    return states;\n  }\n  optimizeConfigs(interpreter) {\n    if (this.readOnly) {\n      throw new Error(\"This set is readonly\");\n    }\n    if (this.configLookup.size === 0) {\n      return;\n    }\n    for (const config of this.configs) {\n      config.context = interpreter.getCachedContext(config.context);\n    }\n  }\n  addAll(coll) {\n    for (const config of coll) {\n      this.add(config);\n    }\n    return false;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (this.fullCtx === other.fullCtx && this.uniqueAlt === other.uniqueAlt && this.conflictingAlts === other.conflictingAlts && this.hasSemanticContext === other.hasSemanticContext && this.dipsIntoOuterContext === other.dipsIntoOuterContext && equalArrays(this.configs, other.configs)) {\n      return true;\n    }\n    return false;\n  }\n  hashCode() {\n    if (this.#cachedHashCode === -1) {\n      this.#cachedHashCode = this.computeHashCode();\n    }\n    return this.#cachedHashCode;\n  }\n  get length() {\n    return this.configs.length;\n  }\n  isEmpty() {\n    return this.configs.length === 0;\n  }\n  contains(item) {\n    if (this.configLookup === null) {\n      throw new Error(\"This method is not implemented for readonly sets.\");\n    }\n    return this.configLookup.contains(item);\n  }\n  containsFast(item) {\n    if (this.configLookup === null) {\n      throw new Error(\"This method is not implemented for readonly sets.\");\n    }\n    return this.configLookup.contains(item);\n  }\n  clear() {\n    if (this.readOnly) {\n      throw new Error(\"This set is readonly\");\n    }\n    this.configs = [];\n    this.#cachedHashCode = -1;\n    this.configLookup = new HashSet(KeyTypeEqualityComparer.instance);\n  }\n  setReadonly(readOnly) {\n    this.readOnly = readOnly;\n    if (readOnly) {\n      this.configLookup = null;\n    }\n  }\n  toString() {\n    return arrayToString(this.configs) + (this.hasSemanticContext ? \",hasSemanticContext=\" + this.hasSemanticContext : \"\") + (this.uniqueAlt !== ATN.INVALID_ALT_NUMBER ? \",uniqueAlt=\" + this.uniqueAlt : \"\") + (this.conflictingAlts !== null ? \",conflictingAlts=\" + this.conflictingAlts : \"\") + (this.dipsIntoOuterContext ? \",dipsIntoOuterContext\" : \"\");\n  }\n  computeHashCode() {\n    let hash = MurmurHash.initialize();\n    this.configs.forEach((config) => {\n      hash = MurmurHash.update(hash, config.hashCode());\n    });\n    hash = MurmurHash.finish(hash, this.configs.length);\n    return hash;\n  }\n};\n\n// src/atn/BasicState.ts\nvar BasicState = class extends ATNState {\n  static {\n    __name(this, \"BasicState\");\n  }\n  static stateType = ATNState.BASIC;\n};\n\n// src/atn/DecisionState.ts\nvar DecisionState = class extends ATNState {\n  static {\n    __name(this, \"DecisionState\");\n  }\n  decision = -1;\n  nonGreedy = false;\n};\n\n// src/atn/BlockStartState.ts\nvar BlockStartState = class extends DecisionState {\n  static {\n    __name(this, \"BlockStartState\");\n  }\n  endState;\n};\n\n// src/atn/BlockEndState.ts\nvar BlockEndState = class extends ATNState {\n  static {\n    __name(this, \"BlockEndState\");\n  }\n  static stateType = ATNState.BLOCK_END;\n  startState;\n};\n\n// src/atn/LoopEndState.ts\nvar LoopEndState = class extends ATNState {\n  static {\n    __name(this, \"LoopEndState\");\n  }\n  static stateType = ATNState.LOOP_END;\n  loopBackState;\n};\n\n// src/atn/RuleStartState.ts\nvar RuleStartState = class extends ATNState {\n  static {\n    __name(this, \"RuleStartState\");\n  }\n  static stateType = ATNState.RULE_START;\n  stopState;\n  isLeftRecursiveRule = false;\n  isPrecedenceRule = false;\n};\n\n// src/atn/RuleStopState.ts\nvar RuleStopState = class extends ATNState {\n  static {\n    __name(this, \"RuleStopState\");\n  }\n  static stateType = ATNState.RULE_STOP;\n};\n\n// src/atn/TokensStartState.ts\nvar TokensStartState = class extends DecisionState {\n  static {\n    __name(this, \"TokensStartState\");\n  }\n  static stateType = ATNState.TOKEN_START;\n};\n\n// src/atn/PlusLoopbackState.ts\nvar PlusLoopbackState = class extends DecisionState {\n  static {\n    __name(this, \"PlusLoopbackState\");\n  }\n  static stateType = ATNState.PLUS_LOOP_BACK;\n};\n\n// src/atn/StarLoopbackState.ts\nvar StarLoopbackState = class extends ATNState {\n  static {\n    __name(this, \"StarLoopbackState\");\n  }\n  static stateType = ATNState.STAR_LOOP_BACK;\n};\n\n// src/atn/StarLoopEntryState.ts\nvar StarLoopEntryState = class extends DecisionState {\n  static {\n    __name(this, \"StarLoopEntryState\");\n  }\n  static stateType = ATNState.STAR_LOOP_ENTRY;\n  // This is always set during ATN deserialization\n  loopBackState;\n  /**\n   * Indicates whether this state can benefit from a precedence DFA during SLL\n   * decision making.\n   *\n   * This is a computed property that is calculated during ATN deserialization\n   * and stored for use in {@link ParserATNSimulator} and\n   * {@link ParserInterpreter}.\n   *\n   * @see `DFA.isPrecedenceDfa`\n   */\n  precedenceRuleDecision = false;\n};\n\n// src/atn/PlusBlockStartState.ts\nvar PlusBlockStartState = class extends BlockStartState {\n  static {\n    __name(this, \"PlusBlockStartState\");\n  }\n  static stateType = ATNState.PLUS_BLOCK_START;\n  loopBackState;\n};\n\n// src/atn/StarBlockStartState.ts\nvar StarBlockStartState = class extends BlockStartState {\n  static {\n    __name(this, \"StarBlockStartState\");\n  }\n  static stateType = ATNState.STAR_BLOCK_START;\n};\n\n// src/atn/BasicBlockStartState.ts\nvar BasicBlockStartState = class extends BlockStartState {\n  static {\n    __name(this, \"BasicBlockStartState\");\n  }\n  static stateType = ATNState.BLOCK_START;\n};\n\n// src/atn/AtomTransition.ts\nvar AtomTransition = class extends Transition {\n  static {\n    __name(this, \"AtomTransition\");\n  }\n  /** The token type or character value; or, signifies special label. */\n  labelValue;\n  #label;\n  constructor(target, label) {\n    super(target);\n    this.labelValue = label;\n    this.#label = IntervalSet.of(label, label);\n  }\n  get label() {\n    return this.#label;\n  }\n  get transitionType() {\n    return Transition.ATOM;\n  }\n  matches(symbol) {\n    return this.labelValue === symbol;\n  }\n  toString() {\n    return this.labelValue.toString();\n  }\n};\n\n// src/atn/RuleTransition.ts\nvar RuleTransition = class extends Transition {\n  static {\n    __name(this, \"RuleTransition\");\n  }\n  ruleIndex;\n  precedence;\n  followState;\n  constructor(ruleStart, ruleIndex, precedence, followState) {\n    super(ruleStart);\n    this.ruleIndex = ruleIndex;\n    this.precedence = precedence;\n    this.followState = followState;\n  }\n  get isEpsilon() {\n    return true;\n  }\n  get transitionType() {\n    return Transition.RULE;\n  }\n  matches(_symbol, _minVocabSymbol, _maxVocabSymbol) {\n    return false;\n  }\n};\n\n// src/atn/RangeTransition.ts\nvar RangeTransition = class extends Transition {\n  static {\n    __name(this, \"RangeTransition\");\n  }\n  start;\n  stop;\n  #label = new IntervalSet();\n  constructor(target, start, stop) {\n    super(target);\n    this.start = start;\n    this.stop = stop;\n    this.#label.addRange(start, stop);\n  }\n  get label() {\n    return this.#label;\n  }\n  get transitionType() {\n    return Transition.RANGE;\n  }\n  matches(symbol, _minVocabSymbol, _maxVocabSymbol) {\n    return symbol >= this.start && symbol <= this.stop;\n  }\n  toString() {\n    return \"'\" + String.fromCharCode(this.start) + \"'..'\" + String.fromCharCode(this.stop) + \"'\";\n  }\n};\n\n// src/atn/ActionTransition.ts\nvar ActionTransition = class extends Transition {\n  static {\n    __name(this, \"ActionTransition\");\n  }\n  ruleIndex;\n  actionIndex;\n  isCtxDependent;\n  constructor(target, ruleIndex, actionIndex, isCtxDependent) {\n    super(target);\n    this.ruleIndex = ruleIndex;\n    this.actionIndex = actionIndex === void 0 ? -1 : actionIndex;\n    this.isCtxDependent = isCtxDependent === void 0 ? false : isCtxDependent;\n  }\n  get isEpsilon() {\n    return true;\n  }\n  get transitionType() {\n    return Transition.ACTION;\n  }\n  matches(_symbol, _minVocabSymbol, _maxVocabSymbol) {\n    return false;\n  }\n  toString() {\n    return \"action_\" + this.ruleIndex + \":\" + this.actionIndex;\n  }\n};\n\n// src/atn/EpsilonTransition.ts\nvar EpsilonTransition = class extends Transition {\n  static {\n    __name(this, \"EpsilonTransition\");\n  }\n  #outermostPrecedenceReturn;\n  constructor(target, outermostPrecedenceReturn = -1) {\n    super(target);\n    this.#outermostPrecedenceReturn = outermostPrecedenceReturn;\n  }\n  /**\n   * @returns the rule index of a precedence rule for which this transition is\n   * returning from, where the precedence value is 0; otherwise, -1.\n   *\n   * @see ATNConfig.isPrecedenceFilterSuppressed()\n   * @see ParserATNSimulator.applyPrecedenceFilter(ATNConfigSet)\n   * @since 4.4.1\n   */\n  get outermostPrecedenceReturn() {\n    return this.#outermostPrecedenceReturn;\n  }\n  get isEpsilon() {\n    return true;\n  }\n  get transitionType() {\n    return Transition.EPSILON;\n  }\n  matches() {\n    return false;\n  }\n  toString() {\n    return \"epsilon\";\n  }\n};\n\n// src/atn/WildcardTransition.ts\nvar WildcardTransition = class extends Transition {\n  static {\n    __name(this, \"WildcardTransition\");\n  }\n  get transitionType() {\n    return Transition.WILDCARD;\n  }\n  matches(symbol, minVocabSymbol, maxVocabSymbol) {\n    return symbol >= minVocabSymbol && symbol <= maxVocabSymbol;\n  }\n  toString() {\n    return \".\";\n  }\n};\n\n// src/atn/AbstractPredicateTransition.ts\nvar AbstractPredicateTransition = class extends Transition {\n  static {\n    __name(this, \"AbstractPredicateTransition\");\n  }\n  constructor(target) {\n    super(target);\n  }\n};\n\n// src/atn/PredicateTransition.ts\nvar PredicateTransition = class extends AbstractPredicateTransition {\n  static {\n    __name(this, \"PredicateTransition\");\n  }\n  ruleIndex;\n  predIndex;\n  isCtxDependent;\n  // e.g., $i ref in pred\n  constructor(target, ruleIndex, predIndex, isCtxDependent) {\n    super(target);\n    this.ruleIndex = ruleIndex;\n    this.predIndex = predIndex;\n    this.isCtxDependent = isCtxDependent;\n  }\n  get isEpsilon() {\n    return true;\n  }\n  matches(_symbol, _minVocabSymbol, _maxVocabSymbol) {\n    return false;\n  }\n  get transitionType() {\n    return Transition.PREDICATE;\n  }\n  getPredicate() {\n    return new SemanticContext.Predicate(this.ruleIndex, this.predIndex, this.isCtxDependent);\n  }\n  toString() {\n    return \"pred_\" + this.ruleIndex + \":\" + this.predIndex;\n  }\n};\n\n// src/atn/PrecedencePredicateTransition.ts\nvar PrecedencePredicateTransition = class extends AbstractPredicateTransition {\n  static {\n    __name(this, \"PrecedencePredicateTransition\");\n  }\n  precedence;\n  constructor(target, precedence) {\n    super(target);\n    this.precedence = precedence;\n  }\n  get isEpsilon() {\n    return true;\n  }\n  matches(_symbol, _minVocabSymbol, _maxVocabSymbol) {\n    return false;\n  }\n  getPredicate() {\n    return new SemanticContext.PrecedencePredicate(this.precedence);\n  }\n  get transitionType() {\n    return Transition.PRECEDENCE;\n  }\n  toString() {\n    return this.precedence + \" >= _p\";\n  }\n};\n\n// src/atn/LexerActionType.ts\nvar LexerActionType = {\n  /** The type of a {@link LexerChannelAction} action. */\n  CHANNEL: 0,\n  /** The type of a {@link LexerCustomAction} action */\n  CUSTOM: 1,\n  /** The type of a {@link LexerModeAction} action. */\n  MODE: 2,\n  /** The type of a {@link LexerMoreAction} action. */\n  MORE: 3,\n  /** The type of a {@link LexerPopModeAction} action. */\n  POP_MODE: 4,\n  /** The type of a {@link LexerPushModeAction} action. */\n  PUSH_MODE: 5,\n  /** The type of a {@link LexerSkipAction} action. */\n  SKIP: 6,\n  /** The type of a {@link LexerTypeAction} action. */\n  TYPE: 7\n};\n\n// src/atn/LexerSkipAction.ts\nvar LexerSkipAction = class _LexerSkipAction {\n  static {\n    __name(this, \"LexerSkipAction\");\n  }\n  /** Provides a singleton instance of this parameter-less lexer action. */\n  static instance = new _LexerSkipAction();\n  actionType;\n  isPositionDependent = false;\n  constructor() {\n    this.actionType = LexerActionType.SKIP;\n  }\n  equals(obj) {\n    return obj === this;\n  }\n  hashCode() {\n    return LexerActionType.SKIP;\n  }\n  execute(lexer) {\n    lexer.skip();\n  }\n  toString() {\n    return \"skip\";\n  }\n};\n\n// src/atn/LexerChannelAction.ts\nvar LexerChannelAction = class _LexerChannelAction {\n  static {\n    __name(this, \"LexerChannelAction\");\n  }\n  channel;\n  actionType;\n  isPositionDependent = false;\n  #cachedHashCode;\n  constructor(channel) {\n    this.actionType = LexerActionType.CHANNEL;\n    this.channel = channel;\n  }\n  /**\n   * This action is implemented by calling {@link Lexer.setChannel} with the\n   * value provided by {@link getChannel}.\n   */\n  execute(lexer) {\n    lexer.channel = this.channel;\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      hash = MurmurHash.update(hash, this.actionType);\n      hash = MurmurHash.update(hash, this.channel);\n      this.#cachedHashCode = MurmurHash.finish(hash, 2);\n    }\n    return this.#cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _LexerChannelAction)) {\n      return false;\n    }\n    return this.channel === other.channel;\n  }\n  toString() {\n    return \"channel(\" + this.channel + \")\";\n  }\n};\n\n// src/atn/LexerCustomAction.ts\nvar LexerCustomAction = class _LexerCustomAction {\n  static {\n    __name(this, \"LexerCustomAction\");\n  }\n  ruleIndex;\n  actionIndex;\n  actionType;\n  isPositionDependent = true;\n  #cachedHashCode;\n  /**\n   * Constructs a custom lexer action with the specified rule and action indexes.\n   *\n   * @param ruleIndex The rule index to use for calls to {@link Recognizer.action}.\n   * @param actionIndex The action index to use for calls to {@link Recognizer.action}.\n   */\n  constructor(ruleIndex, actionIndex) {\n    this.actionType = LexerActionType.CUSTOM;\n    this.ruleIndex = ruleIndex;\n    this.actionIndex = actionIndex;\n  }\n  /**\n   * Custom actions are implemented by calling {@link Lexer.action} with the\n   * appropriate rule and action indexes.\n   */\n  execute(lexer) {\n    lexer.action(null, this.ruleIndex, this.actionIndex);\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      hash = MurmurHash.update(hash, this.actionType);\n      hash = MurmurHash.update(hash, this.ruleIndex);\n      hash = MurmurHash.update(hash, this.actionIndex);\n      this.#cachedHashCode = MurmurHash.finish(hash, 3);\n    }\n    return this.#cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _LexerCustomAction)) {\n      return false;\n    }\n    return this.ruleIndex === other.ruleIndex && this.actionIndex === other.actionIndex;\n  }\n};\n\n// src/atn/LexerMoreAction.ts\nvar LexerMoreAction = class _LexerMoreAction {\n  static {\n    __name(this, \"LexerMoreAction\");\n  }\n  static instance = new _LexerMoreAction();\n  actionType;\n  isPositionDependent = false;\n  constructor() {\n    this.actionType = LexerActionType.MORE;\n  }\n  equals(obj) {\n    return obj === this;\n  }\n  hashCode() {\n    return LexerActionType.MORE;\n  }\n  /**\n   * This action is implemented by calling {@link Lexer.popMode}.\n   */\n  execute(lexer) {\n    lexer.more();\n  }\n  toString() {\n    return \"more\";\n  }\n};\n\n// src/atn/LexerTypeAction.ts\nvar LexerTypeAction = class _LexerTypeAction {\n  static {\n    __name(this, \"LexerTypeAction\");\n  }\n  type;\n  actionType;\n  isPositionDependent = false;\n  #cachedHashCode;\n  constructor(type) {\n    this.actionType = LexerActionType.TYPE;\n    this.type = type;\n  }\n  execute(lexer) {\n    lexer.type = this.type;\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      hash = MurmurHash.update(hash, this.actionType);\n      hash = MurmurHash.update(hash, this.type);\n      this.#cachedHashCode = MurmurHash.finish(hash, 2);\n    }\n    return this.#cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _LexerTypeAction)) {\n      return false;\n    }\n    return this.type === other.type;\n  }\n  toString() {\n    return \"type(\" + this.type + \")\";\n  }\n};\n\n// src/atn/LexerPushModeAction.ts\nvar LexerPushModeAction = class _LexerPushModeAction {\n  static {\n    __name(this, \"LexerPushModeAction\");\n  }\n  mode;\n  actionType;\n  isPositionDependent = false;\n  #cachedHashCode;\n  constructor(mode) {\n    this.actionType = LexerActionType.PUSH_MODE;\n    this.mode = mode;\n  }\n  /**\n   * This action is implemented by calling {@link Lexer.pushMode} with the\n   * value provided by {@link getMode}.\n   */\n  execute(lexer) {\n    lexer.pushMode(this.mode);\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      hash = MurmurHash.update(hash, this.actionType);\n      hash = MurmurHash.update(hash, this.mode);\n      this.#cachedHashCode = MurmurHash.finish(hash, 2);\n    }\n    return this.#cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _LexerPushModeAction)) {\n      return false;\n    }\n    return this.mode === other.mode;\n  }\n  toString() {\n    return \"pushMode(\" + this.mode + \")\";\n  }\n};\n\n// src/atn/LexerPopModeAction.ts\nvar LexerPopModeAction = class _LexerPopModeAction {\n  static {\n    __name(this, \"LexerPopModeAction\");\n  }\n  static instance = new _LexerPopModeAction();\n  actionType;\n  isPositionDependent = false;\n  constructor() {\n    this.actionType = LexerActionType.POP_MODE;\n  }\n  equals(obj) {\n    return obj === this;\n  }\n  hashCode() {\n    return LexerActionType.POP_MODE;\n  }\n  /**\n   * This action is implemented by calling {@link Lexer//popMode}.\n   */\n  execute(lexer) {\n    lexer.popMode();\n  }\n  toString() {\n    return \"popMode\";\n  }\n};\n\n// src/atn/LexerModeAction.ts\nvar LexerModeAction = class _LexerModeAction {\n  static {\n    __name(this, \"LexerModeAction\");\n  }\n  mode;\n  actionType;\n  isPositionDependent = false;\n  #cachedHashCode;\n  constructor(mode) {\n    this.actionType = LexerActionType.MODE;\n    this.mode = mode;\n  }\n  /**\n   * This action is implemented by calling {@link Lexer.mode} with the\n   * value provided by {@link getMode}.\n   */\n  execute(lexer) {\n    lexer.mode = this.mode;\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      hash = MurmurHash.update(hash, this.actionType);\n      hash = MurmurHash.update(hash, this.mode);\n      this.#cachedHashCode = MurmurHash.finish(hash, 2);\n    }\n    return this.#cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _LexerModeAction)) {\n      return false;\n    }\n    return this.mode === other.mode;\n  }\n  toString() {\n    return \"mode(\" + this.mode + \")\";\n  }\n};\n\n// src/atn/ATNDeserializer.ts\nvar ATNDeserializer = class _ATNDeserializer {\n  static {\n    __name(this, \"ATNDeserializer\");\n  }\n  static SERIALIZED_VERSION = 4;\n  static stateTypeMapper = /* @__PURE__ */ new Map([\n    [ATNState.INVALID_TYPE, void 0],\n    [ATNState.BASIC, BasicState],\n    [ATNState.RULE_START, RuleStartState],\n    [ATNState.BLOCK_START, BasicBlockStartState],\n    [ATNState.PLUS_BLOCK_START, PlusBlockStartState],\n    [ATNState.STAR_BLOCK_START, StarBlockStartState],\n    [ATNState.TOKEN_START, TokensStartState],\n    [ATNState.RULE_STOP, RuleStopState],\n    [ATNState.BLOCK_END, BlockEndState],\n    [ATNState.STAR_LOOP_BACK, StarLoopbackState],\n    [ATNState.STAR_LOOP_ENTRY, StarLoopEntryState],\n    [ATNState.PLUS_LOOP_BACK, PlusLoopbackState],\n    [ATNState.LOOP_END, LoopEndState]\n  ]);\n  static lexerActionFactoryMapper = /* @__PURE__ */ new Map([\n    [LexerActionType.CHANNEL, (data1) => {\n      return new LexerChannelAction(data1);\n    }],\n    [LexerActionType.CUSTOM, (data1, data2) => {\n      return new LexerCustomAction(data1, data2);\n    }],\n    [LexerActionType.MODE, (data1) => {\n      return new LexerModeAction(data1);\n    }],\n    [LexerActionType.MORE, () => {\n      return LexerMoreAction.instance;\n    }],\n    [LexerActionType.POP_MODE, () => {\n      return LexerPopModeAction.instance;\n    }],\n    [LexerActionType.PUSH_MODE, (data1) => {\n      return new LexerPushModeAction(data1);\n    }],\n    [LexerActionType.SKIP, () => {\n      return LexerSkipAction.instance;\n    }],\n    [LexerActionType.TYPE, (data1) => {\n      return new LexerTypeAction(data1);\n    }]\n  ]);\n  data = [];\n  pos = 0;\n  deserializationOptions;\n  actionFactories;\n  constructor(options) {\n    if (!options) {\n      options = { readOnly: false, verifyATN: true, generateRuleBypassTransitions: false };\n    }\n    this.deserializationOptions = options;\n  }\n  deserialize(data) {\n    this.data = data;\n    this.checkVersion();\n    const atn = this.readATN();\n    this.readStates(atn);\n    this.readRules(atn);\n    this.readModes(atn);\n    const sets = [];\n    this.readSets(atn, sets);\n    this.readEdges(atn, sets);\n    this.readDecisions(atn);\n    this.readLexerActions(atn);\n    this.markPrecedenceDecisions(atn);\n    this.verifyATN(atn);\n    if (this.deserializationOptions.generateRuleBypassTransitions && atn.grammarType === ATN.PARSER) {\n      this.generateRuleBypassTransitions(atn);\n      this.verifyATN(atn);\n    }\n    return atn;\n  }\n  checkVersion() {\n    const version = this.data[this.pos++];\n    if (version !== _ATNDeserializer.SERIALIZED_VERSION) {\n      throw new Error(\"Could not deserialize ATN with version \" + version + \" (expected \" + _ATNDeserializer.SERIALIZED_VERSION + \").\");\n    }\n  }\n  readATN() {\n    const grammarType = this.data[this.pos++];\n    const maxTokenType = this.data[this.pos++];\n    return new ATN(grammarType, maxTokenType);\n  }\n  readStates(atn) {\n    let j;\n    let stateNumber;\n    const loopBackStateNumbers = [];\n    const endStateNumbers = [];\n    const stateCount = this.data[this.pos++];\n    for (let i = 0; i < stateCount; i++) {\n      const stateType = this.data[this.pos++];\n      if (stateType === ATNState.INVALID_TYPE) {\n        atn.addState(null);\n        continue;\n      }\n      const ruleIndex = this.data[this.pos++];\n      const s = this.stateFactory(stateType, ruleIndex);\n      if (stateType === ATNState.LOOP_END) {\n        const loopBackStateNumber = this.data[this.pos++];\n        loopBackStateNumbers.push([s, loopBackStateNumber]);\n      } else if (s instanceof BlockStartState) {\n        const endStateNumber = this.data[this.pos++];\n        endStateNumbers.push([s, endStateNumber]);\n      }\n      atn.addState(s);\n    }\n    for (j = 0; j < loopBackStateNumbers.length; j++) {\n      const pair = loopBackStateNumbers[j];\n      pair[0].loopBackState = atn.states[pair[1]] ?? void 0;\n    }\n    for (j = 0; j < endStateNumbers.length; j++) {\n      const pair = endStateNumbers[j];\n      pair[0].endState = atn.states[pair[1]];\n    }\n    const numNonGreedyStates = this.data[this.pos++];\n    for (j = 0; j < numNonGreedyStates; j++) {\n      stateNumber = this.data[this.pos++];\n      atn.states[stateNumber].nonGreedy = true;\n    }\n    const numPrecedenceStates = this.data[this.pos++];\n    for (j = 0; j < numPrecedenceStates; j++) {\n      stateNumber = this.data[this.pos++];\n      atn.states[stateNumber].isPrecedenceRule = true;\n    }\n  }\n  readRules(atn) {\n    let i;\n    const ruleCount = this.data[this.pos++];\n    if (atn.grammarType === ATN.LEXER) {\n      atn.ruleToTokenType = new Array(ruleCount);\n      atn.ruleToTokenType.fill(0);\n    }\n    atn.ruleToStartState = new Array(ruleCount);\n    atn.ruleToStartState.fill(null);\n    for (i = 0; i < ruleCount; i++) {\n      const s = this.data[this.pos++];\n      atn.ruleToStartState[i] = atn.states[s];\n      if (atn.grammarType === ATN.LEXER) {\n        const tokenType = this.data[this.pos++];\n        atn.ruleToTokenType[i] = tokenType;\n      }\n    }\n    atn.ruleToStopState = new Array(ruleCount);\n    atn.ruleToStopState.fill(null);\n    for (i = 0; i < atn.states.length; i++) {\n      const state = atn.states[i];\n      if (!(state instanceof RuleStopState)) {\n        continue;\n      }\n      atn.ruleToStopState[state.ruleIndex] = state;\n      atn.ruleToStartState[state.ruleIndex].stopState = state;\n    }\n  }\n  readModes(atn) {\n    const modeCount = this.data[this.pos++];\n    for (let i = 0; i < modeCount; i++) {\n      const s = this.data[this.pos++];\n      atn.modeToStartState.push(atn.states[s]);\n    }\n  }\n  readSets(atn, sets) {\n    const m2 = this.data[this.pos++];\n    for (let i = 0; i < m2; i++) {\n      const intervalSet = new IntervalSet();\n      sets.push(intervalSet);\n      const n2 = this.data[this.pos++];\n      const containsEof = this.data[this.pos++];\n      if (containsEof !== 0) {\n        intervalSet.addOne(-1);\n      }\n      for (let j = 0; j < n2; j++) {\n        const i1 = this.data[this.pos++];\n        const i2 = this.data[this.pos++];\n        intervalSet.addRange(i1, i2);\n      }\n    }\n  }\n  readEdges(atn, sets) {\n    let i;\n    let j;\n    let state;\n    let trans;\n    let target;\n    const edgeCount = this.data[this.pos++];\n    for (i = 0; i < edgeCount; i++) {\n      const src = this.data[this.pos++];\n      const trg = this.data[this.pos++];\n      const ttype = this.data[this.pos++];\n      const arg1 = this.data[this.pos++];\n      const arg2 = this.data[this.pos++];\n      const arg3 = this.data[this.pos++];\n      trans = this.edgeFactory(atn, ttype, trg, arg1, arg2, arg3, sets);\n      const srcState = atn.states[src];\n      srcState.addTransition(trans);\n    }\n    for (i = 0; i < atn.states.length; i++) {\n      state = atn.states[i];\n      for (j = 0; j < state.transitions.length; j++) {\n        const t = state.transitions[j];\n        if (!(t instanceof RuleTransition)) {\n          continue;\n        }\n        let outermostPrecedenceReturn = -1;\n        if (atn.ruleToStartState[t.target.ruleIndex].isPrecedenceRule) {\n          if (t.precedence === 0) {\n            outermostPrecedenceReturn = t.target.ruleIndex;\n          }\n        }\n        trans = new EpsilonTransition(t.followState, outermostPrecedenceReturn);\n        atn.ruleToStopState[t.target.ruleIndex].addTransition(trans);\n      }\n    }\n    for (i = 0; i < atn.states.length; i++) {\n      state = atn.states[i];\n      if (state instanceof BlockStartState) {\n        if (!state.endState) {\n          throw new Error(\"IllegalState\");\n        }\n        if (state.endState.startState) {\n          throw new Error(\"IllegalState\");\n        }\n        state.endState.startState = state;\n      }\n      if (state instanceof PlusLoopbackState) {\n        for (j = 0; j < state.transitions.length; j++) {\n          target = state.transitions[j].target;\n          if (target instanceof PlusBlockStartState) {\n            target.loopBackState = state;\n          }\n        }\n      } else if (state instanceof StarLoopbackState) {\n        for (j = 0; j < state.transitions.length; j++) {\n          target = state.transitions[j].target;\n          if (target instanceof StarLoopEntryState) {\n            target.loopBackState = state;\n          }\n        }\n      }\n    }\n  }\n  readDecisions(atn) {\n    const decisionCount = this.data[this.pos++];\n    for (let i = 0; i < decisionCount; i++) {\n      const s = this.data[this.pos++];\n      const decState = atn.states[s];\n      atn.decisionToState.push(decState);\n      decState.decision = i;\n    }\n  }\n  readLexerActions(atn) {\n    if (atn.grammarType === ATN.LEXER) {\n      const count = this.data[this.pos++];\n      atn.lexerActions = [];\n      for (let i = 0; i < count; i++) {\n        const actionType = this.data[this.pos++];\n        const data1 = this.data[this.pos++];\n        const data2 = this.data[this.pos++];\n        atn.lexerActions.push(this.lexerActionFactory(actionType, data1, data2));\n      }\n    }\n  }\n  generateRuleBypassTransitions(atn) {\n    let i;\n    const count = atn.ruleToStartState.length;\n    for (i = 0; i < count; i++) {\n      atn.ruleToTokenType[i] = atn.maxTokenType + i + 1;\n    }\n    for (i = 0; i < count; i++) {\n      this.generateRuleBypassTransition(atn, i);\n    }\n  }\n  generateRuleBypassTransition(atn, idx) {\n    let i;\n    let state;\n    const bypassStart = new BasicBlockStartState();\n    bypassStart.ruleIndex = idx;\n    atn.addState(bypassStart);\n    const bypassStop = new BlockEndState();\n    bypassStop.ruleIndex = idx;\n    atn.addState(bypassStop);\n    bypassStart.endState = bypassStop;\n    atn.defineDecisionState(bypassStart);\n    bypassStop.startState = bypassStart;\n    let excludeTransition = null;\n    let endState = null;\n    if (atn.ruleToStartState[idx].isPrecedenceRule) {\n      endState = null;\n      for (i = 0; i < atn.states.length; i++) {\n        state = atn.states[i];\n        if (this.stateIsEndStateFor(state, idx)) {\n          endState = state;\n          excludeTransition = state.loopBackState.transitions[0];\n          break;\n        }\n      }\n      if (excludeTransition === null) {\n        throw new Error(\"Couldn't identify final state of the precedence rule prefix section.\");\n      }\n    } else {\n      endState = atn.ruleToStopState[idx];\n    }\n    for (i = 0; i < atn.states.length; i++) {\n      state = atn.states[i];\n      for (const transition of state.transitions) {\n        if (transition === excludeTransition) {\n          continue;\n        }\n        if (transition.target === endState) {\n          transition.target = bypassStop;\n        }\n      }\n    }\n    const ruleToStartState = atn.ruleToStartState[idx];\n    const count = ruleToStartState.transitions.length;\n    while (count > 0) {\n      bypassStart.addTransition(ruleToStartState.transitions[count - 1]);\n      ruleToStartState.transitions = ruleToStartState.transitions.slice(-1);\n    }\n    atn.ruleToStartState[idx].addTransition(new EpsilonTransition(bypassStart));\n    if (endState) {\n      bypassStop.addTransition(new EpsilonTransition(endState));\n    }\n    const matchState = new BasicState();\n    atn.addState(matchState);\n    matchState.addTransition(new AtomTransition(bypassStop, atn.ruleToTokenType[idx]));\n    bypassStart.addTransition(new EpsilonTransition(matchState));\n  }\n  stateIsEndStateFor(state, idx) {\n    if (state.ruleIndex !== idx) {\n      return null;\n    }\n    if (!(state instanceof StarLoopEntryState)) {\n      return null;\n    }\n    const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n    if (!(maybeLoopEndState instanceof LoopEndState)) {\n      return null;\n    }\n    if (maybeLoopEndState.epsilonOnlyTransitions && maybeLoopEndState.transitions[0].target instanceof RuleStopState) {\n      return state;\n    } else {\n      return null;\n    }\n  }\n  /**\n   * Analyze the {@link StarLoopEntryState} states in the specified ATN to set\n   * the {@link StarLoopEntryState} field to the correct value.\n   *\n   * @param atn The ATN.\n   */\n  markPrecedenceDecisions(atn) {\n    for (const state of atn.states) {\n      if (!(state instanceof StarLoopEntryState)) {\n        continue;\n      }\n      if (atn.ruleToStartState[state.ruleIndex].isPrecedenceRule) {\n        const maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n        if (maybeLoopEndState instanceof LoopEndState) {\n          if (maybeLoopEndState.epsilonOnlyTransitions && maybeLoopEndState.transitions[0].target instanceof RuleStopState) {\n            state.precedenceRuleDecision = true;\n          }\n        }\n      }\n    }\n  }\n  verifyATN(atn) {\n    if (!this.deserializationOptions.verifyATN) {\n      return;\n    }\n    for (const state of atn.states) {\n      if (state === null) {\n        continue;\n      }\n      this.checkCondition(state.epsilonOnlyTransitions || state.transitions.length <= 1);\n      if (state instanceof PlusBlockStartState) {\n        this.checkCondition(state.loopBackState !== null);\n      } else if (state instanceof StarLoopEntryState) {\n        this.checkCondition(state.loopBackState !== null);\n        this.checkCondition(state.transitions.length === 2);\n        if (state.transitions[0].target instanceof StarBlockStartState) {\n          this.checkCondition(state.transitions[1].target instanceof LoopEndState);\n          this.checkCondition(!state.nonGreedy);\n        } else if (state.transitions[0].target instanceof LoopEndState) {\n          this.checkCondition(state.transitions[1].target instanceof StarBlockStartState);\n          this.checkCondition(state.nonGreedy);\n        } else {\n          throw new Error(\"IllegalState\");\n        }\n      } else if (state instanceof StarLoopbackState) {\n        this.checkCondition(state.transitions.length === 1);\n        this.checkCondition(state.transitions[0].target instanceof StarLoopEntryState);\n      } else if (state instanceof LoopEndState) {\n        this.checkCondition(state.loopBackState !== null);\n      } else if (state instanceof RuleStartState) {\n        this.checkCondition(state.stopState !== null);\n      } else if (state instanceof BlockStartState) {\n        this.checkCondition(state.endState !== null);\n      } else if (state instanceof BlockEndState) {\n        this.checkCondition(state.startState !== null);\n      } else if (state instanceof DecisionState) {\n        this.checkCondition(state.transitions.length <= 1 || state.decision >= 0);\n      } else {\n        this.checkCondition(state.transitions.length <= 1 || state instanceof RuleStopState);\n      }\n    }\n  }\n  checkCondition(condition, message) {\n    if (!condition) {\n      if (message === void 0 || message === null) {\n        message = \"IllegalState\";\n      }\n      throw message;\n    }\n  }\n  edgeFactory(atn, type, trg, arg1, arg2, arg3, sets) {\n    const target = atn.states[trg];\n    switch (type) {\n      case Transition.EPSILON:\n        return new EpsilonTransition(target);\n      case Transition.RANGE:\n        return arg3 !== 0 ? new RangeTransition(target, Token.EOF, arg2) : new RangeTransition(target, arg1, arg2);\n      case Transition.RULE:\n        return new RuleTransition(atn.states[arg1], arg2, arg3, target);\n      case Transition.PREDICATE:\n        return new PredicateTransition(target, arg1, arg2, arg3 !== 0);\n      case Transition.PRECEDENCE:\n        return new PrecedencePredicateTransition(target, arg1);\n      case Transition.ATOM:\n        return arg3 !== 0 ? new AtomTransition(target, Token.EOF) : new AtomTransition(target, arg1);\n      case Transition.ACTION:\n        return new ActionTransition(target, arg1, arg2, arg3 !== 0);\n      case Transition.SET:\n        return new SetTransition(target, sets[arg1]);\n      case Transition.NOT_SET:\n        return new NotSetTransition(target, sets[arg1]);\n      case Transition.WILDCARD:\n        return new WildcardTransition(target);\n      default:\n        throw new Error(\"The specified transition type: \" + type + \" is not valid.\");\n    }\n  }\n  stateFactory(type, ruleIndex) {\n    const ctor = _ATNDeserializer.stateTypeMapper.get(type);\n    if (!ctor) {\n      throw new Error(\"The specified state type \" + type + \" is not valid.\");\n    }\n    const s = new ctor();\n    s.ruleIndex = ruleIndex;\n    return s;\n  }\n  lexerActionFactory(type, data1, data2) {\n    const factory = _ATNDeserializer.lexerActionFactoryMapper.get(type);\n    if (!factory) {\n      throw new Error(\"The specified lexer action type \" + type + \" is not valid.\");\n    }\n    return factory(data1, data2);\n  }\n};\n\n// src/misc/OrderedHashMap.ts\nvar OrderedHashMap = class _OrderedHashMap extends HashMap {\n  static {\n    __name(this, \"OrderedHashMap\");\n  }\n  #keys = [];\n  clear() {\n    super.clear();\n    this.#keys = [];\n  }\n  get(key) {\n    return super.get(key);\n  }\n  set(key, value) {\n    const result = super.set(key, value);\n    if (result === void 0) {\n      this.#keys.push(key);\n    }\n    return result;\n  }\n  setIfAbsent(key, value) {\n    const result = super.setIfAbsent(key, value);\n    if (result === void 0) {\n      this.#keys.push(key);\n    }\n    return result;\n  }\n  /**\n   * @returns an iterable of the values in the map, in the order they were inserted.\n   */\n  values() {\n    return {\n      [Symbol.iterator]: () => {\n        let index = 0;\n        return {\n          next: () => {\n            if (index < this.#keys.length) {\n              return {\n                done: false,\n                value: super.get(this.#keys[index++])\n              };\n            }\n            return {\n              done: true,\n              value: void 0\n            };\n          }\n        };\n      }\n    };\n  }\n  /**\n   * @returns an iterable of the keys in the map, in the order they were inserted.\n   */\n  keys() {\n    return this.#keys[Symbol.iterator]();\n  }\n  equals(o) {\n    if (!(o instanceof _OrderedHashMap)) {\n      return false;\n    }\n    return super.equals(o);\n  }\n};\n\n// src/atn/ATNSerializer.ts\nvar ATNSerializer = class _ATNSerializer {\n  static {\n    __name(this, \"ATNSerializer\");\n  }\n  atn;\n  data = [];\n  // Note that we use a LinkedHashMap as a set to maintain insertion order while deduplicating entries with the\n  // same key.\n  sets = new OrderedHashMap(ObjectEqualityComparator.instance);\n  nonGreedyStates = [];\n  precedenceStates = [];\n  constructor(atn) {\n    this.atn = atn;\n  }\n  static getSerialized(atn) {\n    return new _ATNSerializer(atn).serialize();\n  }\n  static serializeSets(data, sets) {\n    data.push(sets.length);\n    for (const set of sets) {\n      const containsEof = set.contains(Token.EOF);\n      if (containsEof && set.get(0).stop === Token.EOF) {\n        data.push(set.length - 1);\n      } else {\n        data.push(set.length);\n      }\n      data.push(containsEof ? 1 : 0);\n      for (const interval of set) {\n        if (interval.start === Token.EOF) {\n          if (interval.stop === Token.EOF) {\n            continue;\n          } else {\n            data.push(0);\n          }\n        } else {\n          data.push(interval.start);\n        }\n        data.push(interval.stop);\n      }\n    }\n  }\n  /**\n   * Serialize state descriptors, edge descriptors, and decision -> state map\n   *  into list of ints.  Likely out of date, but keeping as it could be helpful:\n   *\n   *      SERIALIZED_VERSION\n   *      UUID (2 longs)\n   * \t\tgrammar-type, (ANTLRParser.LEXER, ...)\n   *  \tmax token type,\n   *  \tnum states,\n   *  \tstate-0-type ruleIndex, state-1-type ruleIndex, ... state-i-type ruleIndex optional-arg ...\n   *  \tnum rules,\n   *  \trule-1-start-state rule-1-args, rule-2-start-state  rule-2-args, ...\n   *  \t(args are token type,actionIndex in lexer else 0,0)\n   *      num modes,\n   *      mode-0-start-state, mode-1-start-state, ... (parser has 0 modes)\n   *      num unicode-bmp-sets\n   *      bmp-set-0-interval-count intervals, bmp-set-1-interval-count intervals, ...\n   *      num unicode-smp-sets\n   *      smp-set-0-interval-count intervals, smp-set-1-interval-count intervals, ...\n   *\tnum total edges,\n   *      src, trg, edge-type, edge arg1, optional edge arg2 (present always), ...\n   *      num decisions,\n   *      decision-0-start-state, decision-1-start-state, ...\n   *\n   *  Convenient to pack into unsigned shorts to make as Java string.\n   */\n  serialize() {\n    this.addPreamble();\n    const edgeCount = this.addEdges();\n    this.addNonGreedyStates();\n    this.addPrecedenceStates();\n    this.addRuleStatesAndLexerTokenTypes();\n    this.addModeStartStates();\n    let setIndices = null;\n    setIndices = this.addSets();\n    this.addEdges(edgeCount, setIndices);\n    this.addDecisionStartStates();\n    this.addLexerActions();\n    return this.data;\n  }\n  addPreamble() {\n    this.data.push(ATNDeserializer.SERIALIZED_VERSION);\n    this.data.push(this.atn.grammarType);\n    this.data.push(this.atn.maxTokenType);\n  }\n  addLexerActions() {\n    if (this.atn.grammarType === ATN.LEXER) {\n      this.data.push(this.atn.lexerActions.length);\n      for (const action of this.atn.lexerActions) {\n        this.data.push(action.actionType);\n        switch (action.actionType) {\n          case LexerActionType.CHANNEL: {\n            const channel = action.channel;\n            this.data.push(channel);\n            this.data.push(0);\n            break;\n          }\n          case LexerActionType.CUSTOM: {\n            const ruleIndex = action.ruleIndex;\n            const actionIndex = action.actionIndex;\n            this.data.push(ruleIndex);\n            this.data.push(actionIndex);\n            break;\n          }\n          case LexerActionType.MODE: {\n            const mode = action.mode;\n            this.data.push(mode);\n            this.data.push(0);\n            break;\n          }\n          case LexerActionType.MORE: {\n            this.data.push(0);\n            this.data.push(0);\n            break;\n          }\n          case LexerActionType.POP_MODE: {\n            this.data.push(0);\n            this.data.push(0);\n            break;\n          }\n          case LexerActionType.PUSH_MODE: {\n            const mode = action.mode;\n            this.data.push(mode);\n            this.data.push(0);\n            break;\n          }\n          case LexerActionType.SKIP: {\n            this.data.push(0);\n            this.data.push(0);\n            break;\n          }\n          case LexerActionType.TYPE: {\n            const type = action.type;\n            this.data.push(type);\n            this.data.push(0);\n            break;\n          }\n          default: {\n            throw new Error(`The specified lexer action type ${action.actionType} is not valid.`);\n          }\n        }\n      }\n    }\n  }\n  addDecisionStartStates() {\n    this.data.push(this.atn.decisionToState.length);\n    for (const decStartState of this.atn.decisionToState) {\n      this.data.push(decStartState.stateNumber);\n    }\n  }\n  addEdges(...args) {\n    switch (args.length) {\n      case 0: {\n        let edgeCount = 0;\n        this.data.push(this.atn.states.length);\n        for (const s of this.atn.states) {\n          if (s === null) {\n            this.data.push(ATNState.INVALID_TYPE);\n            continue;\n          }\n          const stateType = s.constructor.stateType;\n          if (s instanceof DecisionState && s.nonGreedy) {\n            this.nonGreedyStates.push(s.stateNumber);\n          }\n          if (s instanceof RuleStartState && s.isLeftRecursiveRule) {\n            this.precedenceStates.push(s.stateNumber);\n          }\n          this.data.push(stateType);\n          this.data.push(s.ruleIndex);\n          if (s.constructor.stateType === ATNState.LOOP_END) {\n            this.data.push(s.loopBackState.stateNumber);\n          } else {\n            if (s instanceof BlockStartState) {\n              this.data.push(s.endState.stateNumber);\n            }\n          }\n          if (s.constructor.stateType !== ATNState.RULE_STOP) {\n            edgeCount += s.transitions.length;\n          }\n          for (const t of s.transitions) {\n            const edgeType = t.transitionType;\n            if (edgeType === Transition.SET || edgeType === Transition.NOT_SET) {\n              const st = t;\n              this.sets.set(st.set, true);\n            }\n          }\n        }\n        return edgeCount;\n      }\n      case 2: {\n        const [edgeCount, setIndices] = args;\n        this.data.push(edgeCount);\n        for (const s of this.atn.states) {\n          if (s === null) {\n            continue;\n          }\n          if (s.constructor.stateType === ATNState.RULE_STOP) {\n            continue;\n          }\n          for (const t of s.transitions) {\n            if (this.atn.states[t.target.stateNumber] === null) {\n              throw new Error(\"Cannot serialize a transition to a removed state.\");\n            }\n            const src = s.stateNumber;\n            let trg = t.target.stateNumber;\n            const edgeType = t.transitionType;\n            let arg1 = 0;\n            let arg2 = 0;\n            let arg3 = 0;\n            switch (edgeType) {\n              case Transition.RULE: {\n                trg = t.followState.stateNumber;\n                arg1 = t.target.stateNumber;\n                arg2 = t.ruleIndex;\n                arg3 = t.precedence;\n                break;\n              }\n              case Transition.PRECEDENCE: {\n                const ppt = t;\n                arg1 = ppt.precedence;\n                break;\n              }\n              case Transition.PREDICATE: {\n                const pt = t;\n                arg1 = pt.ruleIndex;\n                arg2 = pt.predIndex;\n                arg3 = pt.isCtxDependent ? 1 : 0;\n                break;\n              }\n              case Transition.RANGE: {\n                arg1 = t.start;\n                arg2 = t.stop;\n                if (arg1 === Token.EOF) {\n                  arg1 = 0;\n                  arg3 = 1;\n                }\n                break;\n              }\n              case Transition.ATOM: {\n                arg1 = t.labelValue;\n                if (arg1 === Token.EOF) {\n                  arg1 = 0;\n                  arg3 = 1;\n                }\n                break;\n              }\n              case Transition.ACTION: {\n                const at = t;\n                arg1 = at.ruleIndex;\n                arg2 = at.actionIndex;\n                arg3 = at.isCtxDependent ? 1 : 0;\n                break;\n              }\n              case Transition.SET: {\n                arg1 = setIndices.get(t.set);\n                break;\n              }\n              case Transition.NOT_SET: {\n                arg1 = setIndices.get(t.set);\n                break;\n              }\n              case Transition.WILDCARD: {\n                break;\n              }\n              default:\n            }\n            this.data.push(src);\n            this.data.push(trg);\n            this.data.push(edgeType);\n            this.data.push(arg1);\n            this.data.push(arg2);\n            this.data.push(arg3);\n          }\n        }\n        break;\n      }\n      default: {\n        throw new Error(\"Invalid number of arguments\");\n      }\n    }\n  }\n  addSets() {\n    _ATNSerializer.serializeSets(this.data, [...this.sets.keys()]);\n    const setIndices = /* @__PURE__ */ new Map();\n    let setIndex = 0;\n    for (const s of this.sets.keys()) {\n      setIndices.set(s, setIndex++);\n    }\n    return setIndices;\n  }\n  addModeStartStates() {\n    const modeCount = this.atn.modeToStartState.length;\n    this.data.push(modeCount);\n    if (modeCount > 0) {\n      for (const modeStartState of this.atn.modeToStartState) {\n        this.data.push(modeStartState.stateNumber);\n      }\n    }\n  }\n  addRuleStatesAndLexerTokenTypes() {\n    const ruleCount = this.atn.ruleToStartState.length;\n    this.data.push(ruleCount);\n    for (let r = 0; r < ruleCount; r++) {\n      const ruleStartState = this.atn.ruleToStartState[r];\n      this.data.push(ruleStartState.stateNumber);\n      if (this.atn.grammarType === ATN.LEXER) {\n        this.data.push(this.atn.ruleToTokenType[r]);\n      }\n    }\n  }\n  addPrecedenceStates() {\n    this.data.push(this.precedenceStates.length);\n    for (const state of this.precedenceStates) {\n      this.data.push(state);\n    }\n  }\n  addNonGreedyStates() {\n    this.data.push(this.nonGreedyStates.length);\n    for (const state of this.nonGreedyStates) {\n      this.data.push(state);\n    }\n  }\n};\n\n// src/dfa/DFAState.ts\nvar DFAState = class _DFAState {\n  static {\n    __name(this, \"DFAState\");\n  }\n  stateNumber = -1;\n  configs;\n  /**\n   * `edges[symbol]` points to target of symbol. Shift up by 1 so (-1) {@link Token.EOF} maps to `edges[0]`.\n   */\n  edges = [];\n  isAcceptState = false;\n  /**\n   * If accept state, what ttype do we match or alt do we predict? This is set to {@link ATN.INVALID_ALT_NUMBER}\n   * when {@link predicates} `!= null` or {@link requiresFullContext}.\n   */\n  prediction = -1;\n  lexerActionExecutor = null;\n  /**\n   * Indicates that this state was created during SLL prediction that discovered a conflict between the configurations\n   * in the state. Future {@link ParserATNSimulator.execATN} invocations immediately jumped doing\n   * full context prediction if this field is true.\n   */\n  requiresFullContext = false;\n  /**\n   * During SLL parsing, this is a list of predicates associated with the ATN configurations of the DFA state.\n   * When we have predicates, {@link requiresFullContext} is `false` since full context prediction evaluates\n   * predicates on-the-fly. If this is not null, then {@link prediction} is `ATN.INVALID_ALT_NUMBER`.\n   *\n   * We only use these for non-{@link #requiresFullContext} but conflicting states. That\n   * means we know from the context (it's $ or we don't dip into outer\n   * context) that it's an ambiguity not a conflict.\n   *\n   * This list is computed by {@link ParserATNSimulator#predicateDFAState}.\n   */\n  predicates = null;\n  constructor(configs) {\n    if (configs) {\n      this.configs = configs;\n    }\n  }\n  static fromState(stateNumber) {\n    const result = new _DFAState();\n    result.stateNumber = stateNumber;\n    return result;\n  }\n  static fromConfigs(configs) {\n    return new _DFAState(configs);\n  }\n  static hashCode(state) {\n    return state.configs.hashCode();\n  }\n  /**\n   * Two {@link DFAState} instances are equal if their ATN configuration sets\n   * are the same. This method is used to see if a state already exists.\n   *\n   * Because the number of alternatives and number of ATN configurations are\n   * finite, there is a finite number of DFA states that can be processed.\n   * This is necessary to show that the algorithm terminates.\n   *\n   * Cannot test the DFA state numbers here because in\n   * {@link ParserATNSimulator#addDFAState} we need to know if any other state\n   * exists that has this exact set of ATN configurations. The\n   * {@link #stateNumber} is irrelevant.\n   *\n   * @param a The first {@link DFAState}.\n   * @param b The second {@link DFAState}.\n   *\n   * @returns `true` if the two states are equal, otherwise `false`.\n   */\n  static equals(a, b) {\n    return a.configs.equals(b.configs);\n  }\n  toString() {\n    let buf = \"\";\n    buf += this.stateNumber;\n    buf += \":\";\n    buf += this.configs ? this.configs.toString() : \"\";\n    if (this.isAcceptState) {\n      buf += \"=>\";\n      if (this.predicates) {\n        buf += arrayToString(this.predicates);\n      } else {\n        buf += this.prediction;\n      }\n    }\n    return buf.toString();\n  }\n};\n\n// src/atn/ATNSimulator.ts\nvar ATNSimulator = class {\n  static {\n    __name(this, \"ATNSimulator\");\n  }\n  /** Must distinguish between missing edge and edge we know leads nowhere */\n  static ERROR = DFAState.fromState(2147483647);\n  atn;\n  /**\n   * The context cache maps all PredictionContext objects that are ==\n   * to a single cached copy. This cache is shared across all contexts\n   * in all ATNConfigs in all DFA states.  We rebuild each ATNConfigSet\n   * to use only cached nodes/graphs in addDFAState(). We don't want to\n   * fill this during closure() since there are lots of contexts that\n   * pop up but are not used ever again. It also greatly slows down closure().\n   *\n   * This cache makes a huge difference in memory and a little bit in speed.\n   * For the Java grammar on java.*, it dropped the memory requirements\n   * at the end from 25M to 16M. We don't store any of the full context\n   * graphs in the DFA because they are limited to local context only,\n   * but apparently there's a lot of repetition there as well. We optimize\n   * the config contexts before storing the config set in the DFA states\n   * by literally rebuilding them with cached subgraphs only.\n   *\n   * I tried a cache for use during closure operations, that was\n   * whacked after each adaptivePredict(). It cost a little bit\n   * more time I think and doesn't save on the overall footprint\n   * so it's not worth the complexity.\n   */\n  sharedContextCache;\n  constructor(atn, sharedContextCache) {\n    this.atn = atn;\n    this.sharedContextCache = sharedContextCache;\n    return this;\n  }\n  getCachedContext(context) {\n    if (!this.sharedContextCache) {\n      return context;\n    }\n    const visited = new HashMap(ObjectEqualityComparator.instance);\n    return getCachedPredictionContext(context, this.sharedContextCache, visited);\n  }\n};\n\n// src/atn/CodePointTransitions.ts\nvar CodePointTransitions = class _CodePointTransitions {\n  static {\n    __name(this, \"CodePointTransitions\");\n  }\n  /** @returns new {@link AtomTransition}     */\n  static createWithCodePoint(target, codePoint) {\n    return _CodePointTransitions.createWithCodePointRange(target, codePoint, codePoint);\n  }\n  /** @returns new {@link AtomTransition} if range represents one atom else {@link SetTransition}. */\n  static createWithCodePointRange(target, codePointFrom, codePointTo) {\n    return codePointFrom === codePointTo ? new AtomTransition(target, codePointFrom) : new RangeTransition(target, codePointFrom, codePointTo);\n  }\n};\n\n// src/atn/DecisionInfo.ts\nvar DecisionInfo = class {\n  static {\n    __name(this, \"DecisionInfo\");\n  }\n  /**\n   * The decision number, which is an index into {@link ATN.decisionToState}.\n   */\n  decision = 0;\n  /**\n   * The total number of times {@link ParserATNSimulator.adaptivePredict} was\n   * invoked for this decision.\n   */\n  invocations = 0;\n  /**\n   * The total time spent in {@link ParserATNSimulator.adaptivePredict} for\n   * this decision, in nanoseconds.\n   *\n   * The value of this field contains the sum of differential results obtained\n   * by {@link process.hrtime()}, and is not adjusted to compensate for JIT\n   * and/or garbage collection overhead. For best accuracy, use a modern Node.js\n   * version that provides precise results from {@link process.hrtime()}, and\n   * perform profiling in a separate process which is warmed up by parsing the\n   * input prior to profiling.\n   */\n  timeInPrediction = 0;\n  /**\n   * The sum of the lookahead required for SLL prediction for this decision.\n   * Note that SLL prediction is used before LL prediction for performance\n   * reasons even when {@link PredictionMode.LL} or\n   * {@link PredictionMode.LL_EXACT_AMBIG_DETECTION} is used.\n   */\n  sllTotalLook = 0;\n  /**\n   * Gets the minimum lookahead required for any single SLL prediction to\n   * complete for this decision, by reaching a unique prediction, reaching an\n   * SLL conflict state, or encountering a syntax error.\n   */\n  sllMinLook = 0;\n  /**\n   * Gets the maximum lookahead required for any single SLL prediction to\n   * complete for this decision, by reaching a unique prediction, reaching an\n   * SLL conflict state, or encountering a syntax error.\n   */\n  sllMaxLook = 0;\n  /**\n   * Gets the {@link LookaheadEventInfo} associated with the event where the\n   * {@link sllMaxLook} value was set.\n   */\n  sllMaxLookEvent;\n  /**\n   * The sum of the lookahead required for LL prediction for this decision.\n   * Note that LL prediction is only used when SLL prediction reaches a\n   * conflict state.\n   */\n  llTotalLook = 0;\n  /**\n   * Gets the minimum lookahead required for any single LL prediction to\n   * complete for this decision. An LL prediction completes when the algorithm\n   * reaches a unique prediction, a conflict state (for\n   * {@link PredictionMode.LL}, an ambiguity state (for\n   * {@link PredictionMode.LL_EXACT_AMBIG_DETECTION}, or a syntax error.\n   */\n  llMinLook = 0;\n  /**\n   * Gets the maximum lookahead required for any single LL prediction to\n   * complete for this decision. An LL prediction completes when the algorithm\n   * reaches a unique prediction, a conflict state (for\n   * {@link PredictionMode.LL}, an ambiguity state (for\n   * {@link PredictionMode.LL_EXACT_AMBIG_DETECTION}, or a syntax error.\n   */\n  llMaxLook = 0;\n  /**\n   * Gets the {@link LookaheadEventInfo} associated with the event where the\n   * {@link llMaxLook} value was set.\n   */\n  llMaxLookEvent;\n  /**\n   * A collection of {@link ContextSensitivityInfo} instances describing the\n   * context sensitivities encountered during LL prediction for this decision.\n   */\n  contextSensitivities;\n  /**\n   * A collection of {@link DecisionEventInfo} instances describing the parse errors\n   * identified during calls to {@link ParserATNSimulator.adaptivePredict} for\n   * this decision.\n   */\n  errors;\n  /**\n   * A collection of {@link AmbiguityInfo} instances describing the\n   * ambiguities encountered during LL prediction for this decision.\n   */\n  ambiguities;\n  /**\n   * A collection of {@link PredicateEvalInfo} instances describing the\n   * results of evaluating individual predicates during prediction for this\n   * decision.\n   */\n  predicateEvals;\n  /**\n   * The total number of ATN transitions required during SLL prediction for\n   * this decision. An ATN transition is determined by the number of times the\n   * DFA does not contain an edge that is required for prediction, resulting\n   * in on-the-fly computation of that edge.\n  /**\n   * If DFA caching of SLL transitions is employed by the implementation, ATN\n   * computation may cache the computed edge for efficient lookup during\n   * future parsing of this decision. Otherwise, the SLL parsing algorithm\n   * will use ATN transitions exclusively.\n   *\n   * @see sllDFATransitions\n   * @see ParserATNSimulator.computeTargetState\n   * @see LexerATNSimulator.computeTargetState\n   */\n  sllATNTransitions = 0;\n  /**\n   * The total number of DFA transitions required during SLL prediction for\n   * this decision.\n   *\n   * If the ATN simulator implementation does not use DFA caching for SLL\n   * transitions, this value will be 0.\n   *\n   * @see ParserATNSimulator.getExistingTargetState\n   * @see LexerATNSimulator.getExistingTargetState\n   */\n  sllDFATransitions = 0;\n  /**\n   * Gets the total number of times SLL prediction completed in a conflict\n   * state, resulting in fallback to LL prediction.\n   *\n   * Note that this value is not related to whether or not\n   * {@link PredictionMode.SLL} may be used successfully with a particular\n   * grammar. If the ambiguity resolution algorithm applied to the SLL\n   * conflicts for this decision produce the same result as LL prediction for\n   * this decision, {@link PredictionMode.SLL} would produce the same overall\n   * parsing result as {@link PredictionMode.LL}.\n   */\n  llFallback = 0;\n  /**\n   * The total number of ATN transitions required during LL prediction for\n   * this decision. An ATN transition is determined by the number of times the\n   * DFA does not contain an edge that is required for prediction, resulting\n   * in on-the-fly computation of that edge.\n   *\n   * If DFA caching of LL transitions is employed by the implementation, ATN\n   * computation may cache the computed edge for efficient lookup during\n   * future parsing of this decision. Otherwise, the LL parsing algorithm will\n   * use ATN transitions exclusively.\n   *\n   * @see llDFATransitions\n   * @see ParserATNSimulator.computeTargetState\n   * @see LexerATNSimulator.computeTargetState\n   */\n  llATNTransitions = 0;\n  /**\n   * The total number of DFA transitions required during LL prediction for\n   * this decision.\n   *\n   * If the ATN simulator implementation does not use DFA caching for LL\n   * transitions, this value will be 0.\n   *\n   * @see ParserATNSimulator.getExistingTargetState\n   * @see LexerATNSimulator.getExistingTargetState\n   */\n  llDFATransitions = 0;\n  /**\n   * Constructs a new instance of the {@link DecisionInfo} class to contain\n   * statistics for a particular decision.\n   *\n   * @param decision The decision number\n   */\n  constructor(decision) {\n    this.decision = decision;\n    this.contextSensitivities = [];\n    this.errors = [];\n    this.ambiguities = [];\n    this.predicateEvals = [];\n  }\n  toString1() {\n    return \"{decision=\" + this.decision + \", contextSensitivities=\" + this.contextSensitivities.length + \", errors=\" + this.errors.length + \", ambiguities=\" + this.ambiguities.length + \", sllLookahead=\" + this.sllTotalLook + \", sllATNTransitions=\" + this.sllATNTransitions + \", sllDFATransitions=\" + this.sllDFATransitions + \", llFallback=\" + this.llFallback + \", llLookahead=\" + this.llTotalLook + \", llATNTransitions=\" + this.llATNTransitions + \"}\";\n  }\n};\n\n// src/atn/LexerATNConfig.ts\nvar LexerATNConfig = class _LexerATNConfig extends ATNConfig {\n  static {\n    __name(this, \"LexerATNConfig\");\n  }\n  /**\n   * This is the backing field for {@link #getLexerActionExecutor}.\n   */\n  lexerActionExecutor;\n  passedThroughNonGreedyDecision;\n  constructor(config, state, context, lexerActionExecutor) {\n    super(config, state, context ?? config.context, context ? SemanticContext.NONE : config.semanticContext);\n    this.lexerActionExecutor = context ? lexerActionExecutor : config.lexerActionExecutor ?? null;\n    this.passedThroughNonGreedyDecision = _LexerATNConfig.checkNonGreedyDecision(config, this.state);\n    return this;\n  }\n  static createWithExecutor(config, state, lexerActionExecutor) {\n    return new _LexerATNConfig(config, state, config.context, lexerActionExecutor);\n  }\n  static createWithConfig(state, config, context) {\n    return new _LexerATNConfig(config, state, context ?? null, config.lexerActionExecutor);\n  }\n  static createWithContext(state, alt, context) {\n    return new _LexerATNConfig({ alt }, state, context, null);\n  }\n  static checkNonGreedyDecision(source, target) {\n    return source.passedThroughNonGreedyDecision || \"nonGreedy\" in target && target.nonGreedy;\n  }\n  hashCode() {\n    if (this.cachedHashCode === void 0) {\n      let hashCode = MurmurHash.initialize(7);\n      hashCode = MurmurHash.update(hashCode, this.state.stateNumber);\n      hashCode = MurmurHash.update(hashCode, this.alt);\n      hashCode = MurmurHash.updateFromComparable(hashCode, this.context);\n      hashCode = MurmurHash.updateFromComparable(hashCode, this.semanticContext);\n      hashCode = MurmurHash.update(hashCode, this.passedThroughNonGreedyDecision ? 1 : 0);\n      hashCode = MurmurHash.updateFromComparable(hashCode, this.lexerActionExecutor);\n      hashCode = MurmurHash.finish(hashCode, 6);\n      this.cachedHashCode = hashCode;\n    }\n    return this.cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    return this.passedThroughNonGreedyDecision === other.passedThroughNonGreedyDecision && (this.lexerActionExecutor && other.lexerActionExecutor ? this.lexerActionExecutor.equals(other.lexerActionExecutor) : !other.lexerActionExecutor) && super.equals(other);\n  }\n};\n\n// src/BaseErrorListener.ts\nvar BaseErrorListener = class {\n  static {\n    __name(this, \"BaseErrorListener\");\n  }\n  syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n  }\n  reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n  }\n  reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n  }\n  reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n  }\n};\n\n// src/ConsoleErrorListener.ts\nvar ConsoleErrorListener = class _ConsoleErrorListener extends BaseErrorListener {\n  static {\n    __name(this, \"ConsoleErrorListener\");\n  }\n  /**\n   * Provides a default instance of {@link ConsoleErrorListener}.\n   */\n  static instance = new _ConsoleErrorListener();\n  syntaxError(recognizer, offendingSymbol, line, charPositionInLine, msg, _e) {\n    console.error(\"line \" + line + \":\" + charPositionInLine + \" \" + msg);\n  }\n};\n\n// src/ProxyErrorListener.ts\nvar ProxyErrorListener = class extends BaseErrorListener {\n  constructor(delegates) {\n    super();\n    this.delegates = delegates;\n    return this;\n  }\n  static {\n    __name(this, \"ProxyErrorListener\");\n  }\n  syntaxError(recognizer, offendingSymbol, line, column, msg, e) {\n    this.delegates.forEach((d) => {\n      d.syntaxError(recognizer, offendingSymbol, line, column, msg, e);\n    });\n  }\n  reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n    this.delegates.forEach((d) => {\n      d.reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs);\n    });\n  }\n  reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n    this.delegates.forEach((d) => {\n      d.reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs);\n    });\n  }\n  reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n    this.delegates.forEach((d) => {\n      d.reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs);\n    });\n  }\n};\n\n// src/Recognizer.ts\nvar Recognizer = class _Recognizer {\n  static {\n    __name(this, \"Recognizer\");\n  }\n  static EOF = -1;\n  static tokenTypeMapCache = /* @__PURE__ */ new Map();\n  static ruleIndexMapCache = /* @__PURE__ */ new Map();\n  interpreter;\n  #listeners = [ConsoleErrorListener.instance];\n  #stateNumber = -1;\n  checkVersion(toolVersion) {\n    const runtimeVersion = \"4.13.1\";\n    if (runtimeVersion !== toolVersion) {\n      console.error(\"ANTLR runtime and generated code versions disagree: \" + runtimeVersion + \"!=\" + toolVersion);\n    }\n  }\n  addErrorListener(listener) {\n    this.#listeners.push(listener);\n  }\n  removeErrorListeners() {\n    this.#listeners = [];\n  }\n  removeErrorListener(listener) {\n    for (let i = 0; i < this.#listeners.length; i++) {\n      if (this.#listeners[i] === listener) {\n        this.#listeners.splice(i, 1);\n        return;\n      }\n    }\n  }\n  getErrorListeners() {\n    return this.#listeners;\n  }\n  getTokenTypeMap() {\n    const vocabulary = this.vocabulary;\n    let result = _Recognizer.tokenTypeMapCache.get(vocabulary);\n    if (!result) {\n      result = /* @__PURE__ */ new Map();\n      for (let i = 0; i <= this.atn.maxTokenType; i++) {\n        const literalName = vocabulary.getLiteralName(i);\n        if (literalName) {\n          result.set(literalName, i);\n        }\n        const symbolicName = vocabulary.getSymbolicName(i);\n        if (symbolicName) {\n          result.set(symbolicName, i);\n        }\n      }\n      result.set(\"EOF\", Token.EOF);\n      _Recognizer.tokenTypeMapCache.set(vocabulary, result);\n    }\n    return result;\n  }\n  /**\n   * Get a map from rule names to rule indexes.\n   * Used for XPath and tree pattern compilation.\n   */\n  getRuleIndexMap() {\n    const ruleNames = this.ruleNames;\n    let result = _Recognizer.ruleIndexMapCache.get(ruleNames);\n    if (!result) {\n      result = /* @__PURE__ */ new Map();\n      ruleNames.forEach((ruleName, idx) => {\n        return result.set(ruleName, idx);\n      });\n      _Recognizer.ruleIndexMapCache.set(ruleNames, result);\n    }\n    return result;\n  }\n  getTokenType(tokenName) {\n    const ttype = this.getTokenTypeMap().get(tokenName);\n    if (ttype) {\n      return ttype;\n    }\n    return Token.INVALID_TYPE;\n  }\n  /** What is the error header, normally line/character position information? */\n  getErrorHeader(e) {\n    const line = e.offendingToken?.line;\n    const column = e.offendingToken?.column;\n    return \"line \" + line + \":\" + column;\n  }\n  get errorListenerDispatch() {\n    return new ProxyErrorListener(this.#listeners);\n  }\n  /**\n   * subclass needs to override these if there are semantic predicates or actions\n   * that the ATN interp needs to execute\n   */\n  sempred(_localctx, _ruleIndex, _actionIndex) {\n    return true;\n  }\n  // TODO: make localCtx an optional parameter, not optional null.\n  precpred(_localctx, _precedence) {\n    return true;\n  }\n  action(_localctx, _ruleIndex, _actionIndex) {\n  }\n  get atn() {\n    return this.interpreter.atn;\n  }\n  get state() {\n    return this.#stateNumber;\n  }\n  set state(state) {\n    this.#stateNumber = state;\n  }\n  getSerializedATN() {\n    throw new Error(\"there is no serialized ATN\");\n  }\n  getParseInfo() {\n    return null;\n  }\n};\n\n// src/CommonToken.ts\nvar CommonToken = class _CommonToken {\n  static {\n    __name(this, \"CommonToken\");\n  }\n  /**\n   * An empty tuple which is used as the default value of\n   * {@link source} for tokens that do not have a source.\n   */\n  // eslint-disable-next-line @typescript-eslint/naming-convention\n  static EMPTY_SOURCE = [null, null];\n  /**\n   * These properties share a field to reduce the memory footprint of\n   * {@link CommonToken}. Tokens created by a {@link CommonTokenFactory} from\n   * the same source and input stream share a reference to the same\n   * {@link Pair} containing these values.\n   */\n  source;\n  tokenIndex;\n  start;\n  stop;\n  /**\n   * This is the backing field for {@link #getType} and {@link #setType}.\n   */\n  type;\n  /**\n   * The (one-based) line number on which the 1st character of this token was.\n   */\n  line;\n  /**\n   * The zero-based index of the first character position in its line.\n   */\n  column;\n  /**\n   * The token's channel.\n   */\n  channel;\n  /**\n   * This is the backing field for {@link getText} when the token text is\n   * explicitly set in the constructor or via {@link setText}.\n   */\n  #text;\n  constructor(details) {\n    this.type = details.type;\n    this.source = details.source;\n    this.tokenIndex = details.tokenIndex ?? -1;\n    this.line = details.line ?? 0;\n    this.column = details.column ?? -1;\n    this.channel = details.channel ?? Token.DEFAULT_CHANNEL;\n    this.start = details.start ?? 0;\n    this.stop = details.stop ?? 0;\n    this.#text = details.text;\n    if (details.source[0] !== null) {\n      this.line = details.source[0].line;\n      this.column = details.source[0].column;\n    }\n  }\n  /**\n   * Constructs a new {@link CommonToken} as a copy of another {@link Token}.\n   *\n   * If `token` is also a {@link CommonToken} instance, the newly\n   * constructed token will share a reference to the {@link #text} field and\n   * the {@link Pair} stored in {@link source}. Otherwise, {@link text} will\n   * be assigned the result of calling {@link getText}, and {@link source}\n   * will be constructed from the result of {@link Token.getTokenSource} and\n   * {@link Token#getInputStream}.\n   *\n   * @param token The token to copy.\n   */\n  static fromToken(token) {\n    let source;\n    if (\"source\" in token) {\n      source = token.source;\n    } else {\n      source = [token.tokenSource, token.inputStream];\n    }\n    return new _CommonToken({\n      type: token.type,\n      line: token.line,\n      tokenIndex: token.tokenIndex,\n      column: token.column,\n      channel: token.channel,\n      start: token.start,\n      stop: token.stop,\n      text: token.text,\n      source\n    });\n  }\n  /**\n   * Constructs a new {@link CommonToken} with the specified token type and text.\n   *\n   * @param type The token type.\n   * @param text The text of the token.\n   */\n  static fromType(type, text) {\n    return new _CommonToken({ type, text, source: _CommonToken.EMPTY_SOURCE });\n  }\n  static fromSource(source, type, channel, start, stop) {\n    return new _CommonToken({ type, channel, start, stop, source });\n  }\n  get tokenSource() {\n    return this.source[0];\n  }\n  get inputStream() {\n    return this.source[1];\n  }\n  /**\n   * Constructs a new {@link CommonToken} as a copy of another {@link Token}.\n   *\n   * If `oldToken` is also a {@link CommonToken} instance, the newly\n   * constructed token will share a reference to the {@link text} field and\n   * the {@link Pair} stored in {@link source}. Otherwise, {@link text} will\n   * be assigned the result of calling {@link getText}, and {@link source}\n   * will be constructed from the result of {@link Token.getTokenSource} and\n   * {@link Token.getInputStream}.\n   */\n  clone() {\n    const t = new _CommonToken({\n      source: this.source,\n      type: this.type,\n      channel: this.channel,\n      start: this.start,\n      stop: this.stop,\n      tokenIndex: this.tokenIndex,\n      line: this.line,\n      column: this.column,\n      text: this.#text\n    });\n    return t;\n  }\n  toString(recognizer) {\n    let channelStr = \"\";\n    if (this.channel > 0) {\n      channelStr = \",channel=\" + this.channel;\n    }\n    let text = this.text;\n    if (text) {\n      text = text.replace(/\\n/g, \"\\\\n\");\n      text = text.replace(/\\r/g, \"\\\\r\");\n      text = text.replace(/\\t/g, \"\\\\t\");\n    } else {\n      text = \"<no text>\";\n    }\n    let typeString = String(this.type);\n    if (recognizer) {\n      typeString = recognizer.vocabulary.getDisplayName(this.type) ?? \"<unknown>\";\n    }\n    return \"[@\" + this.tokenIndex + \",\" + this.start + \":\" + this.stop + \"='\" + text + \"',<\" + typeString + \">\" + channelStr + \",\" + this.line + \":\" + this.column + \"]\";\n  }\n  get text() {\n    if (this.#text) {\n      return this.#text;\n    }\n    const input = this.inputStream;\n    if (!input) {\n      return void 0;\n    }\n    const n2 = input.size;\n    if (this.start < n2 && this.stop < n2) {\n      return input.getTextFromRange(this.start, this.stop);\n    }\n    return \"<EOF>\";\n  }\n  set text(text) {\n    this.#text = text;\n  }\n  // WritableToken implementation\n  setText(text) {\n    this.#text = text;\n  }\n  setType(ttype) {\n    this.type = ttype;\n  }\n  setLine(line) {\n    this.line = line;\n  }\n  setCharPositionInLine(pos) {\n    this.column = pos;\n  }\n  setChannel(channel) {\n    this.channel = channel;\n  }\n  setTokenIndex(index) {\n    this.tokenIndex = index;\n  }\n};\n\n// src/CommonTokenFactory.ts\nvar CommonTokenFactory = class _CommonTokenFactory {\n  static {\n    __name(this, \"CommonTokenFactory\");\n  }\n  /**\n   * The default {@link CommonTokenFactory} instance.\n   *\n   *\n   * This token factory does not explicitly copy token text when constructing\n   * tokens.\n   */\n  static DEFAULT = new _CommonTokenFactory();\n  /**\n   * Indicates whether {@link CommonToken.setText} should be called after\n   * constructing tokens to explicitly set the text. This is useful for cases\n   * where the input stream might not be able to provide arbitrary substrings\n   * of text from the input after the lexer creates a token (e.g. the\n   * implementation of {@link CharStream.getText} in\n   * {@link UnbufferedCharStream} throws an\n   * {@link UnsupportedOperationException}). Explicitly setting the token text\n   * allows {@link Token.getText} to be called at any time regardless of the\n   * input stream implementation.\n   *\n   *\n   * The default value is `false` to avoid the performance and memory\n   * overhead of copying text for every token unless explicitly requested.\n   */\n  copyText = false;\n  constructor(copyText) {\n    this.copyText = copyText ?? false;\n  }\n  create(source, type, text, channel, start, stop, line, column) {\n    const t = CommonToken.fromSource(source, type, channel, start, stop);\n    t.line = line;\n    t.column = column;\n    if (text) {\n      t.text = text;\n    } else if (this.copyText && source[1] !== null) {\n      t.text = source[1].getTextFromRange(start, stop);\n    }\n    return t;\n  }\n};\n\n// src/RecognitionException.ts\nvar RecognitionException = class _RecognitionException extends Error {\n  static {\n    __name(this, \"RecognitionException\");\n  }\n  ctx;\n  /**\n   * The current {@link Token} when an error occurred. Since not all streams\n   * support accessing symbols by index, we have to track the {@link Token}\n   * instance itself\n   */\n  offendingToken = null;\n  /**\n   * Get the ATN state number the parser was in at the time the error\n   * occurred. For {@link NoViableAltException} and\n   * {@link LexerNoViableAltException} exceptions, this is the\n   * {@link DecisionState} number. For others, it is the state whose outgoing\n   * edge we couldn't match.\n   */\n  offendingState = -1;\n  recognizer;\n  input;\n  constructor(params) {\n    super(params.message);\n    if (Error.captureStackTrace) {\n      Error.captureStackTrace(this, _RecognitionException);\n    }\n    this.message = params.message;\n    this.recognizer = params.recognizer;\n    this.input = params.input;\n    this.ctx = params.ctx;\n    if (this.recognizer !== null) {\n      this.offendingState = this.recognizer.state;\n    }\n  }\n  /**\n   * Gets the set of input symbols which could potentially follow the\n   * previously matched symbol at the time this exception was thrown.\n   *\n   * If the set of expected tokens is not known and could not be computed,\n   * this method returns `null`.\n   *\n   * @returns The set of token types that could potentially follow the current\n   * state in the ATN, or `null` if the information is not available.\n   */\n  getExpectedTokens() {\n    if (this.recognizer !== null && this.ctx !== null) {\n      return this.recognizer.atn.getExpectedTokens(this.offendingState, this.ctx);\n    } else {\n      return null;\n    }\n  }\n  // If the state number is not known, this method returns -1.\n  toString() {\n    return this.message;\n  }\n};\n\n// src/LexerNoViableAltException.ts\nvar LexerNoViableAltException = class extends RecognitionException {\n  static {\n    __name(this, \"LexerNoViableAltException\");\n  }\n  startIndex;\n  deadEndConfigs;\n  constructor(lexer, input, startIndex, deadEndConfigs) {\n    super({ message: \"\", recognizer: lexer, input, ctx: null });\n    this.startIndex = startIndex;\n    this.deadEndConfigs = deadEndConfigs;\n  }\n  toString() {\n    let symbol = \"\";\n    if (this.input && this.startIndex >= 0 && this.startIndex < this.input.size) {\n      symbol = this.input.getTextFromRange(this.startIndex, this.startIndex);\n    }\n    return \"LexerNoViableAltException\" + symbol;\n  }\n};\n\n// src/Lexer.ts\nvar Lexer = class _Lexer extends Recognizer {\n  static {\n    __name(this, \"Lexer\");\n  }\n  static DEFAULT_MODE = 0;\n  static MORE = -2;\n  static SKIP = -3;\n  static DEFAULT_TOKEN_CHANNEL = Token.DEFAULT_CHANNEL;\n  static HIDDEN = Token.HIDDEN_CHANNEL;\n  options = {\n    minDFAEdge: 0,\n    maxDFAEdge: 256,\n    minCodePoint: 0,\n    maxCodePoint: 1114111\n  };\n  /**\n   * What character index in the stream did the current token start at?\n   *  Needed, for example, to get the text for current token.  Set at\n   *  the start of nextToken.\n   */\n  tokenStartCharIndex = -1;\n  /** The channel number for the current token */\n  channel = 0;\n  /** The token type for the current token */\n  type = 0;\n  mode = _Lexer.DEFAULT_MODE;\n  /** The start column of the current token (the one that was last read by `nextToken`). */\n  currentTokenColumn = 0;\n  /**\n   * The line on which the first character of the current token (the one that was last read by `nextToken`) resides.\n   */\n  currentTokenStartLine = 0;\n  #input;\n  /**\n   * The goal of all lexer rules/methods is to create a token object.\n   *  This is an instance variable as multiple rules may collaborate to\n   *  create a single token.  nextToken will return this object after\n   *  matching lexer rule(s).  If you subclass to allow multiple token\n   *  emissions, then set this to the last token to be matched or\n   *  something non-null so that the auto token emit mechanism will not\n   *  emit another token.\n   */\n  #token = null;\n  /**\n   * Once we see EOF on char stream, next token will be EOF.\n   *  If you have DONE : EOF ; then you see DONE EOF.\n   */\n  #hitEOF = false;\n  #modeStack = [];\n  /**\n   * The text to be used for the next token. If this is not null, then the text\n   * for the next token is fixed and is not subject to change in the normal\n   * workflow of the lexer.\n   */\n  #text;\n  #factory;\n  constructor(input, options) {\n    super();\n    this.options = { ...this.options, ...options };\n    this.#input = input;\n    this.#factory = CommonTokenFactory.DEFAULT;\n  }\n  reset(seekBack = true) {\n    if (seekBack) {\n      this.#input.seek(0);\n    }\n    this.#token = null;\n    this.type = Token.INVALID_TYPE;\n    this.channel = Token.DEFAULT_CHANNEL;\n    this.tokenStartCharIndex = -1;\n    this.currentTokenColumn = -1;\n    this.currentTokenStartLine = -1;\n    this.#text = void 0;\n    this.#hitEOF = false;\n    this.mode = _Lexer.DEFAULT_MODE;\n    this.#modeStack = [];\n    this.interpreter.reset();\n  }\n  /** @returns a token from this source; i.e., match a token on the char stream. */\n  nextToken() {\n    if (this.#input === null) {\n      throw new Error(\"nextToken requires a non-null input stream.\");\n    }\n    const tokenStartMarker = this.#input.mark();\n    try {\n      while (true) {\n        if (this.#hitEOF) {\n          this.emitEOF();\n          return this.#token;\n        }\n        this.#token = null;\n        this.channel = Token.DEFAULT_CHANNEL;\n        this.tokenStartCharIndex = this.#input.index;\n        this.currentTokenColumn = this.interpreter.column;\n        this.currentTokenStartLine = this.interpreter.line;\n        this.#text = void 0;\n        let continueOuter = false;\n        while (true) {\n          this.type = Token.INVALID_TYPE;\n          let ttype = _Lexer.SKIP;\n          try {\n            ttype = this.interpreter.match(this.#input, this.mode);\n          } catch (e) {\n            if (e instanceof LexerNoViableAltException) {\n              this.notifyListeners(e);\n              this.recover(e);\n            } else {\n              throw e;\n            }\n          }\n          if (this.#input.LA(1) === Token.EOF) {\n            this.#hitEOF = true;\n          }\n          if (this.type === Token.INVALID_TYPE) {\n            this.type = ttype;\n          }\n          if (this.type === _Lexer.SKIP) {\n            continueOuter = true;\n            break;\n          }\n          if (this.type !== _Lexer.MORE) {\n            break;\n          }\n        }\n        if (continueOuter) {\n          continue;\n        }\n        if (this.#token === null) {\n          this.emit();\n        }\n        return this.#token;\n      }\n    } finally {\n      this.#input.release(tokenStartMarker);\n    }\n  }\n  /**\n   * Instruct the lexer to skip creating a token for current lexer rule\n   * and look for another token. nextToken() knows to keep looking when\n   * a lexer rule finishes with token set to SKIP_TOKEN. Recall that\n   * if token==null at end of any token rule, it creates one for you\n   * and emits it.\n   */\n  skip() {\n    this.type = _Lexer.SKIP;\n  }\n  more() {\n    this.type = _Lexer.MORE;\n  }\n  pushMode(m2) {\n    if (LexerATNSimulator.debug) {\n      console.log(\"pushMode \" + m2);\n    }\n    this.#modeStack.push(this.mode);\n    this.mode = m2;\n  }\n  popMode() {\n    if (this.#modeStack.length === 0) {\n      throw new Error(\"Empty Stack\");\n    }\n    if (LexerATNSimulator.debug) {\n      console.log(\"popMode back to \" + this.#modeStack.slice(0, -1));\n    }\n    this.mode = this.#modeStack.pop();\n    return this.mode;\n  }\n  get modeStack() {\n    return this.#modeStack;\n  }\n  /**\n   * By default does not support multiple emits per nextToken invocation\n   * for efficiency reasons. Subclass and override this method, nextToken,\n   * and getToken (to push tokens into a list and pull from that list\n   * rather than a single variable as this implementation does).\n   */\n  emitToken(token) {\n    this.#token = token;\n  }\n  /**\n   * The standard method called to automatically emit a token at the\n   * outermost lexical rule. The token object should point into the\n   * char buffer start..stop. If there is a text override in 'text',\n   * use that to set the token's text. Override this method to emit\n   * custom Token objects or provide a new factory.\n   */\n  emit() {\n    const t = this.#factory.create(\n      [this, this.#input],\n      this.type,\n      this.#text,\n      this.channel,\n      this.tokenStartCharIndex,\n      this.getCharIndex() - 1,\n      this.currentTokenStartLine,\n      this.currentTokenColumn\n    );\n    this.emitToken(t);\n    return t;\n  }\n  emitEOF() {\n    const eof = this.#factory.create(\n      [this, this.#input],\n      Token.EOF,\n      void 0,\n      Token.DEFAULT_CHANNEL,\n      this.#input.index,\n      this.#input.index - 1,\n      this.line,\n      this.column\n    );\n    this.emitToken(eof);\n    return eof;\n  }\n  /** What is the index of the current character of lookahead? */\n  getCharIndex() {\n    return this.#input.index;\n  }\n  /**\n   * Return a list of all Token objects in input char stream.\n   * Forces load of all tokens. Does not include EOF token.\n   */\n  getAllTokens() {\n    const tokens = [];\n    let t = this.nextToken();\n    while (t.type !== Token.EOF) {\n      tokens.push(t);\n      t = this.nextToken();\n    }\n    return tokens;\n  }\n  notifyListeners(e) {\n    const start = this.tokenStartCharIndex;\n    const stop = this.#input.index;\n    const text = this.#input.getTextFromRange(start, stop);\n    const msg = \"token recognition error at: '\" + this.getErrorDisplay(text) + \"'\";\n    this.errorListenerDispatch.syntaxError(this, null, this.currentTokenStartLine, this.currentTokenColumn, msg, e);\n  }\n  getErrorDisplay(s) {\n    return s;\n  }\n  getErrorDisplayForChar(c) {\n    if (c.charCodeAt(0) === Token.EOF) {\n      return \"<EOF>\";\n    }\n    if (c === \"\\n\") {\n      return \"\\\\n\";\n    }\n    if (c === \"\t\") {\n      return \"\\\\t\";\n    }\n    if (c === \"\\r\") {\n      return \"\\\\r\";\n    }\n    return c;\n  }\n  getCharErrorDisplay(c) {\n    return \"'\" + this.getErrorDisplayForChar(c) + \"'\";\n  }\n  /**\n   * Lexers can normally match any char in it's vocabulary after matching\n   * a token, so do the easy thing and just kill a character and hope\n   * it all works out. You can instead use the rule invocation stack\n   * to do sophisticated error recovery if you are in a fragment rule.\n   */\n  recover(re) {\n    if (this.#input.LA(1) !== Token.EOF) {\n      if (re instanceof LexerNoViableAltException) {\n        this.interpreter.consume(this.#input);\n      } else {\n        this.#input.consume();\n      }\n    }\n  }\n  get inputStream() {\n    return this.#input;\n  }\n  set inputStream(input) {\n    this.reset(false);\n    this.#input = input;\n  }\n  set tokenFactory(factory) {\n    this.#factory = factory;\n  }\n  get tokenFactory() {\n    return this.#factory;\n  }\n  get sourceName() {\n    return this.#input.getSourceName();\n  }\n  get line() {\n    return this.interpreter.line;\n  }\n  set line(line) {\n    this.interpreter.line = line;\n  }\n  get column() {\n    return this.interpreter.column;\n  }\n  set column(column) {\n    this.interpreter.column = column;\n  }\n  get text() {\n    if (this.#text) {\n      return this.#text;\n    } else {\n      return this.interpreter.getText(this.#input);\n    }\n  }\n  set text(text) {\n    this.#text = text;\n  }\n};\n\n// src/misc/ParseCancellationException.ts\nvar ParseCancellationException = class _ParseCancellationException extends Error {\n  static {\n    __name(this, \"ParseCancellationException\");\n  }\n  constructor(_e) {\n    super();\n    Error.captureStackTrace(this, _ParseCancellationException);\n  }\n};\n\n// src/misc/InterpreterDataReader.ts\nvar InterpreterDataReader = class {\n  static {\n    __name(this, \"InterpreterDataReader\");\n  }\n  /**\n   * The structure of the data file is very simple. Everything is line based with empty lines\n   * separating the different parts. For lexers the layout is:\n   * token literal names:\n   * ...\n   *\n   * token symbolic names:\n   * ...\n   *\n   * rule names:\n   * ...\n   *\n   * channel names:\n   * ...\n   *\n   * mode names:\n   * ...\n   *\n   * atn:\n   * a single line with comma separated int values, enclosed in a pair of squared brackets.\n   *\n   * Data for a parser does not contain channel and mode names.\n   */\n  static parseInterpreterData(source) {\n    const ruleNames = [];\n    const channels = [];\n    const modes = [];\n    const literalNames = [];\n    const symbolicNames = [];\n    const lines = source.split(\"\\n\");\n    let index = 0;\n    let line = lines[index++];\n    if (line !== \"token literal names:\") {\n      throw new Error(\"Unexpected data entry\");\n    }\n    do {\n      line = lines[index++];\n      if (line.length === 0) {\n        break;\n      }\n      literalNames.push(line === \"null\" ? null : line);\n    } while (true);\n    line = lines[index++];\n    if (line !== \"token symbolic names:\") {\n      throw new Error(\"Unexpected data entry\");\n    }\n    do {\n      line = lines[index++];\n      if (line.length === 0) {\n        break;\n      }\n      symbolicNames.push(line === \"null\" ? null : line);\n    } while (true);\n    line = lines[index++];\n    if (line !== \"rule names:\") {\n      throw new Error(\"Unexpected data entry\");\n    }\n    do {\n      line = lines[index++];\n      if (line.length === 0) {\n        break;\n      }\n      ruleNames.push(line);\n    } while (true);\n    line = lines[index++];\n    if (line === \"channel names:\") {\n      do {\n        line = lines[index++];\n        if (line.length === 0) {\n          break;\n        }\n        channels.push(line);\n      } while (true);\n      line = lines[index++];\n      if (line !== \"mode names:\") {\n        throw new Error(\"Unexpected data entry\");\n      }\n      do {\n        line = lines[index++];\n        if (line.length === 0) {\n          break;\n        }\n        modes.push(line);\n      } while (true);\n    }\n    line = lines[index++];\n    if (line !== \"atn:\") {\n      throw new Error(\"Unexpected data entry\");\n    }\n    line = lines[index++];\n    const elements = line.split(\",\");\n    let value;\n    const serializedATN = [];\n    for (let i = 0; i < elements.length; ++i) {\n      const element = elements[i];\n      if (element.startsWith(\"[\")) {\n        value = Number(element.substring(1).trim());\n      } else if (element.endsWith(\"]\")) {\n        value = Number(element.substring(0, element.length - 1).trim());\n      } else {\n        value = Number(element.trim());\n      }\n      serializedATN[i] = value;\n    }\n    const deserializer = new ATNDeserializer();\n    return {\n      atn: deserializer.deserialize(serializedATN),\n      vocabulary: new Vocabulary(literalNames, symbolicNames, []),\n      ruleNames,\n      channels: channels.length > 0 ? channels : void 0,\n      modes: modes.length > 0 ? modes : void 0\n    };\n  }\n};\n\n// src/misc/OrderedHashSet.ts\nvar OrderedHashSet = class _OrderedHashSet extends HashSet {\n  static {\n    __name(this, \"OrderedHashSet\");\n  }\n  #elements = [];\n  getOrAdd(o) {\n    const oldSize = this.size;\n    const result = super.getOrAdd(o);\n    if (this.size > oldSize) {\n      this.#elements.push(o);\n    }\n    return result;\n  }\n  equals(o) {\n    if (!(o instanceof _OrderedHashSet)) {\n      return false;\n    }\n    return super.equals(o);\n  }\n  add(element) {\n    if (super.add(element)) {\n      this.#elements.push(element);\n      return true;\n    }\n    return false;\n  }\n  clear() {\n    super.clear();\n    this.#elements = [];\n  }\n  *[Symbol.iterator]() {\n    yield* this.#elements;\n  }\n  toArray() {\n    return this.#elements.slice(0);\n  }\n};\n\n// src/atn/OrderedATNConfigSet.ts\nvar OrderedATNConfigSet = class extends ATNConfigSet {\n  static {\n    __name(this, \"OrderedATNConfigSet\");\n  }\n  constructor() {\n    super();\n    this.configLookup = new OrderedHashSet();\n  }\n};\n\n// src/atn/LexerIndexedCustomAction.ts\nvar LexerIndexedCustomAction = class _LexerIndexedCustomAction {\n  static {\n    __name(this, \"LexerIndexedCustomAction\");\n  }\n  offset;\n  action;\n  actionType;\n  isPositionDependent = true;\n  #cachedHashCode;\n  constructor(offset, action) {\n    this.actionType = action.actionType;\n    this.offset = offset;\n    this.action = action;\n  }\n  /**\n   * This method calls {@link execute} on the result of {@link getAction}\n   * using the provided `lexer`.\n   */\n  execute(lexer) {\n    this.action.execute(lexer);\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hash = MurmurHash.initialize();\n      hash = MurmurHash.update(hash, this.offset);\n      hash = MurmurHash.updateFromComparable(hash, this.action);\n      this.#cachedHashCode = MurmurHash.finish(hash, 2);\n    }\n    return this.#cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (!(other instanceof _LexerIndexedCustomAction)) {\n      return false;\n    }\n    return this.offset === other.offset && this.action === other.action;\n  }\n};\n\n// src/atn/LexerActionExecutor.ts\nvar LexerActionExecutor = class _LexerActionExecutor {\n  static {\n    __name(this, \"LexerActionExecutor\");\n  }\n  lexerActions;\n  actionType;\n  isPositionDependent = false;\n  #cachedHashCode;\n  /**\n   * Represents an executor for a sequence of lexer actions which traversed during\n   * the matching operation of a lexer rule (token).\n   *\n   * The executor tracks position information for position-dependent lexer actions\n   * efficiently, ensuring that actions appearing only at the end of the rule do\n   * not cause bloating of the {@link DFA} created for the lexer.\n   */\n  constructor(lexerActions) {\n    this.actionType = -1;\n    this.lexerActions = lexerActions ?? [];\n    return this;\n  }\n  /**\n   * Creates a {@link LexerActionExecutor} which executes the actions for\n   * the input `lexerActionExecutor` followed by a specified\n   * `lexerAction`.\n   *\n   * @param lexerActionExecutor The executor for actions already traversed by\n   * the lexer while matching a token within a particular\n   * {@link LexerATNConfig}. If this is `null`, the method behaves as\n   * though it were an empty executor.\n   * @param lexerAction The lexer action to execute after the actions\n   * specified in `lexerActionExecutor`.\n   *\n   * @returns {LexerActionExecutor} A {@link LexerActionExecutor} for executing the combine actions\n   * of `lexerActionExecutor` and `lexerAction`.\n   */\n  static append(lexerActionExecutor, lexerAction) {\n    if (lexerActionExecutor === null) {\n      return new _LexerActionExecutor([lexerAction]);\n    }\n    const lexerActions = lexerActionExecutor.lexerActions.concat([lexerAction]);\n    return new _LexerActionExecutor(lexerActions);\n  }\n  /**\n   * Creates a {@link LexerActionExecutor} which encodes the current offset\n   * for position-dependent lexer actions.\n   *\n   * Normally, when the executor encounters lexer actions where\n   * {@link LexerAction//isPositionDependent} returns `true`, it calls\n   * {@link IntStream.seek} on the input {@link CharStream} to set the input\n   * position to the *end* of the current token. This behavior provides\n   * for efficient DFA representation of lexer actions which appear at the end\n   * of a lexer rule, even when the lexer rule matches a variable number of\n   * characters.\n   *\n   * Prior to traversing a match transition in the ATN, the current offset\n   * from the token start index is assigned to all position-dependent lexer\n   * actions which have not already been assigned a fixed offset. By storing\n   * the offsets relative to the token start index, the DFA representation of\n   * lexer actions which appear in the middle of tokens remains efficient due\n   * to sharing among tokens of the same length, regardless of their absolute\n   * position in the input stream.\n   *\n   * If the current executor already has offsets assigned to all\n   * position-dependent lexer actions, the method returns `this`.\n   *\n   * @param offset The current offset to assign to all position-dependent\n   * lexer actions which do not already have offsets assigned.\n   *\n   * @returns {LexerActionExecutor} A {@link LexerActionExecutor} which stores input stream offsets\n   * for all position-dependent lexer actions.\n   */\n  fixOffsetBeforeMatch(offset) {\n    let updatedLexerActions = null;\n    for (let i = 0; i < this.lexerActions.length; i++) {\n      if (this.lexerActions[i].isPositionDependent && !(this.lexerActions[i] instanceof LexerIndexedCustomAction)) {\n        if (updatedLexerActions === null) {\n          updatedLexerActions = this.lexerActions.concat([]);\n        }\n        updatedLexerActions[i] = new LexerIndexedCustomAction(\n          offset,\n          this.lexerActions[i]\n        );\n      }\n    }\n    if (updatedLexerActions === null) {\n      return this;\n    } else {\n      return new _LexerActionExecutor(updatedLexerActions);\n    }\n  }\n  /**\n   * Execute the actions encapsulated by this executor within the context of a\n   * particular {@link Lexer}.\n   *\n   * This method calls {@link IntStream.seek} to set the position of the\n   * `input` {@link CharStream} prior to calling\n   * {@link LexerAction.execute} on a position-dependent action. Before the\n   * method returns, the input position will be restored to the same position\n   * it was in when the method was invoked.\n   *\n   * @param lexer The lexer instance.\n   * @param input The input stream which is the source for the current token.\n   * When this method is called, the current {@link IntStream.index} for\n   * `input` should be the start of the following token, i.e. 1\n   * character past the end of the current token.\n   * @param startIndex The token start index. This value may be passed to\n   * {@link IntStream.seek} to set the `input` position to the beginning\n   * of the token.\n   */\n  execute(lexer, input, startIndex) {\n    if (input === void 0 || startIndex === void 0) {\n      return;\n    }\n    let requiresSeek = false;\n    const stopIndex = input.index;\n    try {\n      for (const lexerAction of this.lexerActions) {\n        let action = lexerAction;\n        if (lexerAction instanceof LexerIndexedCustomAction) {\n          const offset = lexerAction.offset;\n          input.seek(startIndex + offset);\n          action = lexerAction.action;\n          requiresSeek = startIndex + offset !== stopIndex;\n        } else if (lexerAction.isPositionDependent) {\n          input.seek(stopIndex);\n          requiresSeek = false;\n        }\n        action.execute(lexer);\n      }\n    } finally {\n      if (requiresSeek) {\n        input.seek(stopIndex);\n      }\n    }\n  }\n  hashCode() {\n    if (this.#cachedHashCode === void 0) {\n      let hashCode = MurmurHash.initialize(7);\n      for (const lexerAction of this.lexerActions) {\n        hashCode = MurmurHash.update(hashCode, lexerAction.hashCode());\n      }\n      this.#cachedHashCode = MurmurHash.finish(hashCode, this.lexerActions.length);\n    }\n    return this.#cachedHashCode;\n  }\n  equals(other) {\n    if (this === other) {\n      return true;\n    }\n    if (this.#cachedHashCode !== other.#cachedHashCode) {\n      return false;\n    }\n    if (this.lexerActions.length !== other.lexerActions.length) {\n      return false;\n    }\n    return this.lexerActions.every((action, index) => {\n      return action.equals(other.lexerActions[index]);\n    });\n  }\n};\n\n// src/dfa/DFASerializer.ts\nvar DFASerializer = class {\n  static {\n    __name(this, \"DFASerializer\");\n  }\n  dfa;\n  vocabulary;\n  constructor(dfa, vocabulary) {\n    this.dfa = dfa;\n    this.vocabulary = vocabulary;\n  }\n  toString() {\n    if (!this.dfa.s0) {\n      return \"\";\n    }\n    let buf = \"\";\n    const states = this.dfa.getStates();\n    for (const s of states) {\n      let n2 = 0;\n      n2 = s.edges.length;\n      for (let i = 0; i < n2; i++) {\n        const t = s.edges[i];\n        if (t && t.stateNumber !== 2147483647) {\n          buf += this.getStateString(s);\n          const label = this.getEdgeLabel(i);\n          buf += \"-\";\n          buf += label;\n          buf += \"->\";\n          buf += this.getStateString(t);\n          buf += \"\\n\";\n        }\n      }\n    }\n    return buf;\n  }\n  getEdgeLabel(i) {\n    const name = this.vocabulary.getDisplayName(i - 1);\n    return `${name}`;\n  }\n  getStateString(s) {\n    const n2 = s.stateNumber;\n    const baseStateStr = (s.isAcceptState ? \":\" : \"\") + \"s\" + n2 + (s.requiresFullContext ? \"^\" : \"\");\n    if (s.isAcceptState) {\n      if (s.predicates !== null) {\n        return `${baseStateStr}=>${s.predicates.toString()}`;\n      }\n      return `${baseStateStr}=>${s.prediction}`;\n    } else {\n      return `${baseStateStr}`;\n    }\n  }\n};\n\n// src/dfa/LexerDFASerializer.ts\nvar LexerDFASerializer = class extends DFASerializer {\n  static {\n    __name(this, \"LexerDFASerializer\");\n  }\n  constructor(dfa) {\n    super(dfa, Vocabulary.EMPTY_VOCABULARY);\n  }\n  getEdgeLabel = (i) => {\n    return \"'\" + String.fromCharCode(i) + \"'\";\n  };\n};\n\n// src/dfa/DFA.ts\nvar DFA = class {\n  static {\n    __name(this, \"DFA\");\n  }\n  s0;\n  decision;\n  /** From which ATN state did we create this DFA? */\n  atnStartState;\n  /**\n   * Gets whether this DFA is a precedence DFA. Precedence DFAs use a special\n   * start state {@link #s0} which is not stored in {@link #states}. The\n   * {@link DFAState#edges} array for this start state contains outgoing edges\n   * supplying individual start states corresponding to specific precedence\n   * values.\n   *\n   * @returns `true` if this is a precedence DFA; otherwise, `false`.\n   */\n  isPrecedenceDfa;\n  /**\n   * A mapping from an ATNConfigSet hash to a DFAState.\n   * Used to quick look up the DFA state for a particular configuration set.\n   */\n  #states = /* @__PURE__ */ new Map();\n  constructor(atnStartState, decision) {\n    this.atnStartState = atnStartState;\n    this.decision = decision ?? 0;\n    let precedenceDfa = false;\n    if (atnStartState instanceof StarLoopEntryState) {\n      if (atnStartState.precedenceRuleDecision) {\n        precedenceDfa = true;\n        this.s0 = DFAState.fromState(-1);\n      }\n    }\n    this.isPrecedenceDfa = precedenceDfa;\n  }\n  [Symbol.iterator] = () => {\n    return this.#states.values()[Symbol.iterator]();\n  };\n  /**\n   * Get the start state for a specific precedence value.\n   *\n   * @param precedence The current precedence.\n    @returns The start state corresponding to the specified precedence, or\n   * `null` if no start state exists for the specified precedence.\n   *\n   * @throws IllegalStateException if this is not a precedence DFA.\n   * @see #isPrecedenceDfa\n   */\n  getPrecedenceStartState = (precedence) => {\n    if (!this.isPrecedenceDfa) {\n      throw new Error(`Only precedence DFAs may contain a precedence start state.`);\n    }\n    if (!this.s0 || !this.s0.edges || precedence < 0 || precedence >= this.s0.edges.length) {\n      return void 0;\n    }\n    return this.s0.edges[precedence];\n  };\n  /**\n   * Set the start state for a specific precedence value.\n   *\n   * @param precedence The current precedence.\n   * @param startState The start state corresponding to the specified precedence.\n   */\n  setPrecedenceStartState = (precedence, startState) => {\n    if (!this.isPrecedenceDfa) {\n      throw new Error(`Only precedence DFAs may contain a precedence start state.`);\n    }\n    if (precedence < 0 || !this.s0) {\n      return;\n    }\n    this.s0.edges[precedence] = startState;\n  };\n  /**\n   * @returns a list of all states in this DFA, ordered by state number.\n   */\n  getStates() {\n    const result = [...this.#states.values()];\n    result.sort((o1, o2) => {\n      return o1.stateNumber - o2.stateNumber;\n    });\n    return result;\n  }\n  getState(state) {\n    return this.#states.get(state.configs.hashCode()) ?? null;\n  }\n  getStateForConfigs(configs) {\n    return this.#states.get(configs.hashCode()) ?? null;\n  }\n  addState(state) {\n    const hash = state.configs.hashCode();\n    if (this.#states.has(hash)) {\n      return;\n    }\n    this.#states.set(hash, state);\n    state.stateNumber = this.#states.size - 1;\n  }\n  toString(vocabulary) {\n    if (!vocabulary) {\n      return this.toString(Vocabulary.EMPTY_VOCABULARY);\n    }\n    if (!this.s0) {\n      return \"\";\n    }\n    const serializer = new DFASerializer(this, vocabulary);\n    return serializer.toString() ?? \"\";\n  }\n  toLexerString() {\n    if (!this.s0) {\n      return \"\";\n    }\n    const serializer = new LexerDFASerializer(this);\n    return serializer.toString() ?? \"\";\n  }\n  get length() {\n    return this.#states.size;\n  }\n};\n\n// src/atn/LexerATNSimulator.ts\nvar LexerATNSimulator = class _LexerATNSimulator extends ATNSimulator {\n  static {\n    __name(this, \"LexerATNSimulator\");\n  }\n  static debug = false;\n  decisionToDFA;\n  recognizer = null;\n  /**\n   * The current token's starting index into the character stream.\n   *  Shared across DFA to ATN simulation in case the ATN fails and the\n   *  DFA did not have a previous accept state. In this case, we use the\n   *  ATN-generated exception object.\n   */\n  startIndex = -1;\n  /** line number 1..n within the input */\n  line = 1;\n  /** The index of the character relative to the beginning of the line 0..n-1 */\n  column = 0;\n  mode = Lexer.DEFAULT_MODE;\n  /** Used during DFA/ATN exec to record the most recent accept configuration info */\n  #prevAccept;\n  #options;\n  /** Lookup table for lexer ATN config creation. */\n  #lexerATNConfigFactory;\n  /**\n   * When we hit an accept state in either the DFA or the ATN, we\n   * have to notify the character stream to start buffering characters\n   * via {@link IntStream//mark} and record the current state. The current sim state\n   * includes the current index into the input, the current line,\n   * and current character position in that line. Note that the Lexer is\n   * tracking the starting line and characterization of the token. These\n   * variables track the \"state\" of the simulator when it hits an accept state.\n   *\n   * We track these variables separately for the DFA and ATN simulation\n   * because the DFA simulation often has to fail over to the ATN\n   * simulation. If the ATN simulation fails, we need the DFA to fall\n   * back to its previously accepted state, if any. If the ATN succeeds,\n   * then the ATN does the accept and the DFA simulator that invoked it\n   * can simply return the predicted token type.\n   */\n  constructor(recog, atn, decisionToDFA, sharedContextCache) {\n    super(atn, sharedContextCache);\n    this.decisionToDFA = decisionToDFA;\n    this.recognizer = recog;\n    if (recog) {\n      this.#options = recog.options;\n    }\n  }\n  match(input, mode) {\n    this.mode = mode;\n    const mark = input.mark();\n    try {\n      this.startIndex = input.index;\n      this.#prevAccept = void 0;\n      const dfa = this.decisionToDFA[mode];\n      if (!dfa.s0) {\n        return this.matchATN(input);\n      }\n      return this.execATN(input, dfa.s0);\n    } finally {\n      input.release(mark);\n    }\n  }\n  reset() {\n    this.#prevAccept = void 0;\n    this.startIndex = -1;\n    this.line = 1;\n    this.column = 0;\n    this.mode = Lexer.DEFAULT_MODE;\n  }\n  clearDFA() {\n    for (let d = 0; d < this.decisionToDFA.length; d++) {\n      this.decisionToDFA[d] = new DFA(this.atn.getDecisionState(d), d);\n    }\n  }\n  getDFA(mode) {\n    return this.decisionToDFA[mode];\n  }\n  /** @returns the text matched so far for the current token. */\n  getText(input) {\n    return input.getTextFromRange(this.startIndex, input.index - 1);\n  }\n  consume(input) {\n    const curChar = input.LA(1);\n    if (curChar === \"\\n\".charCodeAt(0)) {\n      this.line += 1;\n      this.column = 0;\n    } else {\n      this.column += 1;\n    }\n    input.consume();\n  }\n  getTokenName(tt) {\n    if (tt === Token.EOF) {\n      return \"EOF\";\n    } else {\n      return \"'\" + String.fromCharCode(tt) + \"'\";\n    }\n  }\n  matchATN(input) {\n    const startState = this.atn.modeToStartState[this.mode];\n    if (_LexerATNSimulator.debug) {\n      console.log(\"matchATN mode \" + this.mode + \" start: \" + startState);\n    }\n    const oldMode = this.mode;\n    const s0Closure = this.computeStartState(input, startState);\n    const suppressEdge = s0Closure.hasSemanticContext;\n    s0Closure.hasSemanticContext = false;\n    const next = this.addDFAState(s0Closure);\n    if (!suppressEdge) {\n      this.decisionToDFA[this.mode].s0 = next;\n    }\n    const predict = this.execATN(input, next);\n    if (_LexerATNSimulator.debug) {\n      console.log(\"DFA after matchATN: \" + this.decisionToDFA[oldMode].toLexerString());\n    }\n    return predict;\n  }\n  execATN(input, state) {\n    if (_LexerATNSimulator.debug) {\n      console.log(\"start state closure=\" + state.configs);\n    }\n    if (state.isAcceptState) {\n      this.captureSimState(input, state);\n    }\n    let t = input.LA(1);\n    while (true) {\n      if (_LexerATNSimulator.debug) {\n        console.log(\"execATN loop starting closure: \" + state.configs);\n      }\n      let target = this.getExistingTargetState(state, t);\n      if (!target) {\n        target = this.computeTargetState(input, state, t);\n      }\n      if (target === ATNSimulator.ERROR) {\n        break;\n      }\n      if (t !== Token.EOF) {\n        this.consume(input);\n      }\n      if (target.isAcceptState) {\n        this.captureSimState(input, target);\n        if (t === Token.EOF) {\n          break;\n        }\n      }\n      t = input.LA(1);\n      state = target;\n    }\n    return this.failOrAccept(input, state.configs, t);\n  }\n  /**\n   * Get an existing target state for an edge in the DFA. If the target state\n   * for the edge has not yet been computed or is otherwise not available,\n   * this method returns `null`.\n   *\n   * @param s The current DFA state.\n   * @param t The next input symbol.\n   *\n   * @returns The existing target DFA state for the given input symbol\n   * `t`, or `null` if the target state for this edge is not already cached\n   */\n  getExistingTargetState(s, t) {\n    if (t >= this.#options.minDFAEdge && t <= this.#options.maxDFAEdge) {\n      const target = s.edges[t - this.#options.minDFAEdge];\n      if (_LexerATNSimulator.debug && target) {\n        console.log(\"reuse state \" + s.stateNumber + \" edge to \" + target.stateNumber);\n      }\n      return target;\n    }\n    return void 0;\n  }\n  /**\n   * Compute a target state for an edge in the DFA, and attempt to add the computed state and corresponding\n   * edge to the DFA.\n   *\n   * @param input The input stream\n   * @param s The current DFA state\n   * @param t The next input symbol\n   *\n   * @returns The computed target DFA state for the given input symbol `t`.\n   *          If `t` does not lead to a valid DFA state, this method returns `ERROR`.\n   */\n  computeTargetState(input, s, t) {\n    const reach = new OrderedATNConfigSet();\n    this.getReachableConfigSet(input, s.configs, reach, t);\n    if (reach.length === 0) {\n      if (!reach.hasSemanticContext) {\n        this.addDFAEdge(s, t, ATNSimulator.ERROR);\n      }\n      return ATNSimulator.ERROR;\n    }\n    return this.addDFAEdge(s, t, null, reach);\n  }\n  failOrAccept(input, reach, t) {\n    if (this.#prevAccept?.dfaState) {\n      const { dfaState, index, line, column } = this.#prevAccept;\n      this.accept(input, dfaState.lexerActionExecutor, this.startIndex, index, line, column);\n      return dfaState.prediction;\n    }\n    if (t === Token.EOF && input.index === this.startIndex) {\n      return Token.EOF;\n    }\n    throw new LexerNoViableAltException(this.recognizer, input, this.startIndex, reach);\n  }\n  /**\n   * Given a starting configuration set, figure out all ATN configurations we can reach upon input `t`.\n   * Parameter `reach` is a return parameter.\n   */\n  getReachableConfigSet(input, closure, reach, t) {\n    let skipAlt = ATN.INVALID_ALT_NUMBER;\n    for (const cfg of closure) {\n      const currentAltReachedAcceptState = cfg.alt === skipAlt;\n      if (currentAltReachedAcceptState && cfg.passedThroughNonGreedyDecision) {\n        continue;\n      }\n      if (_LexerATNSimulator.debug) {\n        console.log(\"testing %s at %s\\n\", this.getTokenName(t), cfg.toString(this.recognizer, true));\n      }\n      for (const trans of cfg.state.transitions) {\n        const target = this.getReachableTarget(trans, t);\n        if (target) {\n          let lexerActionExecutor = cfg.lexerActionExecutor;\n          if (lexerActionExecutor) {\n            lexerActionExecutor = lexerActionExecutor.fixOffsetBeforeMatch(input.index - this.startIndex);\n          }\n          const treatEofAsEpsilon = t === Token.EOF;\n          const config = LexerATNConfig.createWithExecutor(\n            cfg,\n            target,\n            lexerActionExecutor\n          );\n          if (this.closure(input, config, reach, currentAltReachedAcceptState, true, treatEofAsEpsilon)) {\n            skipAlt = cfg.alt;\n          }\n        }\n      }\n    }\n  }\n  accept(input, lexerActionExecutor, startIndex, index, line, charPos) {\n    if (_LexerATNSimulator.debug) {\n      console.log(\"ACTION %s\\n\", lexerActionExecutor);\n    }\n    input.seek(index);\n    this.line = line;\n    this.column = charPos;\n    if (lexerActionExecutor && this.recognizer) {\n      lexerActionExecutor.execute(this.recognizer, input, startIndex);\n    }\n  }\n  getReachableTarget(trans, t) {\n    if (trans.matches(t, this.#options.minCodePoint, this.#options.maxCodePoint)) {\n      return trans.target;\n    } else {\n      return void 0;\n    }\n  }\n  computeStartState(input, p) {\n    const initialContext = PredictionContext.EMPTY;\n    const configs = new OrderedATNConfigSet();\n    for (let i = 0; i < p.transitions.length; i++) {\n      const target = p.transitions[i].target;\n      const cfg = LexerATNConfig.createWithContext(target, i + 1, initialContext);\n      this.closure(input, cfg, configs, false, false, false);\n    }\n    return configs;\n  }\n  /**\n   * Since the alternatives within any lexer decision are ordered by\n   * preference, this method stops pursuing the closure as soon as an accept\n   * state is reached. After the first accept state is reached by depth-first\n   * search from `config`, all other (potentially reachable) states for\n   * this rule would have a lower priority.\n   *\n   * @returns {boolean} `true` if an accept state is reached, otherwise `false`.\n   */\n  closure(input, config, configs, currentAltReachedAcceptState, speculative, treatEofAsEpsilon) {\n    let cfg = null;\n    if (_LexerATNSimulator.debug) {\n      console.log(\"closure(\" + config.toString(this.recognizer, true) + \")\");\n    }\n    if (config.state.constructor.stateType === ATNState.RULE_STOP) {\n      if (_LexerATNSimulator.debug) {\n        if (this.recognizer !== null) {\n          console.log(\n            \"closure at %s rule stop %s\\n\",\n            this.recognizer.ruleNames[config.state.ruleIndex],\n            config\n          );\n        } else {\n          console.log(\"closure at rule stop %s\\n\", config);\n        }\n      }\n      if (!config.context || config.context.hasEmptyPath()) {\n        if (!config.context || config.context.isEmpty()) {\n          configs.add(config);\n          return true;\n        } else {\n          configs.add(LexerATNConfig.createWithConfig(config.state, config, PredictionContext.EMPTY));\n          currentAltReachedAcceptState = true;\n        }\n      }\n      if (config.context && !config.context.isEmpty()) {\n        for (let i = 0; i < config.context.length; i++) {\n          if (config.context.getReturnState(i) !== PredictionContext.EMPTY_RETURN_STATE) {\n            const newContext = config.context.getParent(i);\n            const returnState = this.atn.states[config.context.getReturnState(i)];\n            cfg = LexerATNConfig.createWithConfig(returnState, config, newContext);\n            currentAltReachedAcceptState = this.closure(\n              input,\n              cfg,\n              configs,\n              currentAltReachedAcceptState,\n              speculative,\n              treatEofAsEpsilon\n            );\n          }\n        }\n      }\n      return currentAltReachedAcceptState;\n    }\n    if (!config.state.epsilonOnlyTransitions) {\n      if (!currentAltReachedAcceptState || !config.passedThroughNonGreedyDecision) {\n        configs.add(config);\n      }\n    }\n    for (const trans of config.state.transitions) {\n      cfg = this.getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon);\n      if (cfg) {\n        currentAltReachedAcceptState = this.closure(\n          input,\n          cfg,\n          configs,\n          currentAltReachedAcceptState,\n          speculative,\n          treatEofAsEpsilon\n        );\n      }\n    }\n    return currentAltReachedAcceptState;\n  }\n  // side-effect: can alter configs.hasSemanticContext\n  getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon) {\n    if (!this.#lexerATNConfigFactory) {\n      this.setupATNFactoryLookup();\n    }\n    const factory = this.#lexerATNConfigFactory[trans.transitionType];\n    if (!factory) {\n      return null;\n    }\n    return factory(input, config, trans, configs, speculative, treatEofAsEpsilon);\n  }\n  /**\n   * Fills the lookup table for creating lexer ATN configs. This helps to avoid frequent checks of the transition\n   * type, which determines the configuration of the created config.\n   */\n  setupATNFactoryLookup() {\n    this.#lexerATNConfigFactory = [];\n    this.#lexerATNConfigFactory[Transition.RULE] = (input, config, trans) => {\n      const newContext = SingletonPredictionContext.create(\n        config.context ?? void 0,\n        trans.followState.stateNumber\n      );\n      return LexerATNConfig.createWithConfig(trans.target, config, newContext);\n    };\n    this.#lexerATNConfigFactory[Transition.PRECEDENCE] = () => {\n      throw new Error(\"Precedence predicates are not supported in lexers.\");\n    };\n    this.#lexerATNConfigFactory[Transition.PREDICATE] = (input, config, trans, configs, speculative) => {\n      const pt = trans;\n      if (_LexerATNSimulator.debug) {\n        console.log(\"EVAL rule \" + pt.ruleIndex + \":\" + pt.predIndex);\n      }\n      configs.hasSemanticContext = true;\n      if (this.evaluatePredicate(input, pt.ruleIndex, pt.predIndex, speculative)) {\n        return LexerATNConfig.createWithConfig(trans.target, config);\n      }\n      return null;\n    };\n    this.#lexerATNConfigFactory[Transition.ACTION] = (input, config, trans) => {\n      if (config.context === null || config.context.hasEmptyPath()) {\n        const lexerActionExecutor = LexerActionExecutor.append(\n          config.lexerActionExecutor,\n          this.atn.lexerActions[trans.actionIndex]\n        );\n        return LexerATNConfig.createWithExecutor(config, trans.target, lexerActionExecutor);\n      } else {\n        return LexerATNConfig.createWithConfig(trans.target, config);\n      }\n    };\n    this.#lexerATNConfigFactory[Transition.EPSILON] = (input, config, trans) => {\n      return LexerATNConfig.createWithConfig(trans.target, config);\n    };\n    const simple = /* @__PURE__ */ __name((input, config, trans, configs, speculative, treatEofAsEpsilon) => {\n      if (treatEofAsEpsilon) {\n        if (trans.matches(Token.EOF, this.#options.minCodePoint, this.#options.maxCodePoint)) {\n          return LexerATNConfig.createWithConfig(trans.target, config);\n        }\n      }\n      return null;\n    }, \"simple\");\n    this.#lexerATNConfigFactory[Transition.ATOM] = simple;\n    this.#lexerATNConfigFactory[Transition.RANGE] = simple;\n    this.#lexerATNConfigFactory[Transition.SET] = simple;\n  }\n  /**\n   * Evaluate a predicate specified in the lexer.\n   *\n   * If `speculative` is `true`, this method was called before\n   * {@link consume} for the matched character. This method should call\n   * {@link consume} before evaluating the predicate to ensure position\n   * sensitive values, including {@link Lexer//getText}, {@link Lexer//getLine},\n   * and {@link Lexer}, properly reflect the current\n   * lexer state. This method should restore `input` and the simulator\n   * to the original state before returning (i.e. undo the actions made by the\n   * call to {@link consume}.\n   *\n   * @param input The input stream.\n   * @param ruleIndex The rule containing the predicate.\n   * @param predIndex The index of the predicate within the rule.\n   * @param speculative `true` if the current index in `input` is\n   * one character before the predicate's location.\n   *\n   * @returns `true` if the specified predicate evaluates to\n   * `true`.\n   */\n  evaluatePredicate(input, ruleIndex, predIndex, speculative) {\n    if (!this.recognizer) {\n      return true;\n    }\n    if (!speculative) {\n      return this.recognizer.sempred(null, ruleIndex, predIndex);\n    }\n    const savedColumn = this.column;\n    const savedLine = this.line;\n    const index = input.index;\n    const marker = input.mark();\n    try {\n      this.consume(input);\n      return this.recognizer.sempred(null, ruleIndex, predIndex);\n    } finally {\n      this.column = savedColumn;\n      this.line = savedLine;\n      input.seek(index);\n      input.release(marker);\n    }\n  }\n  captureSimState(input, dfaState) {\n    this.#prevAccept = {\n      index: input.index,\n      line: this.line,\n      column: this.column,\n      dfaState\n    };\n  }\n  addDFAEdge(from, tk, to, configs) {\n    if (!to && configs) {\n      const suppressEdge = configs.hasSemanticContext;\n      configs.hasSemanticContext = false;\n      to = this.addDFAState(configs);\n      if (suppressEdge) {\n        return to;\n      }\n    }\n    if (tk < this.#options.minDFAEdge || tk > this.#options.maxDFAEdge) {\n      return to;\n    }\n    if (_LexerATNSimulator.debug) {\n      console.log(\"EDGE \" + from + \" -> \" + to + \" upon \" + tk);\n    }\n    from.edges[tk - this.#options.minDFAEdge] = to;\n    return to;\n  }\n  /**\n   * Add a new DFA state if there isn't one with this set of configurations already. This method also detects\n   * the first configuration containing an ATN rule stop state. Later, when traversing the DFA, we will know\n   * which rule to accept.\n   */\n  addDFAState(configs) {\n    const dfa = this.decisionToDFA[this.mode];\n    const existing = dfa.getStateForConfigs(configs);\n    if (existing) {\n      return existing;\n    }\n    const proposed = DFAState.fromConfigs(configs);\n    const firstConfigWithRuleStopState = configs.firstStopState;\n    if (firstConfigWithRuleStopState) {\n      proposed.isAcceptState = true;\n      proposed.lexerActionExecutor = firstConfigWithRuleStopState.lexerActionExecutor;\n      proposed.prediction = this.atn.ruleToTokenType[firstConfigWithRuleStopState.state.ruleIndex];\n    }\n    configs.setReadonly(true);\n    dfa.addState(proposed);\n    return proposed;\n  }\n};\n\n// src/atn/ParseInfo.ts\nvar ParseInfo = class {\n  static {\n    __name(this, \"ParseInfo\");\n  }\n  atnSimulator;\n  constructor(atnSimulator) {\n    this.atnSimulator = atnSimulator;\n  }\n  /**\n   * Gets an array of {@link DecisionInfo} instances containing the profiling\n   * information gathered for each decision in the ATN.\n   *\n   * @returns An array of {@link DecisionInfo} instances, indexed by decision\n   * number.\n   */\n  getDecisionInfo() {\n    return this.atnSimulator.getDecisionInfo();\n  }\n  /**\n   * Gets the decision numbers for decisions that required one or more\n   * full-context predictions during parsing. These are decisions for which\n   * {@link DecisionInfo#llFallback} is non-zero.\n   *\n   * @returns A list of decision numbers which required one or more\n   * full-context predictions during parsing.\n   */\n  getLLDecisions() {\n    const decisions = this.atnSimulator.getDecisionInfo();\n    const result = new Array();\n    for (let i = 0; i < decisions.length; i++) {\n      const fallBack = decisions[i].llFallback;\n      if (fallBack > 0) {\n        result.push(i);\n      }\n    }\n    return result;\n  }\n  /**\n   * Gets the total time spent during prediction across all decisions made\n   * during parsing. This value is the sum of\n   * {@link DecisionInfo#timeInPrediction} for all decisions.\n   */\n  getTotalTimeInPrediction() {\n    const decisions = this.atnSimulator.getDecisionInfo();\n    let t = 0;\n    for (const decision of decisions) {\n      t += decision.timeInPrediction;\n    }\n    return t;\n  }\n  /**\n   * Gets the total number of SLL lookahead operations across all decisions\n   * made during parsing. This value is the sum of\n   * {@link DecisionInfo#sllTotalLook} for all decisions.\n   */\n  getTotalSLLLookaheadOps() {\n    const decisions = this.atnSimulator.getDecisionInfo();\n    let k = 0;\n    for (const decision of decisions) {\n      k += decision.sllTotalLook;\n    }\n    return k;\n  }\n  /**\n   * Gets the total number of LL lookahead operations across all decisions\n   * made during parsing. This value is the sum of\n   * {@link DecisionInfo#llTotalLook} for all decisions.\n   */\n  getTotalLLLookaheadOps() {\n    const decisions = this.atnSimulator.getDecisionInfo();\n    let k = 0;\n    for (const decision of decisions) {\n      k += decision.llTotalLook;\n    }\n    return k;\n  }\n  /**\n   * Gets the total number of ATN lookahead operations for SLL prediction\n   * across all decisions made during parsing.\n   */\n  getTotalSLLATNLookaheadOps() {\n    const decisions = this.atnSimulator.getDecisionInfo();\n    let k = 0;\n    for (const decision of decisions) {\n      k += decision.sllATNTransitions;\n    }\n    return k;\n  }\n  /**\n   * Gets the total number of ATN lookahead operations for LL prediction\n   * across all decisions made during parsing.\n   */\n  getTotalLLATNLookaheadOps() {\n    const decisions = this.atnSimulator.getDecisionInfo();\n    let k = 0;\n    for (const decision of decisions) {\n      k += decision.llATNTransitions;\n    }\n    return k;\n  }\n  /**\n   * Gets the total number of ATN lookahead operations for SLL and LL\n   * prediction across all decisions made during parsing.\n   *\n   *\n   * This value is the sum of {@link #getTotalSLLATNLookaheadOps} and\n   * {@link #getTotalLLATNLookaheadOps}.\n   */\n  getTotalATNLookaheadOps() {\n    const decisions = this.atnSimulator.getDecisionInfo();\n    let k = 0;\n    for (const decision of decisions) {\n      k += decision.sllATNTransitions;\n      k += decision.llATNTransitions;\n    }\n    return k;\n  }\n  getDFASize(decision) {\n    if (decision === void 0) {\n      let n2 = 0;\n      const decisionToDFA = this.atnSimulator.decisionToDFA;\n      for (let i = 0; i < decisionToDFA.length; i++) {\n        n2 += this.getDFASize(i);\n      }\n      return n2;\n    } else {\n      const decisionToDFA = this.atnSimulator.decisionToDFA[decision];\n      return decisionToDFA.length;\n    }\n  }\n};\n\n// src/NoViableAltException.ts\nvar NoViableAltException = class extends RecognitionException {\n  static {\n    __name(this, \"NoViableAltException\");\n  }\n  /** Which configurations did we try at input.index() that couldn't match input.LT(1)? */\n  deadEndConfigs = null;\n  /**\n   * The token object at the start index; the input stream might\n   * \tnot be buffering tokens so get a reference to it. (At the\n   *  time the error occurred, of course the stream needs to keep a\n   *  buffer all of the tokens but later we might not have access to those.)\n   */\n  startToken;\n  constructor(recognizer, input = null, startToken = null, offendingToken = null, deadEndConfigs = null, ctx = null) {\n    ctx = ctx ?? recognizer.context;\n    offendingToken = offendingToken ?? recognizer.getCurrentToken();\n    startToken = startToken ?? recognizer.getCurrentToken();\n    input = input ?? recognizer.inputStream;\n    super({ message: \"\", recognizer, input, ctx });\n    this.deadEndConfigs = deadEndConfigs;\n    this.startToken = startToken;\n    this.offendingToken = offendingToken;\n  }\n};\n\n// src/utils/DoubleDict.ts\nvar DoubleDict = class {\n  static {\n    __name(this, \"DoubleDict\");\n  }\n  cacheMap;\n  constructor() {\n    this.cacheMap = new HashMap(DefaultEqualityComparator.instance);\n  }\n  get(a, b) {\n    const d = this.cacheMap.get(a) ?? null;\n    return d === null ? null : d.get(b) ?? null;\n  }\n  set(a, b, o) {\n    let d = this.cacheMap.get(a);\n    if (!d) {\n      d = new HashMap(DefaultEqualityComparator.instance);\n      this.cacheMap.set(a, d);\n    }\n    d.set(b, o);\n  }\n};\n\n// src/atn/PredictionMode.ts\nvar SubsetEqualityComparer = class _SubsetEqualityComparer {\n  static {\n    __name(this, \"SubsetEqualityComparer\");\n  }\n  static instance = new _SubsetEqualityComparer();\n  hashCode(config) {\n    let hashCode = MurmurHash.initialize(7);\n    hashCode = MurmurHash.update(hashCode, config.state.stateNumber);\n    hashCode = MurmurHash.updateFromComparable(hashCode, config.context);\n    hashCode = MurmurHash.finish(hashCode, 2);\n    return hashCode;\n  }\n  equals(a, b) {\n    return a.state.stateNumber === b.state.stateNumber && (a.context?.equals(b.context) ?? true);\n  }\n};\nvar PredictionMode = class _PredictionMode {\n  static {\n    __name(this, \"PredictionMode\");\n  }\n  /**\n   * The SLL(*) prediction mode. This prediction mode ignores the current\n   * parser context when making predictions. This is the fastest prediction\n   * mode, and provides correct results for many grammars. This prediction\n   * mode is more powerful than the prediction mode provided by ANTLR 3, but\n   * may result in syntax errors for grammar and input combinations which are\n   * not SLL.\n   *\n   *\n   * When using this prediction mode, the parser will either return a correct\n   * parse tree (i.e. the same parse tree that would be returned with the\n   * {@link LL} prediction mode), or it will report a syntax error. If a\n   * syntax error is encountered when using the {@link SLL} prediction mode,\n   * it may be due to either an actual syntax error in the input or indicate\n   * that the particular combination of grammar and input requires the more\n   * powerful {@link LL} prediction abilities to complete successfully.\n   *\n   *\n   * This prediction mode does not provide any guarantees for prediction\n   * behavior for syntactically-incorrect inputs.\n   */\n  static SLL = 0;\n  /**\n   * The LL(*) prediction mode. This prediction mode allows the current parser\n   * context to be used for resolving SLL conflicts that occur during\n   * prediction. This is the fastest prediction mode that guarantees correct\n   * parse results for all combinations of grammars with syntactically correct\n   * inputs.\n   *\n   *\n   * When using this prediction mode, the parser will make correct decisions\n   * for all syntactically-correct grammar and input combinations. However, in\n   * cases where the grammar is truly ambiguous this prediction mode might not\n   * report a precise answer for *exactly which* alternatives are\n   * ambiguous.\n   *\n   *\n   * This prediction mode does not provide any guarantees for prediction\n   * behavior for syntactically-incorrect inputs.\n   */\n  static LL = 1;\n  /**\n   *\n   * The LL(*) prediction mode with exact ambiguity detection. In addition to\n   * the correctness guarantees provided by the {@link LL} prediction mode,\n   * this prediction mode instructs the prediction algorithm to determine the\n   * complete and exact set of ambiguous alternatives for every ambiguous\n   * decision encountered while parsing.\n   *\n   *\n   * This prediction mode may be used for diagnosing ambiguities during\n   * grammar development. Due to the performance overhead of calculating sets\n   * of ambiguous alternatives, this prediction mode should be avoided when\n   * the exact results are not necessary.\n   *\n   *\n   * This prediction mode does not provide any guarantees for prediction\n   * behavior for syntactically-incorrect inputs.\n   */\n  static LL_EXACT_AMBIG_DETECTION = 2;\n  /**\n   *\n   *Computes the SLL prediction termination condition.\n   *\n   *\n   *This method computes the SLL prediction termination condition for both of\n   *the following cases.\n   *\n   * - The usual SLL+LL fallback upon SLL conflict\n   * - Pure SLL without LL fallback\n   *\n   ***COMBINED SLL+LL PARSING**\n   *\n   *When LL-fallback is enabled upon SLL conflict, correct predictions are\n   *ensured regardless of how the termination condition is computed by this\n   *method. Due to the substantially higher cost of LL prediction, the\n   *prediction should only fall back to LL when the additional lookahead\n   *cannot lead to a unique SLL prediction.\n   *\n   *Assuming combined SLL+LL parsing, an SLL configuration set with only\n   *conflicting subsets should fall back to full LL, even if the\n   *configuration sets don't resolve to the same alternative (e.g.\n   *`{1,2`} and `{3,4`}. If there is at least one non-conflicting\n   *configuration, SLL could continue with the hopes that more lookahead will\n   *resolve via one of those non-conflicting configurations.\n   *\n   *Here's the prediction termination rule them: SLL (for SLL+LL parsing)\n   *stops when it sees only conflicting configuration subsets. In contrast,\n   *full LL keeps going when there is uncertainty.\n   *\n   ***HEURISTIC**\n   *\n   *As a heuristic, we stop prediction when we see any conflicting subset\n   *unless we see a state that only has one alternative associated with it.\n   *The single-alt-state thing lets prediction continue upon rules like\n   *(otherwise, it would admit defeat too soon):\n   *\n   *`[12|1|[], 6|2|[], 12|2|[]]. s : (ID | ID ID?) ';' ;`\n   *\n   *When the ATN simulation reaches the state before `';'`, it has a\n   *DFA state that looks like: `[12|1|[], 6|2|[], 12|2|[]]`. Naturally\n   *`12|1|[]` and `12|2|[]` conflict, but we cannot stop\n   *processing this node because alternative to has another way to continue,\n   *via `[6|2|[]]`.\n   *\n   *It also let's us continue for this rule:\n   *\n   *`[1|1|[], 1|2|[], 8|3|[]] a : A | A | A B ;`\n   *\n   *After matching input A, we reach the stop state for rule A, state 1.\n   *State 8 is the state right before B. Clearly alternatives 1 and 2\n   *conflict and no amount of further lookahead will separate the two.\n   *However, alternative 3 will be able to continue and so we do not stop\n   *working on this state. In the previous example, we're concerned with\n   *states associated with the conflicting alternatives. Here alt 3 is not\n   *associated with the conflicting configs, but since we can continue\n   *looking for input reasonably, don't declare the state done.\n   *\n   ***PURE SLL PARSING**\n   *\n   *To handle pure SLL parsing, all we have to do is make sure that we\n   *combine stack contexts for configurations that differ only by semantic\n   *predicate. From there, we can do the usual SLL termination heuristic.\n   *\n   ***PREDICATES IN SLL+LL PARSING**\n   *\n   *SLL decisions don't evaluate predicates until after they reach DFA stop\n   *states because they need to create the DFA cache that works in all\n   *semantic situations. In contrast, full LL evaluates predicates collected\n   *during start state computation so it can ignore predicates thereafter.\n   *This means that SLL termination detection can totally ignore semantic\n   *predicates.\n   *\n   *Implementation-wise, {@link ATNConfigSet} combines stack contexts but not\n   *semantic predicate contexts so we might see two configurations like the\n   *following.\n   *\n   *`(s, 1, x, {`), (s, 1, x', {p})}\n   *\n   *Before testing these configurations against others, we have to merge\n   *`x` and `x'` (without modifying the existing configurations).\n   *For example, we test `(x+x')==x''` when looking for conflicts in\n   *the following configurations.\n   *\n   *`(s, 1, x, {`), (s, 1, x', {p}), (s, 2, x'', {})}\n   *\n   *If the configuration set has predicates (as indicated by\n   *{@link ATNConfigSet//hasSemanticContext}), this algorithm makes a copy of\n   *the configurations to strip out all of the predicates so that a standard\n   *{@link ATNConfigSet} will merge everything ignoring predicates.\n   */\n  static hasSLLConflictTerminatingPrediction(mode, configs) {\n    if (_PredictionMode.allConfigsInRuleStopStates(configs)) {\n      return true;\n    }\n    if (mode === _PredictionMode.SLL) {\n      if (configs.hasSemanticContext) {\n        const dup = new ATNConfigSet();\n        for (let c of configs) {\n          c = ATNConfig.duplicate(c, SemanticContext.NONE);\n          dup.add(c);\n        }\n        configs = dup;\n      }\n    }\n    const altSets = _PredictionMode.getConflictingAltSubsets(configs);\n    return _PredictionMode.hasConflictingAltSet(altSets) && !_PredictionMode.hasStateAssociatedWithOneAlt(configs);\n  }\n  /**\n   * Checks if any configuration in `configs` is in a\n   * {@link RuleStopState}. Configurations meeting this condition have reached\n   * the end of the decision rule (local context) or end of start rule (full\n   * context).\n   *\n   * @param configs the configuration set to test\n   * @returns `true` if any configuration in `configs` is in a\n   * {@link RuleStopState}, otherwise `false`\n   */\n  static hasConfigInRuleStopState(configs) {\n    for (const c of configs) {\n      if (c.state instanceof RuleStopState) {\n        return true;\n      }\n    }\n    return false;\n  }\n  /**\n   * Checks if all configurations in `configs` are in a\n   * {@link RuleStopState}. Configurations meeting this condition have reached\n   * the end of the decision rule (local context) or end of start rule (full\n   * context).\n   *\n   * @param configs the configuration set to test\n   * @returns `true` if all configurations in `configs` are in a\n   * {@link RuleStopState}, otherwise `false`\n   */\n  static allConfigsInRuleStopStates(configs) {\n    for (const c of configs) {\n      if (!(c.state instanceof RuleStopState)) {\n        return false;\n      }\n    }\n    return true;\n  }\n  /**\n   *\n   * Full LL prediction termination.\n   *\n   * Can we stop looking ahead during ATN simulation or is there some\n   * uncertainty as to which alternative we will ultimately pick, after\n   * consuming more input? Even if there are partial conflicts, we might know\n   * that everything is going to resolve to the same minimum alternative. That\n   * means we can stop since no more lookahead will change that fact. On the\n   * other hand, there might be multiple conflicts that resolve to different\n   * minimums. That means we need more look ahead to decide which of those\n   * alternatives we should predict.\n   *\n   * The basic idea is to split the set of configurations `C`, into\n   * conflicting subsets `(s, _, ctx, _)` and singleton subsets with\n   * non-conflicting configurations. Two configurations conflict if they have\n   * identical {@link ATNConfig.state} and {@link ATNConfig.context} values\n   * but different {@link ATNConfig.alt} value, e.g. `(s, i, ctx, _)`\n   * and `(s, j, ctx, _)` for `i!=j`.\n   *\n   * Reduce these configuration subsets to the set of possible alternatives.\n   * You can compute the alternative subsets in one pass as follows:\n   *\n   * `A_s,ctx = {i | (s, i, ctx, _)`} for each configuration in\n   * `C` holding `s` and `ctx` fixed.\n   *\n   * Or in pseudo-code, for each configuration `c` in `C`:\n   *\n   * ```\n   * map[c] U= c.{@link ATNConfig.alt alt} // map hash/equals uses s and x, not\n   * alt and not pred\n   * ```\n   *\n   * The values in `map` are the set of `A_s,ctx` sets.\n   *\n   * If `|A_s,ctx|=1` then there is no conflict associated with\n   * `s` and `ctx`.\n   *\n   * Reduce the subsets to singletons by choosing a minimum of each subset. If\n   * the union of these alternative subsets is a singleton, then no amount of\n   * more lookahead will help us. We will always pick that alternative. If,\n   * however, there is more than one alternative, then we are uncertain which\n   * alternative to predict and must continue looking for resolution. We may\n   * or may not discover an ambiguity in the future, even if there are no\n   * conflicting subsets this round.\n   *\n   * The biggest sin is to terminate early because it means we've made a\n   * decision but were uncertain as to the eventual outcome. We haven't used\n   * enough lookahead. On the other hand, announcing a conflict too late is no\n   * big deal; you will still have the conflict. It's just inefficient. It\n   * might even look until the end of file.\n   *\n   * No special consideration for semantic predicates is required because\n   * predicates are evaluated on-the-fly for full LL prediction, ensuring that\n   * no configuration contains a semantic context during the termination\n   * check.\n   *\n   * **CONFLICTING CONFIGS**\n   *\n   * Two configurations `(s, i, x)` and `(s, j, x')`, conflict when `i!=j` but `x=x'`. Because we merge all\n   * `(s, i, _)` configurations together, that means that there are at most `n` configurations associated with state\n   * `s` for `n` possible alternatives in the decision. The merged stacks complicate the comparison of configuration\n   * contexts `x` and `x'`. Sam checks to see if one is a subset of the other by calling merge and checking to see\n   * if the merged result is either `x` or `x'`. If the `x` associated with lowest alternative `i` is the superset,\n   * then `i` is the only possible prediction since the others resolve to `min(i)` as well. However, if `x` is\n   * associated with `j>i` then at least one stack configuration for `j` is not in conflict with alternative `i`.\n   * The algorithm should keep going, looking for more lookahead due to the uncertainty.\n   *\n   * For simplicity, I'm doing a equality check between `x` and `x'` that lets the algorithm continue to consume\n   * lookahead longer than necessary. The reason I like the equality is of course the simplicity but also because\n   * that is the test you need to detect the alternatives that are actually in conflict.\n   *\n   * **CONTINUE/STOP RULE**\n   *\n   * Continue if union of resolved alternative sets from non-conflicting and conflicting alternative subsets has more\n   * than one alternative. We are uncertain about which alternative to predict.\n   *\n   * The complete set of alternatives, `[i for (_,i,_)]`, tells us which alternatives are still in the running for\n   * the amount of input we've consumed at this point. The conflicting sets let us to strip away configurations that\n   * won't lead to more states because we resolve conflicts to the configuration with a minimum alternate for the\n   * conflicting set.\n   *\n   * **CASES**\n   *\n   * - no conflicts and more than 1 alternative in set => continue\n   * -  `(s, 1, x)`, `(s, 2, x)`, `(s, 3, z)`, `(s', 1, y)`, `(s', 2, y)` yields non-conflicting set `{3`} U\n   *   conflicting sets `min({1,2`)} U `min({1,2`)} = `{1,3`} => continue\n   * - `(s, 1, x)`, `(s, 2, x)`, `(s', 1, y)`, `(s', 2, y)`, `(s'', 1, z)` yields non-conflicting set `{1`} U\n   *   conflicting sets `min({1,2`)} U `min({1,2`)} = `{1`} => stop and predict 1\n   * - `(s, 1, x)`, `(s, 2, x)`, `(s', 1, y)`, `(s', 2, y)` yields conflicting, reduced sets `{1`} U\n   *   `{1`} = `{1`} => stop and predict 1, can announce ambiguity `{1,2`}\n   * - `(s, 1, x)`, `(s, 2, x)`, `(s', 2, y)`, `(s', 3, y)` yields conflicting, reduced sets `{1`} U\n   *   `{2`} = `{1,2`} => continue\n   * - `(s, 1, x)`, `(s, 2, x)`, `(s', 3, y)`, `(s', 4, y)` yields conflicting, reduced sets `{1`} U\n   *   `{3`} = `{1,3`} => continue\n   *\n   * **EXACT AMBIGUITY DETECTION**\n   *\n   *If all states report the same conflicting set of alternatives, then we\n   *know we have the exact ambiguity set.\n   *\n   * `|A_*i*|>1` and `A_*i* = A_*j*` for all *i*, *j*.\n   *\n   * In other words, we continue examining lookahead until all `A_i` have more than one alternative and all `A_i`\n   * are the same. If `A={{1,2`, {1,3}}}, then regular LL prediction would terminate because the resolved set\n   * is `{1`}. To determine what the real ambiguity is, we have to know whether the ambiguity is between one and\n   * two or one and three so we keep going. We can only stop prediction when we need exact ambiguity detection when\n   * the sets look like `A={{1,2`}} or `{{1,2`,{1,2}}}, etc...\n   */\n  static resolvesToJustOneViableAlt(altSets) {\n    return _PredictionMode.getSingleViableAlt(altSets);\n  }\n  /**\n   * Determines if every alternative subset in `altSets` contains more\n   * than one alternative.\n   *\n   * @param altSets a collection of alternative subsets\n   * @returns `true` if every {@link BitSet} in `altSets` has\n   * {@link BitSet//cardinality cardinality} > 1, otherwise `false`\n   */\n  static allSubsetsConflict(altSets) {\n    return !_PredictionMode.hasNonConflictingAltSet(altSets);\n  }\n  /**\n   * Determines if any single alternative subset in `altSets` contains\n   * exactly one alternative.\n   *\n   * @param altSets a collection of alternative subsets\n   * @returns `true` if `altSets` contains a {@link BitSet} with\n   * {@link BitSet//cardinality cardinality} 1, otherwise `false`\n   */\n  static hasNonConflictingAltSet(altSets) {\n    for (const alts of altSets) {\n      if (alts.length === 1) {\n        return true;\n      }\n    }\n    return false;\n  }\n  /**\n   * Determines if any single alternative subset in `altSets` contains\n   * more than one alternative.\n   *\n   * @param altSets a collection of alternative subsets\n   * @returns `true` if `altSets` contains a {@link BitSet} with\n   * {@link BitSet//cardinality cardinality} > 1, otherwise `false`\n   */\n  static hasConflictingAltSet(altSets) {\n    for (const alts of altSets) {\n      if (alts.length > 1) {\n        return true;\n      }\n    }\n    return false;\n  }\n  /**\n   * Determines if every alternative subset in `altSets` is equivalent.\n   *\n   * @param altSets a collection of alternative subsets\n   * @returns `true` if every member of `altSets` is equal to the\n   * others, otherwise `false`\n   */\n  static allSubsetsEqual(altSets) {\n    let first = null;\n    for (const alts of altSets) {\n      if (first === null) {\n        first = alts;\n      } else if (alts !== first) {\n        return false;\n      }\n    }\n    return true;\n  }\n  /**\n   * Returns the unique alternative predicted by all alternative subsets in\n   * `altSets`. If no such alternative exists, this method returns\n   * {@link ATN.INVALID_ALT_NUMBER}.\n   *\n   * @param altSets a collection of alternative subsets\n   */\n  static getUniqueAlt(altSets) {\n    const all = _PredictionMode.getAlts(altSets);\n    if (all.length === 1) {\n      return all.nextSetBit(0);\n    } else {\n      return ATN.INVALID_ALT_NUMBER;\n    }\n  }\n  /**\n   * Gets the complete set of represented alternatives for a collection of\n   * alternative subsets. This method returns the union of each {@link BitSet}\n   * in `altSets`.\n   *\n   * @param altSets a collection of alternative subsets\n   * @returns the set of represented alternatives in `altSets`\n   */\n  static getAlts(altSets) {\n    const all = new BitSet();\n    altSets.forEach((alts) => {\n      all.or(alts);\n    });\n    return all;\n  }\n  /**\n   * This function gets the conflicting alt subsets from a configuration set.\n   * For each configuration `c` in `configs`:\n   *\n   * ```\n   * map[c] U= c.{@link ATNConfig.alt alt} // map hash/equals uses s and x, not\n   * alt and not pred\n   * ```\n   */\n  static getConflictingAltSubsets(configs) {\n    const configToAlts = new HashMap(SubsetEqualityComparer.instance);\n    for (const cfg of configs) {\n      let alts = configToAlts.get(cfg);\n      if (!alts) {\n        alts = new BitSet();\n        configToAlts.set(cfg, alts);\n      }\n      alts.set(cfg.alt);\n    }\n    return Array.from(configToAlts.values());\n  }\n  /**\n   * Get a map from state to alt subset from a configuration set. For each configuration `c` in `configs`:\n   *\n   * ```\n   * map[c.state] = c.alt\n   * ```\n   */\n  static getStateToAltMap(configs) {\n    const m2 = new HashMap(ObjectEqualityComparator.instance);\n    for (const c of configs) {\n      let alts = m2.get(c.state);\n      if (!alts) {\n        alts = new BitSet();\n        m2.set(c.state, alts);\n      }\n      alts.set(c.alt);\n    }\n    return m2;\n  }\n  static hasStateAssociatedWithOneAlt(configs) {\n    const counts = {};\n    for (const c of configs) {\n      const stateNumber = c.state.stateNumber;\n      if (!counts[stateNumber]) {\n        counts[stateNumber] = 0;\n      }\n      counts[stateNumber]++;\n    }\n    return Object.values(counts).some((count) => {\n      return count === 1;\n    });\n  }\n  static getSingleViableAlt(altSets) {\n    let result = null;\n    for (const alts of altSets) {\n      const minAlt = alts.nextSetBit(0);\n      if (result === null) {\n        result = minAlt;\n      } else if (result !== minAlt) {\n        return ATN.INVALID_ALT_NUMBER;\n      }\n    }\n    return result ?? 0;\n  }\n};\n\n// src/atn/ParserATNSimulator.ts\nvar ParserATNSimulator = class _ParserATNSimulator extends ATNSimulator {\n  static {\n    __name(this, \"ParserATNSimulator\");\n  }\n  static traceATNSimulator = false;\n  static debug;\n  static debugAdd = false;\n  static debugClosure = false;\n  static dfaDebug = false;\n  static retryDebug = false;\n  /** SLL, LL, or LL + exact ambig detection? */\n  predictionMode;\n  decisionToDFA;\n  parser;\n  /**\n   * Each prediction operation uses a cache for merge of prediction contexts.\n   * Don't keep around as it wastes huge amounts of memory. DoubleKeyMap\n   * isn't synchronized but we're ok since two threads shouldn't reuse same\n   * parser/atn sim object because it can only handle one input at a time.\n   * This maps graphs a and b to merged result c. (a,b)->c. We can avoid\n   * the merge if we ever see a and b again.  Note that (b,a)->c should\n   * also be examined during cache lookup.\n   */\n  mergeCache = new DoubleDict();\n  // Used also in the profiling ATN simulator.\n  predictionState;\n  constructor(recog, atn, decisionToDFA, sharedContextCache) {\n    super(atn, sharedContextCache);\n    this.parser = recog;\n    this.decisionToDFA = decisionToDFA;\n  }\n  static getUniqueAlt(configs) {\n    let alt = ATN.INVALID_ALT_NUMBER;\n    for (const c of configs) {\n      if (alt === ATN.INVALID_ALT_NUMBER) {\n        alt = c.alt;\n      } else if (c.alt !== alt) {\n        return ATN.INVALID_ALT_NUMBER;\n      }\n    }\n    return alt;\n  }\n  reset() {\n  }\n  clearDFA() {\n    for (let d = 0; d < this.decisionToDFA.length; d++) {\n      this.decisionToDFA[d] = new DFA(this.atn.getDecisionState(d), d);\n    }\n  }\n  // TODO: make outerContext an optional parameter, not optional null.\n  adaptivePredict(input, decision, outerContext) {\n    if (_ParserATNSimulator.debug || _ParserATNSimulator.traceATNSimulator) {\n      console.log(\"adaptivePredict decision \" + decision + \" exec LA(1)==\" + this.getLookaheadName(input) + \" line \" + input.LT(1).line + \":\" + input.LT(1).column);\n    }\n    const dfa = this.decisionToDFA[decision];\n    this.predictionState = {\n      input,\n      startIndex: input.index,\n      outerContext: outerContext ?? void 0,\n      dfa\n    };\n    const m2 = input.mark();\n    const index = input.index;\n    try {\n      let s0;\n      if (dfa.isPrecedenceDfa) {\n        s0 = dfa.getPrecedenceStartState(this.parser.getPrecedence());\n      } else {\n        s0 = dfa.s0;\n      }\n      if (!s0) {\n        if (!outerContext) {\n          outerContext = ParserRuleContext.empty;\n        }\n        if (_ParserATNSimulator.debug) {\n          console.log(\"predictATN decision \" + dfa.decision + \" exec LA(1)==\" + this.getLookaheadName(input) + \", outerContext=\" + outerContext.toString(this.parser.ruleNames));\n        }\n        const fullCtx = false;\n        let s0_closure = this.computeStartState(dfa.atnStartState, ParserRuleContext.empty, fullCtx);\n        if (dfa.isPrecedenceDfa) {\n          s0_closure = this.applyPrecedenceFilter(s0_closure);\n          s0 = this.addDFAState(dfa, DFAState.fromConfigs(s0_closure));\n          dfa.setPrecedenceStartState(this.parser.getPrecedence(), s0);\n        } else {\n          s0 = this.addDFAState(dfa, DFAState.fromConfigs(s0_closure));\n          dfa.s0 = s0;\n        }\n      }\n      const alt = this.execATN(dfa, s0, input, index, outerContext);\n      if (_ParserATNSimulator.debug) {\n        console.log(\"DFA after predictATN: \" + dfa.toString(this.parser.vocabulary));\n      }\n      return alt;\n    } finally {\n      this.predictionState.dfa = void 0;\n      this.mergeCache = new DoubleDict();\n      input.seek(index);\n      input.release(m2);\n    }\n  }\n  /**\n   * Performs ATN simulation to compute a predicted alternative based\n   *  upon the remaining input, but also updates the DFA cache to avoid\n   *  having to traverse the ATN again for the same input sequence.\n   *\n   * There are some key conditions we're looking for after computing a new\n   * set of ATN configs (proposed DFA state):\n   *       if the set is empty, there is no viable alternative for current symbol\n   *       does the state uniquely predict an alternative?\n   *       does the state have a conflict that would prevent us from\n   *         putting it on the work list?\n   *\n   * We also have some key operations to do:\n   *       add an edge from previous DFA state to potentially new DFA state, D,\n   *         upon current symbol but only if adding to work list, which means in all\n   *         cases except no viable alternative (and possibly non-greedy decisions?)\n   *       collecting predicates and adding semantic context to DFA accept states\n   *       adding rule context to context-sensitive DFA accept states\n   *       consuming an input symbol\n   *       reporting a conflict\n   *       reporting an ambiguity\n   *       reporting a context sensitivity\n   *       reporting insufficient predicates\n   *\n   * cover these cases:\n   *    dead end\n   *    single alt\n   *    single alt + preds\n   *    conflict\n   *    conflict + preds\n   */\n  execATN(dfa, s0, input, startIndex, outerContext) {\n    if (_ParserATNSimulator.debug || _ParserATNSimulator.traceATNSimulator) {\n      console.log(\"execATN decision \" + dfa.decision + \", DFA state \" + s0 + \", LA(1)==\" + this.getLookaheadName(input) + \" line \" + input.LT(1).line + \":\" + input.LT(1).column);\n    }\n    let alt;\n    let previousState = s0;\n    let t = input.LA(1);\n    while (true) {\n      let nextState = this.getExistingTargetState(previousState, t);\n      if (!nextState) {\n        nextState = this.computeTargetState(dfa, previousState, t);\n      }\n      if (nextState === ATNSimulator.ERROR) {\n        const e = this.noViableAlt(input, outerContext, previousState.configs, startIndex);\n        input.seek(startIndex);\n        alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previousState.configs, outerContext);\n        if (alt !== ATN.INVALID_ALT_NUMBER) {\n          return alt;\n        } else {\n          throw e;\n        }\n      }\n      if (nextState.requiresFullContext && this.predictionMode !== PredictionMode.SLL) {\n        let conflictingAlts = null;\n        if (nextState.predicates !== null) {\n          if (_ParserATNSimulator.debug) {\n            console.log(\"DFA state has preds in DFA sim LL failover\");\n          }\n          const conflictIndex = input.index;\n          if (conflictIndex !== startIndex) {\n            input.seek(startIndex);\n          }\n          conflictingAlts = this.evalSemanticContext(nextState.predicates, outerContext, true);\n          if (conflictingAlts.length === 1) {\n            if (_ParserATNSimulator.debug) {\n              console.log(\"Full LL avoided\");\n            }\n            return conflictingAlts.nextSetBit(0);\n          }\n          if (conflictIndex !== startIndex) {\n            input.seek(conflictIndex);\n          }\n        }\n        if (_ParserATNSimulator.dfaDebug) {\n          console.log(\"ctx sensitive state \" + outerContext + \" in \" + nextState);\n        }\n        const fullCtx = true;\n        const s0_closure = this.computeStartState(dfa.atnStartState, outerContext, fullCtx);\n        this.reportAttemptingFullContext(dfa, conflictingAlts, nextState.configs, startIndex, input.index);\n        alt = this.execATNWithFullContext(dfa, nextState, s0_closure, input, startIndex, outerContext);\n        return alt;\n      }\n      if (nextState.isAcceptState) {\n        if (nextState.predicates === null) {\n          return nextState.prediction;\n        }\n        const stopIndex = input.index;\n        input.seek(startIndex);\n        const alts = this.evalSemanticContext(nextState.predicates, outerContext, true);\n        if (alts.length === 0) {\n          throw this.noViableAlt(input, outerContext, nextState.configs, startIndex);\n        }\n        if (alts.length === 1) {\n          return alts.nextSetBit(0);\n        }\n        this.reportAmbiguity(dfa, nextState, startIndex, stopIndex, false, alts, nextState.configs);\n        return alts.nextSetBit(0);\n      }\n      previousState = nextState;\n      if (t !== Token.EOF) {\n        input.consume();\n        t = input.LA(1);\n      }\n    }\n  }\n  /**\n   * Get an existing target state for an edge in the DFA. If the target state\n   * for the edge has not yet been computed or is otherwise not available,\n   * this method returns `null`.\n   *\n   * @param previousD The current DFA state\n   * @param t The next input symbol\n   * @returns The existing target DFA state for the given input symbol\n   * `t`, or `null` if the target state for this edge is not\n   * already cached\n   */\n  getExistingTargetState(previousD, t) {\n    return previousD.edges[t + 1];\n  }\n  /**\n   * Compute a target state for an edge in the DFA, and attempt to add the\n   * computed state and corresponding edge to the DFA.\n   *\n   * @param dfa The DFA\n   * @param previousD The current DFA state\n   * @param t The next input symbol\n   *\n   * @returns The computed target DFA state for the given input symbol\n   * `t`. If `t` does not lead to a valid DFA state, this method\n   * returns {@link ERROR\n   */\n  computeTargetState(dfa, previousD, t) {\n    const reach = this.computeReachSet(previousD.configs, t, false);\n    if (reach === null) {\n      this.addDFAEdge(dfa, previousD, t, ATNSimulator.ERROR);\n      return ATNSimulator.ERROR;\n    }\n    let D = DFAState.fromConfigs(reach);\n    const predictedAlt = _ParserATNSimulator.getUniqueAlt(reach);\n    if (_ParserATNSimulator.debug) {\n      const altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n      console.log(\"SLL altSubSets=\" + arrayToString(altSubSets) + /*\", previous=\" + previousD.configs + */\n      \", configs=\" + reach + \", predict=\" + predictedAlt + \", allSubsetsConflict=\" + PredictionMode.allSubsetsConflict(altSubSets) + \", conflictingAlts=\" + this.getConflictingAlts(reach));\n    }\n    if (predictedAlt !== ATN.INVALID_ALT_NUMBER) {\n      D.isAcceptState = true;\n      D.configs.uniqueAlt = predictedAlt;\n      D.prediction = predictedAlt;\n    } else if (PredictionMode.hasSLLConflictTerminatingPrediction(this.predictionMode, reach)) {\n      D.configs.conflictingAlts = this.getConflictingAlts(reach);\n      D.requiresFullContext = true;\n      D.isAcceptState = true;\n      D.prediction = D.configs.conflictingAlts.nextSetBit(0);\n    }\n    if (D.isAcceptState && D.configs.hasSemanticContext) {\n      this.predicateDFAState(D, this.atn.getDecisionState(dfa.decision));\n      if (D.predicates !== null) {\n        D.prediction = ATN.INVALID_ALT_NUMBER;\n      }\n    }\n    D = this.addDFAEdge(dfa, previousD, t, D);\n    return D;\n  }\n  getRuleName(index) {\n    if (this.parser !== null && index >= 0) {\n      return this.parser.ruleNames[index];\n    } else {\n      return \"<rule \" + index + \">\";\n    }\n  }\n  getTokenName(t) {\n    if (t === Token.EOF) {\n      return \"EOF\";\n    }\n    const vocabulary = this.parser?.vocabulary ?? Vocabulary.EMPTY_VOCABULARY;\n    const displayName = vocabulary.getDisplayName(t);\n    if (displayName === t.toString()) {\n      return displayName;\n    }\n    return displayName + \"<\" + t + \">\";\n  }\n  getLookaheadName(input) {\n    return this.getTokenName(input.LA(1));\n  }\n  /**\n   * Used for debugging in adaptivePredict around execATN but I cut\n   * it out for clarity now that alg. works well. We can leave this\n   * \"dead\" code for a bit\n   */\n  dumpDeadEndConfigs(e) {\n    console.log(\"dead end configs: \");\n    const decs = e.deadEndConfigs;\n    for (const c of decs) {\n      let trans = \"no edges\";\n      if (c.state.transitions.length > 0) {\n        const t = c.state.transitions[0];\n        if (t instanceof AtomTransition) {\n          trans = \"Atom \" + this.getTokenName(t.labelValue);\n        } else if (t instanceof SetTransition) {\n          const neg = t instanceof NotSetTransition;\n          trans = (neg ? \"~\" : \"\") + \"Set \" + t.label;\n        }\n      }\n      console.error(c.toString(this.parser, true) + \":\" + trans);\n    }\n  }\n  predicateDFAState(dfaState, decisionState) {\n    const altCount = decisionState.transitions.length;\n    const altsToCollectPredsFrom = this.getConflictingAltsOrUniqueAlt(dfaState.configs);\n    const altToPred = this.getPredsForAmbigAlts(altsToCollectPredsFrom, dfaState.configs, altCount);\n    if (altToPred !== null) {\n      dfaState.predicates = this.getPredicatePredictions(altsToCollectPredsFrom, altToPred);\n      dfaState.prediction = ATN.INVALID_ALT_NUMBER;\n    } else {\n      dfaState.prediction = altsToCollectPredsFrom.nextSetBit(0);\n    }\n  }\n  // comes back with reach.uniqueAlt set to a valid alt\n  execATNWithFullContext(dfa, D, s0, input, startIndex, outerContext) {\n    if (_ParserATNSimulator.debug || _ParserATNSimulator.traceATNSimulator) {\n      console.log(\"execATNWithFullContext \" + s0);\n    }\n    const fullCtx = true;\n    let foundExactAmbig = false;\n    let reach;\n    let previous = s0;\n    input.seek(startIndex);\n    let t = input.LA(1);\n    let predictedAlt = -1;\n    for (; ; ) {\n      reach = this.computeReachSet(previous, t, fullCtx);\n      if (reach === null) {\n        const e = this.noViableAlt(input, outerContext, previous, startIndex);\n        input.seek(startIndex);\n        const alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previous, outerContext);\n        if (alt !== ATN.INVALID_ALT_NUMBER) {\n          return alt;\n        } else {\n          throw e;\n        }\n      }\n      const altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n      if (_ParserATNSimulator.debug) {\n        console.log(\"LL altSubSets=\" + altSubSets + \", predict=\" + PredictionMode.getUniqueAlt(altSubSets) + \", resolvesToJustOneViableAlt=\" + PredictionMode.resolvesToJustOneViableAlt(altSubSets));\n      }\n      reach.uniqueAlt = _ParserATNSimulator.getUniqueAlt(reach);\n      if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER) {\n        predictedAlt = reach.uniqueAlt;\n        break;\n      } else if (this.predictionMode !== PredictionMode.LL_EXACT_AMBIG_DETECTION) {\n        predictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);\n        if (predictedAlt !== ATN.INVALID_ALT_NUMBER) {\n          break;\n        }\n      } else {\n        if (PredictionMode.allSubsetsConflict(altSubSets) && PredictionMode.allSubsetsEqual(altSubSets)) {\n          foundExactAmbig = true;\n          predictedAlt = PredictionMode.getSingleViableAlt(altSubSets);\n          break;\n        }\n      }\n      previous = reach;\n      if (t !== Token.EOF) {\n        input.consume();\n        t = input.LA(1);\n      }\n    }\n    if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER) {\n      this.reportContextSensitivity(dfa, predictedAlt, reach, startIndex, input.index);\n      return predictedAlt;\n    }\n    this.reportAmbiguity(dfa, D, startIndex, input.index, foundExactAmbig, void 0, reach);\n    return predictedAlt;\n  }\n  computeReachSet(closure, t, fullCtx) {\n    if (_ParserATNSimulator.debug) {\n      console.log(\"in computeReachSet, starting closure: \" + closure);\n    }\n    const intermediate = new ATNConfigSet(fullCtx);\n    let skippedStopStates = null;\n    for (const c of closure) {\n      if (_ParserATNSimulator.debug) {\n        console.log(\"testing \" + this.getTokenName(t) + \" at \" + c);\n      }\n      if (c.state instanceof RuleStopState) {\n        if (fullCtx || t === Token.EOF) {\n          if (skippedStopStates === null) {\n            skippedStopStates = [];\n          }\n          skippedStopStates.push(c);\n        }\n        continue;\n      }\n      for (const trans of c.state.transitions) {\n        const target = this.getReachableTarget(trans, t);\n        if (target !== null) {\n          const cfg = ATNConfig.createWithConfig(target, c);\n          intermediate.add(cfg, this.mergeCache);\n          if (_ParserATNSimulator.debugAdd) {\n            console.log(\"added \" + cfg + \" to intermediate\");\n          }\n        }\n      }\n    }\n    let reach = null;\n    if (skippedStopStates === null && t !== Token.EOF) {\n      if (intermediate.length === 1) {\n        reach = intermediate;\n      } else if (_ParserATNSimulator.getUniqueAlt(intermediate) !== ATN.INVALID_ALT_NUMBER) {\n        reach = intermediate;\n      }\n    }\n    if (reach === null) {\n      reach = new ATNConfigSet(fullCtx);\n      const closureBusy = new HashSet();\n      const treatEofAsEpsilon = t === Token.EOF;\n      for (const config of intermediate) {\n        this.closure(config, reach, closureBusy, false, fullCtx, treatEofAsEpsilon);\n      }\n    }\n    if (t === Token.EOF) {\n      reach = this.removeAllConfigsNotInRuleStopState(reach, reach === intermediate);\n    }\n    if (skippedStopStates !== null && (!fullCtx || !PredictionMode.hasConfigInRuleStopState(reach))) {\n      for (const config of skippedStopStates) {\n        reach.add(config, this.mergeCache);\n      }\n    }\n    if (_ParserATNSimulator.traceATNSimulator) {\n      console.log(\"computeReachSet \" + closure + \" -> \" + reach);\n    }\n    if (reach.length === 0) {\n      return null;\n    } else {\n      return reach;\n    }\n  }\n  /**\n   * Return a configuration set containing only the configurations from\n   * `configs` which are in a {@link RuleStopState}. If all\n   * configurations in `configs` are already in a rule stop state, this\n   * method simply returns `configs`.\n   *\n   * When `lookToEndOfRule` is true, this method uses\n   * {@link ATN.nextTokens} for each configuration in `configs` which is\n   * not already in a rule stop state to see if a rule stop state is reachable\n   * from the configuration via epsilon-only transitions.\n   *\n   * @param configs the configuration set to update\n   * @param lookToEndOfRule when true, this method checks for rule stop states\n   * reachable by epsilon-only transitions from each configuration in\n   * `configs`.\n   *\n   * @returns `configs` if all configurations in `configs` are in a\n   * rule stop state, otherwise return a new configuration set containing only\n   * the configurations from `configs` which are in a rule stop state\n   */\n  removeAllConfigsNotInRuleStopState(configs, lookToEndOfRule) {\n    if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n      return configs;\n    }\n    const result = new ATNConfigSet(configs.fullCtx);\n    for (const config of configs) {\n      if (config.state instanceof RuleStopState) {\n        result.add(config, this.mergeCache);\n        continue;\n      }\n      if (lookToEndOfRule && config.state.epsilonOnlyTransitions) {\n        const nextTokens = this.atn.nextTokens(config.state);\n        if (nextTokens.contains(Token.EPSILON)) {\n          const endOfRuleState = this.atn.ruleToStopState[config.state.ruleIndex];\n          result.add(ATNConfig.createWithConfig(endOfRuleState, config), this.mergeCache);\n        }\n      }\n    }\n    return result;\n  }\n  computeStartState(p, ctx, fullCtx) {\n    const initialContext = predictionContextFromRuleContext(this.atn, ctx);\n    const configs = new ATNConfigSet(fullCtx);\n    if (_ParserATNSimulator.traceATNSimulator) {\n      console.log(\"computeStartState from ATN state \" + p + \" initialContext=\" + initialContext.toString(this.parser));\n    }\n    for (let i = 0; i < p.transitions.length; i++) {\n      const target = p.transitions[i].target;\n      const c = ATNConfig.createWithContext(target, i + 1, initialContext);\n      const closureBusy = new HashSet();\n      this.closure(c, configs, closureBusy, true, fullCtx, false);\n    }\n    return configs;\n  }\n  /**\n   * This method transforms the start state computed by\n   * {@link computeStartState} to the special start state used by a\n   * precedence DFA for a particular precedence value. The transformation\n   * process applies the following changes to the start state's configuration\n   * set.\n   *\n   * 1. Evaluate the precedence predicates for each configuration using\n   * {@link SemanticContext//evalPrecedence}.\n   * 2. Remove all configurations which predict an alternative greater than\n   * 1, for which another configuration that predicts alternative 1 is in the\n   * same ATN state with the same prediction context. This transformation is\n   * valid for the following reasons:\n   * 3. The closure block cannot contain any epsilon transitions which bypass\n   * the body of the closure, so all states reachable via alternative 1 are\n   * part of the precedence alternatives of the transformed left-recursive\n   * rule.\n   * 4. The \"primary\" portion of a left recursive rule cannot contain an\n   * epsilon transition, so the only way an alternative other than 1 can exist\n   * in a state that is also reachable via alternative 1 is by nesting calls\n   * to the left-recursive rule, with the outer calls not being at the\n   * preferred precedence level.\n   *\n   *\n   * The prediction context must be considered by this filter to address\n   * situations like the following.\n   *\n   * `\n   * ```\n   * grammar TA;\n   * prog: statement* EOF;\n   * statement: letterA | statement letterA 'b' ;\n   * letterA: 'a';\n   * ```\n   * `\n   *\n   * If the above grammar, the ATN state immediately before the token\n   * reference `'a'` in `letterA` is reachable from the left edge\n   * of both the primary and closure blocks of the left-recursive rule\n   * `statement`. The prediction context associated with each of these\n   * configurations distinguishes between them, and prevents the alternative\n   * which stepped out to `prog` (and then back in to `statement`\n   * from being eliminated by the filter.\n   *\n   * @param configs The configuration set computed by\n   * {@link computeStartState} as the start state for the DFA.\n   * @returns The transformed configuration set representing the start state\n   * for a precedence DFA at a particular precedence level (determined by\n   * calling {@link Parser//getPrecedence})\n   */\n  applyPrecedenceFilter(configs) {\n    const statesFromAlt1 = [];\n    const configSet = new ATNConfigSet(configs.fullCtx);\n    for (const config of configs) {\n      if (config.alt !== 1) {\n        continue;\n      }\n      const updatedContext = config.semanticContext.evalPrecedence(\n        this.parser,\n        this.predictionState.outerContext\n      );\n      if (updatedContext === null) {\n        continue;\n      }\n      statesFromAlt1[config.state.stateNumber] = config.context;\n      if (updatedContext !== config.semanticContext) {\n        configSet.add(ATNConfig.duplicate(config, updatedContext), this.mergeCache);\n      } else {\n        configSet.add(config, this.mergeCache);\n      }\n    }\n    for (const config of configs) {\n      if (config.alt === 1) {\n        continue;\n      }\n      if (!config.precedenceFilterSuppressed) {\n        const context = statesFromAlt1[config.state.stateNumber] || null;\n        if (context !== null && context.equals(config.context)) {\n          continue;\n        }\n      }\n      configSet.add(config, this.mergeCache);\n    }\n    return configSet;\n  }\n  getReachableTarget(trans, ttype) {\n    if (trans.matches(ttype, 0, this.atn.maxTokenType)) {\n      return trans.target;\n    } else {\n      return null;\n    }\n  }\n  getPredsForAmbigAlts(ambigAlts, configs, altCount) {\n    let altToPred = [];\n    for (const c of configs) {\n      if (ambigAlts.get(c.alt)) {\n        altToPred[c.alt] = SemanticContext.orContext(altToPred[c.alt] ?? null, c.semanticContext);\n      }\n    }\n    let nPredAlts = 0;\n    for (let i = 1; i < altCount + 1; i++) {\n      const pred = altToPred[i] ?? null;\n      if (pred === null) {\n        altToPred[i] = SemanticContext.NONE;\n      } else if (pred !== SemanticContext.NONE) {\n        nPredAlts += 1;\n      }\n    }\n    if (nPredAlts === 0) {\n      altToPred = null;\n    }\n    if (_ParserATNSimulator.debug) {\n      console.log(\"getPredsForAmbigAlts result \" + arrayToString(altToPred));\n    }\n    return altToPred;\n  }\n  getPredicatePredictions(ambigAlts, altToPred) {\n    const pairs = [];\n    let containsPredicate = false;\n    for (let i = 1; i < altToPred.length; i++) {\n      const pred = altToPred[i];\n      if (ambigAlts.get(i)) {\n        pairs.push({ pred, alt: i });\n      }\n      if (pred !== SemanticContext.NONE) {\n        containsPredicate = true;\n      }\n    }\n    if (!containsPredicate) {\n      return null;\n    }\n    return pairs;\n  }\n  /**\n   * This method is used to improve the localization of error messages by\n   * choosing an alternative rather than throwing a\n   * {@link NoViableAltException} in particular prediction scenarios where the\n   * {@link ERROR} state was reached during ATN simulation.\n   *\n   *\n   * The default implementation of this method uses the following\n   * algorithm to identify an ATN configuration which successfully parsed the\n   * decision entry rule. Choosing such an alternative ensures that the\n   * {@link ParserRuleContext} returned by the calling rule will be complete\n   * and valid, and the syntax error will be reported later at a more\n   * localized location.\n   *\n   * - If a syntactically valid path or paths reach the end of the decision rule and\n   * they are semantically valid if predicated, return the min associated alt.\n   * - Else, if a semantically invalid but syntactically valid path exist\n   * or paths exist, return the minimum associated alt.\n   *\n   * - Otherwise, return {@link ATN//INVALID_ALT_NUMBER}.\n   *\n   *\n   * In some scenarios, the algorithm described above could predict an\n   * alternative which will result in a {@link FailedPredicateException} in\n   * the parser. Specifically, this could occur if the *only* configuration\n   * capable of successfully parsing to the end of the decision rule is\n   * blocked by a semantic predicate. By choosing this alternative within\n   * {@link adaptivePredict} instead of throwing a\n   * {@link NoViableAltException}, the resulting\n   * {@link FailedPredicateException} in the parser will identify the specific\n   * predicate which is preventing the parser from successfully parsing the\n   * decision rule, which helps developers identify and correct logic errors\n   * in semantic predicates.\n   *\n   * @param configs The ATN configurations which were valid immediately before\n   * the {@link ERROR} state was reached\n   * @param outerContext The is the \\gamma_0 initial parser context from the paper\n   * or the parser stack at the instant before prediction commences.\n   *\n   * @returns The value to return from {@link adaptivePredict}, or\n   * {@link ATN//INVALID_ALT_NUMBER} if a suitable alternative was not\n   * identified and {@link adaptivePredict} should report an error instead\n   */\n  getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(configs, outerContext) {\n    const splitConfigs = this.splitAccordingToSemanticValidity(configs, outerContext);\n    const semValidConfigs = splitConfigs[0];\n    const semInvalidConfigs = splitConfigs[1];\n    let alt = this.getAltThatFinishedDecisionEntryRule(semValidConfigs);\n    if (alt !== ATN.INVALID_ALT_NUMBER) {\n      return alt;\n    }\n    if (semInvalidConfigs.length > 0) {\n      alt = this.getAltThatFinishedDecisionEntryRule(semInvalidConfigs);\n      if (alt !== ATN.INVALID_ALT_NUMBER) {\n        return alt;\n      }\n    }\n    return ATN.INVALID_ALT_NUMBER;\n  }\n  getAltThatFinishedDecisionEntryRule(configs) {\n    const alts = [];\n    for (const c of configs) {\n      if (c.reachesIntoOuterContext || c.state instanceof RuleStopState && c.context.hasEmptyPath()) {\n        if (alts.indexOf(c.alt) < 0) {\n          alts.push(c.alt);\n        }\n      }\n    }\n    if (alts.length === 0) {\n      return ATN.INVALID_ALT_NUMBER;\n    } else {\n      return Math.min(...alts);\n    }\n  }\n  /**\n   * Walk the list of configurations and split them according to\n   * those that have preds evaluating to true/false.  If no pred, assume\n   * true pred and include in succeeded set.  Returns Pair of sets.\n   *\n   * Create a new set so as not to alter the incoming parameter.\n   *\n   * Assumption: the input stream has been restored to the starting point\n   * prediction, which is where predicates need to evaluate.\n   */\n  splitAccordingToSemanticValidity(configs, outerContext) {\n    const succeeded = new ATNConfigSet(configs.fullCtx);\n    const failed = new ATNConfigSet(configs.fullCtx);\n    for (const c of configs) {\n      if (c.semanticContext !== SemanticContext.NONE) {\n        const predicateEvaluationResult = c.semanticContext.evaluate(this.parser, outerContext);\n        if (predicateEvaluationResult) {\n          succeeded.add(c);\n        } else {\n          failed.add(c);\n        }\n      } else {\n        succeeded.add(c);\n      }\n    }\n    return [succeeded, failed];\n  }\n  /**\n   * Look through a list of predicate/alt pairs, returning alts for the\n   * pairs that win. A `NONE` predicate indicates an alt containing an\n   * unpredicated config which behaves as \"always true.\" If !complete\n   * then we stop at the first predicate that evaluates to true. This\n   * includes pairs with null predicates.\n   */\n  evalSemanticContext(predPredictions, outerContext, complete) {\n    const predictions = new BitSet();\n    for (const pair of predPredictions) {\n      if (pair.pred === SemanticContext.NONE) {\n        predictions.set(pair.alt);\n        if (!complete) {\n          break;\n        }\n        continue;\n      }\n      const predicateEvaluationResult = pair.pred.evaluate(this.parser, outerContext);\n      if (_ParserATNSimulator.debug || _ParserATNSimulator.dfaDebug) {\n        console.log(\"eval pred \" + pair + \"=\" + predicateEvaluationResult);\n      }\n      if (predicateEvaluationResult) {\n        predictions.set(pair.alt);\n        if (!complete) {\n          break;\n        }\n      }\n    }\n    return predictions;\n  }\n  // TODO: If we are doing predicates, there is no point in pursuing\n  //     closure operations if we reach a DFA state that uniquely predicts\n  //     alternative. We will not be caching that DFA state and it is a\n  //     waste to pursue the closure. Might have to advance when we do\n  //     ambig detection thought :(\n  //\n  closure(config, configs, closureBusy, collectPredicates, fullCtx, treatEofAsEpsilon) {\n    const initialDepth = 0;\n    this.closureCheckingStopState(\n      config,\n      configs,\n      closureBusy,\n      collectPredicates,\n      fullCtx,\n      initialDepth,\n      treatEofAsEpsilon\n    );\n  }\n  closureCheckingStopState(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n    if (_ParserATNSimulator.traceATNSimulator || _ParserATNSimulator.debugClosure) {\n      console.log(\"closure(\" + config.toString(this.parser, true) + \")\");\n    }\n    if (config.state instanceof RuleStopState) {\n      if (config.context && !config.context.isEmpty()) {\n        for (let i = 0; i < config.context.length; i++) {\n          if (config.context.getReturnState(i) === PredictionContext.EMPTY_RETURN_STATE) {\n            if (fullCtx) {\n              configs.add(\n                ATNConfig.createWithConfig(\n                  config.state,\n                  config,\n                  PredictionContext.EMPTY\n                ),\n                this.mergeCache\n              );\n              continue;\n            } else {\n              if (_ParserATNSimulator.debug) {\n                console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n              }\n              this.closure_(\n                config,\n                configs,\n                closureBusy,\n                collectPredicates,\n                fullCtx,\n                depth,\n                treatEofAsEpsilon\n              );\n            }\n            continue;\n          }\n          const returnState = this.atn.states[config.context.getReturnState(i)];\n          const newContext = config.context.getParent(i);\n          const c = ATNConfig.createWithContext(returnState, config.alt, newContext, config.semanticContext);\n          c.reachesIntoOuterContext = config.reachesIntoOuterContext;\n          this.closureCheckingStopState(\n            c,\n            configs,\n            closureBusy,\n            collectPredicates,\n            fullCtx,\n            depth - 1,\n            treatEofAsEpsilon\n          );\n        }\n        return;\n      } else if (fullCtx) {\n        configs.add(config, this.mergeCache);\n        return;\n      } else {\n        if (_ParserATNSimulator.debug) {\n          console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n        }\n      }\n    }\n    this.closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);\n  }\n  // Do the actual work of walking epsilon edges//\n  closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n    const p = config.state;\n    if (!p.epsilonOnlyTransitions) {\n      configs.add(config, this.mergeCache);\n    }\n    for (let i = 0; i < p.transitions.length; i++) {\n      if (i === 0 && this.canDropLoopEntryEdgeInLeftRecursiveRule(config)) {\n        continue;\n      }\n      const t = p.transitions[i];\n      const continueCollecting = collectPredicates && !(t instanceof ActionTransition);\n      const c = this.getEpsilonTarget(config, t, continueCollecting, depth === 0, fullCtx, treatEofAsEpsilon);\n      if (c) {\n        let newDepth = depth;\n        if (config.state.constructor.stateType === ATNState.RULE_STOP) {\n          if (this.predictionState.dfa && this.predictionState?.dfa.isPrecedenceDfa) {\n            const outermostPrecedenceReturn = t.outermostPrecedenceReturn;\n            if (outermostPrecedenceReturn === this.predictionState?.dfa.atnStartState?.ruleIndex) {\n              c.precedenceFilterSuppressed = true;\n            }\n          }\n          c.reachesIntoOuterContext = true;\n          if (closureBusy.getOrAdd(c) !== c) {\n            continue;\n          }\n          configs.dipsIntoOuterContext = true;\n          newDepth -= 1;\n          if (_ParserATNSimulator.debug) {\n            console.log(\"dips into outer ctx: \" + c);\n          }\n        } else {\n          if (!t.isEpsilon && closureBusy.getOrAdd(c) !== c) {\n            continue;\n          }\n          if (t instanceof RuleTransition) {\n            if (newDepth >= 0) {\n              newDepth += 1;\n            }\n          }\n        }\n        this.closureCheckingStopState(\n          c,\n          configs,\n          closureBusy,\n          continueCollecting,\n          fullCtx,\n          newDepth,\n          treatEofAsEpsilon\n        );\n      }\n    }\n  }\n  canDropLoopEntryEdgeInLeftRecursiveRule(config) {\n    const p = config.state;\n    if (p.constructor.stateType !== ATNState.STAR_LOOP_ENTRY || !config.context) {\n      return false;\n    }\n    if (!p.precedenceRuleDecision || config.context.isEmpty() || config.context.hasEmptyPath()) {\n      return false;\n    }\n    const numCtxs = config.context.length;\n    for (let i = 0; i < numCtxs; i++) {\n      const returnState = this.atn.states[config.context.getReturnState(i)];\n      if (returnState.ruleIndex !== p.ruleIndex) {\n        return false;\n      }\n    }\n    const decisionStartState = p.transitions[0].target;\n    const blockEndStateNum = decisionStartState.endState.stateNumber;\n    const blockEndState = this.atn.states[blockEndStateNum];\n    for (let i = 0; i < numCtxs; i++) {\n      const returnStateNumber = config.context.getReturnState(i);\n      const returnState = this.atn.states[returnStateNumber];\n      if (returnState.transitions.length !== 1 || !returnState.transitions[0].isEpsilon) {\n        return false;\n      }\n      const returnStateTarget = returnState.transitions[0].target;\n      if (returnState.constructor.stateType === ATNState.BLOCK_END && returnStateTarget === p) {\n        continue;\n      }\n      if (returnState === blockEndState) {\n        continue;\n      }\n      if (returnStateTarget === blockEndState) {\n        continue;\n      }\n      if (returnStateTarget.constructor.stateType === ATNState.BLOCK_END && returnStateTarget.transitions.length === 1 && returnStateTarget.transitions[0].isEpsilon && returnStateTarget.transitions[0].target === p) {\n        continue;\n      }\n      return false;\n    }\n    return true;\n  }\n  getEpsilonTarget(config, t, collectPredicates, inContext, fullCtx, treatEofAsEpsilon) {\n    switch (t.transitionType) {\n      case Transition.RULE: {\n        return this.ruleTransition(config, t);\n      }\n      case Transition.PRECEDENCE: {\n        return this.precedenceTransition(\n          config,\n          t,\n          collectPredicates,\n          inContext,\n          fullCtx\n        );\n      }\n      case Transition.PREDICATE: {\n        return this.predTransition(config, t, collectPredicates, inContext, fullCtx);\n      }\n      case Transition.ACTION: {\n        if (_ParserATNSimulator.debug) {\n          const at = t;\n          const index = at.actionIndex === -1 ? 65535 : at.actionIndex;\n          console.log(\"ACTION edge \" + at.ruleIndex + \":\" + index);\n        }\n        return ATNConfig.createWithConfig(t.target, config);\n      }\n      case Transition.EPSILON: {\n        return ATNConfig.createWithConfig(t.target, config);\n      }\n      case Transition.ATOM:\n      case Transition.RANGE:\n      case Transition.SET: {\n        if (treatEofAsEpsilon) {\n          if (t.matches(Token.EOF, 0, 1)) {\n            return ATNConfig.createWithConfig(t.target, config);\n          }\n        }\n        return null;\n      }\n      default:\n        return null;\n    }\n  }\n  precedenceTransition(config, pt, collectPredicates, inContext, fullCtx) {\n    if (_ParserATNSimulator.debug) {\n      console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" + pt.precedence + \">=_p, ctx dependent=true\");\n      if (this.parser !== null) {\n        console.log(\"context surrounding pred is \" + arrayToString(this.parser.getRuleInvocationStack()));\n      }\n    }\n    let c = null;\n    if (collectPredicates && inContext) {\n      if (fullCtx && this.predictionState?.input) {\n        const currentPosition = this.predictionState.input.index;\n        this.predictionState.input.seek(this.predictionState.startIndex);\n        const predSucceeds = pt.getPredicate().evaluate(this.parser, this.predictionState.outerContext);\n        this.predictionState.input.seek(currentPosition);\n        if (predSucceeds) {\n          c = ATNConfig.createWithConfig(pt.target, config);\n        }\n      } else {\n        const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n        c = ATNConfig.createWithSemanticContext(pt.target, config, newSemCtx);\n      }\n    } else {\n      c = ATNConfig.createWithConfig(pt.target, config);\n    }\n    if (_ParserATNSimulator.debug) {\n      console.log(\"config from pred transition=\" + c);\n    }\n    return c;\n  }\n  predTransition(config, pt, collectPredicates, inContext, fullCtx) {\n    if (_ParserATNSimulator.debug) {\n      console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" + pt.ruleIndex + \":\" + pt.predIndex + \", ctx dependent=\" + pt.isCtxDependent);\n      if (this.parser !== null) {\n        console.log(\"context surrounding pred is \" + arrayToString(this.parser.getRuleInvocationStack()));\n      }\n    }\n    let c = null;\n    if (collectPredicates && (pt.isCtxDependent && inContext || !pt.isCtxDependent)) {\n      if (fullCtx && this.predictionState?.input) {\n        const currentPosition = this.predictionState.input.index;\n        this.predictionState.input.seek(this.predictionState.startIndex);\n        const predSucceeds = pt.getPredicate().evaluate(this.parser, this.predictionState.outerContext);\n        this.predictionState.input.seek(currentPosition);\n        if (predSucceeds) {\n          c = ATNConfig.createWithConfig(pt.target, config);\n        }\n      } else {\n        const newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n        c = ATNConfig.createWithSemanticContext(pt.target, config, newSemCtx);\n      }\n    } else {\n      c = ATNConfig.createWithConfig(pt.target, config);\n    }\n    if (_ParserATNSimulator.debug) {\n      console.log(\"config from pred transition=\" + c);\n    }\n    return c;\n  }\n  ruleTransition(config, t) {\n    if (_ParserATNSimulator.debug) {\n      console.log(\"CALL rule \" + this.getRuleName(t.target.ruleIndex) + \", ctx=\" + config.context);\n    }\n    const returnState = t.followState;\n    const newContext = SingletonPredictionContext.create(config.context ?? void 0, returnState.stateNumber);\n    return ATNConfig.createWithConfig(t.target, config, newContext);\n  }\n  getConflictingAlts(configs) {\n    const altSets = PredictionMode.getConflictingAltSubsets(configs);\n    return PredictionMode.getAlts(altSets);\n  }\n  /**\n   * Sam pointed out a problem with the previous definition, v3, of\n   * ambiguous states. If we have another state associated with conflicting\n   * alternatives, we should keep going. For example, the following grammar\n   *\n   * s : (ID | ID ID?) ';' ;\n   *\n   * When the ATN simulation reaches the state before ';', it has a DFA\n   * state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally\n   * 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node\n   * because alternative to has another way to continue, via [6|2|[]].\n   * The key is that we have a single state that has config's only associated\n   * with a single alternative, 2, and crucially the state transitions\n   * among the configurations are all non-epsilon transitions. That means\n   * we don't consider any conflicts that include alternative 2. So, we\n   * ignore the conflict between alts 1 and 2. We ignore a set of\n   * conflicting alts when there is an intersection with an alternative\n   * associated with a single alt state in the state -> config-list map.\n   *\n   * It's also the case that we might have two conflicting configurations but\n   * also a 3rd nonconflicting configuration for a different alternative:\n   * [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar:\n   *\n   * a : A | A | A B ;\n   *\n   * After matching input A, we reach the stop state for rule A, state 1.\n   * State 8 is the state right before B. Clearly alternatives 1 and 2\n   * conflict and no amount of further lookahead will separate the two.\n   * However, alternative 3 will be able to continue and so we do not\n   * stop working on this state. In the previous example, we're concerned\n   * with states associated with the conflicting alternatives. Here alt\n   * 3 is not associated with the conflicting configs, but since we can continue\n   * looking for input reasonably, I don't declare the state done. We\n   * ignore a set of conflicting alts when we have an alternative\n   * that we still need to pursue\n   */\n  getConflictingAltsOrUniqueAlt(configs) {\n    let conflictingAlts;\n    if (configs.uniqueAlt !== ATN.INVALID_ALT_NUMBER) {\n      conflictingAlts = new BitSet();\n      conflictingAlts.set(configs.uniqueAlt);\n    } else {\n      conflictingAlts = configs.conflictingAlts;\n    }\n    return conflictingAlts;\n  }\n  noViableAlt(input, outerContext, configs, startIndex) {\n    return new NoViableAltException(this.parser, input, input.get(startIndex), input.LT(1), configs, outerContext);\n  }\n  /**\n   * Add an edge to the DFA, if possible. This method calls\n   * {@link addDFAState} to ensure the `to` state is present in the\n   * DFA. If `from` is `null`, or if `t` is outside the\n   * range of edges that can be represented in the DFA tables, this method\n   * returns without adding the edge to the DFA.\n   *\n   * If `to` is `null`, this method returns `null`.\n   * Otherwise, this method returns the {@link DFAState} returned by calling\n   * {@link addDFAState} for the `to` state.\n   *\n   * @param dfa The DFA\n   * @param from The source state for the edge\n   * @param t The input symbol\n   * @param to The target state for the edge\n   *\n   * @returns If `to` is `null`, this method returns `null`;\n   * otherwise this method returns the result of calling {@link addDFAState}\n   * on `to`\n   */\n  addDFAEdge(dfa, from, t, to) {\n    if (_ParserATNSimulator.debug) {\n      console.log(\"EDGE \" + from + \" -> \" + to + \" upon \" + this.getTokenName(t));\n    }\n    to = this.addDFAState(dfa, to);\n    if (t < -1 || t > this.atn.maxTokenType) {\n      return to;\n    }\n    if (_ParserATNSimulator.debug) {\n      console.log(\"DFA=\\n\" + dfa.toString(this.parser != null ? this.parser.vocabulary : Vocabulary.EMPTY_VOCABULARY));\n    }\n    from.edges[t + 1] = to;\n    return to;\n  }\n  /**\n   * Add state `D` to the DFA if it is not already present, and return\n   * the actual instance stored in the DFA. If a state equivalent to `D`\n   * is already in the DFA, the existing state is returned. Otherwise this\n   * method returns `D` after adding it to the DFA.\n   *\n   * If `D` is {@link ERROR}, this method returns {@link ERROR} and\n   * does not change the DFA.\n   *\n   * @param dfa The dfa.\n   * @param newState The DFA state to add.\n   *\n   * @returns The state stored in the DFA. This will be either the existing state if `newState` is already in\n   *          the DFA, or `newState` itself if the state was not already present.\n   */\n  addDFAState(dfa, newState) {\n    if (newState === ATNSimulator.ERROR) {\n      return newState;\n    }\n    const existing = dfa.getState(newState);\n    if (existing !== null) {\n      return existing;\n    }\n    if (!newState.configs.readOnly) {\n      newState.configs.optimizeConfigs(this);\n      newState.configs.setReadonly(true);\n    }\n    if (_ParserATNSimulator.traceATNSimulator) {\n      console.log(\"addDFAState new \" + newState);\n    }\n    dfa.addState(newState);\n    return newState;\n  }\n  reportAttemptingFullContext(dfa, conflictingAlts, configs, startIndex, stopIndex) {\n    if (_ParserATNSimulator.debug || _ParserATNSimulator.retryDebug) {\n      const interval = new Interval(startIndex, stopIndex + 1);\n      console.log(\"reportAttemptingFullContext decision=\" + dfa.decision + \":\" + configs + \", input=\" + this.parser.tokenStream.getTextFromInterval(interval));\n    }\n    this.parser.errorListenerDispatch.reportAttemptingFullContext(\n      this.parser,\n      dfa,\n      startIndex,\n      stopIndex,\n      conflictingAlts,\n      configs\n    );\n  }\n  reportContextSensitivity(dfa, prediction, configs, startIndex, stopIndex) {\n    if (_ParserATNSimulator.debug || _ParserATNSimulator.retryDebug) {\n      const interval = new Interval(startIndex, stopIndex + 1);\n      console.log(\"reportContextSensitivity decision=\" + dfa.decision + \":\" + configs + \", input=\" + this.parser.tokenStream.getTextFromInterval(interval));\n    }\n    this.parser.errorListenerDispatch.reportContextSensitivity(\n      this.parser,\n      dfa,\n      startIndex,\n      stopIndex,\n      prediction,\n      configs\n    );\n  }\n  // If context sensitive parsing, we know it's ambiguity not conflict.\n  reportAmbiguity(dfa, D, startIndex, stopIndex, exact, ambigAlts, configs) {\n    if (_ParserATNSimulator.debug || _ParserATNSimulator.retryDebug) {\n      const interval = new Interval(startIndex, stopIndex + 1);\n      console.log(\"reportAmbiguity \" + ambigAlts + \":\" + configs + \", input=\" + this.parser.tokenStream.getTextFromInterval(interval));\n    }\n    this.parser.errorListenerDispatch.reportAmbiguity(\n      this.parser,\n      dfa,\n      startIndex,\n      stopIndex,\n      exact,\n      ambigAlts,\n      configs\n    );\n  }\n};\n\n// src/atn/PredictionContextCache.ts\nvar PredictionContextCache = class {\n  static {\n    __name(this, \"PredictionContextCache\");\n  }\n  cache = new HashMap(ObjectEqualityComparator.instance);\n  /**\n   * Add a context to the cache and return it. If the context already exists,\n   * return that one instead and do not add a new context to the cache.\n   * Protect shared cache from unsafe thread access.\n   *\n   * @param ctx tbd\n   * @returns tbd\n   */\n  add(ctx) {\n    if (ctx === PredictionContext.EMPTY) {\n      return ctx;\n    }\n    const existing = this.cache.get(ctx);\n    if (existing) {\n      return existing;\n    }\n    this.cache.set(ctx, ctx);\n    return ctx;\n  }\n  get(ctx) {\n    return this.cache.get(ctx);\n  }\n  get length() {\n    return this.cache.size;\n  }\n};\n\n// src/atn/ProfilingATNSimulator.ts\nvar ProfilingATNSimulator = class extends ParserATNSimulator {\n  static {\n    __name(this, \"ProfilingATNSimulator\");\n  }\n  decisions;\n  numDecisions = 0;\n  currentDecision = 0;\n  currentState;\n  /**\n   * At the point of LL failover, we record how SLL would resolve the conflict so that\n   *  we can determine whether or not a decision / input pair is context-sensitive.\n   *  If LL gives a different result than SLL's predicted alternative, we have a\n   *  context sensitivity for sure. The converse is not necessarily true, however.\n   *  It's possible that after conflict resolution chooses minimum alternatives,\n   *  SLL could get the same answer as LL. Regardless of whether or not the result indicates\n   *  an ambiguity, it is not treated as a context sensitivity because LL prediction\n   *  was not required in order to produce a correct prediction for this decision and input sequence.\n   *  It may in fact still be a context sensitivity but we don't know by looking at the\n   *  minimum alternatives for the current input.\n   */\n  conflictingAltResolvedBySLL;\n  #sllStopIndex = 0;\n  #llStopIndex = 0;\n  constructor(parser) {\n    const sharedContextCache = parser.interpreter.sharedContextCache;\n    super(parser, parser.interpreter.atn, parser.interpreter.decisionToDFA, sharedContextCache);\n    if (sharedContextCache) {\n      this.numDecisions = this.atn.decisionToState.length;\n      this.decisions = new Array(this.numDecisions);\n      for (let i = 0; i < this.numDecisions; i++) {\n        this.decisions[i] = new DecisionInfo(i);\n      }\n    }\n  }\n  adaptivePredict(input, decision, outerContext) {\n    try {\n      this.#sllStopIndex = -1;\n      this.#llStopIndex = -1;\n      this.currentDecision = decision;\n      const start = performance.now();\n      const alt = super.adaptivePredict(input, decision, outerContext);\n      const stop = performance.now();\n      this.decisions[decision].timeInPrediction += stop - start;\n      this.decisions[decision].invocations++;\n      const sllLook = this.#sllStopIndex - this.predictionState.startIndex + 1;\n      this.decisions[decision].sllTotalLook += sllLook;\n      this.decisions[decision].sllMinLook = this.decisions[decision].sllMinLook === 0 ? sllLook : Math.min(this.decisions[decision].sllMinLook, sllLook);\n      if (sllLook > this.decisions[decision].sllMaxLook) {\n        this.decisions[decision].sllMaxLook = sllLook;\n        this.decisions[decision].sllMaxLookEvent = {\n          decision,\n          configs: null,\n          predictedAlt: alt,\n          input,\n          startIndex: this.predictionState.startIndex,\n          stopIndex: this.#sllStopIndex,\n          fullCtx: false\n        };\n      }\n      if (this.#llStopIndex >= 0) {\n        const llLook = this.#llStopIndex - this.predictionState.startIndex + 1;\n        this.decisions[decision].llTotalLook += llLook;\n        this.decisions[decision].llMinLook = this.decisions[decision].llMinLook === 0 ? llLook : Math.min(this.decisions[decision].llMinLook, llLook);\n        if (llLook > this.decisions[decision].llMaxLook) {\n          this.decisions[decision].llMaxLook = llLook;\n          this.decisions[decision].llMaxLookEvent = {\n            decision,\n            configs: null,\n            predictedAlt: alt,\n            input,\n            startIndex: this.predictionState.startIndex,\n            stopIndex: this.#llStopIndex,\n            fullCtx: true\n          };\n        }\n      }\n      return alt;\n    } finally {\n      this.currentDecision = -1;\n    }\n  }\n  getExistingTargetState(previousD, t) {\n    if (this.predictionState?.input) {\n      this.#sllStopIndex = this.predictionState.input.index;\n      const existingTargetState = super.getExistingTargetState(previousD, t);\n      if (existingTargetState !== null) {\n        this.decisions[this.currentDecision].sllDFATransitions++;\n        if (existingTargetState === ATNSimulator.ERROR) {\n          this.decisions[this.currentDecision].errors.push({\n            decision: this.currentDecision,\n            configs: previousD.configs,\n            input: this.predictionState.input,\n            startIndex: this.predictionState.startIndex,\n            stopIndex: this.#sllStopIndex,\n            fullCtx: false\n          });\n        }\n      }\n      this.currentState = existingTargetState;\n      return existingTargetState;\n    }\n    return void 0;\n  }\n  computeTargetState(dfa, previousD, t) {\n    const state = super.computeTargetState(dfa, previousD, t);\n    this.currentState = state;\n    return state;\n  }\n  computeReachSet(closure, t, fullCtx) {\n    if (fullCtx && this.predictionState?.input) {\n      this.#llStopIndex = this.predictionState.input.index;\n    }\n    const reachConfigs = super.computeReachSet(closure, t, fullCtx);\n    if (this.predictionState?.input) {\n      if (fullCtx) {\n        this.decisions[this.currentDecision].llATNTransitions++;\n        if (reachConfigs === null) {\n          this.decisions[this.currentDecision].errors.push({\n            decision: this.currentDecision,\n            configs: closure,\n            input: this.predictionState.input,\n            startIndex: this.predictionState.startIndex,\n            stopIndex: this.#sllStopIndex,\n            fullCtx: true\n          });\n        }\n      } else {\n        this.decisions[this.currentDecision].sllATNTransitions++;\n        if (reachConfigs === null) {\n          this.decisions[this.currentDecision].errors.push({\n            decision: this.currentDecision,\n            configs: closure,\n            input: this.predictionState.input,\n            startIndex: this.predictionState.startIndex,\n            stopIndex: this.#sllStopIndex,\n            fullCtx: false\n          });\n        }\n      }\n    }\n    return reachConfigs;\n  }\n  reportAttemptingFullContext(dfa, conflictingAlts, configs, startIndex, stopIndex) {\n    if (conflictingAlts !== null) {\n      this.conflictingAltResolvedBySLL = conflictingAlts.nextSetBit(0);\n    } else {\n      this.conflictingAltResolvedBySLL = configs.getAlts().nextSetBit(0);\n    }\n    this.decisions[this.currentDecision].llFallback++;\n    if (conflictingAlts) {\n      super.reportAttemptingFullContext(dfa, conflictingAlts, configs, startIndex, stopIndex);\n    }\n  }\n  reportContextSensitivity(dfa, prediction, configs, startIndex, stopIndex) {\n    if (prediction !== this.conflictingAltResolvedBySLL && this.predictionState.input) {\n      this.decisions[this.currentDecision].contextSensitivities.push({\n        decision: this.currentDecision,\n        configs,\n        input: this.predictionState.input,\n        startIndex,\n        stopIndex,\n        fullCtx: true\n      });\n    }\n    super.reportContextSensitivity(dfa, prediction, configs, startIndex, stopIndex);\n  }\n  reportAmbiguity(dfa, state, startIndex, stopIndex, exact, ambigAlts, configs) {\n    let prediction;\n    if (ambigAlts) {\n      prediction = ambigAlts.nextSetBit(0);\n    } else {\n      prediction = configs.getAlts().nextSetBit(0);\n    }\n    if (this.predictionState?.input) {\n      if (configs.fullCtx && prediction !== this.conflictingAltResolvedBySLL) {\n        this.decisions[this.currentDecision].contextSensitivities.push({\n          decision: this.currentDecision,\n          configs,\n          input: this.predictionState.input,\n          startIndex,\n          stopIndex,\n          fullCtx: true\n        });\n      }\n      this.decisions[this.currentDecision].ambiguities.push({\n        ambigAlts,\n        decision: this.currentDecision,\n        configs,\n        input: this.predictionState.input,\n        startIndex,\n        stopIndex,\n        fullCtx: configs.fullCtx\n      });\n    }\n    super.reportAmbiguity(dfa, state, startIndex, stopIndex, exact, ambigAlts, configs);\n  }\n  getDecisionInfo() {\n    return this.decisions;\n  }\n  getCurrentState() {\n    return this.currentState;\n  }\n};\n\n// src/dfa/PredPrediction.ts\nvar PredPrediction;\n((PredPrediction2) => {\n  PredPrediction2.toString = /* @__PURE__ */ __name((prediction) => {\n    return `(${prediction.pred}, ${prediction.alt})`;\n  }, \"toString\");\n})(PredPrediction || (PredPrediction = {}));\n\n// src/tree/AbstractParseTreeVisitor.ts\nvar AbstractParseTreeVisitor = class {\n  static {\n    __name(this, \"AbstractParseTreeVisitor\");\n  }\n  visit(tree) {\n    return tree.accept(this);\n  }\n  visitChildren(node) {\n    let result = this.defaultResult();\n    const n2 = node.getChildCount();\n    for (let i = 0; i < n2; i++) {\n      if (!this.shouldVisitNextChild(node, result)) {\n        break;\n      }\n      const c = node.getChild(i);\n      if (c) {\n        const childResult = c.accept(this);\n        result = this.aggregateResult(result, childResult);\n      }\n    }\n    return result;\n  }\n  visitTerminal(_node) {\n    return this.defaultResult();\n  }\n  visitErrorNode(_node) {\n    return this.defaultResult();\n  }\n  defaultResult() {\n    return null;\n  }\n  shouldVisitNextChild(_node, _currentResult) {\n    return true;\n  }\n  aggregateResult(aggregate, nextResult) {\n    return nextResult;\n  }\n};\n\n// src/tree/ParseTreeWalker.ts\nvar ParseTreeWalker = class _ParseTreeWalker {\n  static {\n    __name(this, \"ParseTreeWalker\");\n  }\n  static DEFAULT = new _ParseTreeWalker();\n  /**\n   * Performs a walk on the given parse tree starting at the root and going down recursively\n   * with depth-first search. On each node, {@link ParseTreeWalker.enterRule} is called before\n   * recursively walking down into child nodes, then\n   * {@link ParseTreeWalker.exitRule} is called after the recursive call to wind up.\n   *\n   * @param listener The listener used by the walker to process grammar rules\n   * @param t The parse tree to be walked on\n   */\n  walk(listener, t) {\n    const errorNode = t instanceof ErrorNode;\n    if (errorNode) {\n      listener.visitErrorNode(t);\n    } else if (t instanceof TerminalNode) {\n      listener.visitTerminal(t);\n    } else {\n      const r = t;\n      this.enterRule(listener, r);\n      for (let i = 0; i < t.getChildCount(); i++) {\n        this.walk(listener, t.getChild(i));\n      }\n      this.exitRule(listener, r);\n    }\n  }\n  /**\n   * Enters a grammar rule by first triggering the generic event {@link ParseTreeListener.enterEveryRule}\n   * then by triggering the event specific to the given parse tree node\n   *\n   * @param listener The listener responding to the trigger events\n   * @param r The grammar rule containing the rule context\n   */\n  enterRule(listener, r) {\n    const ctx = r.ruleContext;\n    listener.enterEveryRule(ctx);\n    ctx.enterRule(listener);\n  }\n  /**\n   * Exits a grammar rule by first triggering the event specific to the given parse tree node\n   * then by triggering the generic event {@link ParseTreeListener.exitEveryRule}\n   *\n   * @param listener The listener responding to the trigger events\n   * @param r The grammar rule containing the rule context\n   */\n  exitRule(listener, r) {\n    const ctx = r.ruleContext;\n    ctx.exitRule(listener);\n    listener.exitEveryRule(ctx);\n  }\n};\n\n// src/CharStream.ts\nvar CharStream;\n((CharStream2) => {\n  CharStream2.fromString = /* @__PURE__ */ __name((str) => {\n    return new CharStreamImpl(str);\n  }, \"fromString\");\n})(CharStream || (CharStream = {}));\nvar CharStreamImpl = class {\n  static {\n    __name(this, \"CharStreamImpl\");\n  }\n  name = \"\";\n  index = 0;\n  data;\n  constructor(input) {\n    const codePoints = [];\n    for (const char of input) {\n      codePoints.push(char.codePointAt(0));\n    }\n    this.data = new Uint32Array(codePoints);\n  }\n  /**\n   * Reset the stream so that it's in the same state it was\n   * when the object was created *except* the data array is not\n   * touched.\n   */\n  reset() {\n    this.index = 0;\n  }\n  consume() {\n    if (this.index >= this.data.length) {\n      throw new Error(\"cannot consume EOF\");\n    }\n    this.index += 1;\n  }\n  LA(offset) {\n    if (offset === 0) {\n      return 0;\n    }\n    if (offset < 0) {\n      offset += 1;\n    }\n    const pos = this.index + offset - 1;\n    if (pos < 0 || pos >= this.data.length) {\n      return Token.EOF;\n    }\n    return this.data[pos];\n  }\n  // mark/release do nothing; we have entire buffer\n  mark() {\n    return -1;\n  }\n  release(_marker) {\n  }\n  /**\n   * consume() ahead until p==_index; can't just set p=_index as we must\n   * update line and column. If we seek backwards, just set p\n   */\n  seek(index) {\n    if (index <= this.index) {\n      this.index = index;\n      return;\n    }\n    this.index = Math.min(index, this.data.length);\n  }\n  getTextFromRange(start, stop) {\n    stop = stop ?? this.data.length - 1;\n    if (stop >= this.data.length) {\n      stop = this.data.length - 1;\n    }\n    if (start >= this.data.length) {\n      return \"\";\n    }\n    return this.#stringFromRange(start, stop + 1);\n  }\n  getTextFromInterval(interval) {\n    const start = interval.start;\n    let stop = interval.stop;\n    if (stop >= this.data.length) {\n      stop = this.data.length - 1;\n    }\n    if (start >= this.data.length) {\n      return \"\";\n    }\n    return this.#stringFromRange(start, stop + 1);\n  }\n  toString() {\n    return this.#stringFromRange(0);\n  }\n  get size() {\n    return this.data.length;\n  }\n  getSourceName() {\n    if (this.name) {\n      return this.name;\n    }\n    return IntStream.UNKNOWN_SOURCE_NAME;\n  }\n  #stringFromRange(start, stop) {\n    const data = this.data.slice(start, stop);\n    let result = \"\";\n    data.forEach((value) => {\n      result += String.fromCodePoint(value);\n    });\n    return result;\n  }\n};\n\n// src/BufferedTokenStream.ts\nvar BufferedTokenStream = class {\n  static {\n    __name(this, \"BufferedTokenStream\");\n  }\n  /**\n   * The {@link TokenSource} from which tokens for this stream are fetched.\n   */\n  tokenSource;\n  /**\n   * A collection of all tokens fetched from the token source. The list is\n   * considered a complete view of the input once {@link fetchedEOF} is set\n   * to `true`.\n   */\n  tokens = [];\n  /**\n   * The index into {@link tokens} of the current token (next token to\n   * {@link consume}). {@link tokens}`[p]` should be\n   * {@link LT LT(1)}.\n   *\n   * This field is set to -1 when the stream is first constructed or when\n   * {@link setTokenSource} is called, indicating that the first token has\n   * not yet been fetched from the token source. For additional information,\n   * see the documentation of {@link IntStream} for a description of\n   * Initializing Methods.\n   */\n  p = -1;\n  /**\n   * Indicates whether the {@link Token.EOF} token has been fetched from\n   * {@link tokenSource} and added to {@link tokens}. This field improves\n   * performance for the following cases:\n   *\n   * - {@link consume}: The lookahead check in {@link consume} to prevent\n   * consuming the EOF symbol is optimized by checking the values of\n   * {@link fetchedEOF} and {@link p} instead of calling {@link LA}.\n   * - {@link fetch}: The check to prevent adding multiple EOF symbols into\n   * {@link tokens} is trivial with this field.\n   */\n  fetchedEOF = false;\n  constructor(tokenSource) {\n    this.tokenSource = tokenSource;\n  }\n  mark() {\n    return 0;\n  }\n  release(_marker) {\n  }\n  reset() {\n    this.seek(0);\n  }\n  seek(index) {\n    this.lazyInit();\n    this.p = this.adjustSeekIndex(index);\n  }\n  get size() {\n    return this.tokens.length;\n  }\n  get index() {\n    return this.p;\n  }\n  get(index) {\n    this.lazyInit();\n    return this.tokens[index];\n  }\n  consume() {\n    let skipEofCheck = false;\n    if (this.p >= 0) {\n      if (this.fetchedEOF) {\n        skipEofCheck = this.p < this.tokens.length - 1;\n      } else {\n        skipEofCheck = this.p < this.tokens.length;\n      }\n    } else {\n      skipEofCheck = false;\n    }\n    if (!skipEofCheck && this.LA(1) === Token.EOF) {\n      throw new Error(\"cannot consume EOF\");\n    }\n    if (this.sync(this.p + 1)) {\n      this.p = this.adjustSeekIndex(this.p + 1);\n    }\n  }\n  /**\n   * Make sure index `i` in tokens has a token.\n   *\n   * @returns {boolean} `true` if a token is located at index `i`, otherwise `false`.\n   */\n  sync(i) {\n    const n2 = i - this.tokens.length + 1;\n    if (n2 > 0) {\n      const fetched = this.fetch(n2);\n      return fetched >= n2;\n    }\n    return true;\n  }\n  /**\n   * Add `n` elements to buffer.\n   *\n   * @returns {number} The actual number of elements added to the buffer.\n   */\n  fetch(n2) {\n    if (this.fetchedEOF) {\n      return 0;\n    }\n    for (let i = 0; i < n2; i++) {\n      const t = this.tokenSource.nextToken();\n      t.tokenIndex = this.tokens.length;\n      this.tokens.push(t);\n      if (t.type === Token.EOF) {\n        this.fetchedEOF = true;\n        return i + 1;\n      }\n    }\n    return n2;\n  }\n  /** Get all tokens from start..stop, inclusively. */\n  getTokens(start, stop, types) {\n    this.lazyInit();\n    if (start === void 0 && stop === void 0) {\n      return this.tokens;\n    }\n    start ??= 0;\n    if (stop === void 0) {\n      stop = this.tokens.length - 1;\n    }\n    if (start < 0 || stop >= this.tokens.length || stop < 0 || start >= this.tokens.length) {\n      throw new RangeError(\"start \" + start + \" or stop \" + stop + \" not in 0..\" + (this.tokens.length - 1));\n    }\n    if (start > stop) {\n      return [];\n    }\n    if (types === void 0) {\n      return this.tokens.slice(start, stop + 1);\n    }\n    const subset = [];\n    if (stop >= this.tokens.length) {\n      stop = this.tokens.length - 1;\n    }\n    for (let i = start; i < stop; i++) {\n      const t = this.tokens[i];\n      if (t.type === Token.EOF) {\n        subset.push(t);\n        break;\n      }\n      if (types.has(t.type)) {\n        subset.push(t);\n      }\n    }\n    return subset;\n  }\n  LA(k) {\n    return this.LT(k)?.type ?? Token.INVALID_TYPE;\n  }\n  LB(k) {\n    if (this.p - k < 0) {\n      return null;\n    }\n    return this.tokens[this.p - k];\n  }\n  LT(k) {\n    this.lazyInit();\n    if (k === 0) {\n      return null;\n    }\n    if (k < 0) {\n      return this.LB(-k);\n    }\n    const i = this.p + k - 1;\n    this.sync(i);\n    if (i >= this.tokens.length) {\n      return this.tokens[this.tokens.length - 1];\n    }\n    return this.tokens[i];\n  }\n  /**\n   * Allowed derived classes to modify the behavior of operations which change\n   * the current stream position by adjusting the target token index of a seek\n   * operation. The default implementation simply returns `i`. If an\n   * exception is thrown in this method, the current stream index should not be\n   * changed.\n   *\n   * For example, {@link CommonTokenStream} overrides this method to ensure that\n   * the seek target is always an on-channel token.\n   *\n   * @param  i The target token index.\n   *\n   * @returns The adjusted target token index.\n   */\n  adjustSeekIndex(i) {\n    return i;\n  }\n  lazyInit() {\n    if (this.p === -1) {\n      this.setup();\n    }\n  }\n  setup() {\n    this.sync(0);\n    this.p = this.adjustSeekIndex(0);\n  }\n  /** Reset this token stream by setting its token source. */\n  setTokenSource(tokenSource) {\n    this.tokenSource = tokenSource;\n    this.tokens = [];\n    this.p = -1;\n    this.fetchedEOF = false;\n  }\n  /**\n   * Given a starting index, return the index of the next token on channel.\n   * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n   * on channel between i and EOF.\n   */\n  nextTokenOnChannel(i, channel) {\n    this.sync(i);\n    if (i >= this.tokens.length) {\n      return -1;\n    }\n    let token = this.tokens[i];\n    while (token.channel !== channel) {\n      if (token.type === Token.EOF) {\n        return -1;\n      }\n      i += 1;\n      this.sync(i);\n      token = this.tokens[i];\n    }\n    return i;\n  }\n  /**\n   * Given a starting index, return the index of the previous token on channel.\n   * Return i if tokens[i] is on channel. Return -1 if there are no tokens\n   * on channel between i and 0.\n   */\n  previousTokenOnChannel(i, channel) {\n    while (i >= 0 && this.tokens[i].channel !== channel) {\n      i -= 1;\n    }\n    return i;\n  }\n  /**\n   * Collect all tokens on specified channel to the right of\n   * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or\n   * EOF. If channel is -1, find any non default channel token.\n   */\n  getHiddenTokensToRight(tokenIndex, channel) {\n    if (channel === void 0) {\n      channel = -1;\n    }\n    this.lazyInit();\n    if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n      throw new Error(`${tokenIndex} not in 0..${this.tokens.length - 1}`);\n    }\n    const nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n    const from = tokenIndex + 1;\n    const to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;\n    return this.filterForChannel(from, to, channel);\n  }\n  /**\n   * Collect all tokens on specified channel to the left of\n   * the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.\n   * If channel is -1, find any non default channel token.\n   */\n  getHiddenTokensToLeft(tokenIndex, channel) {\n    if (channel === void 0) {\n      channel = -1;\n    }\n    this.lazyInit();\n    if (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n      throw new Error(`${tokenIndex} not in 0..${this.tokens.length - 1}`);\n    }\n    const prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n    if (prevOnChannel === tokenIndex - 1) {\n      return void 0;\n    }\n    const from = prevOnChannel + 1;\n    const to = tokenIndex - 1;\n    return this.filterForChannel(from, to, channel);\n  }\n  filterForChannel(left, right, channel) {\n    const hidden = [];\n    for (let i = left; i < right + 1; i++) {\n      const t = this.tokens[i];\n      if (channel === -1) {\n        if (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {\n          hidden.push(t);\n        }\n      } else if (t.channel === channel) {\n        hidden.push(t);\n      }\n    }\n    if (hidden.length === 0) {\n      return void 0;\n    }\n    return hidden;\n  }\n  getSourceName() {\n    return this.tokenSource.sourceName;\n  }\n  /** Get the text of all tokens in this buffer. */\n  getText() {\n    return this.getTextFromInterval(Interval.of(0, this.size - 1));\n  }\n  getTextFromInterval(interval) {\n    const start = interval.start;\n    let stop = interval.stop;\n    if (start < 0 || stop < 0) {\n      return \"\";\n    }\n    this.sync(stop);\n    if (stop >= this.tokens.length) {\n      stop = this.tokens.length - 1;\n    }\n    let result = \"\";\n    for (let i = start; i <= stop; ++i) {\n      const t = this.tokens[i];\n      if (t.type === Token.EOF) {\n        break;\n      }\n      result += t.text;\n    }\n    return result;\n  }\n  getTextFromContext(ctx) {\n    return this.getTextFromInterval(ctx.getSourceInterval());\n  }\n  getTextFromRange(start, stop) {\n    if (start !== null && stop !== null) {\n      return this.getTextFromInterval(Interval.of(start.tokenIndex, stop.tokenIndex));\n    }\n    return \"\";\n  }\n  /** Get all tokens from lexer until EOF. */\n  fill() {\n    this.lazyInit();\n    while (this.fetch(1e3) === 1e3) {\n      ;\n    }\n  }\n};\n\n// src/CommonTokenStream.ts\nvar CommonTokenStream = class extends BufferedTokenStream {\n  static {\n    __name(this, \"CommonTokenStream\");\n  }\n  /**\n   * Specifies the channel to use for filtering tokens.\n   *\n   *\n   * The default value is {@link Token.DEFAULT_CHANNEL}, which matches the\n   * default channel assigned to tokens created by the lexer.\n   */\n  channel = Token.DEFAULT_CHANNEL;\n  constructor(lexer, channel) {\n    super(lexer);\n    this.channel = channel ?? Token.DEFAULT_CHANNEL;\n  }\n  adjustSeekIndex(i) {\n    return this.nextTokenOnChannel(i, this.channel);\n  }\n  LB(k) {\n    if (k === 0 || this.index - k < 0) {\n      return null;\n    }\n    let i = this.index;\n    let n2 = 1;\n    while (n2 <= k) {\n      i = this.previousTokenOnChannel(i - 1, this.channel);\n      n2 += 1;\n    }\n    if (i < 0) {\n      return null;\n    }\n    return this.tokens[i];\n  }\n  LT(k) {\n    this.lazyInit();\n    if (k === 0) {\n      return null;\n    }\n    if (k < 0) {\n      return this.LB(-k);\n    }\n    let i = this.index;\n    let n2 = 1;\n    while (n2 < k) {\n      if (this.sync(i + 1)) {\n        i = this.nextTokenOnChannel(i + 1, this.channel);\n      }\n      n2 += 1;\n    }\n    return this.tokens[i];\n  }\n  // Count EOF just once.\n  getNumberOfOnChannelTokens() {\n    let n2 = 0;\n    this.fill();\n    for (const t of this.tokens) {\n      if (t.channel === this.channel) {\n        n2 += 1;\n      }\n      if (t.type === Token.EOF) {\n        break;\n      }\n    }\n    return n2;\n  }\n};\n\n// src/tree/xpath/XPathLexer.ts\nvar XPathLexer = class _XPathLexer extends Lexer {\n  static {\n    __name(this, \"XPathLexer\");\n  }\n  static TOKEN_REF = 1;\n  static RULE_REF = 2;\n  static ANYWHERE = 3;\n  static ROOT = 4;\n  static WILDCARD = 5;\n  static BANG = 6;\n  static ID = 7;\n  static STRING = 8;\n  static channelNames = [\n    \"DEFAULT_TOKEN_CHANNEL\",\n    \"HIDDEN\"\n  ];\n  static literalNames = [\n    null,\n    null,\n    null,\n    \"'//'\",\n    \"'/'\",\n    \"'*'\",\n    \"'!'\"\n  ];\n  static symbolicNames = [\n    null,\n    \"TOKEN_REF\",\n    \"RULE_REF\",\n    \"ANYWHERE\",\n    \"ROOT\",\n    \"WILDCARD\",\n    \"BANG\",\n    \"ID\",\n    \"STRING\"\n  ];\n  static modeNames = [\n    \"DEFAULT_MODE\"\n  ];\n  static ruleNames = [\n    \"ANYWHERE\",\n    \"ROOT\",\n    \"WILDCARD\",\n    \"BANG\",\n    \"ID\",\n    \"NameChar\",\n    \"NameStartChar\",\n    \"STRING\"\n  ];\n  constructor(input) {\n    super(input);\n    this.interpreter = new LexerATNSimulator(this, _XPathLexer._ATN, _XPathLexer.decisionsToDFA, new PredictionContextCache());\n  }\n  get grammarFileName() {\n    return \"XPathLexer.g4\";\n  }\n  get literalNames() {\n    return _XPathLexer.literalNames;\n  }\n  get symbolicNames() {\n    return _XPathLexer.symbolicNames;\n  }\n  get ruleNames() {\n    return _XPathLexer.ruleNames;\n  }\n  get serializedATN() {\n    return _XPathLexer._serializedATN;\n  }\n  get channelNames() {\n    return _XPathLexer.channelNames;\n  }\n  get modeNames() {\n    return _XPathLexer.modeNames;\n  }\n  action(localContext, ruleIndex, actionIndex) {\n    switch (ruleIndex) {\n      case 4:\n        this.ID_action(localContext, actionIndex);\n        break;\n    }\n  }\n  ID_action(localContext, actionIndex) {\n    switch (actionIndex) {\n      case 0:\n        const text = this.text;\n        if (text.charAt(0) === text.charAt(0).toUpperCase()) {\n          this.type = _XPathLexer.TOKEN_REF;\n        } else {\n          this.type = _XPathLexer.RULE_REF;\n        }\n        break;\n    }\n  }\n  static _serializedATN = [\n    4,\n    0,\n    8,\n    48,\n    6,\n    -1,\n    2,\n    0,\n    7,\n    0,\n    2,\n    1,\n    7,\n    1,\n    2,\n    2,\n    7,\n    2,\n    2,\n    3,\n    7,\n    3,\n    2,\n    4,\n    7,\n    4,\n    2,\n    5,\n    7,\n    5,\n    2,\n    6,\n    7,\n    6,\n    2,\n    7,\n    7,\n    7,\n    1,\n    0,\n    1,\n    0,\n    1,\n    0,\n    1,\n    1,\n    1,\n    1,\n    1,\n    2,\n    1,\n    2,\n    1,\n    3,\n    1,\n    3,\n    1,\n    4,\n    1,\n    4,\n    5,\n    4,\n    29,\n    8,\n    4,\n    10,\n    4,\n    12,\n    4,\n    32,\n    9,\n    4,\n    1,\n    4,\n    1,\n    4,\n    1,\n    5,\n    1,\n    5,\n    1,\n    6,\n    1,\n    6,\n    1,\n    7,\n    1,\n    7,\n    5,\n    7,\n    42,\n    8,\n    7,\n    10,\n    7,\n    12,\n    7,\n    45,\n    9,\n    7,\n    1,\n    7,\n    1,\n    7,\n    1,\n    43,\n    0,\n    8,\n    1,\n    3,\n    3,\n    4,\n    5,\n    5,\n    7,\n    6,\n    9,\n    7,\n    11,\n    0,\n    13,\n    0,\n    15,\n    8,\n    1,\n    0,\n    2,\n    784,\n    0,\n    0,\n    8,\n    14,\n    27,\n    48,\n    57,\n    65,\n    90,\n    95,\n    95,\n    97,\n    122,\n    127,\n    159,\n    170,\n    170,\n    173,\n    173,\n    181,\n    181,\n    186,\n    186,\n    192,\n    214,\n    216,\n    246,\n    248,\n    705,\n    710,\n    721,\n    736,\n    740,\n    748,\n    748,\n    750,\n    750,\n    768,\n    884,\n    886,\n    887,\n    890,\n    893,\n    895,\n    895,\n    902,\n    902,\n    904,\n    906,\n    908,\n    908,\n    910,\n    929,\n    931,\n    1013,\n    1015,\n    1153,\n    1155,\n    1159,\n    1162,\n    1327,\n    1329,\n    1366,\n    1369,\n    1369,\n    1376,\n    1416,\n    1425,\n    1469,\n    1471,\n    1471,\n    1473,\n    1474,\n    1476,\n    1477,\n    1479,\n    1479,\n    1488,\n    1514,\n    1519,\n    1522,\n    1536,\n    1541,\n    1552,\n    1562,\n    1564,\n    1564,\n    1568,\n    1641,\n    1646,\n    1747,\n    1749,\n    1757,\n    1759,\n    1768,\n    1770,\n    1788,\n    1791,\n    1791,\n    1807,\n    1866,\n    1869,\n    1969,\n    1984,\n    2037,\n    2042,\n    2042,\n    2045,\n    2045,\n    2048,\n    2093,\n    2112,\n    2139,\n    2144,\n    2154,\n    2160,\n    2183,\n    2185,\n    2190,\n    2192,\n    2193,\n    2200,\n    2403,\n    2406,\n    2415,\n    2417,\n    2435,\n    2437,\n    2444,\n    2447,\n    2448,\n    2451,\n    2472,\n    2474,\n    2480,\n    2482,\n    2482,\n    2486,\n    2489,\n    2492,\n    2500,\n    2503,\n    2504,\n    2507,\n    2510,\n    2519,\n    2519,\n    2524,\n    2525,\n    2527,\n    2531,\n    2534,\n    2545,\n    2556,\n    2556,\n    2558,\n    2558,\n    2561,\n    2563,\n    2565,\n    2570,\n    2575,\n    2576,\n    2579,\n    2600,\n    2602,\n    2608,\n    2610,\n    2611,\n    2613,\n    2614,\n    2616,\n    2617,\n    2620,\n    2620,\n    2622,\n    2626,\n    2631,\n    2632,\n    2635,\n    2637,\n    2641,\n    2641,\n    2649,\n    2652,\n    2654,\n    2654,\n    2662,\n    2677,\n    2689,\n    2691,\n    2693,\n    2701,\n    2703,\n    2705,\n    2707,\n    2728,\n    2730,\n    2736,\n    2738,\n    2739,\n    2741,\n    2745,\n    2748,\n    2757,\n    2759,\n    2761,\n    2763,\n    2765,\n    2768,\n    2768,\n    2784,\n    2787,\n    2790,\n    2799,\n    2809,\n    2815,\n    2817,\n    2819,\n    2821,\n    2828,\n    2831,\n    2832,\n    2835,\n    2856,\n    2858,\n    2864,\n    2866,\n    2867,\n    2869,\n    2873,\n    2876,\n    2884,\n    2887,\n    2888,\n    2891,\n    2893,\n    2901,\n    2903,\n    2908,\n    2909,\n    2911,\n    2915,\n    2918,\n    2927,\n    2929,\n    2929,\n    2946,\n    2947,\n    2949,\n    2954,\n    2958,\n    2960,\n    2962,\n    2965,\n    2969,\n    2970,\n    2972,\n    2972,\n    2974,\n    2975,\n    2979,\n    2980,\n    2984,\n    2986,\n    2990,\n    3001,\n    3006,\n    3010,\n    3014,\n    3016,\n    3018,\n    3021,\n    3024,\n    3024,\n    3031,\n    3031,\n    3046,\n    3055,\n    3072,\n    3084,\n    3086,\n    3088,\n    3090,\n    3112,\n    3114,\n    3129,\n    3132,\n    3140,\n    3142,\n    3144,\n    3146,\n    3149,\n    3157,\n    3158,\n    3160,\n    3162,\n    3165,\n    3165,\n    3168,\n    3171,\n    3174,\n    3183,\n    3200,\n    3203,\n    3205,\n    3212,\n    3214,\n    3216,\n    3218,\n    3240,\n    3242,\n    3251,\n    3253,\n    3257,\n    3260,\n    3268,\n    3270,\n    3272,\n    3274,\n    3277,\n    3285,\n    3286,\n    3293,\n    3294,\n    3296,\n    3299,\n    3302,\n    3311,\n    3313,\n    3315,\n    3328,\n    3340,\n    3342,\n    3344,\n    3346,\n    3396,\n    3398,\n    3400,\n    3402,\n    3406,\n    3412,\n    3415,\n    3423,\n    3427,\n    3430,\n    3439,\n    3450,\n    3455,\n    3457,\n    3459,\n    3461,\n    3478,\n    3482,\n    3505,\n    3507,\n    3515,\n    3517,\n    3517,\n    3520,\n    3526,\n    3530,\n    3530,\n    3535,\n    3540,\n    3542,\n    3542,\n    3544,\n    3551,\n    3558,\n    3567,\n    3570,\n    3571,\n    3585,\n    3642,\n    3648,\n    3662,\n    3664,\n    3673,\n    3713,\n    3714,\n    3716,\n    3716,\n    3718,\n    3722,\n    3724,\n    3747,\n    3749,\n    3749,\n    3751,\n    3773,\n    3776,\n    3780,\n    3782,\n    3782,\n    3784,\n    3790,\n    3792,\n    3801,\n    3804,\n    3807,\n    3840,\n    3840,\n    3864,\n    3865,\n    3872,\n    3881,\n    3893,\n    3893,\n    3895,\n    3895,\n    3897,\n    3897,\n    3902,\n    3911,\n    3913,\n    3948,\n    3953,\n    3972,\n    3974,\n    3991,\n    3993,\n    4028,\n    4038,\n    4038,\n    4096,\n    4169,\n    4176,\n    4253,\n    4256,\n    4293,\n    4295,\n    4295,\n    4301,\n    4301,\n    4304,\n    4346,\n    4348,\n    4680,\n    4682,\n    4685,\n    4688,\n    4694,\n    4696,\n    4696,\n    4698,\n    4701,\n    4704,\n    4744,\n    4746,\n    4749,\n    4752,\n    4784,\n    4786,\n    4789,\n    4792,\n    4798,\n    4800,\n    4800,\n    4802,\n    4805,\n    4808,\n    4822,\n    4824,\n    4880,\n    4882,\n    4885,\n    4888,\n    4954,\n    4957,\n    4959,\n    4992,\n    5007,\n    5024,\n    5109,\n    5112,\n    5117,\n    5121,\n    5740,\n    5743,\n    5759,\n    5761,\n    5786,\n    5792,\n    5866,\n    5870,\n    5880,\n    5888,\n    5909,\n    5919,\n    5940,\n    5952,\n    5971,\n    5984,\n    5996,\n    5998,\n    6e3,\n    6002,\n    6003,\n    6016,\n    6099,\n    6103,\n    6103,\n    6108,\n    6109,\n    6112,\n    6121,\n    6155,\n    6169,\n    6176,\n    6264,\n    6272,\n    6314,\n    6320,\n    6389,\n    6400,\n    6430,\n    6432,\n    6443,\n    6448,\n    6459,\n    6470,\n    6509,\n    6512,\n    6516,\n    6528,\n    6571,\n    6576,\n    6601,\n    6608,\n    6617,\n    6656,\n    6683,\n    6688,\n    6750,\n    6752,\n    6780,\n    6783,\n    6793,\n    6800,\n    6809,\n    6823,\n    6823,\n    6832,\n    6845,\n    6847,\n    6862,\n    6912,\n    6988,\n    6992,\n    7001,\n    7019,\n    7027,\n    7040,\n    7155,\n    7168,\n    7223,\n    7232,\n    7241,\n    7245,\n    7293,\n    7296,\n    7304,\n    7312,\n    7354,\n    7357,\n    7359,\n    7376,\n    7378,\n    7380,\n    7418,\n    7424,\n    7957,\n    7960,\n    7965,\n    7968,\n    8005,\n    8008,\n    8013,\n    8016,\n    8023,\n    8025,\n    8025,\n    8027,\n    8027,\n    8029,\n    8029,\n    8031,\n    8061,\n    8064,\n    8116,\n    8118,\n    8124,\n    8126,\n    8126,\n    8130,\n    8132,\n    8134,\n    8140,\n    8144,\n    8147,\n    8150,\n    8155,\n    8160,\n    8172,\n    8178,\n    8180,\n    8182,\n    8188,\n    8203,\n    8207,\n    8234,\n    8238,\n    8255,\n    8256,\n    8276,\n    8276,\n    8288,\n    8292,\n    8294,\n    8303,\n    8305,\n    8305,\n    8319,\n    8319,\n    8336,\n    8348,\n    8400,\n    8412,\n    8417,\n    8417,\n    8421,\n    8432,\n    8450,\n    8450,\n    8455,\n    8455,\n    8458,\n    8467,\n    8469,\n    8469,\n    8473,\n    8477,\n    8484,\n    8484,\n    8486,\n    8486,\n    8488,\n    8488,\n    8490,\n    8493,\n    8495,\n    8505,\n    8508,\n    8511,\n    8517,\n    8521,\n    8526,\n    8526,\n    8544,\n    8584,\n    11264,\n    11492,\n    11499,\n    11507,\n    11520,\n    11557,\n    11559,\n    11559,\n    11565,\n    11565,\n    11568,\n    11623,\n    11631,\n    11631,\n    11647,\n    11670,\n    11680,\n    11686,\n    11688,\n    11694,\n    11696,\n    11702,\n    11704,\n    11710,\n    11712,\n    11718,\n    11720,\n    11726,\n    11728,\n    11734,\n    11736,\n    11742,\n    11744,\n    11775,\n    11823,\n    11823,\n    12293,\n    12295,\n    12321,\n    12335,\n    12337,\n    12341,\n    12344,\n    12348,\n    12353,\n    12438,\n    12441,\n    12442,\n    12445,\n    12447,\n    12449,\n    12538,\n    12540,\n    12543,\n    12549,\n    12591,\n    12593,\n    12686,\n    12704,\n    12735,\n    12784,\n    12799,\n    13312,\n    19903,\n    19968,\n    42124,\n    42192,\n    42237,\n    42240,\n    42508,\n    42512,\n    42539,\n    42560,\n    42607,\n    42612,\n    42621,\n    42623,\n    42737,\n    42775,\n    42783,\n    42786,\n    42888,\n    42891,\n    42954,\n    42960,\n    42961,\n    42963,\n    42963,\n    42965,\n    42969,\n    42994,\n    43047,\n    43052,\n    43052,\n    43072,\n    43123,\n    43136,\n    43205,\n    43216,\n    43225,\n    43232,\n    43255,\n    43259,\n    43259,\n    43261,\n    43309,\n    43312,\n    43347,\n    43360,\n    43388,\n    43392,\n    43456,\n    43471,\n    43481,\n    43488,\n    43518,\n    43520,\n    43574,\n    43584,\n    43597,\n    43600,\n    43609,\n    43616,\n    43638,\n    43642,\n    43714,\n    43739,\n    43741,\n    43744,\n    43759,\n    43762,\n    43766,\n    43777,\n    43782,\n    43785,\n    43790,\n    43793,\n    43798,\n    43808,\n    43814,\n    43816,\n    43822,\n    43824,\n    43866,\n    43868,\n    43881,\n    43888,\n    44010,\n    44012,\n    44013,\n    44016,\n    44025,\n    44032,\n    55203,\n    55216,\n    55238,\n    55243,\n    55291,\n    63744,\n    64109,\n    64112,\n    64217,\n    64256,\n    64262,\n    64275,\n    64279,\n    64285,\n    64296,\n    64298,\n    64310,\n    64312,\n    64316,\n    64318,\n    64318,\n    64320,\n    64321,\n    64323,\n    64324,\n    64326,\n    64433,\n    64467,\n    64829,\n    64848,\n    64911,\n    64914,\n    64967,\n    65008,\n    65019,\n    65024,\n    65039,\n    65056,\n    65071,\n    65075,\n    65076,\n    65101,\n    65103,\n    65136,\n    65140,\n    65142,\n    65276,\n    65279,\n    65279,\n    65296,\n    65305,\n    65313,\n    65338,\n    65343,\n    65343,\n    65345,\n    65370,\n    65382,\n    65470,\n    65474,\n    65479,\n    65482,\n    65487,\n    65490,\n    65495,\n    65498,\n    65500,\n    65529,\n    65531,\n    65536,\n    65547,\n    65549,\n    65574,\n    65576,\n    65594,\n    65596,\n    65597,\n    65599,\n    65613,\n    65616,\n    65629,\n    65664,\n    65786,\n    65856,\n    65908,\n    66045,\n    66045,\n    66176,\n    66204,\n    66208,\n    66256,\n    66272,\n    66272,\n    66304,\n    66335,\n    66349,\n    66378,\n    66384,\n    66426,\n    66432,\n    66461,\n    66464,\n    66499,\n    66504,\n    66511,\n    66513,\n    66517,\n    66560,\n    66717,\n    66720,\n    66729,\n    66736,\n    66771,\n    66776,\n    66811,\n    66816,\n    66855,\n    66864,\n    66915,\n    66928,\n    66938,\n    66940,\n    66954,\n    66956,\n    66962,\n    66964,\n    66965,\n    66967,\n    66977,\n    66979,\n    66993,\n    66995,\n    67001,\n    67003,\n    67004,\n    67072,\n    67382,\n    67392,\n    67413,\n    67424,\n    67431,\n    67456,\n    67461,\n    67463,\n    67504,\n    67506,\n    67514,\n    67584,\n    67589,\n    67592,\n    67592,\n    67594,\n    67637,\n    67639,\n    67640,\n    67644,\n    67644,\n    67647,\n    67669,\n    67680,\n    67702,\n    67712,\n    67742,\n    67808,\n    67826,\n    67828,\n    67829,\n    67840,\n    67861,\n    67872,\n    67897,\n    67968,\n    68023,\n    68030,\n    68031,\n    68096,\n    68099,\n    68101,\n    68102,\n    68108,\n    68115,\n    68117,\n    68119,\n    68121,\n    68149,\n    68152,\n    68154,\n    68159,\n    68159,\n    68192,\n    68220,\n    68224,\n    68252,\n    68288,\n    68295,\n    68297,\n    68326,\n    68352,\n    68405,\n    68416,\n    68437,\n    68448,\n    68466,\n    68480,\n    68497,\n    68608,\n    68680,\n    68736,\n    68786,\n    68800,\n    68850,\n    68864,\n    68903,\n    68912,\n    68921,\n    69248,\n    69289,\n    69291,\n    69292,\n    69296,\n    69297,\n    69373,\n    69404,\n    69415,\n    69415,\n    69424,\n    69456,\n    69488,\n    69509,\n    69552,\n    69572,\n    69600,\n    69622,\n    69632,\n    69702,\n    69734,\n    69749,\n    69759,\n    69818,\n    69821,\n    69821,\n    69826,\n    69826,\n    69837,\n    69837,\n    69840,\n    69864,\n    69872,\n    69881,\n    69888,\n    69940,\n    69942,\n    69951,\n    69956,\n    69959,\n    69968,\n    70003,\n    70006,\n    70006,\n    70016,\n    70084,\n    70089,\n    70092,\n    70094,\n    70106,\n    70108,\n    70108,\n    70144,\n    70161,\n    70163,\n    70199,\n    70206,\n    70209,\n    70272,\n    70278,\n    70280,\n    70280,\n    70282,\n    70285,\n    70287,\n    70301,\n    70303,\n    70312,\n    70320,\n    70378,\n    70384,\n    70393,\n    70400,\n    70403,\n    70405,\n    70412,\n    70415,\n    70416,\n    70419,\n    70440,\n    70442,\n    70448,\n    70450,\n    70451,\n    70453,\n    70457,\n    70459,\n    70468,\n    70471,\n    70472,\n    70475,\n    70477,\n    70480,\n    70480,\n    70487,\n    70487,\n    70493,\n    70499,\n    70502,\n    70508,\n    70512,\n    70516,\n    70656,\n    70730,\n    70736,\n    70745,\n    70750,\n    70753,\n    70784,\n    70853,\n    70855,\n    70855,\n    70864,\n    70873,\n    71040,\n    71093,\n    71096,\n    71104,\n    71128,\n    71133,\n    71168,\n    71232,\n    71236,\n    71236,\n    71248,\n    71257,\n    71296,\n    71352,\n    71360,\n    71369,\n    71424,\n    71450,\n    71453,\n    71467,\n    71472,\n    71481,\n    71488,\n    71494,\n    71680,\n    71738,\n    71840,\n    71913,\n    71935,\n    71942,\n    71945,\n    71945,\n    71948,\n    71955,\n    71957,\n    71958,\n    71960,\n    71989,\n    71991,\n    71992,\n    71995,\n    72003,\n    72016,\n    72025,\n    72096,\n    72103,\n    72106,\n    72151,\n    72154,\n    72161,\n    72163,\n    72164,\n    72192,\n    72254,\n    72263,\n    72263,\n    72272,\n    72345,\n    72349,\n    72349,\n    72368,\n    72440,\n    72704,\n    72712,\n    72714,\n    72758,\n    72760,\n    72768,\n    72784,\n    72793,\n    72818,\n    72847,\n    72850,\n    72871,\n    72873,\n    72886,\n    72960,\n    72966,\n    72968,\n    72969,\n    72971,\n    73014,\n    73018,\n    73018,\n    73020,\n    73021,\n    73023,\n    73031,\n    73040,\n    73049,\n    73056,\n    73061,\n    73063,\n    73064,\n    73066,\n    73102,\n    73104,\n    73105,\n    73107,\n    73112,\n    73120,\n    73129,\n    73440,\n    73462,\n    73472,\n    73488,\n    73490,\n    73530,\n    73534,\n    73538,\n    73552,\n    73561,\n    73648,\n    73648,\n    73728,\n    74649,\n    74752,\n    74862,\n    74880,\n    75075,\n    77712,\n    77808,\n    77824,\n    78933,\n    82944,\n    83526,\n    92160,\n    92728,\n    92736,\n    92766,\n    92768,\n    92777,\n    92784,\n    92862,\n    92864,\n    92873,\n    92880,\n    92909,\n    92912,\n    92916,\n    92928,\n    92982,\n    92992,\n    92995,\n    93008,\n    93017,\n    93027,\n    93047,\n    93053,\n    93071,\n    93760,\n    93823,\n    93952,\n    94026,\n    94031,\n    94087,\n    94095,\n    94111,\n    94176,\n    94177,\n    94179,\n    94180,\n    94192,\n    94193,\n    94208,\n    100343,\n    100352,\n    101589,\n    101632,\n    101640,\n    110576,\n    110579,\n    110581,\n    110587,\n    110589,\n    110590,\n    110592,\n    110882,\n    110898,\n    110898,\n    110928,\n    110930,\n    110933,\n    110933,\n    110948,\n    110951,\n    110960,\n    111355,\n    113664,\n    113770,\n    113776,\n    113788,\n    113792,\n    113800,\n    113808,\n    113817,\n    113821,\n    113822,\n    113824,\n    113827,\n    118528,\n    118573,\n    118576,\n    118598,\n    119141,\n    119145,\n    119149,\n    119170,\n    119173,\n    119179,\n    119210,\n    119213,\n    119362,\n    119364,\n    119808,\n    119892,\n    119894,\n    119964,\n    119966,\n    119967,\n    119970,\n    119970,\n    119973,\n    119974,\n    119977,\n    119980,\n    119982,\n    119993,\n    119995,\n    119995,\n    119997,\n    120003,\n    120005,\n    120069,\n    120071,\n    120074,\n    120077,\n    120084,\n    120086,\n    120092,\n    120094,\n    120121,\n    120123,\n    120126,\n    120128,\n    120132,\n    120134,\n    120134,\n    120138,\n    120144,\n    120146,\n    120485,\n    120488,\n    120512,\n    120514,\n    120538,\n    120540,\n    120570,\n    120572,\n    120596,\n    120598,\n    120628,\n    120630,\n    120654,\n    120656,\n    120686,\n    120688,\n    120712,\n    120714,\n    120744,\n    120746,\n    120770,\n    120772,\n    120779,\n    120782,\n    120831,\n    121344,\n    121398,\n    121403,\n    121452,\n    121461,\n    121461,\n    121476,\n    121476,\n    121499,\n    121503,\n    121505,\n    121519,\n    122624,\n    122654,\n    122661,\n    122666,\n    122880,\n    122886,\n    122888,\n    122904,\n    122907,\n    122913,\n    122915,\n    122916,\n    122918,\n    122922,\n    122928,\n    122989,\n    123023,\n    123023,\n    123136,\n    123180,\n    123184,\n    123197,\n    123200,\n    123209,\n    123214,\n    123214,\n    123536,\n    123566,\n    123584,\n    123641,\n    124112,\n    124153,\n    124896,\n    124902,\n    124904,\n    124907,\n    124909,\n    124910,\n    124912,\n    124926,\n    124928,\n    125124,\n    125136,\n    125142,\n    125184,\n    125259,\n    125264,\n    125273,\n    126464,\n    126467,\n    126469,\n    126495,\n    126497,\n    126498,\n    126500,\n    126500,\n    126503,\n    126503,\n    126505,\n    126514,\n    126516,\n    126519,\n    126521,\n    126521,\n    126523,\n    126523,\n    126530,\n    126530,\n    126535,\n    126535,\n    126537,\n    126537,\n    126539,\n    126539,\n    126541,\n    126543,\n    126545,\n    126546,\n    126548,\n    126548,\n    126551,\n    126551,\n    126553,\n    126553,\n    126555,\n    126555,\n    126557,\n    126557,\n    126559,\n    126559,\n    126561,\n    126562,\n    126564,\n    126564,\n    126567,\n    126570,\n    126572,\n    126578,\n    126580,\n    126583,\n    126585,\n    126588,\n    126590,\n    126590,\n    126592,\n    126601,\n    126603,\n    126619,\n    126625,\n    126627,\n    126629,\n    126633,\n    126635,\n    126651,\n    130032,\n    130041,\n    131072,\n    173791,\n    173824,\n    177977,\n    177984,\n    178205,\n    178208,\n    183969,\n    183984,\n    191456,\n    194560,\n    195101,\n    196608,\n    201546,\n    201552,\n    205743,\n    917505,\n    917505,\n    917536,\n    917631,\n    917760,\n    917999,\n    662,\n    0,\n    65,\n    90,\n    97,\n    122,\n    170,\n    170,\n    181,\n    181,\n    186,\n    186,\n    192,\n    214,\n    216,\n    246,\n    248,\n    705,\n    710,\n    721,\n    736,\n    740,\n    748,\n    748,\n    750,\n    750,\n    880,\n    884,\n    886,\n    887,\n    890,\n    893,\n    895,\n    895,\n    902,\n    902,\n    904,\n    906,\n    908,\n    908,\n    910,\n    929,\n    931,\n    1013,\n    1015,\n    1153,\n    1162,\n    1327,\n    1329,\n    1366,\n    1369,\n    1369,\n    1376,\n    1416,\n    1488,\n    1514,\n    1519,\n    1522,\n    1568,\n    1610,\n    1646,\n    1647,\n    1649,\n    1747,\n    1749,\n    1749,\n    1765,\n    1766,\n    1774,\n    1775,\n    1786,\n    1788,\n    1791,\n    1791,\n    1808,\n    1808,\n    1810,\n    1839,\n    1869,\n    1957,\n    1969,\n    1969,\n    1994,\n    2026,\n    2036,\n    2037,\n    2042,\n    2042,\n    2048,\n    2069,\n    2074,\n    2074,\n    2084,\n    2084,\n    2088,\n    2088,\n    2112,\n    2136,\n    2144,\n    2154,\n    2160,\n    2183,\n    2185,\n    2190,\n    2208,\n    2249,\n    2308,\n    2361,\n    2365,\n    2365,\n    2384,\n    2384,\n    2392,\n    2401,\n    2417,\n    2432,\n    2437,\n    2444,\n    2447,\n    2448,\n    2451,\n    2472,\n    2474,\n    2480,\n    2482,\n    2482,\n    2486,\n    2489,\n    2493,\n    2493,\n    2510,\n    2510,\n    2524,\n    2525,\n    2527,\n    2529,\n    2544,\n    2545,\n    2556,\n    2556,\n    2565,\n    2570,\n    2575,\n    2576,\n    2579,\n    2600,\n    2602,\n    2608,\n    2610,\n    2611,\n    2613,\n    2614,\n    2616,\n    2617,\n    2649,\n    2652,\n    2654,\n    2654,\n    2674,\n    2676,\n    2693,\n    2701,\n    2703,\n    2705,\n    2707,\n    2728,\n    2730,\n    2736,\n    2738,\n    2739,\n    2741,\n    2745,\n    2749,\n    2749,\n    2768,\n    2768,\n    2784,\n    2785,\n    2809,\n    2809,\n    2821,\n    2828,\n    2831,\n    2832,\n    2835,\n    2856,\n    2858,\n    2864,\n    2866,\n    2867,\n    2869,\n    2873,\n    2877,\n    2877,\n    2908,\n    2909,\n    2911,\n    2913,\n    2929,\n    2929,\n    2947,\n    2947,\n    2949,\n    2954,\n    2958,\n    2960,\n    2962,\n    2965,\n    2969,\n    2970,\n    2972,\n    2972,\n    2974,\n    2975,\n    2979,\n    2980,\n    2984,\n    2986,\n    2990,\n    3001,\n    3024,\n    3024,\n    3077,\n    3084,\n    3086,\n    3088,\n    3090,\n    3112,\n    3114,\n    3129,\n    3133,\n    3133,\n    3160,\n    3162,\n    3165,\n    3165,\n    3168,\n    3169,\n    3200,\n    3200,\n    3205,\n    3212,\n    3214,\n    3216,\n    3218,\n    3240,\n    3242,\n    3251,\n    3253,\n    3257,\n    3261,\n    3261,\n    3293,\n    3294,\n    3296,\n    3297,\n    3313,\n    3314,\n    3332,\n    3340,\n    3342,\n    3344,\n    3346,\n    3386,\n    3389,\n    3389,\n    3406,\n    3406,\n    3412,\n    3414,\n    3423,\n    3425,\n    3450,\n    3455,\n    3461,\n    3478,\n    3482,\n    3505,\n    3507,\n    3515,\n    3517,\n    3517,\n    3520,\n    3526,\n    3585,\n    3632,\n    3634,\n    3635,\n    3648,\n    3654,\n    3713,\n    3714,\n    3716,\n    3716,\n    3718,\n    3722,\n    3724,\n    3747,\n    3749,\n    3749,\n    3751,\n    3760,\n    3762,\n    3763,\n    3773,\n    3773,\n    3776,\n    3780,\n    3782,\n    3782,\n    3804,\n    3807,\n    3840,\n    3840,\n    3904,\n    3911,\n    3913,\n    3948,\n    3976,\n    3980,\n    4096,\n    4138,\n    4159,\n    4159,\n    4176,\n    4181,\n    4186,\n    4189,\n    4193,\n    4193,\n    4197,\n    4198,\n    4206,\n    4208,\n    4213,\n    4225,\n    4238,\n    4238,\n    4256,\n    4293,\n    4295,\n    4295,\n    4301,\n    4301,\n    4304,\n    4346,\n    4348,\n    4680,\n    4682,\n    4685,\n    4688,\n    4694,\n    4696,\n    4696,\n    4698,\n    4701,\n    4704,\n    4744,\n    4746,\n    4749,\n    4752,\n    4784,\n    4786,\n    4789,\n    4792,\n    4798,\n    4800,\n    4800,\n    4802,\n    4805,\n    4808,\n    4822,\n    4824,\n    4880,\n    4882,\n    4885,\n    4888,\n    4954,\n    4992,\n    5007,\n    5024,\n    5109,\n    5112,\n    5117,\n    5121,\n    5740,\n    5743,\n    5759,\n    5761,\n    5786,\n    5792,\n    5866,\n    5870,\n    5880,\n    5888,\n    5905,\n    5919,\n    5937,\n    5952,\n    5969,\n    5984,\n    5996,\n    5998,\n    6e3,\n    6016,\n    6067,\n    6103,\n    6103,\n    6108,\n    6108,\n    6176,\n    6264,\n    6272,\n    6276,\n    6279,\n    6312,\n    6314,\n    6314,\n    6320,\n    6389,\n    6400,\n    6430,\n    6480,\n    6509,\n    6512,\n    6516,\n    6528,\n    6571,\n    6576,\n    6601,\n    6656,\n    6678,\n    6688,\n    6740,\n    6823,\n    6823,\n    6917,\n    6963,\n    6981,\n    6988,\n    7043,\n    7072,\n    7086,\n    7087,\n    7098,\n    7141,\n    7168,\n    7203,\n    7245,\n    7247,\n    7258,\n    7293,\n    7296,\n    7304,\n    7312,\n    7354,\n    7357,\n    7359,\n    7401,\n    7404,\n    7406,\n    7411,\n    7413,\n    7414,\n    7418,\n    7418,\n    7424,\n    7615,\n    7680,\n    7957,\n    7960,\n    7965,\n    7968,\n    8005,\n    8008,\n    8013,\n    8016,\n    8023,\n    8025,\n    8025,\n    8027,\n    8027,\n    8029,\n    8029,\n    8031,\n    8061,\n    8064,\n    8116,\n    8118,\n    8124,\n    8126,\n    8126,\n    8130,\n    8132,\n    8134,\n    8140,\n    8144,\n    8147,\n    8150,\n    8155,\n    8160,\n    8172,\n    8178,\n    8180,\n    8182,\n    8188,\n    8305,\n    8305,\n    8319,\n    8319,\n    8336,\n    8348,\n    8450,\n    8450,\n    8455,\n    8455,\n    8458,\n    8467,\n    8469,\n    8469,\n    8473,\n    8477,\n    8484,\n    8484,\n    8486,\n    8486,\n    8488,\n    8488,\n    8490,\n    8493,\n    8495,\n    8505,\n    8508,\n    8511,\n    8517,\n    8521,\n    8526,\n    8526,\n    8544,\n    8584,\n    11264,\n    11492,\n    11499,\n    11502,\n    11506,\n    11507,\n    11520,\n    11557,\n    11559,\n    11559,\n    11565,\n    11565,\n    11568,\n    11623,\n    11631,\n    11631,\n    11648,\n    11670,\n    11680,\n    11686,\n    11688,\n    11694,\n    11696,\n    11702,\n    11704,\n    11710,\n    11712,\n    11718,\n    11720,\n    11726,\n    11728,\n    11734,\n    11736,\n    11742,\n    11823,\n    11823,\n    12293,\n    12295,\n    12321,\n    12329,\n    12337,\n    12341,\n    12344,\n    12348,\n    12353,\n    12438,\n    12445,\n    12447,\n    12449,\n    12538,\n    12540,\n    12543,\n    12549,\n    12591,\n    12593,\n    12686,\n    12704,\n    12735,\n    12784,\n    12799,\n    13312,\n    19903,\n    19968,\n    42124,\n    42192,\n    42237,\n    42240,\n    42508,\n    42512,\n    42527,\n    42538,\n    42539,\n    42560,\n    42606,\n    42623,\n    42653,\n    42656,\n    42735,\n    42775,\n    42783,\n    42786,\n    42888,\n    42891,\n    42954,\n    42960,\n    42961,\n    42963,\n    42963,\n    42965,\n    42969,\n    42994,\n    43009,\n    43011,\n    43013,\n    43015,\n    43018,\n    43020,\n    43042,\n    43072,\n    43123,\n    43138,\n    43187,\n    43250,\n    43255,\n    43259,\n    43259,\n    43261,\n    43262,\n    43274,\n    43301,\n    43312,\n    43334,\n    43360,\n    43388,\n    43396,\n    43442,\n    43471,\n    43471,\n    43488,\n    43492,\n    43494,\n    43503,\n    43514,\n    43518,\n    43520,\n    43560,\n    43584,\n    43586,\n    43588,\n    43595,\n    43616,\n    43638,\n    43642,\n    43642,\n    43646,\n    43695,\n    43697,\n    43697,\n    43701,\n    43702,\n    43705,\n    43709,\n    43712,\n    43712,\n    43714,\n    43714,\n    43739,\n    43741,\n    43744,\n    43754,\n    43762,\n    43764,\n    43777,\n    43782,\n    43785,\n    43790,\n    43793,\n    43798,\n    43808,\n    43814,\n    43816,\n    43822,\n    43824,\n    43866,\n    43868,\n    43881,\n    43888,\n    44002,\n    44032,\n    55203,\n    55216,\n    55238,\n    55243,\n    55291,\n    63744,\n    64109,\n    64112,\n    64217,\n    64256,\n    64262,\n    64275,\n    64279,\n    64285,\n    64285,\n    64287,\n    64296,\n    64298,\n    64310,\n    64312,\n    64316,\n    64318,\n    64318,\n    64320,\n    64321,\n    64323,\n    64324,\n    64326,\n    64433,\n    64467,\n    64829,\n    64848,\n    64911,\n    64914,\n    64967,\n    65008,\n    65019,\n    65136,\n    65140,\n    65142,\n    65276,\n    65313,\n    65338,\n    65345,\n    65370,\n    65382,\n    65470,\n    65474,\n    65479,\n    65482,\n    65487,\n    65490,\n    65495,\n    65498,\n    65500,\n    65536,\n    65547,\n    65549,\n    65574,\n    65576,\n    65594,\n    65596,\n    65597,\n    65599,\n    65613,\n    65616,\n    65629,\n    65664,\n    65786,\n    65856,\n    65908,\n    66176,\n    66204,\n    66208,\n    66256,\n    66304,\n    66335,\n    66349,\n    66378,\n    66384,\n    66421,\n    66432,\n    66461,\n    66464,\n    66499,\n    66504,\n    66511,\n    66513,\n    66517,\n    66560,\n    66717,\n    66736,\n    66771,\n    66776,\n    66811,\n    66816,\n    66855,\n    66864,\n    66915,\n    66928,\n    66938,\n    66940,\n    66954,\n    66956,\n    66962,\n    66964,\n    66965,\n    66967,\n    66977,\n    66979,\n    66993,\n    66995,\n    67001,\n    67003,\n    67004,\n    67072,\n    67382,\n    67392,\n    67413,\n    67424,\n    67431,\n    67456,\n    67461,\n    67463,\n    67504,\n    67506,\n    67514,\n    67584,\n    67589,\n    67592,\n    67592,\n    67594,\n    67637,\n    67639,\n    67640,\n    67644,\n    67644,\n    67647,\n    67669,\n    67680,\n    67702,\n    67712,\n    67742,\n    67808,\n    67826,\n    67828,\n    67829,\n    67840,\n    67861,\n    67872,\n    67897,\n    67968,\n    68023,\n    68030,\n    68031,\n    68096,\n    68096,\n    68112,\n    68115,\n    68117,\n    68119,\n    68121,\n    68149,\n    68192,\n    68220,\n    68224,\n    68252,\n    68288,\n    68295,\n    68297,\n    68324,\n    68352,\n    68405,\n    68416,\n    68437,\n    68448,\n    68466,\n    68480,\n    68497,\n    68608,\n    68680,\n    68736,\n    68786,\n    68800,\n    68850,\n    68864,\n    68899,\n    69248,\n    69289,\n    69296,\n    69297,\n    69376,\n    69404,\n    69415,\n    69415,\n    69424,\n    69445,\n    69488,\n    69505,\n    69552,\n    69572,\n    69600,\n    69622,\n    69635,\n    69687,\n    69745,\n    69746,\n    69749,\n    69749,\n    69763,\n    69807,\n    69840,\n    69864,\n    69891,\n    69926,\n    69956,\n    69956,\n    69959,\n    69959,\n    69968,\n    70002,\n    70006,\n    70006,\n    70019,\n    70066,\n    70081,\n    70084,\n    70106,\n    70106,\n    70108,\n    70108,\n    70144,\n    70161,\n    70163,\n    70187,\n    70207,\n    70208,\n    70272,\n    70278,\n    70280,\n    70280,\n    70282,\n    70285,\n    70287,\n    70301,\n    70303,\n    70312,\n    70320,\n    70366,\n    70405,\n    70412,\n    70415,\n    70416,\n    70419,\n    70440,\n    70442,\n    70448,\n    70450,\n    70451,\n    70453,\n    70457,\n    70461,\n    70461,\n    70480,\n    70480,\n    70493,\n    70497,\n    70656,\n    70708,\n    70727,\n    70730,\n    70751,\n    70753,\n    70784,\n    70831,\n    70852,\n    70853,\n    70855,\n    70855,\n    71040,\n    71086,\n    71128,\n    71131,\n    71168,\n    71215,\n    71236,\n    71236,\n    71296,\n    71338,\n    71352,\n    71352,\n    71424,\n    71450,\n    71488,\n    71494,\n    71680,\n    71723,\n    71840,\n    71903,\n    71935,\n    71942,\n    71945,\n    71945,\n    71948,\n    71955,\n    71957,\n    71958,\n    71960,\n    71983,\n    71999,\n    71999,\n    72001,\n    72001,\n    72096,\n    72103,\n    72106,\n    72144,\n    72161,\n    72161,\n    72163,\n    72163,\n    72192,\n    72192,\n    72203,\n    72242,\n    72250,\n    72250,\n    72272,\n    72272,\n    72284,\n    72329,\n    72349,\n    72349,\n    72368,\n    72440,\n    72704,\n    72712,\n    72714,\n    72750,\n    72768,\n    72768,\n    72818,\n    72847,\n    72960,\n    72966,\n    72968,\n    72969,\n    72971,\n    73008,\n    73030,\n    73030,\n    73056,\n    73061,\n    73063,\n    73064,\n    73066,\n    73097,\n    73112,\n    73112,\n    73440,\n    73458,\n    73474,\n    73474,\n    73476,\n    73488,\n    73490,\n    73523,\n    73648,\n    73648,\n    73728,\n    74649,\n    74752,\n    74862,\n    74880,\n    75075,\n    77712,\n    77808,\n    77824,\n    78895,\n    78913,\n    78918,\n    82944,\n    83526,\n    92160,\n    92728,\n    92736,\n    92766,\n    92784,\n    92862,\n    92880,\n    92909,\n    92928,\n    92975,\n    92992,\n    92995,\n    93027,\n    93047,\n    93053,\n    93071,\n    93760,\n    93823,\n    93952,\n    94026,\n    94032,\n    94032,\n    94099,\n    94111,\n    94176,\n    94177,\n    94179,\n    94179,\n    94208,\n    100343,\n    100352,\n    101589,\n    101632,\n    101640,\n    110576,\n    110579,\n    110581,\n    110587,\n    110589,\n    110590,\n    110592,\n    110882,\n    110898,\n    110898,\n    110928,\n    110930,\n    110933,\n    110933,\n    110948,\n    110951,\n    110960,\n    111355,\n    113664,\n    113770,\n    113776,\n    113788,\n    113792,\n    113800,\n    113808,\n    113817,\n    119808,\n    119892,\n    119894,\n    119964,\n    119966,\n    119967,\n    119970,\n    119970,\n    119973,\n    119974,\n    119977,\n    119980,\n    119982,\n    119993,\n    119995,\n    119995,\n    119997,\n    120003,\n    120005,\n    120069,\n    120071,\n    120074,\n    120077,\n    120084,\n    120086,\n    120092,\n    120094,\n    120121,\n    120123,\n    120126,\n    120128,\n    120132,\n    120134,\n    120134,\n    120138,\n    120144,\n    120146,\n    120485,\n    120488,\n    120512,\n    120514,\n    120538,\n    120540,\n    120570,\n    120572,\n    120596,\n    120598,\n    120628,\n    120630,\n    120654,\n    120656,\n    120686,\n    120688,\n    120712,\n    120714,\n    120744,\n    120746,\n    120770,\n    120772,\n    120779,\n    122624,\n    122654,\n    122661,\n    122666,\n    122928,\n    122989,\n    123136,\n    123180,\n    123191,\n    123197,\n    123214,\n    123214,\n    123536,\n    123565,\n    123584,\n    123627,\n    124112,\n    124139,\n    124896,\n    124902,\n    124904,\n    124907,\n    124909,\n    124910,\n    124912,\n    124926,\n    124928,\n    125124,\n    125184,\n    125251,\n    125259,\n    125259,\n    126464,\n    126467,\n    126469,\n    126495,\n    126497,\n    126498,\n    126500,\n    126500,\n    126503,\n    126503,\n    126505,\n    126514,\n    126516,\n    126519,\n    126521,\n    126521,\n    126523,\n    126523,\n    126530,\n    126530,\n    126535,\n    126535,\n    126537,\n    126537,\n    126539,\n    126539,\n    126541,\n    126543,\n    126545,\n    126546,\n    126548,\n    126548,\n    126551,\n    126551,\n    126553,\n    126553,\n    126555,\n    126555,\n    126557,\n    126557,\n    126559,\n    126559,\n    126561,\n    126562,\n    126564,\n    126564,\n    126567,\n    126570,\n    126572,\n    126578,\n    126580,\n    126583,\n    126585,\n    126588,\n    126590,\n    126590,\n    126592,\n    126601,\n    126603,\n    126619,\n    126625,\n    126627,\n    126629,\n    126633,\n    126635,\n    126651,\n    131072,\n    173791,\n    173824,\n    177977,\n    177984,\n    178205,\n    178208,\n    183969,\n    183984,\n    191456,\n    194560,\n    195101,\n    196608,\n    201546,\n    201552,\n    205743,\n    47,\n    0,\n    1,\n    1,\n    0,\n    0,\n    0,\n    0,\n    3,\n    1,\n    0,\n    0,\n    0,\n    0,\n    5,\n    1,\n    0,\n    0,\n    0,\n    0,\n    7,\n    1,\n    0,\n    0,\n    0,\n    0,\n    9,\n    1,\n    0,\n    0,\n    0,\n    0,\n    15,\n    1,\n    0,\n    0,\n    0,\n    1,\n    17,\n    1,\n    0,\n    0,\n    0,\n    3,\n    20,\n    1,\n    0,\n    0,\n    0,\n    5,\n    22,\n    1,\n    0,\n    0,\n    0,\n    7,\n    24,\n    1,\n    0,\n    0,\n    0,\n    9,\n    26,\n    1,\n    0,\n    0,\n    0,\n    11,\n    35,\n    1,\n    0,\n    0,\n    0,\n    13,\n    37,\n    1,\n    0,\n    0,\n    0,\n    15,\n    39,\n    1,\n    0,\n    0,\n    0,\n    17,\n    18,\n    5,\n    47,\n    0,\n    0,\n    18,\n    19,\n    5,\n    47,\n    0,\n    0,\n    19,\n    2,\n    1,\n    0,\n    0,\n    0,\n    20,\n    21,\n    5,\n    47,\n    0,\n    0,\n    21,\n    4,\n    1,\n    0,\n    0,\n    0,\n    22,\n    23,\n    5,\n    42,\n    0,\n    0,\n    23,\n    6,\n    1,\n    0,\n    0,\n    0,\n    24,\n    25,\n    5,\n    33,\n    0,\n    0,\n    25,\n    8,\n    1,\n    0,\n    0,\n    0,\n    26,\n    30,\n    3,\n    13,\n    6,\n    0,\n    27,\n    29,\n    3,\n    11,\n    5,\n    0,\n    28,\n    27,\n    1,\n    0,\n    0,\n    0,\n    29,\n    32,\n    1,\n    0,\n    0,\n    0,\n    30,\n    28,\n    1,\n    0,\n    0,\n    0,\n    30,\n    31,\n    1,\n    0,\n    0,\n    0,\n    31,\n    33,\n    1,\n    0,\n    0,\n    0,\n    32,\n    30,\n    1,\n    0,\n    0,\n    0,\n    33,\n    34,\n    6,\n    4,\n    0,\n    0,\n    34,\n    10,\n    1,\n    0,\n    0,\n    0,\n    35,\n    36,\n    7,\n    0,\n    0,\n    0,\n    36,\n    12,\n    1,\n    0,\n    0,\n    0,\n    37,\n    38,\n    7,\n    1,\n    0,\n    0,\n    38,\n    14,\n    1,\n    0,\n    0,\n    0,\n    39,\n    43,\n    5,\n    39,\n    0,\n    0,\n    40,\n    42,\n    9,\n    0,\n    0,\n    0,\n    41,\n    40,\n    1,\n    0,\n    0,\n    0,\n    42,\n    45,\n    1,\n    0,\n    0,\n    0,\n    43,\n    44,\n    1,\n    0,\n    0,\n    0,\n    43,\n    41,\n    1,\n    0,\n    0,\n    0,\n    44,\n    46,\n    1,\n    0,\n    0,\n    0,\n    45,\n    43,\n    1,\n    0,\n    0,\n    0,\n    46,\n    47,\n    5,\n    39,\n    0,\n    0,\n    47,\n    16,\n    1,\n    0,\n    0,\n    0,\n    3,\n    0,\n    30,\n    43,\n    1,\n    1,\n    4,\n    0\n  ];\n  static __ATN;\n  static get _ATN() {\n    if (!_XPathLexer.__ATN) {\n      _XPathLexer.__ATN = new ATNDeserializer().deserialize(_XPathLexer._serializedATN);\n    }\n    return _XPathLexer.__ATN;\n  }\n  static vocabulary = new Vocabulary(_XPathLexer.literalNames, _XPathLexer.symbolicNames, []);\n  get vocabulary() {\n    return _XPathLexer.vocabulary;\n  }\n  static decisionsToDFA = _XPathLexer._ATN.decisionToState.map((ds, index) => {\n    return new DFA(ds, index);\n  });\n};\n\n// src/tree/xpath/XPathLexerErrorListener.ts\nvar XPathLexerErrorListener = class extends BaseErrorListener {\n  static {\n    __name(this, \"XPathLexerErrorListener\");\n  }\n  syntaxError(_recognizer, _offendingSymbol, _line, _charPositionInLine, _msg, _e) {\n  }\n};\n\n// src/tree/xpath/XPathElement.ts\nvar XPathElement = class {\n  static {\n    __name(this, \"XPathElement\");\n  }\n  invert;\n  nodeName;\n  /**\n   * Construct element like `/ID` or `ID` or `/*` etc... `nodeName` is undefined if just node\n   *\n   * @param nodeName The name of the node; may be undefined for any node.\n   */\n  constructor(nodeName) {\n    this.nodeName = nodeName;\n    this.invert = false;\n  }\n  toString() {\n    const inv = this.invert ? \"!\" : \"\";\n    return \"XPathElement[\" + inv + this.nodeName + \"]\";\n  }\n};\n\n// src/tree/xpath/XPathRuleAnywhereElement.ts\nvar XPathRuleAnywhereElement = class extends XPathElement {\n  static {\n    __name(this, \"XPathRuleAnywhereElement\");\n  }\n  ruleIndex;\n  constructor(ruleName, ruleIndex) {\n    super(ruleName);\n    this.ruleIndex = ruleIndex;\n  }\n  evaluate(t) {\n    return Trees.findAllRuleNodes(t, this.ruleIndex);\n  }\n  toString() {\n    const inv = this.invert ? \"!\" : \"\";\n    return \"XPathRuleAnywhereElement[\" + inv + this.nodeName + \"]\";\n  }\n};\n\n// src/tree/xpath/XPathRuleElement.ts\nvar XPathRuleElement = class extends XPathElement {\n  static {\n    __name(this, \"XPathRuleElement\");\n  }\n  ruleIndex;\n  constructor(ruleName, ruleIndex) {\n    super(ruleName);\n    this.ruleIndex = ruleIndex;\n  }\n  evaluate(t) {\n    const nodes = [];\n    for (const c of Trees.getChildren(t)) {\n      if (c instanceof ParserRuleContext) {\n        if (c.ruleIndex === this.ruleIndex && !this.invert || c.ruleIndex !== this.ruleIndex && this.invert) {\n          nodes.push(c);\n        }\n      }\n    }\n    return nodes;\n  }\n  toString() {\n    const inv = this.invert ? \"!\" : \"\";\n    return \"XPathRuleElement[\" + inv + this.nodeName + \"]\";\n  }\n};\n\n// src/tree/xpath/XPathTokenAnywhereElement.ts\nvar XPathTokenAnywhereElement = class extends XPathElement {\n  static {\n    __name(this, \"XPathTokenAnywhereElement\");\n  }\n  tokenType;\n  constructor(tokenName, tokenType) {\n    super(tokenName);\n    this.tokenType = tokenType;\n  }\n  evaluate(t) {\n    return Trees.findAllTokenNodes(t, this.tokenType);\n  }\n  toString() {\n    const inv = this.invert ? \"!\" : \"\";\n    return \"XPathTokenAnywhereElement[\" + inv + this.nodeName + \"]\";\n  }\n};\n\n// src/tree/xpath/XPathTokenElement.ts\nvar XPathTokenElement = class extends XPathElement {\n  static {\n    __name(this, \"XPathTokenElement\");\n  }\n  tokenType;\n  constructor(tokenName, tokenType) {\n    super(tokenName);\n    this.tokenType = tokenType;\n  }\n  evaluate(t) {\n    const nodes = [];\n    for (const c of Trees.getChildren(t)) {\n      if (c instanceof TerminalNode && c.symbol) {\n        if (c.symbol.type === this.tokenType && !this.invert || c.symbol.type !== this.tokenType && this.invert) {\n          nodes.push(c);\n        }\n      }\n    }\n    return nodes;\n  }\n  toString() {\n    const inv = this.invert ? \"!\" : \"\";\n    return \"XPathTokenElement[\" + inv + this.nodeName + \"]\";\n  }\n};\n\n// src/tree/xpath/XPathWildcardAnywhereElement.ts\nvar XPathWildcardAnywhereElement = class extends XPathElement {\n  static {\n    __name(this, \"XPathWildcardAnywhereElement\");\n  }\n  constructor() {\n    super(XPath.WILDCARD);\n  }\n  evaluate(t) {\n    if (this.invert) {\n      return [];\n    }\n    return Trees.descendants(t);\n  }\n  toString() {\n    const inv = this.invert ? \"!\" : \"\";\n    return \"XPathWildcardAnywhereElement[\" + inv + this.nodeName + \"]\";\n  }\n};\n\n// src/tree/xpath/XPathWildcardElement.ts\nvar XPathWildcardElement = class extends XPathElement {\n  static {\n    __name(this, \"XPathWildcardElement\");\n  }\n  constructor() {\n    super(XPath.WILDCARD);\n  }\n  evaluate(t) {\n    const kids = [];\n    if (this.invert) {\n      return kids;\n    }\n    for (const c of Trees.getChildren(t)) {\n      kids.push(c);\n    }\n    return kids;\n  }\n  toString() {\n    const inv = this.invert ? \"!\" : \"\";\n    return \"XPathWildcardElement[\" + inv + this.nodeName + \"]\";\n  }\n};\n\n// src/tree/xpath/XPath.ts\nvar XPath = class _XPath {\n  static {\n    __name(this, \"XPath\");\n  }\n  static WILDCARD = \"*\";\n  // word not operator/separator\n  static NOT = \"!\";\n  // word for invert operator\n  path;\n  elements;\n  parser;\n  constructor(parser, path) {\n    this.parser = parser;\n    this.path = path;\n    this.elements = this.split(path);\n  }\n  static findAll(tree, xpath, parser) {\n    const p = new _XPath(parser, xpath);\n    return p.evaluate(tree);\n  }\n  // TODO: check for invalid token/rule names, bad syntax\n  split(path) {\n    const lexer = new XPathLexer(CharStream.fromString(path));\n    lexer.recover = (e) => {\n      throw e;\n    };\n    lexer.removeErrorListeners();\n    lexer.addErrorListener(new XPathLexerErrorListener());\n    const tokenStream = new CommonTokenStream(lexer);\n    try {\n      tokenStream.fill();\n    } catch (e) {\n      if (e instanceof LexerNoViableAltException) {\n        const pos = lexer.column;\n        const msg = \"Invalid tokens or characters at index \" + pos + \" in path '\" + path + \"' -- \" + e.message;\n        throw new RangeError(msg);\n      }\n      throw e;\n    }\n    const tokens = tokenStream.getTokens();\n    const elements = [];\n    const n2 = tokens.length;\n    let i = 0;\n    loop:\n      while (i < n2) {\n        const el = tokens[i];\n        let next;\n        switch (el.type) {\n          case XPathLexer.ROOT:\n          case XPathLexer.ANYWHERE:\n            const anywhere = el.type === XPathLexer.ANYWHERE;\n            i++;\n            next = tokens[i];\n            const invert = next.type === XPathLexer.BANG;\n            if (invert) {\n              i++;\n              next = tokens[i];\n            }\n            const pathElement = this.getXPathElement(next, anywhere);\n            pathElement.invert = invert;\n            elements.push(pathElement);\n            i++;\n            break;\n          case XPathLexer.TOKEN_REF:\n          case XPathLexer.RULE_REF:\n          case XPathLexer.WILDCARD:\n            elements.push(this.getXPathElement(el, false));\n            ++i;\n            break;\n          case Token.EOF:\n            break loop;\n          default:\n            throw new Error(\"Unknown path element \" + el);\n        }\n      }\n    return elements;\n  }\n  /**\n   * Return a list of all nodes starting at `t` as root that satisfy the\n   * path. The root `/` is relative to the node passed to {@link evaluate}.\n   */\n  evaluate(t) {\n    const dummyRoot = new ParserRuleContext(null);\n    dummyRoot.addChild(t);\n    let work = /* @__PURE__ */ new Set([dummyRoot]);\n    let i = 0;\n    while (i < this.elements.length) {\n      const next = /* @__PURE__ */ new Set();\n      for (const node of work) {\n        if (node.getChildCount() > 0) {\n          const matching = this.elements[i].evaluate(node);\n          matching.forEach((tree) => {\n            next.add(tree);\n          }, next);\n        }\n      }\n      i++;\n      work = next;\n    }\n    return work;\n  }\n  /**\n   * Convert word like `*` or `ID` or `expr` to a path\n   * element. `anywhere` is `true` if `//` precedes the\n   * word.\n   */\n  getXPathElement(wordToken, anywhere) {\n    if (wordToken.type === Token.EOF) {\n      throw new Error(\"Missing path element at end of path\");\n    }\n    const word = wordToken.text;\n    if (word == null) {\n      throw new Error(\"Expected wordToken to have text content.\");\n    }\n    const ttype = this.parser.getTokenType(word);\n    const ruleIndex = this.parser.getRuleIndex(word);\n    switch (wordToken.type) {\n      case XPathLexer.WILDCARD:\n        return anywhere ? new XPathWildcardAnywhereElement() : new XPathWildcardElement();\n      case XPathLexer.TOKEN_REF:\n      case XPathLexer.STRING:\n        if (ttype === Token.INVALID_TYPE) {\n          throw new Error(word + \" at index \" + wordToken.start + \" isn't a valid token name\");\n        }\n        return anywhere ? new XPathTokenAnywhereElement(word, ttype) : new XPathTokenElement(word, ttype);\n      default:\n        if (ruleIndex === -1) {\n          throw new Error(word + \" at index \" + wordToken.start + \" isn't a valid rule name\");\n        }\n        return anywhere ? new XPathRuleAnywhereElement(word, ruleIndex) : new XPathRuleElement(word, ruleIndex);\n    }\n  }\n};\n\n// src/tree/pattern/Chunk.ts\nvar Chunk = class {\n  static {\n    __name(this, \"Chunk\");\n  }\n};\n\n// src/tree/pattern/ParseTreeMatch.ts\nvar ParseTreeMatch = class {\n  static {\n    __name(this, \"ParseTreeMatch\");\n  }\n  /**\n   * This is the backing field for {@link #getTree()}.\n   */\n  tree;\n  /**\n   * This is the backing field for {@link #getPattern()}.\n   */\n  pattern;\n  /**\n   * This is the backing field for {@link #getLabels()}.\n   */\n  labels;\n  /**\n   * This is the backing field for {@link #getMismatchedNode()}.\n   */\n  mismatchedNode;\n  /**\n   * Constructs a new instance of {@link ParseTreeMatch} from the specified\n   * parse tree and pattern.\n   *\n   * @param tree The parse tree to match against the pattern.\n   * @param pattern The parse tree pattern.\n   * @param labels A mapping from label names to collections of\n   * {@link ParseTree} objects located by the tree pattern matching process.\n   * @param mismatchedNode The first node which failed to match the tree\n   * pattern during the matching process.\n   */\n  constructor(tree, pattern, labels, mismatchedNode) {\n    this.tree = tree;\n    this.pattern = pattern;\n    this.labels = labels;\n    this.mismatchedNode = mismatchedNode;\n  }\n  /**\n   * Get the last node associated with a specific `label`.\n   *\n   * For example, for pattern `<id:ID>`, `get(\"id\")` returns the\n   * node matched for that `ID`. If more than one node\n   * matched the specified label, only the last is returned. If there is\n   * no node associated with the label, this returns `null`.\n   *\n   * Pattern tags like `<ID>` and `<expr>` without labels are\n   * considered to be labeled with `ID` and `expr`, respectively.\n   *\n   * @param label The label to check.\n   *\n   * @returns The last {@link ParseTree} to match a tag with the specified\n   * label, or `null` if no parse tree matched a tag with the label.\n   */\n  get(label) {\n    const parseTrees = this.labels.get(label);\n    if (!parseTrees || parseTrees.length === 0) {\n      return null;\n    }\n    return parseTrees[parseTrees.length - 1];\n  }\n  /**\n   * Return all nodes matching a rule or token tag with the specified label.\n   *\n   * If the `label` is the name of a parser rule or token in the\n   * grammar, the resulting list will contain both the parse trees matching\n   * rule or tags explicitly labeled with the label and the complete set of\n   * parse trees matching the labeled and unlabeled tags in the pattern for\n   * the parser rule or token. For example, if `label` is `\"foo\"`,\n   * the result will contain *all* of the following.\n   *\n   * - Parse tree nodes matching tags of the form `<foo:anyRuleName>` and\n   * `<foo:AnyTokenName>`.\n   * - Parse tree nodes matching tags of the form `<anyLabel:foo>`.\n   * - Parse tree nodes matching tags of the form `<foo>`.\n   *\n   * @param label The label.\n   *\n   * @returns A collection of all {@link ParseTree} nodes matching tags with\n   * the specified `label`. If no nodes matched the label, an empty list\n   * is returned.\n   */\n  getAll(label) {\n    const nodes = this.labels.get(label);\n    return nodes ?? [];\n  }\n  /**\n   * Return a mapping from label -> [list of nodes].\n   *\n   * The map includes special entries corresponding to the names of rules and\n   * tokens referenced in tags in the original pattern. For additional\n   * information, see the description of {@link getAll(String)}.\n   *\n   * @returns A mapping from labels to parse tree nodes. If the parse tree\n   * pattern did not contain any rule or token tags, this map will be empty.\n   */\n  getLabels() {\n    return this.labels;\n  }\n  /**\n   * Get the node at which we first detected a mismatch.\n   *\n   * @returns the node at which we first detected a mismatch, or `null`\n   * if the match was successful.\n   */\n  getMismatchedNode() {\n    return this.mismatchedNode;\n  }\n  /**\n   * Gets a value indicating whether the match operation succeeded.\n   *\n   * @returns `true` if the match operation succeeded; otherwise, `false`.\n   */\n  succeeded() {\n    return !this.mismatchedNode;\n  }\n  /**\n   * Get the tree pattern we are matching against.\n   *\n   * @returns The tree pattern we are matching against.\n   */\n  getPattern() {\n    return this.pattern;\n  }\n  /**\n   * Get the parse tree we are trying to match to a pattern.\n   *\n   * @returns The {@link ParseTree} we are trying to match to a pattern.\n   */\n  getTree() {\n    return this.tree;\n  }\n  toString() {\n    return `Match ${this.succeeded() ? \"succeeded\" : \"failed\"}; found ${this.getLabels().size} labels`;\n  }\n};\n\n// src/tree/pattern/ParseTreePattern.ts\nvar ParseTreePattern = class {\n  static {\n    __name(this, \"ParseTreePattern\");\n  }\n  /**\n   * This is the backing field for {@link #getPatternRuleIndex()}.\n   */\n  patternRuleIndex;\n  /**\n   * This is the backing field for {@link #getPattern()}.\n   */\n  pattern;\n  /**\n   * This is the backing field for {@link #getPatternTree()}.\n   */\n  patternTree;\n  /**\n   * This is the backing field for {@link #getMatcher()}.\n   */\n  matcher;\n  /**\n   * Construct a new instance of the {@link ParseTreePattern} class.\n   *\n   * @param matcher The {@link ParseTreePatternMatcher} which created this\n   * tree pattern.\n   * @param pattern The tree pattern in concrete syntax form.\n   * @param patternRuleIndex The parser rule which serves as the root of the\n   * tree pattern.\n   * @param patternTree The tree pattern in {@link ParseTree} form.\n   */\n  constructor(matcher, pattern, patternRuleIndex, patternTree) {\n    this.matcher = matcher;\n    this.patternRuleIndex = patternRuleIndex;\n    this.pattern = pattern;\n    this.patternTree = patternTree;\n  }\n  /**\n   * Match a specific parse tree against this tree pattern.\n   *\n   * @param tree The parse tree to match against this tree pattern.\n   * @returns A {@link ParseTreeMatch} object describing the result of the\n   * match operation. The {@link ParseTreeMatch#succeeded()} method can be\n   * used to determine whether or not the match was successful.\n   */\n  match(tree) {\n    return this.matcher.match(tree, this);\n  }\n  /**\n   * Determine whether or not a parse tree matches this tree pattern.\n   *\n   * @param tree The parse tree to match against this tree pattern.\n   * @returns `true` if `tree` is a match for the current tree\n   * pattern; otherwise, `false`.\n   */\n  matches(tree) {\n    return this.matcher.match(tree, this).succeeded();\n  }\n  /**\n   * Find all nodes using XPath and then try to match those subtrees against\n   * this tree pattern.\n   *\n   * @param tree The {@link ParseTree} to match against this pattern.\n   * @param xpath An expression matching the nodes\n   *\n   * @returns A collection of {@link ParseTreeMatch} objects describing the\n   * successful matches. Unsuccessful matches are omitted from the result,\n   * regardless of the reason for the failure.\n   */\n  findAll(tree, xpath) {\n    const subtrees = XPath.findAll(tree, xpath, this.matcher.getParser());\n    const matches = new Array();\n    for (const t of subtrees) {\n      const match = this.match(t);\n      if (match.succeeded()) {\n        matches.push(match);\n      }\n    }\n    return matches;\n  }\n  /**\n   * Get the {@link ParseTreePatternMatcher} which created this tree pattern.\n   *\n   * @returns The {@link ParseTreePatternMatcher} which created this tree\n   * pattern.\n   */\n  getMatcher() {\n    return this.matcher;\n  }\n  /**\n   * Get the tree pattern in concrete syntax form.\n   *\n   * @returns The tree pattern in concrete syntax form.\n   */\n  getPattern() {\n    return this.pattern;\n  }\n  /**\n   * Get the parser rule which serves as the outermost rule for the tree\n   * pattern.\n   *\n   * @returns The parser rule which serves as the outermost rule for the tree\n   * pattern.\n   */\n  getPatternRuleIndex() {\n    return this.patternRuleIndex;\n  }\n  /**\n   * Get the tree pattern as a {@link ParseTree}. The rule and token tags from\n   * the pattern are present in the parse tree as terminal nodes with a symbol\n   * of type {@link RuleTagToken} or {@link TokenTagToken}.\n   *\n   * @returns The tree pattern as a {@link ParseTree}.\n   */\n  getPatternTree() {\n    return this.patternTree;\n  }\n};\n\n// src/InputMismatchException.ts\nvar InputMismatchException = class extends RecognitionException {\n  static {\n    __name(this, \"InputMismatchException\");\n  }\n  constructor(recognizer) {\n    super({ message: \"\", recognizer, input: recognizer.inputStream, ctx: recognizer.context });\n    this.offendingToken = recognizer.getCurrentToken();\n  }\n};\n\n// src/FailedPredicateException.ts\nvar FailedPredicateException = class extends RecognitionException {\n  static {\n    __name(this, \"FailedPredicateException\");\n  }\n  ruleIndex = 0;\n  predicateIndex = 0;\n  predicate;\n  constructor(recognizer, predicate, message = null) {\n    super({\n      message: formatMessage(predicate ?? \"no predicate\", message ?? null),\n      recognizer,\n      input: recognizer.inputStream,\n      ctx: recognizer.context\n    });\n    const s = recognizer.atn.states[recognizer.state];\n    const trans = s.transitions[0];\n    if (trans instanceof PredicateTransition) {\n      this.ruleIndex = trans.ruleIndex;\n      this.predicateIndex = trans.predIndex;\n    } else {\n      this.ruleIndex = 0;\n      this.predicateIndex = 0;\n    }\n    this.predicate = predicate;\n    this.offendingToken = recognizer.getCurrentToken();\n  }\n};\nvar formatMessage = /* @__PURE__ */ __name((predicate, message) => {\n  if (message !== null) {\n    return message;\n  }\n  return \"failed predicate: {\" + predicate + \"}?\";\n}, \"formatMessage\");\n\n// src/DefaultErrorStrategy.ts\nvar DefaultErrorStrategy = class {\n  static {\n    __name(this, \"DefaultErrorStrategy\");\n  }\n  /**\n   * Indicates whether the error strategy is currently \"recovering from an\n   * error\". This is used to suppress reporting multiple error messages while\n   * attempting to recover from a detected syntax error.\n   *\n   * @see #inErrorRecoveryMode\n   */\n  errorRecoveryMode = false;\n  /**\n   * The index into the input stream where the last error occurred.\n   * \tThis is used to prevent infinite loops where an error is found\n   *  but no token is consumed during recovery...another error is found,\n   *  ad nauseam.  This is a failsafe mechanism to guarantee that at least\n   *  one token/tree node is consumed for two errors.\n   */\n  lastErrorIndex = -1;\n  lastErrorStates = new IntervalSet();\n  /**\n   * This field is used to propagate information about the lookahead following\n   * the previous match. Since prediction prefers completing the current rule\n   * to error recovery efforts, error reporting may occur later than the\n   * original point where it was discoverable. The original context is used to\n   * compute the true expected sets as though the reporting occurred as early\n   * as possible.\n   */\n  nextTokensContext = null;\n  nextTokenState = 0;\n  /**\n   * The default implementation simply calls {@link endErrorCondition} to\n   * ensure that the handler is not in error recovery mode.\n   */\n  reset(recognizer) {\n    this.endErrorCondition(recognizer);\n  }\n  /**\n   * This method is called to enter error recovery mode when a recognition\n   * exception is reported.\n   *\n   * @param _recognizer the parser instance\n   */\n  beginErrorCondition(_recognizer) {\n    this.errorRecoveryMode = true;\n  }\n  inErrorRecoveryMode(_recognizer) {\n    return this.errorRecoveryMode;\n  }\n  /**\n   * This method is called to leave error recovery mode after recovering from\n   * a recognition exception.\n   */\n  endErrorCondition(_recognizer) {\n    this.errorRecoveryMode = false;\n    this.lastErrorStates = new IntervalSet();\n    this.lastErrorIndex = -1;\n  }\n  /**\n   * The default implementation simply calls {@link endErrorCondition}.\n   */\n  reportMatch(recognizer) {\n    this.endErrorCondition(recognizer);\n  }\n  /**\n   * The default implementation returns immediately if the handler is already\n   * in error recovery mode. Otherwise, it calls {@link beginErrorCondition}\n   * and dispatches the reporting task based on the runtime type of `e`\n   * according to the following table.\n   *\n   * - {@link NoViableAltException}: Dispatches the call to {@link reportNoViableAlternative}\n   * - {@link InputMismatchException}: Dispatches the call to {@link reportInputMismatch}\n   * - {@link FailedPredicateException}: Dispatches the call to {@link reportFailedPredicate}\n   * - All other types: calls {@link Parser.notifyErrorListeners} to report the exception\n   */\n  reportError(recognizer, e) {\n    if (this.inErrorRecoveryMode(recognizer)) {\n      return;\n    }\n    this.beginErrorCondition(recognizer);\n    if (e instanceof NoViableAltException) {\n      this.reportNoViableAlternative(recognizer, e);\n    } else if (e instanceof InputMismatchException) {\n      this.reportInputMismatch(recognizer, e);\n    } else if (e instanceof FailedPredicateException) {\n      this.reportFailedPredicate(recognizer, e);\n    } else {\n      recognizer.notifyErrorListeners(e.message, e.offendingToken, e);\n    }\n  }\n  /**\n   * The default implementation resynchronizes the parser by consuming tokens\n   * until we find one in the resynchronization set--loosely the set of tokens\n   * that can follow the current rule.\n   *\n   */\n  recover(recognizer, _e) {\n    if (this.lastErrorIndex === recognizer.inputStream?.index && this.lastErrorStates.contains(recognizer.state)) {\n      recognizer.consume();\n    }\n    this.lastErrorIndex = recognizer.inputStream?.index ?? 0;\n    this.lastErrorStates.addOne(recognizer.state);\n    const followSet = this.getErrorRecoverySet(recognizer);\n    this.consumeUntil(recognizer, followSet);\n  }\n  /**\n   * The default implementation of {@link ANTLRErrorStrategy.sync} makes sure\n   * that the current lookahead symbol is consistent with what were expecting\n   * at this point in the ATN. You can call this anytime but ANTLR only\n   * generates code to check before subrules/loops and each iteration.\n   *\n   * Implements Jim Idle's magic sync mechanism in closures and optional\n   * subrules. E.g.,\n   *\n   * ```\n   * a : sync ( stuff sync )* ;\n   * sync : {consume to what can follow sync} ;\n   * ```\n   *\n   * At the start of a sub rule upon error, {@link sync} performs single\n   * token deletion, if possible. If it can't do that, it bails on the current\n   * rule and uses the default error recovery, which consumes until the\n   * resynchronization set of the current rule.\n   *\n   * If the sub rule is optional (`(...)?`, `(...)*`, or block\n   * with an empty alternative), then the expected set includes what follows\n   * the subrule.\n   *\n   * During loop iteration, it consumes until it sees a token that can start a\n   * sub rule or what follows loop. Yes, that is pretty aggressive. We opt to\n   * stay in the loop as long as possible.\n   *\n   * **ORIGINS**\n   *\n   * Previous versions of ANTLR did a poor job of their recovery within loops.\n   * A single mismatch token or missing token would force the parser to bail\n   * out of the entire rules surrounding the loop. So, for rule\n   *\n   * ```\n   * classDef : 'class' ID '{' member* '}'\n   * ```\n   *\n   * input with an extra token between members would force the parser to\n   * consume until it found the next class definition rather than the next\n   * member definition of the current class.\n   *\n   * This functionality cost a little bit of effort because the parser has to\n   * compare token set at the start of the loop and at each iteration. If for\n   * some reason speed is suffering for you, you can turn off this\n   * functionality by simply overriding this method as a blank { }.\n   *\n   */\n  sync(recognizer) {\n    if (this.inErrorRecoveryMode(recognizer)) {\n      return;\n    }\n    const s = recognizer.atn.states[recognizer.state];\n    const la = recognizer.tokenStream.LA(1);\n    const nextTokens = recognizer.atn.nextTokens(s);\n    if (nextTokens.contains(la)) {\n      this.nextTokensContext = null;\n      this.nextTokenState = ATNState.INVALID_STATE_NUMBER;\n      return;\n    }\n    if (nextTokens.contains(Token.EPSILON)) {\n      if (this.nextTokensContext === null) {\n        this.nextTokensContext = recognizer.context;\n        this.nextTokenState = recognizer.state;\n      }\n      return;\n    }\n    switch (s.constructor.stateType) {\n      case ATNState.BLOCK_START:\n      case ATNState.STAR_BLOCK_START:\n      case ATNState.PLUS_BLOCK_START:\n      case ATNState.STAR_LOOP_ENTRY: {\n        if (this.singleTokenDeletion(recognizer) !== null) {\n          return;\n        }\n        throw new InputMismatchException(recognizer);\n      }\n      case ATNState.PLUS_LOOP_BACK:\n      case ATNState.STAR_LOOP_BACK: {\n        this.reportUnwantedToken(recognizer);\n        const expecting = new IntervalSet();\n        expecting.addSet(recognizer.getExpectedTokens());\n        const whatFollowsLoopIterationOrRule = expecting.addSet(this.getErrorRecoverySet(recognizer));\n        this.consumeUntil(recognizer, whatFollowsLoopIterationOrRule);\n        break;\n      }\n      default:\n    }\n  }\n  /**\n   * This is called by {@link reportError} when the exception is a\n   * {@link NoViableAltException}.\n   *\n   * @see reportError\n   *\n   * @param recognizer the parser instance\n   * @param e the recognition exception\n   */\n  reportNoViableAlternative(recognizer, e) {\n    if (e.message.length > 0) {\n      recognizer.notifyErrorListeners(e.message, e.offendingToken, e);\n      return;\n    }\n    const tokens = recognizer.tokenStream;\n    let input;\n    if (tokens !== null && e.startToken) {\n      if (e.startToken.type === Token.EOF) {\n        input = \"<EOF>\";\n      } else {\n        input = tokens.getTextFromRange(e.startToken, e.offendingToken);\n      }\n    } else {\n      input = \"<unknown input>\";\n    }\n    const msg = \"no viable alternative at input \" + this.escapeWSAndQuote(input);\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n  }\n  /**\n   * This is called by {@link reportError} when the exception is an {@link InputMismatchException}.\n   *\n   * @see reportError\n   *\n   * @param recognizer the parser instance\n   * @param e the recognition exception\n   */\n  reportInputMismatch(recognizer, e) {\n    if (e.message.length > 0) {\n      recognizer.notifyErrorListeners(e.message, e.offendingToken, e);\n      return;\n    }\n    const msg = \"mismatched input \" + this.getTokenErrorDisplay(e.offendingToken) + \" expecting \" + e.getExpectedTokens().toStringWithVocabulary(recognizer.vocabulary);\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n  }\n  /**\n   * This is called by {@link reportError} when the exception is a\n   * {@link FailedPredicateException}.\n   *\n   * @see reportError\n   *\n   * @param recognizer the parser instance\n   * @param e the recognition exception\n   */\n  reportFailedPredicate(recognizer, e) {\n    const ruleName = recognizer.ruleNames[recognizer.context.ruleIndex];\n    const msg = \"rule \" + ruleName + \" \" + e.message;\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n  }\n  /**\n   * This method is called to report a syntax error which requires the removal\n   * of a token from the input stream. At the time this method is called, the\n   * erroneous symbol is current `LT(1)` symbol and has not yet been\n   * removed from the input stream. When this method returns,\n   * `recognizer` is in error recovery mode.\n   *\n   * This method is called when {@link singleTokenDeletion} identifies\n   * single-token deletion as a viable recovery strategy for a mismatched\n   * input error.\n   *\n   * The default implementation simply returns if the handler is already in\n   * error recovery mode. Otherwise, it calls {@link beginErrorCondition} to\n   * enter error recovery mode, followed by calling\n   * {@link Parser.notifyErrorListeners}.\n   *\n   * @param recognizer the parser instance\n   */\n  reportUnwantedToken(recognizer) {\n    if (this.inErrorRecoveryMode(recognizer)) {\n      return;\n    }\n    this.beginErrorCondition(recognizer);\n    const t = recognizer.getCurrentToken();\n    const tokenName = this.getTokenErrorDisplay(t);\n    const expecting = this.getExpectedTokens(recognizer);\n    const msg = \"extraneous input \" + tokenName + \" expecting \" + expecting.toStringWithVocabulary(recognizer.vocabulary);\n    recognizer.notifyErrorListeners(msg, t, null);\n  }\n  /**\n   * This method is called to report a syntax error which requires the\n   * insertion of a missing token into the input stream. At the time this\n   * method is called, the missing token has not yet been inserted. When this\n   * method returns, `recognizer` is in error recovery mode.\n   *\n   * This method is called when {@link singleTokenInsertion} identifies\n   * single-token insertion as a viable recovery strategy for a mismatched\n   * input error.\n   *\n   * The default implementation simply returns if the handler is already in\n   * error recovery mode. Otherwise, it calls {@link beginErrorCondition} to\n   * enter error recovery mode, followed by calling\n   * {@link Parser.notifyErrorListeners}.\n   *\n   * @param recognizer the parser instance\n   */\n  reportMissingToken(recognizer) {\n    if (this.inErrorRecoveryMode(recognizer)) {\n      return;\n    }\n    this.beginErrorCondition(recognizer);\n    const t = recognizer.getCurrentToken();\n    const expecting = this.getExpectedTokens(recognizer);\n    const msg = \"missing \" + expecting.toStringWithVocabulary(recognizer.vocabulary) + \" at \" + this.getTokenErrorDisplay(t);\n    recognizer.notifyErrorListeners(msg, t, null);\n  }\n  /**\n   * The default implementation attempts to recover from the mismatched input\n   * by using single token insertion and deletion as described below. If the\n   * recovery attempt fails, this method throws an\n   * {@link InputMismatchException}.\n   *\n   * **EXTRA TOKEN** (single token deletion)\n   *\n   * `LA(1)` is not what we are looking for. If `LA(2)` has the\n   * right token, however, then assume `LA(1)` is some extra spurious\n   * token and delete it. Then consume and return the next token (which was\n   * the `LA(2)` token) as the successful result of the match operation.\n   *\n   * This recovery strategy is implemented by {@link singleTokenDeletion}.\n   *\n   * **MISSING TOKEN** (single token insertion)\n   *\n   * If current token (at `LA(1)`) is consistent with what could come\n   * after the expected `LA(1)` token, then assume the token is missing\n   * and use the parser's {@link TokenFactory} to create it on the fly. The\n   * \"insertion\" is performed by returning the created token as the successful\n   * result of the match operation.\n   *\n   * This recovery strategy is implemented by {@link singleTokenInsertion}.\n   *\n   * **EXAMPLE**\n   *\n   * For example, Input `i=(3;` is clearly missing the `')'`. When\n   * the parser returns from the nested call to `expr`, it will have\n   * call chain:\n   *\n   * ```\n   * stat -> expr -> atom\n   * ```\n   *\n   * and it will be trying to match the `')'` at this point in the\n   * derivation:\n   *\n   * ```\n   * => ID '=' '(' INT ')' ('+' atom)* ';'\n   * ^\n   * ```\n   *\n   * The attempt to match `')'` will fail when it sees `';'` and\n   * call {@link recoverInline}. To recover, it sees that `LA(1)==';'`\n   * is in the set of tokens that can follow the `')'` token reference\n   * in rule `atom`. It can assume that you forgot the `')'`.\n   */\n  recoverInline(recognizer) {\n    const matchedSymbol = this.singleTokenDeletion(recognizer);\n    if (matchedSymbol) {\n      recognizer.consume();\n      return matchedSymbol;\n    }\n    if (this.singleTokenInsertion(recognizer)) {\n      return this.getMissingSymbol(recognizer);\n    }\n    throw new InputMismatchException(recognizer);\n  }\n  /**\n   * This method implements the single-token insertion inline error recovery\n   * strategy. It is called by {@link recoverInline} if the single-token\n   * deletion strategy fails to recover from the mismatched input. If this\n   * method returns `true`, `recognizer` will be in error recovery\n   * mode.\n   *\n   * This method determines whether or not single-token insertion is viable by\n   * checking if the `LA(1)` input symbol could be successfully matched\n   * if it were instead the `LA(2)` symbol. If this method returns\n   * `true`, the caller is responsible for creating and inserting a\n   * token with the correct type to produce this behavior.\n   *\n   * @param recognizer the parser instance\n   * @returns `true` if single-token insertion is a viable recovery\n   * strategy for the current mismatched input, otherwise `false`\n   */\n  singleTokenInsertion(recognizer) {\n    const currentSymbolType = recognizer.tokenStream?.LA(1) ?? -1;\n    const atn = recognizer.atn;\n    const currentState = atn.states[recognizer.state];\n    const next = currentState.transitions[0].target;\n    const expectingAtLL2 = atn.nextTokens(next, recognizer.context ?? void 0);\n    if (expectingAtLL2.contains(currentSymbolType)) {\n      this.reportMissingToken(recognizer);\n      return true;\n    }\n    return false;\n  }\n  /**\n   * This method implements the single-token deletion inline error recovery\n   * strategy. It is called by {@link recoverInline} to attempt to recover\n   * from mismatched input. If this method returns null, the parser and error\n   * handler state will not have changed. If this method returns non-null,\n   * `recognizer` will *not* be in error recovery mode since the\n   * returned token was a successful match.\n   *\n   * If the single-token deletion is successful, this method calls\n   * {@link reportUnwantedToken} to report the error, followed by\n   * {@link Parser.consume} to actually \"delete\" the extraneous token. Then,\n   * before returning {@link reportMatch} is called to signal a successful\n   * match.\n   *\n   * @param recognizer the parser instance\n   * @returns the successfully matched {@link Token} instance if single-token\n   * deletion successfully recovers from the mismatched input, otherwise\n   * `null`\n   */\n  singleTokenDeletion(recognizer) {\n    const nextTokenType = recognizer.tokenStream?.LA(2) ?? -1;\n    const expecting = this.getExpectedTokens(recognizer);\n    if (expecting.contains(nextTokenType)) {\n      this.reportUnwantedToken(recognizer);\n      recognizer.consume();\n      const matchedSymbol = recognizer.getCurrentToken();\n      this.reportMatch(recognizer);\n      return matchedSymbol;\n    }\n    return null;\n  }\n  /**\n   * Conjure up a missing token during error recovery.\n   *\n   * The recognizer attempts to recover from single missing\n   * symbols. But, actions might refer to that missing symbol.\n   * For example, x=ID {f($x);}. The action clearly assumes\n   * that there has been an identifier matched previously and that\n   * $x points at that token. If that token is missing, but\n   * the next token in the stream is what we want we assume that\n   * this token is missing and we keep going. Because we\n   * have to return some token to replace the missing token,\n   * we have to conjure one up. This method gives the user control\n   * over the tokens returned for missing tokens. Mostly,\n   * you will want to create something special for identifier\n   * tokens. For literals such as '{' and ',', the default\n   * action in the parser or tree parser works. It simply creates\n   * a CommonToken of the appropriate type. The text will be the token.\n   * If you change what tokens must be created by the lexer,\n   * override this method to create the appropriate tokens.\n   */\n  getMissingSymbol(recognizer) {\n    const currentSymbol = recognizer.getCurrentToken();\n    const expecting = this.getExpectedTokens(recognizer);\n    let expectedTokenType = Token.INVALID_TYPE;\n    if (expecting.length !== 0) {\n      expectedTokenType = expecting.minElement;\n    }\n    let tokenText;\n    if (expectedTokenType === Token.EOF) {\n      tokenText = \"<missing EOF>\";\n    } else {\n      tokenText = \"<missing \" + recognizer.vocabulary.getDisplayName(expectedTokenType) + \">\";\n    }\n    let current = currentSymbol;\n    const lookBack = recognizer.tokenStream?.LT(-1);\n    if (current.type === Token.EOF && lookBack !== null) {\n      current = lookBack;\n    }\n    return recognizer.getTokenFactory().create(\n      current.source,\n      expectedTokenType,\n      tokenText,\n      Token.DEFAULT_CHANNEL,\n      -1,\n      -1,\n      current.line,\n      current.column\n    );\n  }\n  getExpectedTokens(recognizer) {\n    return recognizer.getExpectedTokens();\n  }\n  /**\n   * How should a token be displayed in an error message? The default\n   * is to display just the text, but during development you might\n   * want to have a lot of information spit out. Override in that case\n   * to use t.toString() (which, for CommonToken, dumps everything about\n   * the token). This is better than forcing you to override a method in\n   * your token objects because you don't have to go modify your lexer\n   * so that it creates a new Java type.\n   */\n  getTokenErrorDisplay(t) {\n    if (t === null) {\n      return \"<no token>\";\n    }\n    let s = t.text;\n    if (!s) {\n      if (t.type === Token.EOF) {\n        s = \"<EOF>\";\n      } else {\n        s = \"<\" + t.type + \">\";\n      }\n    }\n    return this.escapeWSAndQuote(s);\n  }\n  escapeWSAndQuote(s) {\n    s = s.replace(/\\n/g, \"\\\\n\");\n    s = s.replace(/\\r/g, \"\\\\r\");\n    s = s.replace(/\\t/g, \"\\\\t\");\n    return \"'\" + s + \"'\";\n  }\n  /**\n   * Compute the error recovery set for the current rule. During\n   * rule invocation, the parser pushes the set of tokens that can\n   * follow that rule reference on the stack; this amounts to\n   * computing FIRST of what follows the rule reference in the\n   * enclosing rule. See LinearApproximator.FIRST().\n   * This local follow set only includes tokens\n   * from within the rule; i.e., the FIRST computation done by\n   * ANTLR stops at the end of a rule.\n   *\n   * EXAMPLE\n   *\n   * When you find a \"no viable alt exception\", the input is not\n   * consistent with any of the alternatives for rule r. The best\n   * thing to do is to consume tokens until you see something that\n   * can legally follow a call to r//or* any rule that called r.\n   * You don't want the exact set of viable next tokens because the\n   * input might just be missing a token--you might consume the\n   * rest of the input looking for one of the missing tokens.\n   *\n   * Consider grammar:\n   *\n   * a : '[' b ']'\n   * | '(' b ')'\n   * ;\n   * b : c '^' INT ;\n   * c : ID\n   * | INT\n   * ;\n   *\n   * At each rule invocation, the set of tokens that could follow\n   * that rule is pushed on a stack. Here are the various\n   * context-sensitive follow sets:\n   *\n   * FOLLOW(b1_in_a) = FIRST(']') = ']'\n   * FOLLOW(b2_in_a) = FIRST(')') = ')'\n   * FOLLOW(c_in_b) = FIRST('^') = '^'\n   *\n   * Upon erroneous input \"[]\", the call chain is\n   *\n   * a -> b -> c\n   *\n   * and, hence, the follow context stack is:\n   *\n   * depth follow set start of rule execution\n   * 0 <EOF> a (from main())\n   * 1 ']' b\n   * 2 '^' c\n   *\n   * Notice that ')' is not included, because b would have to have\n   * been called from a different context in rule a for ')' to be\n   * included.\n   *\n   * For error recovery, we cannot consider FOLLOW(c)\n   * (context-sensitive or otherwise). We need the combined set of\n   * all context-sensitive FOLLOW sets--the set of all tokens that\n   * could follow any reference in the call chain. We need to\n   * resync to one of those tokens. Note that FOLLOW(c)='^' and if\n   * we resync'd to that token, we'd consume until EOF. We need to\n   * sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.\n   * In this case, for input \"[]\", LA(1) is ']' and in the set, so we would\n   * not consume anything. After printing an error, rule c would\n   * return normally. Rule b would not find the required '^' though.\n   * At this point, it gets a mismatched token error and throws an\n   * exception (since LA(1) is not in the viable following token\n   * set). The rule exception handler tries to recover, but finds\n   * the same recovery set and doesn't consume anything. Rule b\n   * exits normally returning to rule a. Now it finds the ']' (and\n   * with the successful match exits errorRecovery mode).\n   *\n   * So, you can see that the parser walks up the call chain looking\n   * for the token that was a member of the recovery set.\n   *\n   * Errors are not generated in errorRecovery mode.\n   *\n   * ANTLR's error recovery mechanism is based upon original ideas:\n   *\n   * \"Algorithms + Data Structures = Programs\" by Niklaus Wirth\n   *\n   * and\n   *\n   * \"A note on error recovery in recursive descent parsers\":\n   * http://portal.acm.org/citation.cfm?id=947902.947905\n   *\n   * Later, Josef Grosch had some good ideas:\n   *\n   * \"Efficient and Comfortable Error Recovery in Recursive Descent\n   * Parsers\":\n   * ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip\n   *\n   * Like Grosch I implement context-sensitive FOLLOW sets that are combined\n   * at run-time upon error to avoid overhead during parsing.\n   */\n  getErrorRecoverySet(recognizer) {\n    const atn = recognizer.atn;\n    let ctx = recognizer.context;\n    const recoverSet = new IntervalSet();\n    while (ctx !== null && ctx.invokingState >= 0) {\n      const invokingState = atn.states[ctx.invokingState];\n      const rt = invokingState.transitions[0];\n      const follow = atn.nextTokens(rt.followState);\n      recoverSet.addSet(follow);\n      ctx = ctx.parent;\n    }\n    recoverSet.removeOne(Token.EPSILON);\n    return recoverSet;\n  }\n  /** Consume tokens until one matches the given token set. */\n  consumeUntil(recognizer, set) {\n    let ttype = recognizer.tokenStream?.LA(1) ?? -1;\n    while (ttype !== Token.EOF && !set.contains(ttype)) {\n      recognizer.consume();\n      ttype = recognizer.tokenStream?.LA(1) ?? -1;\n    }\n  }\n};\n\n// src/BailErrorStrategy.ts\nvar BailErrorStrategy = class extends DefaultErrorStrategy {\n  static {\n    __name(this, \"BailErrorStrategy\");\n  }\n  /**\n   * Instead of recovering from exception `e`, re-throw it wrapped\n   * in a {@link ParseCancellationException} so it is not caught by the\n   * rule function catches. Use {@link Exception//getCause()} to get the\n   * original {@link RecognitionException}.\n   */\n  recover(recognizer, e) {\n    throw new ParseCancellationException(e);\n  }\n  /**\n   * Make sure we don't attempt to recover inline; if the parser\n   * successfully recovers, it won't throw an exception.\n   */\n  recoverInline(recognizer) {\n    const exception = new InputMismatchException(recognizer);\n    throw new ParseCancellationException(exception);\n  }\n  // Make sure we don't attempt to recover from problems in subrules.\n  sync(_recognizer) {\n  }\n};\n\n// src/ListTokenSource.ts\nvar ListTokenSource = class {\n  static {\n    __name(this, \"ListTokenSource\");\n  }\n  /**\n   * The name of the input source. If this value is `null`, a call to\n   * {@link #getSourceName} should return the source name used to create the\n   * the next token in {@link #tokens} (or the previous token if the end of\n   * the input has been reached).\n   */\n  sourceName;\n  tokenFactory = CommonTokenFactory.DEFAULT;\n  /**\n   * The wrapped collection of {@link Token} objects to return.\n   */\n  tokens;\n  /**\n   * The index into {@link tokens} of token to return by the next call to\n   * {@link #nextToken}. The end of the input is indicated by this value\n   * being greater than or equal to the number of items in {@link #tokens}.\n   */\n  i;\n  /**\n   * This field caches the EOF token for the token source.\n   */\n  eofToken;\n  constructor(tokens, sourceName) {\n    this.tokens = tokens;\n    this.sourceName = sourceName ?? \"\";\n  }\n  get column() {\n    if (this.i < this.tokens.length) {\n      return this.tokens[this.i].column;\n    }\n    if (this.eofToken !== null) {\n      return this.eofToken.column;\n    }\n    if (this.tokens.length > 0) {\n      const lastToken = this.tokens[this.tokens.length - 1];\n      const tokenText = lastToken.text;\n      if (tokenText) {\n        const lastNewLine = tokenText.lastIndexOf(\"\\n\");\n        if (lastNewLine >= 0) {\n          return tokenText.length - lastNewLine - 1;\n        }\n      }\n      return lastToken.column + lastToken.stop - lastToken.start + 1;\n    }\n    return 0;\n  }\n  nextToken() {\n    if (this.i >= this.tokens.length) {\n      if (this.eofToken === null) {\n        let start = -1;\n        if (this.tokens.length > 0) {\n          const previousStop = this.tokens[this.tokens.length - 1].stop;\n          if (previousStop !== -1) {\n            start = previousStop + 1;\n          }\n        }\n        const stop = Math.max(-1, start - 1);\n        this.eofToken = this.tokenFactory.create(\n          [this, this.inputStream],\n          Token.EOF,\n          \"EOF\",\n          Token.DEFAULT_CHANNEL,\n          start,\n          stop,\n          this.line,\n          this.column\n        );\n      }\n      return this.eofToken;\n    }\n    const t = this.tokens[this.i];\n    if (this.i === this.tokens.length - 1 && t.type === Token.EOF) {\n      this.eofToken = t;\n    }\n    this.i++;\n    return t;\n  }\n  get line() {\n    if (this.i < this.tokens.length) {\n      return this.tokens[this.i].line;\n    }\n    if (this.eofToken !== null) {\n      return this.eofToken.line;\n    }\n    if (this.tokens.length > 0) {\n      const lastToken = this.tokens[this.tokens.length - 1];\n      let line = lastToken.line;\n      const tokenText = lastToken.text;\n      if (tokenText) {\n        for (const char of tokenText) {\n          if (char === \"\\n\") {\n            line++;\n          }\n        }\n      }\n      return line;\n    }\n    return 1;\n  }\n  get inputStream() {\n    if (this.i < this.tokens.length) {\n      return this.tokens[this.i].inputStream;\n    }\n    if (this.eofToken !== null) {\n      return this.eofToken.inputStream;\n    }\n    if (this.tokens.length > 0) {\n      return this.tokens[this.tokens.length - 1].inputStream;\n    }\n    return null;\n  }\n  getSourceName() {\n    if (this.sourceName !== null) {\n      return this.sourceName;\n    }\n    const inputStream = this.inputStream;\n    if (inputStream !== null) {\n      return inputStream.getSourceName();\n    }\n    return \"List\";\n  }\n};\n\n// src/InterpreterRuleContext.ts\nvar InterpreterRuleContext = class extends ParserRuleContext {\n  static {\n    __name(this, \"InterpreterRuleContext\");\n  }\n  /** This is the backing field for {@link #getRuleIndex}. */\n  #ruleIndex;\n  constructor(ruleIndex, parent, invokingStateNumber) {\n    super(parent, invokingStateNumber);\n    this.#ruleIndex = ruleIndex;\n  }\n  get ruleIndex() {\n    return this.#ruleIndex;\n  }\n};\n\n// src/TraceListener.ts\nvar TraceListener = class {\n  static {\n    __name(this, \"TraceListener\");\n  }\n  parser;\n  constructor(parser) {\n    this.parser = parser;\n  }\n  enterEveryRule(ctx) {\n    console.log(\"enter   \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser.inputStream?.LT(1)?.text);\n  }\n  visitTerminal(node) {\n    console.log(\"consume \" + node.getSymbol() + \" rule \" + this.parser.ruleNames[this.parser.context.ruleIndex]);\n  }\n  exitEveryRule(ctx) {\n    console.log(\"exit    \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser.inputStream?.LT(1)?.text);\n  }\n  visitErrorNode(_node) {\n  }\n};\n\n// src/Parser.ts\nvar Parser = class extends Recognizer {\n  static {\n    __name(this, \"Parser\");\n  }\n  /** For testing only. */\n  printer = null;\n  /**\n   * Specifies whether or not the parser should construct a parse tree during\n   * the parsing process. The default value is `true`.\n   *\n   * @see #getBuildParseTree\n   * @see #setBuildParseTree\n   */\n  buildParseTrees = true;\n  /**\n   * The error handling strategy for the parser. The default value is a new\n   * instance of {@link DefaultErrorStrategy}.\n   *\n   * @see #getErrorHandler\n   * @see #setErrorHandler\n   */\n  errorHandler = new DefaultErrorStrategy();\n  /**\n   * The {@link ParserRuleContext} object for the currently executing rule.\n   * This is always non-null during the parsing process.\n   */\n  // TODO: make private\n  context = null;\n  precedenceStack = [];\n  /**\n   * The list of {@link ParseTreeListener} listeners registered to receive\n   * events during the parse.\n   *\n   * @see #addParseListener\n   */\n  parseListeners = null;\n  /**\n   * The number of syntax errors reported during parsing. This value is\n   * incremented each time {@link #notifyErrorListeners} is called.\n   */\n  syntaxErrors = 0;\n  /** Indicates parser has matched EOF token. See {@link #exitRule()}. */\n  matchedEOF = false;\n  /**\n   * When {@link #setTrace}`(true)` is called, a reference to the\n   * {@link TraceListener} is stored here so it can be easily removed in a\n   * later call to {@link #setTrace}`(false)`. The listener itself is\n   * implemented as a parser listener so this field is not directly used by\n   * other parser methods.\n   */\n  #tracer = null;\n  /**\n   * This field holds the deserialized {@link ATN} with bypass alternatives, created\n   * lazily upon first demand. In 4.10 I changed from map<serializedATNstring, ATN>\n   * since we only need one per parser object and also it complicates other targets\n   * that don't use ATN strings.\n   *\n   * @see ATNDeserializationOptions#isGenerateRuleBypassTransitions()\n   */\n  #bypassAltsAtnCache = null;\n  #inputStream;\n  /**\n   * This is all the parsing support code essentially. Most of it is error recovery stuff.\n   */\n  constructor(input) {\n    super();\n    this.precedenceStack.push(0);\n    this.syntaxErrors = 0;\n    this.#inputStream = input;\n  }\n  /** reset the parser's state */\n  reset(rewindInputStream = true) {\n    if (rewindInputStream) {\n      this.inputStream.seek(0);\n    }\n    this.errorHandler.reset(this);\n    this.context = null;\n    this.syntaxErrors = 0;\n    this.setTrace(false);\n    this.precedenceStack = [];\n    this.precedenceStack.push(0);\n    if (this.interpreter) {\n      this.interpreter.reset();\n    }\n  }\n  /**\n   * Match current input symbol against `ttype`. If the symbol type\n   * matches, {@link ANTLRErrorStrategy//reportMatch} and {@link consume} are\n   * called to complete the match process.\n   *\n   * If the symbol type does not match,\n   * {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n   * strategy to attempt recovery. If {@link buildParseTree} is\n   * `true` and the token index of the symbol returned by\n   * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n   * the parse tree by calling {@link ParserRuleContext//addErrorNode}.\n   *\n   * @param ttype the token type to match\n   * @returns the matched symbol\n   * @throws RecognitionException if the current input symbol did not match\n   * `ttype` and the error strategy could not recover from the\n   * mismatched symbol\n   */\n  match(ttype) {\n    let t = this.getCurrentToken();\n    if (t.type === ttype) {\n      this.errorHandler.reportMatch(this);\n      this.consume();\n    } else {\n      t = this.errorHandler.recoverInline(this);\n      if (this.buildParseTrees && t.tokenIndex === -1) {\n        this.context.addErrorNode(this.createErrorNode(this.context, t));\n      }\n    }\n    return t;\n  }\n  /**\n   * Match current input symbol as a wildcard. If the symbol type matches\n   * (i.e. has a value greater than 0), {@link ANTLRErrorStrategy//reportMatch}\n   * and {@link consume} are called to complete the match process.\n   *\n   * If the symbol type does not match,\n   * {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n   * strategy to attempt recovery. If {@link buildParseTree} is\n   * `true` and the token index of the symbol returned by\n   * {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n   * the parse tree by calling {@link ParserRuleContext//addErrorNode}.\n   *\n   * @returns the matched symbol\n   * @throws RecognitionException if the current input symbol did not match\n   * a wildcard and the error strategy could not recover from the mismatched\n   * symbol\n   */\n  matchWildcard() {\n    let t = this.getCurrentToken();\n    if (t.type > 0) {\n      this.errorHandler.reportMatch(this);\n      this.consume();\n    } else {\n      t = this.errorHandler.recoverInline(this);\n      if (this.buildParseTrees && t.tokenIndex === -1) {\n        this.context.addErrorNode(this.createErrorNode(this.context, t));\n      }\n    }\n    return t;\n  }\n  getParseListeners() {\n    return this.parseListeners ?? [];\n  }\n  /**\n   * Registers `listener` to receive events during the parsing process.\n   *\n   * To support output-preserving grammar transformations (including but not\n   * limited to left-recursion removal, automated left-factoring, and\n   * optimized code generation), calls to listener methods during the parse\n   * may differ substantially from calls made by\n   * {@link ParseTreeWalker//DEFAULT} used after the parse is complete. In\n   * particular, rule entry and exit events may occur in a different order\n   * during the parse than after the parser. In addition, calls to certain\n   * rule entry methods may be omitted.\n   *\n   * With the following specific exceptions, calls to listener events are\n   * deterministic*, i.e. for identical input the calls to listener\n   * methods will be the same.\n   *\n   * - Alterations to the grammar used to generate code may change the\n   * behavior of the listener calls.\n   * - Alterations to the command line options passed to ANTLR 4 when\n   * generating the parser may change the behavior of the listener calls.\n   * - Changing the version of the ANTLR Tool used to generate the parser\n   * may change the behavior of the listener calls.\n   *\n   * @param listener the listener to add\n   *\n   * @throws NullPointerException if {@code} listener is `null`\n   */\n  addParseListener(listener) {\n    if (listener === null) {\n      throw new Error(\"listener\");\n    }\n    if (this.parseListeners === null) {\n      this.parseListeners = [];\n    }\n    this.parseListeners.push(listener);\n  }\n  /**\n   * Remove `listener` from the list of parse listeners.\n   *\n   * If `listener` is `null` or has not been added as a parse\n   * listener, this method does nothing.\n   *\n   * @param listener the listener to remove\n   */\n  removeParseListener(listener) {\n    if (this.parseListeners !== null && listener !== null) {\n      const idx = this.parseListeners.indexOf(listener);\n      if (idx >= 0) {\n        this.parseListeners.splice(idx, 1);\n      }\n      if (this.parseListeners.length === 0) {\n        this.parseListeners = null;\n      }\n    }\n  }\n  // Remove all parse listeners.\n  removeParseListeners() {\n    this.parseListeners = null;\n  }\n  // Notify any parse listeners of an enter rule event.\n  triggerEnterRuleEvent() {\n    if (this.parseListeners !== null) {\n      const ctx = this.context;\n      this.parseListeners.forEach((listener) => {\n        listener.enterEveryRule(ctx);\n        ctx.enterRule(listener);\n      });\n    }\n  }\n  /**\n   * Notify any parse listeners of an exit rule event.\n   *\n   * @see //addParseListener\n   */\n  triggerExitRuleEvent() {\n    if (this.parseListeners !== null) {\n      const ctx = this.context;\n      this.parseListeners.slice(0).reverse().forEach((listener) => {\n        ctx.exitRule(listener);\n        listener.exitEveryRule(ctx);\n      });\n    }\n  }\n  getTokenFactory() {\n    return this.inputStream.tokenSource.tokenFactory;\n  }\n  // Tell our token source and error strategy about a new way to create tokens.\n  setTokenFactory(factory) {\n    this.inputStream.tokenSource.tokenFactory = factory;\n  }\n  /**\n   * The preferred method of getting a tree pattern. For example, here's a\n   * sample use:\n   *\n   * ```\n   * const t = parser.expr();\n   * const p = parser.compileParseTreePattern(\"<ID>+0\", MyParser.RULE_expr);\n   * const m = p.match(t);\n   * const id = m.get(\"ID\");\n   * ```\n   */\n  compileParseTreePattern(pattern, patternRuleIndex, lexer) {\n    if (!lexer) {\n      if (this.tokenStream !== null) {\n        const tokenSource = this.tokenStream.tokenSource;\n        if (tokenSource instanceof Lexer) {\n          lexer = tokenSource;\n        }\n      }\n    }\n    if (!lexer) {\n      throw new Error(\"Parser can't discover a lexer to use\");\n    }\n    const m2 = new ParseTreePatternMatcher(lexer, this);\n    return m2.compile(pattern, patternRuleIndex);\n  }\n  /**\n   * The ATN with bypass alternatives is expensive to create so we create it\n   * lazily.\n   *\n   * @throws UnsupportedOperationException if the current parser does not\n   * implement the {@link getSerializedATN()} method.\n   */\n  getATNWithBypassAlts() {\n    const serializedAtn = this.getSerializedATN();\n    if (serializedAtn === null) {\n      throw new Error(\"The current parser does not support an ATN with bypass alternatives.\");\n    }\n    if (this.#bypassAltsAtnCache !== null) {\n      return this.#bypassAltsAtnCache;\n    }\n    const deserializationOptions = { readOnly: false, verifyATN: true, generateRuleBypassTransitions: true };\n    this.#bypassAltsAtnCache = new ATNDeserializer(deserializationOptions).deserialize(serializedAtn);\n    return this.#bypassAltsAtnCache;\n  }\n  /**\n   * Gets the number of syntax errors reported during parsing. This value is\n   * incremented each time {@link notifyErrorListeners} is called.\n   */\n  get numberOfSyntaxErrors() {\n    return this.syntaxErrors;\n  }\n  get inputStream() {\n    return this.#inputStream;\n  }\n  set inputStream(input) {\n    this.tokenStream = input;\n  }\n  get tokenStream() {\n    return this.#inputStream;\n  }\n  /** Set the token stream and reset the parser. */\n  set tokenStream(input) {\n    this.reset(false);\n    this.#inputStream = input;\n  }\n  /**\n   * Match needs to return the current input symbol, which gets put\n   * into the label for the associated token ref; e.g., x=ID.\n   */\n  getCurrentToken() {\n    return this.inputStream.LT(1);\n  }\n  notifyErrorListeners(msg, offendingToken, err) {\n    offendingToken = offendingToken ?? null;\n    err = err ?? null;\n    if (offendingToken === null) {\n      offendingToken = this.getCurrentToken();\n    }\n    this.syntaxErrors += 1;\n    const line = offendingToken.line;\n    const column = offendingToken.column;\n    this.errorListenerDispatch.syntaxError(this, offendingToken, line, column, msg, err);\n  }\n  /**\n   * Consume and return the {@link getCurrentToken current symbol}.\n   *\n   * E.g., given the following input with `A` being the current\n   * lookahead symbol, this function moves the cursor to `B` and returns\n   * `A`.\n   *\n   * ```\n   * A B\n   * ^\n   * ```\n   *\n   * If the parser is not in error recovery mode, the consumed symbol is added\n   * to the parse tree using {@link ParserRuleContext//addChild(Token)}, and\n   * {@link ParseTreeListener//visitTerminal} is called on any parse listeners.\n   * If the parser *is* in error recovery mode, the consumed symbol is\n   * added to the parse tree using\n   * {@link ParserRuleContext//addErrorNode(Token)}, and\n   * {@link ParseTreeListener//visitErrorNode} is called on any parse\n   * listeners.\n   */\n  consume() {\n    const o = this.getCurrentToken();\n    if (o.type !== Token.EOF) {\n      this.tokenStream.consume();\n    }\n    const hasListener = this.parseListeners !== null && this.parseListeners.length > 0;\n    if (this.buildParseTrees || hasListener) {\n      let node;\n      if (this.errorHandler.inErrorRecoveryMode(this)) {\n        node = this.context.addErrorNode(this.createErrorNode(this.context, o));\n      } else {\n        node = this.context.addTokenNode(o);\n      }\n      if (hasListener) {\n        this.parseListeners.forEach((listener) => {\n          if (node instanceof ErrorNode) {\n            listener.visitErrorNode(node);\n          } else {\n            listener.visitTerminal(node);\n          }\n        });\n      }\n    }\n    return o;\n  }\n  addContextToParseTree() {\n    if (this.context?.parent !== null) {\n      this.context.parent.addChild(this.context);\n    }\n  }\n  /**\n   * Always called by generated parsers upon entry to a rule. Access field\n   * {@link context} get the current context.\n   */\n  enterRule(localctx, state, _ruleIndex) {\n    this.state = state;\n    this.context = localctx;\n    this.context.start = this.inputStream.LT(1);\n    if (this.buildParseTrees) {\n      this.addContextToParseTree();\n    }\n    this.triggerEnterRuleEvent();\n  }\n  exitRule() {\n    this.context.stop = this.inputStream.LT(-1);\n    this.triggerExitRuleEvent();\n    this.state = this.context.invokingState;\n    this.context = this.context.parent;\n  }\n  enterOuterAlt(localctx, altNum) {\n    localctx.setAltNumber(altNum);\n    if (this.buildParseTrees && this.context !== localctx) {\n      if (this.context.parent !== null) {\n        this.context.parent.removeLastChild();\n        this.context.parent.addChild(localctx);\n      }\n    }\n    this.context = localctx;\n  }\n  /**\n   * Get the precedence level for the top-most precedence rule.\n   *\n   * @returns The precedence level for the top-most precedence rule, or -1 if\n   * the parser context is not nested within a precedence rule.\n   */\n  getPrecedence() {\n    if (this.precedenceStack.length === 0) {\n      return -1;\n    } else {\n      return this.precedenceStack[this.precedenceStack.length - 1];\n    }\n  }\n  enterRecursionRule(localctx, state, ruleIndex, precedence) {\n    this.state = state;\n    this.precedenceStack.push(precedence);\n    this.context = localctx;\n    this.context.start = this.inputStream.LT(1);\n    this.triggerEnterRuleEvent();\n  }\n  /** Like {@link enterRule} but for recursive rules. */\n  pushNewRecursionContext(localctx, state, _ruleIndex) {\n    const previous = this.context;\n    previous.parent = localctx;\n    previous.invokingState = state;\n    previous.stop = this.inputStream.LT(-1);\n    this.context = localctx;\n    this.context.start = previous.start;\n    if (this.buildParseTrees) {\n      this.context.addChild(previous);\n    }\n    this.triggerEnterRuleEvent();\n  }\n  unrollRecursionContexts(parent) {\n    this.precedenceStack.pop();\n    this.context.stop = this.inputStream.LT(-1);\n    const retCtx = this.context;\n    const parseListeners = this.getParseListeners();\n    if (parseListeners !== null && parseListeners.length > 0) {\n      while (this.context !== parent) {\n        this.triggerExitRuleEvent();\n        this.context = this.context.parent;\n      }\n    } else {\n      this.context = parent;\n    }\n    retCtx.parent = parent;\n    if (this.buildParseTrees && parent !== null) {\n      parent.addChild(retCtx);\n    }\n  }\n  getInvokingContext(ruleIndex) {\n    let ctx = this.context;\n    while (ctx !== null) {\n      if (ctx.ruleIndex === ruleIndex) {\n        return ctx;\n      }\n      ctx = ctx.parent;\n    }\n    return null;\n  }\n  precpred(_localctx, precedence) {\n    return precedence >= this.precedenceStack[this.precedenceStack.length - 1];\n  }\n  inContext(_context) {\n    return false;\n  }\n  /**\n   * Checks whether or not `symbol` can follow the current state in the\n   * ATN. The behavior of this method is equivalent to the following, but is\n   * implemented such that the complete context-sensitive follow set does not\n   * need to be explicitly constructed.\n   *\n   * ```\n   * return getExpectedTokens().contains(symbol);\n   * ```\n   *\n   * @param symbol the symbol type to check\n   * @returns `true` if `symbol` can follow the current state in\n   * the ATN, otherwise `false`.\n   */\n  isExpectedToken(symbol) {\n    const atn = this.interpreter.atn;\n    let ctx = this.context;\n    const s = atn.states[this.state];\n    let following = atn.nextTokens(s);\n    if (following.contains(symbol)) {\n      return true;\n    }\n    if (!following.contains(Token.EPSILON)) {\n      return false;\n    }\n    while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n      const invokingState = atn.states[ctx.invokingState];\n      const rt = invokingState.transitions[0];\n      following = atn.nextTokens(rt.followState);\n      if (following.contains(symbol)) {\n        return true;\n      }\n      ctx = ctx.parent;\n    }\n    if (following.contains(Token.EPSILON) && symbol === Token.EOF) {\n      return true;\n    } else {\n      return false;\n    }\n  }\n  /**\n   * Computes the set of input symbols which could follow the current parser\n   * state and context, as given by {@link getState} and {@link getContext},\n   * respectively.\n   *\n   * {@link ATN.getExpectedTokens ATN.getExpectedTokens(int, RuleContext)}\n   */\n  getExpectedTokens() {\n    return this.interpreter.atn.getExpectedTokens(this.state, this.context);\n  }\n  getExpectedTokensWithinCurrentRule() {\n    const atn = this.interpreter.atn;\n    const s = atn.states[this.state];\n    return atn.nextTokens(s);\n  }\n  /** Get a rule's index (i.e., `RULE_ruleName` field) or -1 if not found. */\n  getRuleIndex(ruleName) {\n    return this.getRuleIndexMap().get(ruleName) ?? -1;\n  }\n  /**\n   * @returns an array of string of the rule names in your parser instance\n   * leading up to a call to the current rule. You could override if\n   * you want more details such as the file/line info of where\n   * in the ATN a rule is invoked.\n   *\n   * this is very useful for error messages.\n   */\n  getRuleInvocationStack(p) {\n    p = p ?? null;\n    if (p === null) {\n      p = this.context;\n    }\n    const stack = [];\n    while (p !== null) {\n      const ruleIndex = p.ruleIndex;\n      if (ruleIndex < 0) {\n        stack.push(\"n/a\");\n      } else {\n        stack.push(this.ruleNames[ruleIndex]);\n      }\n      p = p.parent;\n    }\n    return stack;\n  }\n  /**\n   * For debugging and other purposes.\n   *\n   * TODO: this differs from the Java version. Change it.\n   */\n  getDFAStrings() {\n    return this.interpreter.decisionToDFA.toString();\n  }\n  /** For debugging and other purposes. */\n  dumpDFA() {\n    let seenOne = false;\n    for (const dfa of this.interpreter.decisionToDFA) {\n      if (dfa.length > 0) {\n        if (seenOne) {\n          console.log();\n        }\n        if (this.printer) {\n          this.printer.println(\"Decision \" + dfa.decision + \":\");\n          this.printer.print(dfa.toString(this.vocabulary));\n        }\n        seenOne = true;\n      }\n    }\n  }\n  getSourceName() {\n    return this.inputStream.getSourceName();\n  }\n  setProfile(profile) {\n    const interp = this.interpreter;\n    const saveMode = interp.predictionMode;\n    if (profile) {\n      if (!(interp instanceof ProfilingATNSimulator)) {\n        this.interpreter = new ProfilingATNSimulator(this);\n      }\n    } else if (interp instanceof ProfilingATNSimulator) {\n      const sharedContextCache = interp.sharedContextCache;\n      if (sharedContextCache) {\n        const sim = new ParserATNSimulator(this, this.atn, interp.decisionToDFA, sharedContextCache);\n        this.interpreter = sim;\n      }\n    }\n    this.interpreter.predictionMode = saveMode;\n  }\n  /**\n   * During a parse is sometimes useful to listen in on the rule entry and exit\n   * events as well as token matches. this is for quick and dirty debugging.\n   */\n  setTrace(trace) {\n    if (!trace) {\n      this.removeParseListener(this.#tracer);\n      this.#tracer = null;\n    } else {\n      if (this.#tracer !== null) {\n        this.removeParseListener(this.#tracer);\n      }\n      this.#tracer = new TraceListener(this);\n      this.addParseListener(this.#tracer);\n    }\n  }\n  createTerminalNode(parent, t) {\n    return new TerminalNode(t);\n  }\n  createErrorNode(parent, t) {\n    return new ErrorNode(t);\n  }\n};\n\n// src/ParserInterpreter.ts\nvar ParserInterpreter = class extends Parser {\n  static {\n    __name(this, \"ParserInterpreter\");\n  }\n  rootContext;\n  parentContextStack = [];\n  #overrideDecision = -1;\n  #overrideDecisionInputIndex = -1;\n  #overrideDecisionAlt = -1;\n  #overrideDecisionReached = false;\n  #overrideDecisionRoot = null;\n  #grammarFileName;\n  #atn;\n  #ruleNames;\n  #vocabulary;\n  #decisionToDFA;\n  #sharedContextCache = new PredictionContextCache();\n  #pushRecursionContextStates;\n  constructor(grammarFileName, vocabulary, ruleNames, atn, input) {\n    super(input);\n    this.#grammarFileName = grammarFileName;\n    this.#atn = atn;\n    this.#ruleNames = ruleNames.slice(0);\n    this.#vocabulary = vocabulary;\n    this.#pushRecursionContextStates = new BitSet();\n    for (const state of atn.states) {\n      if (state instanceof StarLoopEntryState && state.precedenceRuleDecision) {\n        this.#pushRecursionContextStates.set(state.stateNumber);\n      }\n    }\n    this.#decisionToDFA = atn.decisionToState.map((ds, i) => {\n      return new DFA(ds, i);\n    });\n    this.interpreter = new ParserATNSimulator(this, atn, this.#decisionToDFA, this.#sharedContextCache);\n  }\n  reset() {\n    super.reset();\n    this.#overrideDecisionReached = false;\n    this.#overrideDecisionRoot = null;\n  }\n  get atn() {\n    return this.#atn;\n  }\n  get vocabulary() {\n    return this.#vocabulary;\n  }\n  get ruleNames() {\n    return this.#ruleNames;\n  }\n  get grammarFileName() {\n    return this.#grammarFileName;\n  }\n  get atnState() {\n    return this.#atn.states[this.state];\n  }\n  parse(startRuleIndex) {\n    const startRuleStartState = this.#atn.ruleToStartState[startRuleIndex];\n    this.rootContext = this.createInterpreterRuleContext(null, ATNState.INVALID_STATE_NUMBER, startRuleIndex);\n    if (startRuleStartState.isPrecedenceRule) {\n      this.enterRecursionRule(this.rootContext, startRuleStartState.stateNumber, startRuleIndex, 0);\n    } else {\n      this.enterRule(this.rootContext, startRuleStartState.stateNumber, startRuleIndex);\n    }\n    while (true) {\n      const p = this.atnState;\n      switch (p.constructor.stateType) {\n        case ATNState.RULE_STOP:\n          if (this.context?.isEmpty) {\n            if (startRuleStartState.isPrecedenceRule) {\n              const result = this.context;\n              const parentContext = this.parentContextStack.pop();\n              this.unrollRecursionContexts(parentContext[0]);\n              return result;\n            } else {\n              this.exitRule();\n              return this.rootContext;\n            }\n          }\n          this.visitRuleStopState(p);\n          break;\n        default:\n          try {\n            this.visitState(p);\n          } catch (e) {\n            if (e instanceof RecognitionException) {\n              this.state = this.#atn.ruleToStopState[p.ruleIndex].stateNumber;\n              this.errorHandler.reportError(this, e);\n              this.recover(e);\n            } else {\n              throw e;\n            }\n          }\n          break;\n      }\n    }\n  }\n  addDecisionOverride(decision, tokenIndex, forcedAlt) {\n    this.#overrideDecision = decision;\n    this.#overrideDecisionInputIndex = tokenIndex;\n    this.#overrideDecisionAlt = forcedAlt;\n  }\n  get overrideDecisionRoot() {\n    return this.#overrideDecisionRoot;\n  }\n  enterRecursionRule(localctx, state, ruleIndex, precedence) {\n    this.parentContextStack.push([this.context, localctx.invokingState]);\n    super.enterRecursionRule(localctx, state, ruleIndex, precedence);\n  }\n  visitState(p) {\n    let predictedAlt = 1;\n    if (p instanceof DecisionState) {\n      predictedAlt = this.visitDecisionState(p);\n    }\n    const transition = p.transitions[predictedAlt - 1];\n    switch (transition.transitionType) {\n      case Transition.EPSILON:\n        if (this.#pushRecursionContextStates.get(p.stateNumber) && !(transition.target.constructor.stateType === ATNState.LOOP_END)) {\n          const parentContext = this.parentContextStack[this.parentContextStack.length - 1];\n          const localctx = this.createInterpreterRuleContext(parentContext[0], parentContext[1], this.context.ruleIndex);\n          this.pushNewRecursionContext(\n            localctx,\n            this.#atn.ruleToStartState[p.ruleIndex].stateNumber,\n            this.context.ruleIndex\n          );\n        }\n        break;\n      case Transition.ATOM:\n        this.match(transition.label.minElement);\n        break;\n      case Transition.RANGE:\n      case Transition.SET:\n      case Transition.NOT_SET:\n        if (!transition.matches(this.inputStream.LA(1), Token.MIN_USER_TOKEN_TYPE, 65535)) {\n          this.recoverInline();\n        }\n        this.matchWildcard();\n        break;\n      case Transition.WILDCARD:\n        this.matchWildcard();\n        break;\n      case Transition.RULE:\n        const ruleStartState = transition.target;\n        const ruleIndex = ruleStartState.ruleIndex;\n        const newContext = this.createInterpreterRuleContext(this.context, p.stateNumber, ruleIndex);\n        if (ruleStartState.isPrecedenceRule) {\n          this.enterRecursionRule(\n            newContext,\n            ruleStartState.stateNumber,\n            ruleIndex,\n            transition.precedence\n          );\n        } else {\n          this.enterRule(newContext, transition.target.stateNumber, ruleIndex);\n        }\n        break;\n      case Transition.PREDICATE:\n        const predicateTransition = transition;\n        if (!this.sempred(this.context, predicateTransition.ruleIndex, predicateTransition.predIndex)) {\n          throw new FailedPredicateException(this);\n        }\n        break;\n      case Transition.ACTION:\n        const actionTransition = transition;\n        this.action(this.context, actionTransition.ruleIndex, actionTransition.actionIndex);\n        break;\n      case Transition.PRECEDENCE:\n        if (!this.precpred(this.context, transition.precedence)) {\n          const precedence = transition.precedence;\n          throw new FailedPredicateException(this, `precpred(_ctx, ${precedence})`);\n        }\n        break;\n      default:\n        throw new Error(\"UnsupportedOperationException: Unrecognized ATN transition type.\");\n    }\n    this.state = transition.target.stateNumber;\n  }\n  visitDecisionState(p) {\n    let predictedAlt = 1;\n    if (p.transitions.length > 1) {\n      this.errorHandler.sync(this);\n      const decision = p.decision;\n      if (decision === this.#overrideDecision && this.inputStream.index === this.#overrideDecisionInputIndex && !this.#overrideDecisionReached) {\n        predictedAlt = this.#overrideDecisionAlt;\n        this.#overrideDecisionReached = true;\n      } else {\n        predictedAlt = this.interpreter.adaptivePredict(this.inputStream, decision, this.context);\n      }\n    }\n    return predictedAlt;\n  }\n  createInterpreterRuleContext(parent, invokingStateNumber, ruleIndex) {\n    return new InterpreterRuleContext(ruleIndex, parent, invokingStateNumber);\n  }\n  visitRuleStopState(p) {\n    const ruleStartState = this.#atn.ruleToStartState[p.ruleIndex];\n    if (ruleStartState.isPrecedenceRule) {\n      const [parentContext, state] = this.parentContextStack.pop();\n      this.unrollRecursionContexts(parentContext);\n      this.state = state;\n    } else {\n      this.exitRule();\n    }\n    const ruleTransition = this.#atn.states[this.state].transitions[0];\n    this.state = ruleTransition.followState.stateNumber;\n  }\n  recover(e) {\n    const i = this.inputStream.index;\n    this.errorHandler.recover(this, e);\n    if (this.inputStream.index === i) {\n      const tok = e.offendingToken;\n      if (!tok) {\n        throw new Error(\"Expected exception to have an offending token\");\n      }\n      const source = tok.tokenSource;\n      const stream = source?.inputStream ?? null;\n      const sourcePair = [source, stream];\n      if (e instanceof InputMismatchException) {\n        const expectedTokens = e.getExpectedTokens();\n        if (!expectedTokens) {\n          throw new Error(\"Expected the exception to provide expected tokens\");\n        }\n        let expectedTokenType = Token.INVALID_TYPE;\n        if (expectedTokens.length !== 0) {\n          expectedTokenType = expectedTokens.minElement;\n        }\n        const errToken = this.getTokenFactory().create(\n          sourcePair,\n          expectedTokenType,\n          tok.text,\n          Token.DEFAULT_CHANNEL,\n          -1,\n          -1,\n          tok.line,\n          tok.column\n        );\n        this.context.addErrorNode(this.createErrorNode(this.context, errToken));\n      } else {\n        const errToken = this.getTokenFactory().create(\n          sourcePair,\n          Token.INVALID_TYPE,\n          tok.text,\n          Token.DEFAULT_CHANNEL,\n          -1,\n          -1,\n          tok.line,\n          tok.column\n        );\n        this.context.addErrorNode(this.createErrorNode(this.context, errToken));\n      }\n    }\n  }\n  recoverInline() {\n    return this.errorHandler.recoverInline(this);\n  }\n};\n\n// src/misc/MultiMap.ts\nvar MultiMap = class extends Map {\n  static {\n    __name(this, \"MultiMap\");\n  }\n  map(key, value) {\n    let elementsForKey = this.get(key);\n    if (!elementsForKey) {\n      elementsForKey = new Array();\n      this.set(key, elementsForKey);\n    }\n    elementsForKey.push(value);\n  }\n  getPairs() {\n    const pairs = new Array();\n    for (const key of this.keys()) {\n      const keys = this.get(key) ?? [];\n      for (const value of keys) {\n        pairs.push([key, value]);\n      }\n    }\n    return pairs;\n  }\n};\n\n// src/tree/pattern/RuleTagToken.ts\nvar RuleTagToken = class {\n  static {\n    __name(this, \"RuleTagToken\");\n  }\n  /** The name of the label associated with the rule tag. */\n  label;\n  /** The name of the parser rule associated with this rule tag. */\n  ruleName;\n  /**\n   * The token type for the current token. This is the token type assigned to\n   * the bypass alternative for the rule during ATN deserialization.\n   */\n  bypassTokenType;\n  constructor(ruleName, bypassTokenType, label) {\n    this.ruleName = ruleName;\n    this.bypassTokenType = bypassTokenType;\n    this.label = label;\n  }\n  /**\n   * Rule tag tokens are always placed on the {@link #DEFAULT_CHANNEL}.\n   */\n  get channel() {\n    return Token.DEFAULT_CHANNEL;\n  }\n  /**\n   * This method returns the rule tag formatted with `<` and `>`\n   * delimiters.\n   */\n  get text() {\n    if (this.label !== null) {\n      return \"<\" + this.label + \":\" + this.ruleName + \">\";\n    }\n    return \"<\" + this.ruleName + \">\";\n  }\n  /**\n   * Rule tag tokens have types assigned according to the rule bypass\n   * transitions created during ATN deserialization.\n   */\n  get type() {\n    return this.bypassTokenType;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} always returns 0.\n   */\n  get line() {\n    return 0;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} always returns -1.\n   */\n  get column() {\n    return -1;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} always returns -1.\n   */\n  get tokenIndex() {\n    return -1;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} always returns -1.\n   */\n  get start() {\n    return -1;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} always returns -1.\n   */\n  get stop() {\n    return -1;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} always returns `null`.\n   */\n  get tokenSource() {\n    return null;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} always returns `null`.\n   */\n  get inputStream() {\n    return null;\n  }\n  /**\n   * The implementation for {@link RuleTagToken} returns a string of the form\n   * `ruleName:bypassTokenType`.\n   */\n  toString() {\n    return this.ruleName + \":\" + this.bypassTokenType;\n  }\n};\n\n// src/tree/pattern/TagChunk.ts\nvar TagChunk = class extends Chunk {\n  static {\n    __name(this, \"TagChunk\");\n  }\n  tag;\n  label;\n  constructor(...args) {\n    let label;\n    let tag;\n    if (args.length === 1) {\n      tag = args[0];\n    } else {\n      label = args[0];\n      tag = args[1];\n    }\n    super();\n    if (!tag) {\n      throw new Error(\"tag cannot be null or empty\");\n    }\n    this.label = label;\n    this.tag = tag;\n  }\n  /**\n   * @returns a text representation of the tag chunk. Labeled tags\n   * are returned in the form `label:tag`, and unlabeled tags are\n   * returned as just the tag name.\n   */\n  toString() {\n    if (this.label !== null) {\n      return this.label + \":\" + this.tag;\n    }\n    return this.tag;\n  }\n};\n\n// src/tree/pattern/TextChunk.ts\nvar TextChunk = class extends Chunk {\n  static {\n    __name(this, \"TextChunk\");\n  }\n  text;\n  /**\n   * Constructs a new instance of {@link TextChunk} with the specified text.\n   *\n   * @param text The text of this chunk.\n   */\n  constructor(text) {\n    super();\n    this.text = text;\n  }\n  /**\n   * @returns the result of {@link #getText()} in single quotes.\n   */\n  toString() {\n    return \"'\" + this.text + \"'\";\n  }\n};\n\n// src/tree/pattern/TokenTagToken.ts\nvar TokenTagToken = class extends CommonToken {\n  static {\n    __name(this, \"TokenTagToken\");\n  }\n  tokenName;\n  /**\n   * The name of the label associated with the rule tag, or undefined if this is an unlabeled rule tag.\n   */\n  label;\n  constructor(tokenName, type, label) {\n    super({ type, source: CommonToken.EMPTY_SOURCE });\n    this.tokenName = tokenName;\n    this.label = label;\n  }\n  /**\n   *\n   * @returns the token tag formatted with `<` and `>` delimiters.\n   */\n  get text() {\n    if (this.label !== null) {\n      return \"<\" + this.label + \":\" + this.tokenName + \">\";\n    }\n    return \"<\" + this.tokenName + \">\";\n  }\n  /**\n   * @returns a string of the form `tokenName:type`.\n   */\n  toString() {\n    return this.tokenName + \":\" + this.type;\n  }\n};\n\n// src/tree/pattern/ParseTreePatternMatcher.ts\nvar ParseTreePatternMatcher = class _ParseTreePatternMatcher {\n  static {\n    __name(this, \"ParseTreePatternMatcher\");\n  }\n  // eslint-disable-next-line @typescript-eslint/naming-convention\n  static CannotInvokeStartRule = class CannotInvokeStartRule extends Error {\n    static {\n      __name(this, \"CannotInvokeStartRule\");\n    }\n    constructor(e) {\n      super();\n      this.cause = e;\n    }\n  };\n  // Fixes https://github.com/antlr/antlr4/issues/413\n  // \"Tree pattern compilation doesn't check for a complete parse\"\n  // eslint-disable-next-line @typescript-eslint/naming-convention\n  static StartRuleDoesNotConsumeFullPattern = class StartRuleDoesNotConsumeFullPattern extends Error {\n    static {\n      __name(this, \"StartRuleDoesNotConsumeFullPattern\");\n    }\n  };\n  start = \"<\";\n  stop = \">\";\n  escape = \"\\\\\";\n  /**\n   * This is the backing field for {@link #getLexer()}.\n   */\n  lexer;\n  /**\n   * This is the backing field for {@link #getParser()}.\n   */\n  parser;\n  // e.g., \\< and \\> must escape BOTH!\n  /**\n   * Constructs a {@link ParseTreePatternMatcher} or from a {@link Lexer} and\n   * {@link Parser} object. The lexer input stream is altered for tokenizing\n   * the tree patterns. The parser is used as a convenient mechanism to get\n   * the grammar name, plus token, rule names.\n   */\n  constructor(lexer, parser) {\n    this.lexer = lexer;\n    this.parser = parser;\n  }\n  /**\n   * Set the delimiters used for marking rule and token tags within concrete\n   * syntax used by the tree pattern parser.\n   *\n   * @param start The start delimiter.\n   * @param stop The stop delimiter.\n   * @param escapeLeft The escape sequence to use for escaping a start or stop delimiter.\n   *\n   * @throws Error if `start` is `null` or empty.\n   * @throws Error if `stop` is `null` or empty.\n   */\n  setDelimiters(start, stop, escapeLeft) {\n    if (start === null || start.length === 0) {\n      throw new Error(\"start cannot be null or empty\");\n    }\n    if (stop === null || stop.length === 0) {\n      throw new Error(\"stop cannot be null or empty\");\n    }\n    this.start = start;\n    this.stop = stop;\n    this.escape = escapeLeft;\n  }\n  matches(...args) {\n    switch (args.length) {\n      case 2: {\n        const [tree, pattern] = args;\n        const labels = new MultiMap();\n        const mismatchedNode = this.matchImpl(tree, pattern.getPatternTree(), labels);\n        return mismatchedNode === null;\n      }\n      case 3: {\n        const [tree, pattern, patternRuleIndex] = args;\n        const p = this.compile(pattern, patternRuleIndex);\n        return this.matches(tree, p);\n      }\n      default: {\n        throw new Error(\"Invalid number of arguments\");\n      }\n    }\n  }\n  match(...args) {\n    switch (args.length) {\n      case 2: {\n        const [tree, pattern] = args;\n        const labels = new MultiMap();\n        const mismatchedNode = this.matchImpl(tree, pattern.getPatternTree(), labels);\n        return new ParseTreeMatch(tree, pattern, labels, mismatchedNode);\n      }\n      case 3: {\n        const [tree, pattern, patternRuleIndex] = args;\n        const p = this.compile(pattern, patternRuleIndex);\n        return this.match(tree, p);\n      }\n      default: {\n        throw new Error(\"Invalid number of arguments\");\n      }\n    }\n  }\n  /**\n   * For repeated use of a tree pattern, compile it to a\n   * {@link ParseTreePattern} using this method.\n   */\n  compile(pattern, patternRuleIndex) {\n    const tokenList = this.tokenize(pattern);\n    const tokenSrc = new ListTokenSource(tokenList);\n    const tokens = new CommonTokenStream(tokenSrc);\n    const parserInterp = new ParserInterpreter(\n      this.parser.grammarFileName,\n      this.parser.vocabulary,\n      this.parser.ruleNames,\n      this.parser.getATNWithBypassAlts(),\n      tokens\n    );\n    let tree = null;\n    try {\n      parserInterp.errorHandler = new BailErrorStrategy();\n      tree = parserInterp.parse(patternRuleIndex);\n    } catch (eOrRe) {\n      if (eOrRe instanceof ParseCancellationException) {\n        const e = eOrRe;\n        throw e.cause;\n      } else if (eOrRe instanceof RecognitionException) {\n        throw eOrRe;\n      } else if (eOrRe instanceof Error) {\n        throw new _ParseTreePatternMatcher.CannotInvokeStartRule(eOrRe);\n      } else {\n        throw eOrRe;\n      }\n    }\n    if (tokens.LA(1) !== Token.EOF) {\n      throw new _ParseTreePatternMatcher.StartRuleDoesNotConsumeFullPattern();\n    }\n    return new ParseTreePattern(this, pattern, patternRuleIndex, tree);\n  }\n  /**\n   * Used to convert the tree pattern string into a series of tokens. The\n   * input stream is reset.\n   */\n  getLexer() {\n    return this.lexer;\n  }\n  /**\n   * Used to collect to the grammar file name, token names, rule names for\n   * used to parse the pattern into a parse tree.\n   */\n  getParser() {\n    return this.parser;\n  }\n  // ---- SUPPORT CODE ----\n  tokenize(pattern) {\n    const chunks = this.split(pattern);\n    const tokens = new Array();\n    for (const chunk of chunks) {\n      if (chunk instanceof TagChunk) {\n        const tagChunk = chunk;\n        const char = tagChunk.tag[0];\n        if (char === char.toUpperCase()) {\n          const ttype = this.parser.getTokenType(tagChunk.tag);\n          if (ttype === Token.INVALID_TYPE) {\n            throw new Error(\"Unknown token \" + tagChunk.tag + \" in pattern: \" + pattern);\n          }\n          const t = new TokenTagToken(tagChunk.tag, ttype, tagChunk.label);\n          tokens.push(t);\n        } else {\n          if (char === char.toLowerCase()) {\n            const ruleIndex = this.parser.getRuleIndex(tagChunk.tag);\n            if (ruleIndex === -1) {\n              throw new Error(\"Unknown rule \" + tagChunk.tag + \" in pattern: \" + pattern);\n            }\n            const ruleImaginaryTokenType = this.parser.getATNWithBypassAlts().ruleToTokenType[ruleIndex];\n            tokens.push(new RuleTagToken(tagChunk.tag, ruleImaginaryTokenType, tagChunk.label));\n          } else {\n            throw new Error(\"invalid tag: \" + tagChunk.tag + \" in pattern: \" + pattern);\n          }\n        }\n      } else {\n        const textChunk = chunk;\n        const input = CharStream.fromString(textChunk.text);\n        this.lexer.inputStream = input;\n        let t = this.lexer.nextToken();\n        while (t.type !== Token.EOF) {\n          tokens.push(t);\n          t = this.lexer.nextToken();\n        }\n      }\n    }\n    return tokens;\n  }\n  /**\n   * Split `<ID> = <e:expr> ;` into 4 chunks for tokenizing by {@link #tokenize}.\n   */\n  split(pattern) {\n    let p = 0;\n    const n2 = pattern.length;\n    const chunks = new Array();\n    const starts = new Array();\n    const stops = new Array();\n    while (p < n2) {\n      if (p === pattern.indexOf(this.escape + this.start, p)) {\n        p += this.escape.length + this.start.length;\n      } else {\n        if (p === pattern.indexOf(this.escape + this.stop, p)) {\n          p += this.escape.length + this.stop.length;\n        } else {\n          if (p === pattern.indexOf(this.start, p)) {\n            starts.push(p);\n            p += this.start.length;\n          } else {\n            if (p === pattern.indexOf(this.stop, p)) {\n              stops.push(p);\n              p += this.stop.length;\n            } else {\n              p++;\n            }\n          }\n        }\n      }\n    }\n    if (starts.length > stops.length) {\n      throw new Error(\"unterminated tag in pattern: \" + pattern);\n    }\n    if (starts.length < stops.length) {\n      throw new Error(\"missing start tag in pattern: \" + pattern);\n    }\n    const tagCount = starts.length;\n    for (let i = 0; i < tagCount; i++) {\n      if (starts[i] >= stops[i]) {\n        throw new Error(\"tag delimiters out of order in pattern: \" + pattern);\n      }\n    }\n    if (tagCount === 0) {\n      const text = pattern.substring(0, n2);\n      chunks.push(new TextChunk(text));\n    }\n    if (tagCount > 0 && starts[0] > 0) {\n      const text = pattern.substring(0, starts[0]);\n      chunks.push(new TextChunk(text));\n    }\n    for (let i = 0; i < tagCount; i++) {\n      const tag = pattern.substring(starts[i] + this.start.length, stops[i]);\n      let ruleOrToken = tag;\n      let label;\n      const colon = tag.indexOf(\":\");\n      if (colon >= 0) {\n        label = tag.substring(0, colon);\n        ruleOrToken = tag.substring(colon + 1, tag.length);\n      }\n      chunks.push(new TagChunk(label, ruleOrToken));\n      if (i + 1 < tagCount) {\n        const text = pattern.substring(stops[i] + this.stop.length, starts[i + 1]);\n        chunks.push(new TextChunk(text));\n      }\n    }\n    if (tagCount > 0) {\n      const afterLastTag = stops[tagCount - 1] + this.stop.length;\n      if (afterLastTag < n2) {\n        const text = pattern.substring(afterLastTag, n2);\n        chunks.push(new TextChunk(text));\n      }\n    }\n    for (let i = 0; i < chunks.length; i++) {\n      const c = chunks[i];\n      if (c instanceof TextChunk) {\n        const tc = c;\n        const unescaped = tc.text.replace(this.escape, \"\");\n        if (unescaped.length < tc.text.length) {\n          chunks[i] = new TextChunk(unescaped);\n        }\n      }\n    }\n    return chunks;\n  }\n  /**\n   * Recursively walk `tree` against `patternTree`, filling\n   * `match.`{@link ParseTreeMatch#labels labels}.\n   *\n   * @returns the first node encountered in `tree` which does not match\n   * a corresponding node in `patternTree`, or `null` if the match\n   * was successful. The specific node returned depends on the matching\n   * algorithm used by the implementation, and may be overridden.\n   */\n  matchImpl(tree, patternTree, labels) {\n    if (tree instanceof TerminalNode && patternTree instanceof TerminalNode) {\n      const t1 = tree;\n      const t2 = patternTree;\n      let mismatchedNode;\n      if (t1.getSymbol().type === t2.getSymbol().type) {\n        if (t2.getSymbol() instanceof TokenTagToken) {\n          const tokenTagToken = t2.getSymbol();\n          labels.map(tokenTagToken.tokenName, tree);\n          if (tokenTagToken.label !== void 0) {\n            labels.map(tokenTagToken.label, tree);\n          }\n        } else {\n          if (t1.getText() === t2.getText()) {\n          } else {\n            if (!mismatchedNode) {\n              mismatchedNode = t1;\n            }\n          }\n        }\n      } else {\n        if (!mismatchedNode) {\n          mismatchedNode = t1;\n        }\n      }\n      return mismatchedNode;\n    }\n    if (tree instanceof ParserRuleContext && patternTree instanceof ParserRuleContext) {\n      let mismatchedNode;\n      const ruleTagToken = this.getRuleTagToken(patternTree);\n      if (ruleTagToken) {\n        if (tree.ruleIndex === patternTree.ruleIndex) {\n          labels.map(ruleTagToken.ruleName, tree);\n          if (ruleTagToken.label) {\n            labels.map(ruleTagToken.label, tree);\n          }\n        } else {\n          if (!mismatchedNode) {\n            mismatchedNode = tree;\n          }\n        }\n        return mismatchedNode;\n      }\n      if (tree.getChildCount() !== patternTree.getChildCount()) {\n        if (!mismatchedNode) {\n          mismatchedNode = tree;\n        }\n        return mismatchedNode;\n      }\n      const n2 = tree.getChildCount();\n      for (let i = 0; i < n2; i++) {\n        const childMatch = this.matchImpl(tree.getChild(i), patternTree.getChild(i), labels);\n        if (childMatch) {\n          return childMatch;\n        }\n      }\n      return mismatchedNode;\n    }\n    return tree;\n  }\n  /**\n   * Is `t` `(expr <expr>)` subtree?\n   */\n  getRuleTagToken(t) {\n    if (t instanceof ParserRuleContext) {\n      if (t.getChildCount() === 1 && t.getChild(0) instanceof TerminalNode) {\n        const c = t.getChild(0);\n        if (c.getSymbol() instanceof RuleTagToken) {\n          return c.getSymbol();\n        }\n      }\n    }\n    return void 0;\n  }\n};\n\n// src/DiagnosticErrorListener.ts\nvar DiagnosticErrorListener = class extends BaseErrorListener {\n  static {\n    __name(this, \"DiagnosticErrorListener\");\n  }\n  /**\n   * When `true`, only exactly known ambiguities are reported.\n   */\n  exactOnly;\n  constructor(exactOnly) {\n    super();\n    this.exactOnly = exactOnly ?? true;\n  }\n  reportAmbiguity = (recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) => {\n    if (this.exactOnly && !exact) {\n      return;\n    }\n    const decision = this.getDecisionDescription(recognizer, dfa);\n    const conflictingAlts = this.getConflictingAlts(ambigAlts, configs);\n    const text = recognizer.tokenStream?.getTextFromInterval(Interval.of(startIndex, stopIndex));\n    const message = `reportAmbiguity d=${decision}: ambigAlts=${conflictingAlts}, input='${text}'`;\n    recognizer.notifyErrorListeners(message, null, null);\n  };\n  reportAttemptingFullContext = (recognizer, dfa, startIndex, stopIndex, _conflictingAlts, _configs) => {\n    const decision = this.getDecisionDescription(recognizer, dfa);\n    const text = recognizer.tokenStream?.getTextFromInterval(Interval.of(startIndex, stopIndex));\n    const message = `reportAttemptingFullContext d=${decision}, input='${text}'`;\n    recognizer.notifyErrorListeners(message, null, null);\n  };\n  reportContextSensitivity = (recognizer, dfa, startIndex, stopIndex, _prediction, _configs) => {\n    const decision = this.getDecisionDescription(recognizer, dfa);\n    const text = recognizer.tokenStream?.getTextFromInterval(Interval.of(startIndex, stopIndex));\n    const message = `reportContextSensitivity d=${decision}, input='${text}'`;\n    recognizer.notifyErrorListeners(message, null, null);\n  };\n  getDecisionDescription = (recognizer, dfa) => {\n    const decision = dfa.decision;\n    const ruleIndex = dfa.atnStartState.ruleIndex;\n    const ruleNames = recognizer.ruleNames;\n    if (ruleIndex < 0 || ruleIndex >= ruleNames.length) {\n      return decision.toString();\n    }\n    const ruleName = ruleNames[ruleIndex];\n    if (ruleName.length === 0) {\n      return decision.toString();\n    }\n    return `${decision} (${ruleName})`;\n  };\n  /**\n   * Computes the set of conflicting or ambiguous alternatives from a\n   * configuration set, if that information was not already provided by the\n   * parser.\n   *\n   * @param reportedAlts The set of conflicting or ambiguous alternatives, as\n   * reported by the parser.\n   * @param configs The conflicting or ambiguous configuration set.\n   * @returns Returns `reportedAlts` if it is not `null`, otherwise\n   * returns the set of alternatives represented in `configs`.\n   */\n  getConflictingAlts = (reportedAlts, configs) => {\n    if (reportedAlts) {\n      return reportedAlts;\n    }\n    const result = new BitSet();\n    for (let i = 0; i < configs.configs.length; i++) {\n      result.set(configs.configs[i].alt);\n    }\n    return result;\n  };\n};\n\n// src/LexerInterpreter.ts\nvar LexerInterpreter = class extends Lexer {\n  static {\n    __name(this, \"LexerInterpreter\");\n  }\n  #grammarFileName;\n  #atn;\n  #ruleNames;\n  #channelNames;\n  #modeNames;\n  #vocabulary;\n  #decisionToDFA;\n  #sharedContextCache = new PredictionContextCache();\n  constructor(grammarFileName, vocabulary, ruleNames, channelNames, modeNames, atn, input) {\n    super(input);\n    if (atn.grammarType !== ATN.LEXER) {\n      throw new Error(\"IllegalArgumentException: The ATN must be a lexer ATN.\");\n    }\n    this.#grammarFileName = grammarFileName;\n    this.#atn = atn;\n    this.#ruleNames = ruleNames.slice(0);\n    this.#channelNames = channelNames.slice(0);\n    this.#modeNames = modeNames.slice(0);\n    this.#vocabulary = vocabulary;\n    this.#decisionToDFA = atn.decisionToState.map((ds, i) => {\n      return new DFA(ds, i);\n    });\n    this.interpreter = new LexerATNSimulator(this, atn, this.#decisionToDFA, this.#sharedContextCache);\n  }\n  get atn() {\n    return this.#atn;\n  }\n  get grammarFileName() {\n    return this.#grammarFileName;\n  }\n  get ruleNames() {\n    return this.#ruleNames;\n  }\n  get channelNames() {\n    return this.#channelNames;\n  }\n  get modeNames() {\n    return this.#modeNames;\n  }\n  get vocabulary() {\n    return this.#vocabulary;\n  }\n};\n\n// src/TokenStreamRewriter.ts\nvar TokenStreamRewriter = class _TokenStreamRewriter {\n  static {\n    __name(this, \"TokenStreamRewriter\");\n  }\n  static DEFAULT_PROGRAM_NAME = \"default\";\n  static PROGRAM_INIT_SIZE = 100;\n  static MIN_TOKEN_INDEX = 0;\n  /** Our source stream */\n  tokens;\n  /**\n   * You may have multiple, named streams of rewrite operations.\n   *  I'm calling these things \"programs.\"\n   *  Maps String (name) -> rewrite (List)\n   */\n  programs = /* @__PURE__ */ new Map();\n  /** Map String (program name) -> Integer index */\n  lastRewriteTokenIndexes;\n  /**\n   * @param tokens The token stream to modify\n   */\n  constructor(tokens) {\n    this.tokens = tokens;\n  }\n  getTokenStream() {\n    return this.tokens;\n  }\n  /**\n   * Insert the supplied text after the specified token (or token index)\n   */\n  insertAfter(tokenOrIndex, text, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n    let index;\n    if (typeof tokenOrIndex === \"number\") {\n      index = tokenOrIndex;\n    } else {\n      index = tokenOrIndex.tokenIndex;\n    }\n    const rewrites = this.getProgram(programName);\n    const op = new InsertAfterOp(this.tokens, index, rewrites.length, text);\n    rewrites.push(op);\n  }\n  /**\n   * Insert the supplied text before the specified token (or token index)\n   */\n  insertBefore(tokenOrIndex, text, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n    let index;\n    if (typeof tokenOrIndex === \"number\") {\n      index = tokenOrIndex;\n    } else {\n      index = tokenOrIndex.tokenIndex;\n    }\n    const rewrites = this.getProgram(programName);\n    const op = new InsertBeforeOp(this.tokens, index, rewrites.length, text);\n    rewrites.push(op);\n  }\n  /**\n   * Replace the specified token with the supplied text\n   */\n  replaceSingle(tokenOrIndex, text, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n    this.replace(tokenOrIndex, tokenOrIndex, text, programName);\n  }\n  /**\n   * Replace the specified range of tokens with the supplied text.\n   */\n  replace(from, to, text, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n    if (typeof from !== \"number\") {\n      from = from.tokenIndex;\n    }\n    if (typeof to !== \"number\") {\n      to = to.tokenIndex;\n    }\n    if (from > to || from < 0 || to < 0 || to >= this.tokens.size) {\n      throw new RangeError(`replace: range invalid: ${from}..${to}(size=${this.tokens.size})`);\n    }\n    const rewrites = this.getProgram(programName);\n    const op = new ReplaceOp(this.tokens, from, to, rewrites.length, text);\n    rewrites.push(op);\n  }\n  /**\n   * Delete the specified range of tokens\n   */\n  delete(from, to, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n    if (to == null) {\n      to = from;\n    }\n    this.replace(from, to, null, programName);\n  }\n  getProgram(name) {\n    let is = this.programs.get(name);\n    if (is == null) {\n      is = this.initializeProgram(name);\n    }\n    return is;\n  }\n  initializeProgram(name) {\n    const is = [];\n    this.programs.set(name, is);\n    return is;\n  }\n  /**\n   * @returns the text from the original tokens altered per the instructions given to this rewriter\n   */\n  getText(intervalOrProgram, programName = _TokenStreamRewriter.DEFAULT_PROGRAM_NAME) {\n    let interval;\n    if (intervalOrProgram instanceof Interval) {\n      interval = intervalOrProgram;\n    } else {\n      interval = new Interval(0, this.tokens.size - 1);\n    }\n    if (typeof intervalOrProgram === \"string\") {\n      programName = intervalOrProgram;\n    }\n    const rewrites = this.programs.get(programName);\n    let start = interval.start;\n    let stop = interval.stop;\n    if (stop > this.tokens.size - 1) {\n      stop = this.tokens.size - 1;\n    }\n    if (start < 0) {\n      start = 0;\n    }\n    if (rewrites == null || rewrites.length === 0) {\n      return this.tokens.getTextFromInterval(new Interval(start, stop));\n    }\n    const buf = [];\n    const indexToOp = this.reduceToSingleOperationPerIndex(rewrites);\n    let i = start;\n    while (i <= stop && i < this.tokens.size) {\n      const op = indexToOp.get(i);\n      indexToOp.delete(i);\n      const t = this.tokens.get(i);\n      if (op == null) {\n        if (t.type !== Token.EOF) {\n          buf.push(String(t.text));\n        }\n        i++;\n      } else {\n        i = op.execute(buf);\n      }\n    }\n    if (stop === this.tokens.size - 1) {\n      for (const op of indexToOp.values()) {\n        if (op && op.index >= this.tokens.size - 1) {\n          buf.push(String(op.text));\n        }\n      }\n    }\n    return buf.join(\"\");\n  }\n  /**\n   * @returns a map from token index to operation\n   */\n  reduceToSingleOperationPerIndex(rewrites) {\n    for (let i = 0; i < rewrites.length; i++) {\n      const op = rewrites[i];\n      if (op == null) {\n        continue;\n      }\n      if (!(op instanceof ReplaceOp)) {\n        continue;\n      }\n      const rop = op;\n      const inserts = this.getKindOfOps(rewrites, InsertBeforeOp, i);\n      for (const iop of inserts) {\n        if (iop.index === rop.index) {\n          rewrites[iop.instructionIndex] = null;\n          rop.text = String(iop.text) + (rop.text != null ? rop.text.toString() : \"\");\n        } else if (iop.index > rop.index && iop.index <= rop.lastIndex) {\n          rewrites[iop.instructionIndex] = null;\n        }\n      }\n      const prevReplaces = this.getKindOfOps(rewrites, ReplaceOp, i);\n      for (const prevRop of prevReplaces) {\n        if (prevRop.index >= rop.index && prevRop.lastIndex <= rop.lastIndex) {\n          rewrites[prevRop.instructionIndex] = null;\n          continue;\n        }\n        const disjoint = prevRop.lastIndex < rop.index || prevRop.index > rop.lastIndex;\n        if (prevRop.text == null && rop.text == null && !disjoint) {\n          rewrites[prevRop.instructionIndex] = null;\n          rop.index = Math.min(prevRop.index, rop.index);\n          rop.lastIndex = Math.max(prevRop.lastIndex, rop.lastIndex);\n        } else if (!disjoint) {\n          throw new Error(`replace op boundaries of ${rop} overlap with previous ${prevRop}`);\n        }\n      }\n    }\n    for (let i = 0; i < rewrites.length; i++) {\n      const op = rewrites[i];\n      if (op == null) {\n        continue;\n      }\n      if (!(op instanceof InsertBeforeOp)) {\n        continue;\n      }\n      const iop = op;\n      const prevInserts = this.getKindOfOps(rewrites, InsertBeforeOp, i);\n      for (const prevIop of prevInserts) {\n        if (prevIop.index === iop.index) {\n          if (prevIop instanceof InsertAfterOp) {\n            iop.text = this.catOpText(prevIop.text, iop.text);\n            rewrites[prevIop.instructionIndex] = null;\n          } else if (prevIop instanceof InsertBeforeOp) {\n            iop.text = this.catOpText(iop.text, prevIop.text);\n            rewrites[prevIop.instructionIndex] = null;\n          }\n        }\n      }\n      const prevReplaces = this.getKindOfOps(rewrites, ReplaceOp, i);\n      for (const rop of prevReplaces) {\n        if (iop.index === rop.index) {\n          rop.text = this.catOpText(iop.text, rop.text);\n          rewrites[i] = null;\n          continue;\n        }\n        if (iop.index >= rop.index && iop.index <= rop.lastIndex) {\n          throw new Error(`insert op ${iop} within boundaries of previous ${rop}`);\n        }\n      }\n    }\n    const m2 = /* @__PURE__ */ new Map();\n    for (const op of rewrites) {\n      if (op == null) {\n        continue;\n      }\n      if (m2.get(op.index) != null) {\n        throw new Error(\"should only be one op per index\");\n      }\n      m2.set(op.index, op);\n    }\n    return m2;\n  }\n  catOpText(a, b) {\n    let x = \"\";\n    let y = \"\";\n    if (a != null) {\n      x = a.toString();\n    }\n    if (b != null) {\n      y = b.toString();\n    }\n    return x + y;\n  }\n  /**\n   * Get all operations before an index of a particular kind\n   */\n  getKindOfOps(rewrites, kind, before) {\n    return rewrites.slice(0, before).filter((op) => {\n      return op && op instanceof kind;\n    });\n  }\n};\nvar RewriteOperation = class {\n  static {\n    __name(this, \"RewriteOperation\");\n  }\n  /** What index into rewrites List are we? */\n  instructionIndex;\n  /** Token buffer index. */\n  index;\n  text;\n  tokens;\n  constructor(tokens, index, instructionIndex, text) {\n    this.tokens = tokens;\n    this.instructionIndex = instructionIndex;\n    this.index = index;\n    this.text = text === void 0 ? \"\" : text;\n  }\n  execute(_buf) {\n    return this.index;\n  }\n  toString() {\n    return \"<RewriteOperation@\" + this.tokens.get(this.index) + ':\"' + this.text + '\">';\n  }\n};\nvar InsertBeforeOp = class extends RewriteOperation {\n  static {\n    __name(this, \"InsertBeforeOp\");\n  }\n  constructor(tokens, index, instructionIndex, text) {\n    super(tokens, index, instructionIndex, text);\n  }\n  /**\n   * @returns the index of the next token to operate on\n   */\n  execute(buf) {\n    if (this.text) {\n      buf.push(this.text.toString());\n    }\n    if (this.tokens.get(this.index).type !== Token.EOF) {\n      buf.push(String(this.tokens.get(this.index).text));\n    }\n    return this.index + 1;\n  }\n  toString() {\n    return \"<InsertBeforeOp@\" + this.tokens.get(this.index) + ':\"' + this.text + '\">';\n  }\n};\nvar InsertAfterOp = class extends InsertBeforeOp {\n  static {\n    __name(this, \"InsertAfterOp\");\n  }\n  constructor(tokens, index, instructionIndex, text) {\n    super(tokens, index + 1, instructionIndex, text);\n  }\n  toString() {\n    return \"<InsertAfterOp@\" + this.tokens.get(this.index) + ':\"' + this.text + '\">';\n  }\n};\nvar ReplaceOp = class extends RewriteOperation {\n  static {\n    __name(this, \"ReplaceOp\");\n  }\n  lastIndex;\n  constructor(tokens, from, to, instructionIndex, text) {\n    super(tokens, from, instructionIndex, text);\n    this.lastIndex = to;\n  }\n  /**\n   * @returns the index of the next token to operate on\n   */\n  execute(buf) {\n    if (this.text) {\n      buf.push(this.text.toString());\n    }\n    return this.lastIndex + 1;\n  }\n  toString() {\n    if (this.text == null) {\n      return \"<DeleteOp@\" + this.tokens.get(this.index) + \"..\" + this.tokens.get(this.lastIndex) + \">\";\n    }\n    return \"<ReplaceOp@\" + this.tokens.get(this.index) + \"..\" + this.tokens.get(this.lastIndex) + ':\"' + this.text + '\">';\n  }\n};\n\n// src/WritableToken.ts\nvar isWritableToken = /* @__PURE__ */ __name((candidate) => {\n  return candidate.setText !== void 0;\n}, \"isWritableToken\");\nexport {\n  ATN,\n  ATNConfig,\n  ATNConfigSet,\n  ATNDeserializer,\n  ATNSerializer,\n  ATNSimulator,\n  ATNState,\n  AbstractParseTreeVisitor,\n  AbstractPredicateTransition,\n  ActionTransition,\n  ArrayPredictionContext,\n  AtomTransition,\n  BailErrorStrategy,\n  BaseErrorListener,\n  BasicBlockStartState,\n  BasicState,\n  BitSet,\n  BlockEndState,\n  BlockStartState,\n  BufferedTokenStream,\n  CharStream,\n  CharStreamImpl,\n  Chunk,\n  CodePointTransitions,\n  CommonToken,\n  CommonTokenFactory,\n  CommonTokenStream,\n  ConsoleErrorListener,\n  DFA,\n  DFASerializer,\n  DFAState,\n  DecisionInfo,\n  DecisionState,\n  DefaultErrorStrategy,\n  DiagnosticErrorListener,\n  EmptyPredictionContext,\n  EpsilonTransition,\n  ErrorNode,\n  FailedPredicateException,\n  HashMap,\n  HashSet,\n  InputMismatchException,\n  IntStream,\n  InterpreterDataReader,\n  InterpreterRuleContext,\n  Interval,\n  IntervalSet,\n  LL1Analyzer,\n  Lexer,\n  LexerATNConfig,\n  LexerATNSimulator,\n  LexerActionExecutor,\n  LexerActionType,\n  LexerChannelAction,\n  LexerCustomAction,\n  LexerDFASerializer,\n  LexerIndexedCustomAction,\n  LexerInterpreter,\n  LexerModeAction,\n  LexerMoreAction,\n  LexerNoViableAltException,\n  LexerPopModeAction,\n  LexerPushModeAction,\n  LexerSkipAction,\n  LexerTypeAction,\n  LoopEndState,\n  NoViableAltException,\n  NotSetTransition,\n  OrderedATNConfigSet,\n  OrderedHashMap,\n  OrderedHashSet,\n  ParseCancellationException,\n  ParseInfo,\n  ParseTreeMatch,\n  ParseTreePattern,\n  ParseTreePatternMatcher,\n  ParseTreeWalker,\n  Parser,\n  ParserATNSimulator,\n  ParserInterpreter,\n  ParserRuleContext,\n  PlusBlockStartState,\n  PlusLoopbackState,\n  PrecedencePredicateTransition,\n  PredPrediction,\n  PredicateTransition,\n  PredictionContext,\n  PredictionContextCache,\n  PredictionMode,\n  ProfilingATNSimulator,\n  ProxyErrorListener,\n  RangeTransition,\n  RecognitionException,\n  Recognizer,\n  RuleStartState,\n  RuleStopState,\n  RuleTagToken,\n  RuleTransition,\n  SemanticContext,\n  SetTransition,\n  SingletonPredictionContext,\n  StarBlockStartState,\n  StarLoopEntryState,\n  StarLoopbackState,\n  TagChunk,\n  TerminalNode,\n  TextChunk,\n  Token,\n  TokenStreamRewriter,\n  TokenTagToken,\n  TokensStartState,\n  TraceListener,\n  Transition,\n  Trees,\n  Vocabulary,\n  WildcardTransition,\n  XPath,\n  XPathElement,\n  XPathLexer,\n  XPathLexerErrorListener,\n  XPathRuleAnywhereElement,\n  XPathRuleElement,\n  XPathTokenAnywhereElement,\n  XPathTokenElement,\n  XPathWildcardAnywhereElement,\n  XPathWildcardElement,\n  arrayToString,\n  combineCommonParents,\n  equalArrays,\n  equalNumberArrays,\n  escapeWhitespace,\n  getCachedPredictionContext,\n  isComparable,\n  isToken,\n  isWritableToken,\n  merge,\n  mergeRoot,\n  mergeSingletons,\n  predictionContextFromRuleContext\n};\n","// Generated from ./g4/Daedalus.g4 by ANTLR 4.13.1\n\nimport * as antlr from \"antlr4ng\";\nimport { Token } from \"antlr4ng\";\n\n\nexport class DaedalusLexer extends antlr.Lexer {\n    public static readonly T__0 = 1;\n    public static readonly T__1 = 2;\n    public static readonly T__2 = 3;\n    public static readonly T__3 = 4;\n    public static readonly T__4 = 5;\n    public static readonly T__5 = 6;\n    public static readonly T__6 = 7;\n    public static readonly T__7 = 8;\n    public static readonly T__8 = 9;\n    public static readonly T__9 = 10;\n    public static readonly T__10 = 11;\n    public static readonly T__11 = 12;\n    public static readonly T__12 = 13;\n    public static readonly T__13 = 14;\n    public static readonly T__14 = 15;\n    public static readonly T__15 = 16;\n    public static readonly T__16 = 17;\n    public static readonly T__17 = 18;\n    public static readonly T__18 = 19;\n    public static readonly T__19 = 20;\n    public static readonly T__20 = 21;\n    public static readonly T__21 = 22;\n    public static readonly T__22 = 23;\n    public static readonly T__23 = 24;\n    public static readonly T__24 = 25;\n    public static readonly T__25 = 26;\n    public static readonly T__26 = 27;\n    public static readonly T__27 = 28;\n    public static readonly T__28 = 29;\n    public static readonly T__29 = 30;\n    public static readonly T__30 = 31;\n    public static readonly T__31 = 32;\n    public static readonly T__32 = 33;\n    public static readonly Const = 34;\n    public static readonly Var = 35;\n    public static readonly If = 36;\n    public static readonly Int = 37;\n    public static readonly Else = 38;\n    public static readonly Func = 39;\n    public static readonly String = 40;\n    public static readonly Class = 41;\n    public static readonly Void = 42;\n    public static readonly Return = 43;\n    public static readonly Float = 44;\n    public static readonly Prototype = 45;\n    public static readonly Instance = 46;\n    public static readonly Null = 47;\n    public static readonly NoFunc = 48;\n    public static readonly While = 49;\n    public static readonly Break = 50;\n    public static readonly Continue = 51;\n    public static readonly Extern = 52;\n    public static readonly Identifier = 53;\n    public static readonly IntegerLiteral = 54;\n    public static readonly FloatLiteral = 55;\n    public static readonly StringLiteral = 56;\n    public static readonly Whitespace = 57;\n    public static readonly Newline = 58;\n    public static readonly BlockComment = 59;\n    public static readonly LineComment = 60;\n    public static readonly UnexpectedCharacter = 61;\n\n    public static readonly channelNames = [\n        \"DEFAULT_TOKEN_CHANNEL\", \"HIDDEN\"\n    ];\n\n    public static readonly literalNames = [\n        null, \"';'\", \"','\", \"'{'\", \"'}'\", \"'('\", \"')'\", \"'['\", \"']'\", \"'='\", \n        \"'.'\", \"'+='\", \"'-='\", \"'*='\", \"'/='\", \"'+'\", \"'-'\", \"'<<'\", \"'>>'\", \n        \"'<'\", \"'>'\", \"'<='\", \"'>='\", \"'=='\", \"'!='\", \"'!'\", \"'~'\", \"'*'\", \n        \"'/'\", \"'%'\", \"'&'\", \"'|'\", \"'&&'\", \"'||'\", null, null, null, null, \n        null, null, null, null, null, null, null, null, null, null, null, \n        \"'while'\", \"'break'\", \"'continue'\", \"'extern'\"\n    ];\n\n    public static readonly symbolicNames = [\n        null, null, null, null, null, null, null, null, null, null, null, \n        null, null, null, null, null, null, null, null, null, null, null, \n        null, null, null, null, null, null, null, null, null, null, null, \n        null, \"Const\", \"Var\", \"If\", \"Int\", \"Else\", \"Func\", \"String\", \"Class\", \n        \"Void\", \"Return\", \"Float\", \"Prototype\", \"Instance\", \"Null\", \"NoFunc\", \n        \"While\", \"Break\", \"Continue\", \"Extern\", \"Identifier\", \"IntegerLiteral\", \n        \"FloatLiteral\", \"StringLiteral\", \"Whitespace\", \"Newline\", \"BlockComment\", \n        \"LineComment\", \"UnexpectedCharacter\"\n    ];\n\n    public static readonly modeNames = [\n        \"DEFAULT_MODE\",\n    ];\n\n    public static readonly ruleNames = [\n        \"T__0\", \"T__1\", \"T__2\", \"T__3\", \"T__4\", \"T__5\", \"T__6\", \"T__7\", \n        \"T__8\", \"T__9\", \"T__10\", \"T__11\", \"T__12\", \"T__13\", \"T__14\", \"T__15\", \n        \"T__16\", \"T__17\", \"T__18\", \"T__19\", \"T__20\", \"T__21\", \"T__22\", \"T__23\", \n        \"T__24\", \"T__25\", \"T__26\", \"T__27\", \"T__28\", \"T__29\", \"T__30\", \"T__31\", \n        \"T__32\", \"Const\", \"Var\", \"If\", \"Int\", \"Else\", \"Func\", \"String\", \n        \"Class\", \"Void\", \"Return\", \"Float\", \"Prototype\", \"Instance\", \"Null\", \n        \"NoFunc\", \"While\", \"Break\", \"Continue\", \"Extern\", \"Identifier\", \n        \"IntegerLiteral\", \"FloatLiteral\", \"StringLiteral\", \"Whitespace\", \n        \"Newline\", \"BlockComment\", \"LineComment\", \"UnexpectedCharacter\", \n        \"IdStart\", \"IdContinue\", \"SpecialCharacter\", \"GermanCharacter\", \n        \"Digit\", \"PointFloat\", \"ExponentFloat\", \"Exponent\",\n    ];\n\n\n    public constructor(input: antlr.CharStream) {\n        super(input);\n        this.interpreter = new antlr.LexerATNSimulator(this, DaedalusLexer._ATN, DaedalusLexer.decisionsToDFA, new antlr.PredictionContextCache());\n    }\n\n    public get grammarFileName(): string { return \"Daedalus.g4\"; }\n\n    public get literalNames(): (string | null)[] { return DaedalusLexer.literalNames; }\n    public get symbolicNames(): (string | null)[] { return DaedalusLexer.symbolicNames; }\n    public get ruleNames(): string[] { return DaedalusLexer.ruleNames; }\n\n    public get serializedATN(): number[] { return DaedalusLexer._serializedATN; }\n\n    public get channelNames(): string[] { return DaedalusLexer.channelNames; }\n\n    public get modeNames(): string[] { return DaedalusLexer.modeNames; }\n\n    public static readonly _serializedATN: number[] = [\n        4,0,61,561,6,-1,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,\n        2,6,7,6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,\n        13,7,13,2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,7,\n        19,2,20,7,20,2,21,7,21,2,22,7,22,2,23,7,23,2,24,7,24,2,25,7,25,2,\n        26,7,26,2,27,7,27,2,28,7,28,2,29,7,29,2,30,7,30,2,31,7,31,2,32,7,\n        32,2,33,7,33,2,34,7,34,2,35,7,35,2,36,7,36,2,37,7,37,2,38,7,38,2,\n        39,7,39,2,40,7,40,2,41,7,41,2,42,7,42,2,43,7,43,2,44,7,44,2,45,7,\n        45,2,46,7,46,2,47,7,47,2,48,7,48,2,49,7,49,2,50,7,50,2,51,7,51,2,\n        52,7,52,2,53,7,53,2,54,7,54,2,55,7,55,2,56,7,56,2,57,7,57,2,58,7,\n        58,2,59,7,59,2,60,7,60,2,61,7,61,2,62,7,62,2,63,7,63,2,64,7,64,2,\n        65,7,65,2,66,7,66,2,67,7,67,2,68,7,68,1,0,1,0,1,1,1,1,1,2,1,2,1,\n        3,1,3,1,4,1,4,1,5,1,5,1,6,1,6,1,7,1,7,1,8,1,8,1,9,1,9,1,10,1,10,\n        1,10,1,11,1,11,1,11,1,12,1,12,1,12,1,13,1,13,1,13,1,14,1,14,1,15,\n        1,15,1,16,1,16,1,16,1,17,1,17,1,17,1,18,1,18,1,19,1,19,1,20,1,20,\n        1,20,1,21,1,21,1,21,1,22,1,22,1,22,1,23,1,23,1,23,1,24,1,24,1,25,\n        1,25,1,26,1,26,1,27,1,27,1,28,1,28,1,29,1,29,1,30,1,30,1,31,1,31,\n        1,31,1,32,1,32,1,32,1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,33,\n        1,33,3,33,228,8,33,1,34,1,34,1,34,1,34,1,34,1,34,3,34,236,8,34,1,\n        35,1,35,1,35,1,35,3,35,242,8,35,1,36,1,36,1,36,1,36,1,36,1,36,3,\n        36,250,8,36,1,37,1,37,1,37,1,37,1,37,1,37,1,37,1,37,3,37,260,8,37,\n        1,38,1,38,1,38,1,38,1,38,1,38,1,38,1,38,3,38,270,8,38,1,39,1,39,\n        1,39,1,39,1,39,1,39,1,39,1,39,1,39,1,39,1,39,1,39,3,39,284,8,39,\n        1,40,1,40,1,40,1,40,1,40,1,40,1,40,1,40,1,40,1,40,3,40,296,8,40,\n        1,41,1,41,1,41,1,41,1,41,1,41,1,41,1,41,3,41,306,8,41,1,42,1,42,\n        1,42,1,42,1,42,1,42,1,42,1,42,1,42,1,42,1,42,1,42,3,42,320,8,42,\n        1,43,1,43,1,43,1,43,1,43,1,43,1,43,1,43,1,43,1,43,3,43,332,8,43,\n        1,44,1,44,1,44,1,44,1,44,1,44,1,44,1,44,1,44,1,44,1,44,1,44,1,44,\n        1,44,1,44,1,44,1,44,1,44,3,44,352,8,44,1,45,1,45,1,45,1,45,1,45,\n        1,45,1,45,1,45,1,45,1,45,1,45,1,45,1,45,1,45,1,45,1,45,3,45,370,\n        8,45,1,46,1,46,1,46,1,46,1,46,1,46,1,46,1,46,1,46,1,46,1,46,1,46,\n        3,46,384,8,46,1,47,1,47,1,47,1,47,1,47,1,47,1,47,1,47,1,47,1,47,\n        1,47,1,47,1,47,1,47,1,47,1,47,1,47,1,47,3,47,404,8,47,1,48,1,48,\n        1,48,1,48,1,48,1,48,1,49,1,49,1,49,1,49,1,49,1,49,1,50,1,50,1,50,\n        1,50,1,50,1,50,1,50,1,50,1,50,1,51,1,51,1,51,1,51,1,51,1,51,1,51,\n        1,52,1,52,5,52,436,8,52,10,52,12,52,439,9,52,1,53,4,53,442,8,53,\n        11,53,12,53,443,1,54,1,54,3,54,448,8,54,1,55,1,55,1,55,1,55,1,55,\n        3,55,455,8,55,5,55,457,8,55,10,55,12,55,460,9,55,1,55,1,55,1,56,\n        4,56,465,8,56,11,56,12,56,466,1,56,1,56,1,57,1,57,3,57,473,8,57,\n        1,57,3,57,476,8,57,1,57,1,57,1,58,1,58,1,58,1,58,5,58,484,8,58,10,\n        58,12,58,487,9,58,1,58,1,58,1,58,1,58,1,58,1,59,1,59,1,59,1,59,5,\n        59,498,8,59,10,59,12,59,501,9,59,1,59,1,59,1,60,1,60,1,61,1,61,3,\n        61,509,8,61,1,62,1,62,1,62,3,62,514,8,62,1,63,1,63,1,64,1,64,1,65,\n        1,65,1,66,5,66,523,8,66,10,66,12,66,526,9,66,1,66,1,66,4,66,530,\n        8,66,11,66,12,66,531,1,66,4,66,535,8,66,11,66,12,66,536,1,66,1,66,\n        3,66,541,8,66,1,67,4,67,544,8,67,11,67,12,67,545,1,67,3,67,549,8,\n        67,1,67,1,67,1,68,1,68,3,68,555,8,68,1,68,4,68,558,8,68,11,68,12,\n        68,559,1,485,0,69,1,1,3,2,5,3,7,4,9,5,11,6,13,7,15,8,17,9,19,10,\n        21,11,23,12,25,13,27,14,29,15,31,16,33,17,35,18,37,19,39,20,41,21,\n        43,22,45,23,47,24,49,25,51,26,53,27,55,28,57,29,59,30,61,31,63,32,\n        65,33,67,34,69,35,71,36,73,37,75,38,77,39,79,40,81,41,83,42,85,43,\n        87,44,89,45,91,46,93,47,95,48,97,49,99,50,101,51,103,52,105,53,107,\n        54,109,55,111,56,113,57,115,58,117,59,119,60,121,61,123,0,125,0,\n        127,0,129,0,131,0,133,0,135,0,137,0,1,0,9,4,0,10,10,13,13,34,34,\n        92,92,2,0,9,9,32,32,2,0,10,10,13,13,3,0,65,90,95,95,97,122,2,0,64,\n        64,94,94,4,0,223,223,228,228,246,246,252,252,1,0,48,57,2,0,69,69,\n        101,101,2,0,43,43,45,45,591,0,1,1,0,0,0,0,3,1,0,0,0,0,5,1,0,0,0,\n        0,7,1,0,0,0,0,9,1,0,0,0,0,11,1,0,0,0,0,13,1,0,0,0,0,15,1,0,0,0,0,\n        17,1,0,0,0,0,19,1,0,0,0,0,21,1,0,0,0,0,23,1,0,0,0,0,25,1,0,0,0,0,\n        27,1,0,0,0,0,29,1,0,0,0,0,31,1,0,0,0,0,33,1,0,0,0,0,35,1,0,0,0,0,\n        37,1,0,0,0,0,39,1,0,0,0,0,41,1,0,0,0,0,43,1,0,0,0,0,45,1,0,0,0,0,\n        47,1,0,0,0,0,49,1,0,0,0,0,51,1,0,0,0,0,53,1,0,0,0,0,55,1,0,0,0,0,\n        57,1,0,0,0,0,59,1,0,0,0,0,61,1,0,0,0,0,63,1,0,0,0,0,65,1,0,0,0,0,\n        67,1,0,0,0,0,69,1,0,0,0,0,71,1,0,0,0,0,73,1,0,0,0,0,75,1,0,0,0,0,\n        77,1,0,0,0,0,79,1,0,0,0,0,81,1,0,0,0,0,83,1,0,0,0,0,85,1,0,0,0,0,\n        87,1,0,0,0,0,89,1,0,0,0,0,91,1,0,0,0,0,93,1,0,0,0,0,95,1,0,0,0,0,\n        97,1,0,0,0,0,99,1,0,0,0,0,101,1,0,0,0,0,103,1,0,0,0,0,105,1,0,0,\n        0,0,107,1,0,0,0,0,109,1,0,0,0,0,111,1,0,0,0,0,113,1,0,0,0,0,115,\n        1,0,0,0,0,117,1,0,0,0,0,119,1,0,0,0,0,121,1,0,0,0,1,139,1,0,0,0,\n        3,141,1,0,0,0,5,143,1,0,0,0,7,145,1,0,0,0,9,147,1,0,0,0,11,149,1,\n        0,0,0,13,151,1,0,0,0,15,153,1,0,0,0,17,155,1,0,0,0,19,157,1,0,0,\n        0,21,159,1,0,0,0,23,162,1,0,0,0,25,165,1,0,0,0,27,168,1,0,0,0,29,\n        171,1,0,0,0,31,173,1,0,0,0,33,175,1,0,0,0,35,178,1,0,0,0,37,181,\n        1,0,0,0,39,183,1,0,0,0,41,185,1,0,0,0,43,188,1,0,0,0,45,191,1,0,\n        0,0,47,194,1,0,0,0,49,197,1,0,0,0,51,199,1,0,0,0,53,201,1,0,0,0,\n        55,203,1,0,0,0,57,205,1,0,0,0,59,207,1,0,0,0,61,209,1,0,0,0,63,211,\n        1,0,0,0,65,214,1,0,0,0,67,227,1,0,0,0,69,235,1,0,0,0,71,241,1,0,\n        0,0,73,249,1,0,0,0,75,259,1,0,0,0,77,269,1,0,0,0,79,283,1,0,0,0,\n        81,295,1,0,0,0,83,305,1,0,0,0,85,319,1,0,0,0,87,331,1,0,0,0,89,351,\n        1,0,0,0,91,369,1,0,0,0,93,383,1,0,0,0,95,403,1,0,0,0,97,405,1,0,\n        0,0,99,411,1,0,0,0,101,417,1,0,0,0,103,426,1,0,0,0,105,433,1,0,0,\n        0,107,441,1,0,0,0,109,447,1,0,0,0,111,449,1,0,0,0,113,464,1,0,0,\n        0,115,475,1,0,0,0,117,479,1,0,0,0,119,493,1,0,0,0,121,504,1,0,0,\n        0,123,508,1,0,0,0,125,513,1,0,0,0,127,515,1,0,0,0,129,517,1,0,0,\n        0,131,519,1,0,0,0,133,540,1,0,0,0,135,548,1,0,0,0,137,552,1,0,0,\n        0,139,140,5,59,0,0,140,2,1,0,0,0,141,142,5,44,0,0,142,4,1,0,0,0,\n        143,144,5,123,0,0,144,6,1,0,0,0,145,146,5,125,0,0,146,8,1,0,0,0,\n        147,148,5,40,0,0,148,10,1,0,0,0,149,150,5,41,0,0,150,12,1,0,0,0,\n        151,152,5,91,0,0,152,14,1,0,0,0,153,154,5,93,0,0,154,16,1,0,0,0,\n        155,156,5,61,0,0,156,18,1,0,0,0,157,158,5,46,0,0,158,20,1,0,0,0,\n        159,160,5,43,0,0,160,161,5,61,0,0,161,22,1,0,0,0,162,163,5,45,0,\n        0,163,164,5,61,0,0,164,24,1,0,0,0,165,166,5,42,0,0,166,167,5,61,\n        0,0,167,26,1,0,0,0,168,169,5,47,0,0,169,170,5,61,0,0,170,28,1,0,\n        0,0,171,172,5,43,0,0,172,30,1,0,0,0,173,174,5,45,0,0,174,32,1,0,\n        0,0,175,176,5,60,0,0,176,177,5,60,0,0,177,34,1,0,0,0,178,179,5,62,\n        0,0,179,180,5,62,0,0,180,36,1,0,0,0,181,182,5,60,0,0,182,38,1,0,\n        0,0,183,184,5,62,0,0,184,40,1,0,0,0,185,186,5,60,0,0,186,187,5,61,\n        0,0,187,42,1,0,0,0,188,189,5,62,0,0,189,190,5,61,0,0,190,44,1,0,\n        0,0,191,192,5,61,0,0,192,193,5,61,0,0,193,46,1,0,0,0,194,195,5,33,\n        0,0,195,196,5,61,0,0,196,48,1,0,0,0,197,198,5,33,0,0,198,50,1,0,\n        0,0,199,200,5,126,0,0,200,52,1,0,0,0,201,202,5,42,0,0,202,54,1,0,\n        0,0,203,204,5,47,0,0,204,56,1,0,0,0,205,206,5,37,0,0,206,58,1,0,\n        0,0,207,208,5,38,0,0,208,60,1,0,0,0,209,210,5,124,0,0,210,62,1,0,\n        0,0,211,212,5,38,0,0,212,213,5,38,0,0,213,64,1,0,0,0,214,215,5,124,\n        0,0,215,216,5,124,0,0,216,66,1,0,0,0,217,218,5,99,0,0,218,219,5,\n        111,0,0,219,220,5,110,0,0,220,221,5,115,0,0,221,228,5,116,0,0,222,\n        223,5,67,0,0,223,224,5,79,0,0,224,225,5,78,0,0,225,226,5,83,0,0,\n        226,228,5,84,0,0,227,217,1,0,0,0,227,222,1,0,0,0,228,68,1,0,0,0,\n        229,230,5,118,0,0,230,231,5,97,0,0,231,236,5,114,0,0,232,233,5,86,\n        0,0,233,234,5,65,0,0,234,236,5,82,0,0,235,229,1,0,0,0,235,232,1,\n        0,0,0,236,70,1,0,0,0,237,238,5,105,0,0,238,242,5,102,0,0,239,240,\n        5,73,0,0,240,242,5,70,0,0,241,237,1,0,0,0,241,239,1,0,0,0,242,72,\n        1,0,0,0,243,244,5,105,0,0,244,245,5,110,0,0,245,250,5,116,0,0,246,\n        247,5,73,0,0,247,248,5,78,0,0,248,250,5,84,0,0,249,243,1,0,0,0,249,\n        246,1,0,0,0,250,74,1,0,0,0,251,252,5,101,0,0,252,253,5,108,0,0,253,\n        254,5,115,0,0,254,260,5,101,0,0,255,256,5,69,0,0,256,257,5,76,0,\n        0,257,258,5,83,0,0,258,260,5,69,0,0,259,251,1,0,0,0,259,255,1,0,\n        0,0,260,76,1,0,0,0,261,262,5,102,0,0,262,263,5,117,0,0,263,264,5,\n        110,0,0,264,270,5,99,0,0,265,266,5,70,0,0,266,267,5,85,0,0,267,268,\n        5,78,0,0,268,270,5,67,0,0,269,261,1,0,0,0,269,265,1,0,0,0,270,78,\n        1,0,0,0,271,272,5,115,0,0,272,273,5,116,0,0,273,274,5,114,0,0,274,\n        275,5,105,0,0,275,276,5,110,0,0,276,284,5,103,0,0,277,278,5,83,0,\n        0,278,279,5,84,0,0,279,280,5,82,0,0,280,281,5,73,0,0,281,282,5,78,\n        0,0,282,284,5,71,0,0,283,271,1,0,0,0,283,277,1,0,0,0,284,80,1,0,\n        0,0,285,286,5,99,0,0,286,287,5,108,0,0,287,288,5,97,0,0,288,289,\n        5,115,0,0,289,296,5,115,0,0,290,291,5,67,0,0,291,292,5,76,0,0,292,\n        293,5,65,0,0,293,294,5,83,0,0,294,296,5,83,0,0,295,285,1,0,0,0,295,\n        290,1,0,0,0,296,82,1,0,0,0,297,298,5,118,0,0,298,299,5,111,0,0,299,\n        300,5,105,0,0,300,306,5,100,0,0,301,302,5,86,0,0,302,303,5,79,0,\n        0,303,304,5,73,0,0,304,306,5,68,0,0,305,297,1,0,0,0,305,301,1,0,\n        0,0,306,84,1,0,0,0,307,308,5,114,0,0,308,309,5,101,0,0,309,310,5,\n        116,0,0,310,311,5,117,0,0,311,312,5,114,0,0,312,320,5,110,0,0,313,\n        314,5,82,0,0,314,315,5,69,0,0,315,316,5,84,0,0,316,317,5,85,0,0,\n        317,318,5,82,0,0,318,320,5,78,0,0,319,307,1,0,0,0,319,313,1,0,0,\n        0,320,86,1,0,0,0,321,322,5,102,0,0,322,323,5,108,0,0,323,324,5,111,\n        0,0,324,325,5,97,0,0,325,332,5,116,0,0,326,327,5,70,0,0,327,328,\n        5,76,0,0,328,329,5,79,0,0,329,330,5,65,0,0,330,332,5,84,0,0,331,\n        321,1,0,0,0,331,326,1,0,0,0,332,88,1,0,0,0,333,334,5,112,0,0,334,\n        335,5,114,0,0,335,336,5,111,0,0,336,337,5,116,0,0,337,338,5,111,\n        0,0,338,339,5,116,0,0,339,340,5,121,0,0,340,341,5,112,0,0,341,352,\n        5,101,0,0,342,343,5,80,0,0,343,344,5,82,0,0,344,345,5,79,0,0,345,\n        346,5,84,0,0,346,347,5,79,0,0,347,348,5,84,0,0,348,349,5,89,0,0,\n        349,350,5,80,0,0,350,352,5,69,0,0,351,333,1,0,0,0,351,342,1,0,0,\n        0,352,90,1,0,0,0,353,354,5,105,0,0,354,355,5,110,0,0,355,356,5,115,\n        0,0,356,357,5,116,0,0,357,358,5,97,0,0,358,359,5,110,0,0,359,360,\n        5,99,0,0,360,370,5,101,0,0,361,362,5,73,0,0,362,363,5,78,0,0,363,\n        364,5,83,0,0,364,365,5,84,0,0,365,366,5,65,0,0,366,367,5,78,0,0,\n        367,368,5,67,0,0,368,370,5,69,0,0,369,353,1,0,0,0,369,361,1,0,0,\n        0,370,92,1,0,0,0,371,372,5,110,0,0,372,373,5,117,0,0,373,374,5,108,\n        0,0,374,384,5,108,0,0,375,376,5,78,0,0,376,377,5,117,0,0,377,378,\n        5,108,0,0,378,384,5,108,0,0,379,380,5,78,0,0,380,381,5,85,0,0,381,\n        382,5,76,0,0,382,384,5,76,0,0,383,371,1,0,0,0,383,375,1,0,0,0,383,\n        379,1,0,0,0,384,94,1,0,0,0,385,386,5,110,0,0,386,387,5,111,0,0,387,\n        388,5,102,0,0,388,389,5,117,0,0,389,390,5,110,0,0,390,404,5,99,0,\n        0,391,392,5,78,0,0,392,393,5,111,0,0,393,394,5,70,0,0,394,395,5,\n        117,0,0,395,396,5,110,0,0,396,404,5,99,0,0,397,398,5,78,0,0,398,\n        399,5,79,0,0,399,400,5,70,0,0,400,401,5,85,0,0,401,402,5,78,0,0,\n        402,404,5,67,0,0,403,385,1,0,0,0,403,391,1,0,0,0,403,397,1,0,0,0,\n        404,96,1,0,0,0,405,406,5,119,0,0,406,407,5,104,0,0,407,408,5,105,\n        0,0,408,409,5,108,0,0,409,410,5,101,0,0,410,98,1,0,0,0,411,412,5,\n        98,0,0,412,413,5,114,0,0,413,414,5,101,0,0,414,415,5,97,0,0,415,\n        416,5,107,0,0,416,100,1,0,0,0,417,418,5,99,0,0,418,419,5,111,0,0,\n        419,420,5,110,0,0,420,421,5,116,0,0,421,422,5,105,0,0,422,423,5,\n        110,0,0,423,424,5,117,0,0,424,425,5,101,0,0,425,102,1,0,0,0,426,\n        427,5,101,0,0,427,428,5,120,0,0,428,429,5,116,0,0,429,430,5,101,\n        0,0,430,431,5,114,0,0,431,432,5,110,0,0,432,104,1,0,0,0,433,437,\n        3,123,61,0,434,436,3,125,62,0,435,434,1,0,0,0,436,439,1,0,0,0,437,\n        435,1,0,0,0,437,438,1,0,0,0,438,106,1,0,0,0,439,437,1,0,0,0,440,\n        442,3,131,65,0,441,440,1,0,0,0,442,443,1,0,0,0,443,441,1,0,0,0,443,\n        444,1,0,0,0,444,108,1,0,0,0,445,448,3,133,66,0,446,448,3,135,67,\n        0,447,445,1,0,0,0,447,446,1,0,0,0,448,110,1,0,0,0,449,458,5,34,0,\n        0,450,457,8,0,0,0,451,454,5,92,0,0,452,455,9,0,0,0,453,455,5,0,0,\n        1,454,452,1,0,0,0,454,453,1,0,0,0,455,457,1,0,0,0,456,450,1,0,0,\n        0,456,451,1,0,0,0,457,460,1,0,0,0,458,456,1,0,0,0,458,459,1,0,0,\n        0,459,461,1,0,0,0,460,458,1,0,0,0,461,462,5,34,0,0,462,112,1,0,0,\n        0,463,465,7,1,0,0,464,463,1,0,0,0,465,466,1,0,0,0,466,464,1,0,0,\n        0,466,467,1,0,0,0,467,468,1,0,0,0,468,469,6,56,0,0,469,114,1,0,0,\n        0,470,472,5,13,0,0,471,473,5,10,0,0,472,471,1,0,0,0,472,473,1,0,\n        0,0,473,476,1,0,0,0,474,476,5,10,0,0,475,470,1,0,0,0,475,474,1,0,\n        0,0,476,477,1,0,0,0,477,478,6,57,0,0,478,116,1,0,0,0,479,480,5,47,\n        0,0,480,481,5,42,0,0,481,485,1,0,0,0,482,484,9,0,0,0,483,482,1,0,\n        0,0,484,487,1,0,0,0,485,486,1,0,0,0,485,483,1,0,0,0,486,488,1,0,\n        0,0,487,485,1,0,0,0,488,489,5,42,0,0,489,490,5,47,0,0,490,491,1,\n        0,0,0,491,492,6,58,0,0,492,118,1,0,0,0,493,494,5,47,0,0,494,495,\n        5,47,0,0,495,499,1,0,0,0,496,498,8,2,0,0,497,496,1,0,0,0,498,501,\n        1,0,0,0,499,497,1,0,0,0,499,500,1,0,0,0,500,502,1,0,0,0,501,499,\n        1,0,0,0,502,503,6,59,0,0,503,120,1,0,0,0,504,505,9,0,0,0,505,122,\n        1,0,0,0,506,509,3,129,64,0,507,509,7,3,0,0,508,506,1,0,0,0,508,507,\n        1,0,0,0,509,124,1,0,0,0,510,514,3,123,61,0,511,514,3,131,65,0,512,\n        514,3,127,63,0,513,510,1,0,0,0,513,511,1,0,0,0,513,512,1,0,0,0,514,\n        126,1,0,0,0,515,516,7,4,0,0,516,128,1,0,0,0,517,518,7,5,0,0,518,\n        130,1,0,0,0,519,520,7,6,0,0,520,132,1,0,0,0,521,523,3,131,65,0,522,\n        521,1,0,0,0,523,526,1,0,0,0,524,522,1,0,0,0,524,525,1,0,0,0,525,\n        527,1,0,0,0,526,524,1,0,0,0,527,529,5,46,0,0,528,530,3,131,65,0,\n        529,528,1,0,0,0,530,531,1,0,0,0,531,529,1,0,0,0,531,532,1,0,0,0,\n        532,541,1,0,0,0,533,535,3,131,65,0,534,533,1,0,0,0,535,536,1,0,0,\n        0,536,534,1,0,0,0,536,537,1,0,0,0,537,538,1,0,0,0,538,539,5,46,0,\n        0,539,541,1,0,0,0,540,524,1,0,0,0,540,534,1,0,0,0,541,134,1,0,0,\n        0,542,544,3,131,65,0,543,542,1,0,0,0,544,545,1,0,0,0,545,543,1,0,\n        0,0,545,546,1,0,0,0,546,549,1,0,0,0,547,549,3,133,66,0,548,543,1,\n        0,0,0,548,547,1,0,0,0,549,550,1,0,0,0,550,551,3,137,68,0,551,136,\n        1,0,0,0,552,554,7,7,0,0,553,555,7,8,0,0,554,553,1,0,0,0,554,555,\n        1,0,0,0,555,557,1,0,0,0,556,558,3,131,65,0,557,556,1,0,0,0,558,559,\n        1,0,0,0,559,557,1,0,0,0,559,560,1,0,0,0,560,138,1,0,0,0,37,0,227,\n        235,241,249,259,269,283,295,305,319,331,351,369,383,403,437,443,\n        447,454,456,458,466,472,475,485,499,508,513,524,531,536,540,545,\n        548,554,559,1,6,0,0\n    ];\n\n    private static __ATN: antlr.ATN;\n    public static get _ATN(): antlr.ATN {\n        if (!DaedalusLexer.__ATN) {\n            DaedalusLexer.__ATN = new antlr.ATNDeserializer().deserialize(DaedalusLexer._serializedATN);\n        }\n\n        return DaedalusLexer.__ATN;\n    }\n\n\n    private static readonly vocabulary = new antlr.Vocabulary(DaedalusLexer.literalNames, DaedalusLexer.symbolicNames, []);\n\n    public override get vocabulary(): antlr.Vocabulary {\n        return DaedalusLexer.vocabulary;\n    }\n\n    private static readonly decisionsToDFA = DaedalusLexer._ATN.decisionToState.map( (ds: antlr.DecisionState, index: number) => new antlr.DFA(ds, index) );\n}","// Generated from ./g4/Daedalus.g4 by ANTLR 4.13.1\n\nimport * as antlr from \"antlr4ng\";\nimport { Token } from \"antlr4ng\";\n\nimport { DaedalusVisitor } from \"./DaedalusVisitor.js\";\n\n// for running tests with parameters, TODO: discuss strategy for typed parameters in CI\n// eslint-disable-next-line no-unused-vars\ntype int = number;\n\n\nexport class DaedalusParser extends antlr.Parser {\n    public static readonly T__0 = 1;\n    public static readonly T__1 = 2;\n    public static readonly T__2 = 3;\n    public static readonly T__3 = 4;\n    public static readonly T__4 = 5;\n    public static readonly T__5 = 6;\n    public static readonly T__6 = 7;\n    public static readonly T__7 = 8;\n    public static readonly T__8 = 9;\n    public static readonly T__9 = 10;\n    public static readonly T__10 = 11;\n    public static readonly T__11 = 12;\n    public static readonly T__12 = 13;\n    public static readonly T__13 = 14;\n    public static readonly T__14 = 15;\n    public static readonly T__15 = 16;\n    public static readonly T__16 = 17;\n    public static readonly T__17 = 18;\n    public static readonly T__18 = 19;\n    public static readonly T__19 = 20;\n    public static readonly T__20 = 21;\n    public static readonly T__21 = 22;\n    public static readonly T__22 = 23;\n    public static readonly T__23 = 24;\n    public static readonly T__24 = 25;\n    public static readonly T__25 = 26;\n    public static readonly T__26 = 27;\n    public static readonly T__27 = 28;\n    public static readonly T__28 = 29;\n    public static readonly T__29 = 30;\n    public static readonly T__30 = 31;\n    public static readonly T__31 = 32;\n    public static readonly T__32 = 33;\n    public static readonly Const = 34;\n    public static readonly Var = 35;\n    public static readonly If = 36;\n    public static readonly Int = 37;\n    public static readonly Else = 38;\n    public static readonly Func = 39;\n    public static readonly String = 40;\n    public static readonly Class = 41;\n    public static readonly Void = 42;\n    public static readonly Return = 43;\n    public static readonly Float = 44;\n    public static readonly Prototype = 45;\n    public static readonly Instance = 46;\n    public static readonly Null = 47;\n    public static readonly NoFunc = 48;\n    public static readonly While = 49;\n    public static readonly Break = 50;\n    public static readonly Continue = 51;\n    public static readonly Extern = 52;\n    public static readonly Identifier = 53;\n    public static readonly IntegerLiteral = 54;\n    public static readonly FloatLiteral = 55;\n    public static readonly StringLiteral = 56;\n    public static readonly Whitespace = 57;\n    public static readonly Newline = 58;\n    public static readonly BlockComment = 59;\n    public static readonly LineComment = 60;\n    public static readonly UnexpectedCharacter = 61;\n    public static readonly RULE_daedalusFile = 0;\n    public static readonly RULE_blockDef = 1;\n    public static readonly RULE_inlineDef = 2;\n    public static readonly RULE_externFunctionDecl = 3;\n    public static readonly RULE_functionDef = 4;\n    public static readonly RULE_constDef = 5;\n    public static readonly RULE_classDef = 6;\n    public static readonly RULE_prototypeDef = 7;\n    public static readonly RULE_instanceDef = 8;\n    public static readonly RULE_instanceDecl = 9;\n    public static readonly RULE_varDecl = 10;\n    public static readonly RULE_constArrayDef = 11;\n    public static readonly RULE_constArrayAssignment = 12;\n    public static readonly RULE_constValueDef = 13;\n    public static readonly RULE_constValueAssignment = 14;\n    public static readonly RULE_varArrayDecl = 15;\n    public static readonly RULE_varArrayAssignment = 16;\n    public static readonly RULE_varValueDecl = 17;\n    public static readonly RULE_varValueAssignment = 18;\n    public static readonly RULE_parameterList = 19;\n    public static readonly RULE_parameterDecl = 20;\n    public static readonly RULE_statementBlock = 21;\n    public static readonly RULE_statement = 22;\n    public static readonly RULE_functionCall = 23;\n    public static readonly RULE_assignment = 24;\n    public static readonly RULE_elseBlock = 25;\n    public static readonly RULE_elseIfBlock = 26;\n    public static readonly RULE_ifBlock = 27;\n    public static readonly RULE_ifBlockStatement = 28;\n    public static readonly RULE_returnStatement = 29;\n    public static readonly RULE_whileStatement = 30;\n    public static readonly RULE_breakStatement = 31;\n    public static readonly RULE_continueStatement = 32;\n    public static readonly RULE_expression = 33;\n    public static readonly RULE_arrayIndex = 34;\n    public static readonly RULE_arraySize = 35;\n    public static readonly RULE_value = 36;\n    public static readonly RULE_referenceAtom = 37;\n    public static readonly RULE_reference = 38;\n    public static readonly RULE_dataType = 39;\n    public static readonly RULE_nameNode = 40;\n    public static readonly RULE_parentReference = 41;\n    public static readonly RULE_assignmentOperator = 42;\n    public static readonly RULE_addOperator = 43;\n    public static readonly RULE_bitMoveOperator = 44;\n    public static readonly RULE_compOperator = 45;\n    public static readonly RULE_eqOperator = 46;\n    public static readonly RULE_unaryOperator = 47;\n    public static readonly RULE_multOperator = 48;\n    public static readonly RULE_binAndOperator = 49;\n    public static readonly RULE_binOrOperator = 50;\n    public static readonly RULE_logAndOperator = 51;\n    public static readonly RULE_logOrOperator = 52;\n\n    public static readonly literalNames = [\n        null, \"';'\", \"','\", \"'{'\", \"'}'\", \"'('\", \"')'\", \"'['\", \"']'\", \"'='\", \n        \"'.'\", \"'+='\", \"'-='\", \"'*='\", \"'/='\", \"'+'\", \"'-'\", \"'<<'\", \"'>>'\", \n        \"'<'\", \"'>'\", \"'<='\", \"'>='\", \"'=='\", \"'!='\", \"'!'\", \"'~'\", \"'*'\", \n        \"'/'\", \"'%'\", \"'&'\", \"'|'\", \"'&&'\", \"'||'\", null, null, null, null, \n        null, null, null, null, null, null, null, null, null, null, null, \n        \"'while'\", \"'break'\", \"'continue'\", \"'extern'\"\n    ];\n\n    public static readonly symbolicNames = [\n        null, null, null, null, null, null, null, null, null, null, null, \n        null, null, null, null, null, null, null, null, null, null, null, \n        null, null, null, null, null, null, null, null, null, null, null, \n        null, \"Const\", \"Var\", \"If\", \"Int\", \"Else\", \"Func\", \"String\", \"Class\", \n        \"Void\", \"Return\", \"Float\", \"Prototype\", \"Instance\", \"Null\", \"NoFunc\", \n        \"While\", \"Break\", \"Continue\", \"Extern\", \"Identifier\", \"IntegerLiteral\", \n        \"FloatLiteral\", \"StringLiteral\", \"Whitespace\", \"Newline\", \"BlockComment\", \n        \"LineComment\", \"UnexpectedCharacter\"\n    ];\n    public static readonly ruleNames = [\n        \"daedalusFile\", \"blockDef\", \"inlineDef\", \"externFunctionDecl\", \"functionDef\", \n        \"constDef\", \"classDef\", \"prototypeDef\", \"instanceDef\", \"instanceDecl\", \n        \"varDecl\", \"constArrayDef\", \"constArrayAssignment\", \"constValueDef\", \n        \"constValueAssignment\", \"varArrayDecl\", \"varArrayAssignment\", \"varValueDecl\", \n        \"varValueAssignment\", \"parameterList\", \"parameterDecl\", \"statementBlock\", \n        \"statement\", \"functionCall\", \"assignment\", \"elseBlock\", \"elseIfBlock\", \n        \"ifBlock\", \"ifBlockStatement\", \"returnStatement\", \"whileStatement\", \n        \"breakStatement\", \"continueStatement\", \"expression\", \"arrayIndex\", \n        \"arraySize\", \"value\", \"referenceAtom\", \"reference\", \"dataType\", \n        \"nameNode\", \"parentReference\", \"assignmentOperator\", \"addOperator\", \n        \"bitMoveOperator\", \"compOperator\", \"eqOperator\", \"unaryOperator\", \n        \"multOperator\", \"binAndOperator\", \"binOrOperator\", \"logAndOperator\", \n        \"logOrOperator\",\n    ];\n\n    public get grammarFileName(): string { return \"Daedalus.g4\"; }\n    public get literalNames(): (string | null)[] { return DaedalusParser.literalNames; }\n    public get symbolicNames(): (string | null)[] { return DaedalusParser.symbolicNames; }\n    public get ruleNames(): string[] { return DaedalusParser.ruleNames; }\n    public get serializedATN(): number[] { return DaedalusParser._serializedATN; }\n\n    protected createFailedPredicateException(predicate?: string, message?: string): antlr.FailedPredicateException {\n        return new antlr.FailedPredicateException(this, predicate, message);\n    }\n\n    public constructor(input: antlr.TokenStream) {\n        super(input);\n        this.interpreter = new antlr.ParserATNSimulator(this, DaedalusParser._ATN, DaedalusParser.decisionsToDFA, new antlr.PredictionContextCache());\n    }\n    public daedalusFile(): DaedalusFileContext {\n        let localContext = new DaedalusFileContext(this.context, this.state);\n        this.enterRule(localContext, 0, DaedalusParser.RULE_daedalusFile);\n        try {\n            let alternative: number;\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 110;\n            this.errorHandler.sync(this);\n            alternative = this.interpreter.adaptivePredict(this.tokenStream, 1, this.context);\n            while (alternative !== 1 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {\n                if (alternative === 1 + 1) {\n                    {\n                    this.state = 108;\n                    this.errorHandler.sync(this);\n                    switch (this.interpreter.adaptivePredict(this.tokenStream, 0, this.context) ) {\n                    case 1:\n                        {\n                        this.state = 106;\n                        this.blockDef();\n                        }\n                        break;\n                    case 2:\n                        {\n                        this.state = 107;\n                        this.inlineDef();\n                        }\n                        break;\n                    }\n                    }\n                }\n                this.state = 112;\n                this.errorHandler.sync(this);\n                alternative = this.interpreter.adaptivePredict(this.tokenStream, 1, this.context);\n            }\n            this.state = 113;\n            this.match(DaedalusParser.EOF);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public blockDef(): BlockDefContext {\n        let localContext = new BlockDefContext(this.context, this.state);\n        this.enterRule(localContext, 2, DaedalusParser.RULE_blockDef);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 119;\n            this.errorHandler.sync(this);\n            switch (this.tokenStream.LA(1)) {\n            case DaedalusParser.Func:\n                {\n                this.state = 115;\n                this.functionDef();\n                }\n                break;\n            case DaedalusParser.Class:\n                {\n                this.state = 116;\n                this.classDef();\n                }\n                break;\n            case DaedalusParser.Prototype:\n                {\n                this.state = 117;\n                this.prototypeDef();\n                }\n                break;\n            case DaedalusParser.Instance:\n                {\n                this.state = 118;\n                this.instanceDef();\n                }\n                break;\n            default:\n                throw new antlr.NoViableAltException(this);\n            }\n            this.state = 122;\n            this.errorHandler.sync(this);\n            _la = this.tokenStream.LA(1);\n            if (_la === 1) {\n                {\n                this.state = 121;\n                this.match(DaedalusParser.T__0);\n                }\n            }\n\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public inlineDef(): InlineDefContext {\n        let localContext = new InlineDefContext(this.context, this.state);\n        this.enterRule(localContext, 4, DaedalusParser.RULE_inlineDef);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 128;\n            this.errorHandler.sync(this);\n            switch (this.tokenStream.LA(1)) {\n            case DaedalusParser.Extern:\n                {\n                this.state = 124;\n                this.externFunctionDecl();\n                }\n                break;\n            case DaedalusParser.Const:\n                {\n                this.state = 125;\n                this.constDef();\n                }\n                break;\n            case DaedalusParser.Var:\n                {\n                this.state = 126;\n                this.varDecl();\n                }\n                break;\n            case DaedalusParser.Instance:\n                {\n                this.state = 127;\n                this.instanceDecl();\n                }\n                break;\n            default:\n                throw new antlr.NoViableAltException(this);\n            }\n            this.state = 130;\n            this.match(DaedalusParser.T__0);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public externFunctionDecl(): ExternFunctionDeclContext {\n        let localContext = new ExternFunctionDeclContext(this.context, this.state);\n        this.enterRule(localContext, 6, DaedalusParser.RULE_externFunctionDecl);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 132;\n            this.match(DaedalusParser.Extern);\n            this.state = 133;\n            this.match(DaedalusParser.Func);\n            this.state = 134;\n            this.dataType();\n            this.state = 135;\n            this.nameNode();\n            this.state = 136;\n            this.parameterList();\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public functionDef(): FunctionDefContext {\n        let localContext = new FunctionDefContext(this.context, this.state);\n        this.enterRule(localContext, 8, DaedalusParser.RULE_functionDef);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 138;\n            this.match(DaedalusParser.Func);\n            this.state = 139;\n            this.dataType();\n            this.state = 140;\n            this.nameNode();\n            this.state = 141;\n            this.parameterList();\n            this.state = 142;\n            this.statementBlock();\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public constDef(): ConstDefContext {\n        let localContext = new ConstDefContext(this.context, this.state);\n        this.enterRule(localContext, 10, DaedalusParser.RULE_constDef);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 144;\n            this.match(DaedalusParser.Const);\n            this.state = 145;\n            this.dataType();\n            this.state = 148;\n            this.errorHandler.sync(this);\n            switch (this.interpreter.adaptivePredict(this.tokenStream, 5, this.context) ) {\n            case 1:\n                {\n                this.state = 146;\n                this.constValueDef();\n                }\n                break;\n            case 2:\n                {\n                this.state = 147;\n                this.constArrayDef();\n                }\n                break;\n            }\n            this.state = 157;\n            this.errorHandler.sync(this);\n            _la = this.tokenStream.LA(1);\n            while (_la === 2) {\n                {\n                {\n                this.state = 150;\n                this.match(DaedalusParser.T__1);\n                this.state = 153;\n                this.errorHandler.sync(this);\n                switch (this.interpreter.adaptivePredict(this.tokenStream, 6, this.context) ) {\n                case 1:\n                    {\n                    this.state = 151;\n                    this.constValueDef();\n                    }\n                    break;\n                case 2:\n                    {\n                    this.state = 152;\n                    this.constArrayDef();\n                    }\n                    break;\n                }\n                }\n                }\n                this.state = 159;\n                this.errorHandler.sync(this);\n                _la = this.tokenStream.LA(1);\n            }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public classDef(): ClassDefContext {\n        let localContext = new ClassDefContext(this.context, this.state);\n        this.enterRule(localContext, 12, DaedalusParser.RULE_classDef);\n        try {\n            let alternative: number;\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 160;\n            this.match(DaedalusParser.Class);\n            this.state = 161;\n            this.nameNode();\n            this.state = 162;\n            this.match(DaedalusParser.T__2);\n            this.state = 168;\n            this.errorHandler.sync(this);\n            alternative = this.interpreter.adaptivePredict(this.tokenStream, 8, this.context);\n            while (alternative !== 1 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {\n                if (alternative === 1 + 1) {\n                    {\n                    {\n                    this.state = 163;\n                    this.varDecl();\n                    this.state = 164;\n                    this.match(DaedalusParser.T__0);\n                    }\n                    }\n                }\n                this.state = 170;\n                this.errorHandler.sync(this);\n                alternative = this.interpreter.adaptivePredict(this.tokenStream, 8, this.context);\n            }\n            this.state = 171;\n            this.match(DaedalusParser.T__3);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public prototypeDef(): PrototypeDefContext {\n        let localContext = new PrototypeDefContext(this.context, this.state);\n        this.enterRule(localContext, 14, DaedalusParser.RULE_prototypeDef);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 173;\n            this.match(DaedalusParser.Prototype);\n            this.state = 174;\n            this.nameNode();\n            this.state = 175;\n            this.match(DaedalusParser.T__4);\n            this.state = 176;\n            this.parentReference();\n            this.state = 177;\n            this.match(DaedalusParser.T__5);\n            this.state = 178;\n            this.statementBlock();\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public instanceDef(): InstanceDefContext {\n        let localContext = new InstanceDefContext(this.context, this.state);\n        this.enterRule(localContext, 16, DaedalusParser.RULE_instanceDef);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 180;\n            this.match(DaedalusParser.Instance);\n            this.state = 181;\n            this.nameNode();\n            this.state = 182;\n            this.match(DaedalusParser.T__4);\n            this.state = 183;\n            this.parentReference();\n            this.state = 184;\n            this.match(DaedalusParser.T__5);\n            this.state = 185;\n            this.statementBlock();\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public instanceDecl(): InstanceDeclContext {\n        let localContext = new InstanceDeclContext(this.context, this.state);\n        this.enterRule(localContext, 18, DaedalusParser.RULE_instanceDecl);\n        try {\n            let alternative: number;\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 187;\n            this.match(DaedalusParser.Instance);\n            this.state = 188;\n            this.nameNode();\n            this.state = 193;\n            this.errorHandler.sync(this);\n            alternative = this.interpreter.adaptivePredict(this.tokenStream, 9, this.context);\n            while (alternative !== 1 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {\n                if (alternative === 1 + 1) {\n                    {\n                    {\n                    this.state = 189;\n                    this.match(DaedalusParser.T__1);\n                    this.state = 190;\n                    this.nameNode();\n                    }\n                    }\n                }\n                this.state = 195;\n                this.errorHandler.sync(this);\n                alternative = this.interpreter.adaptivePredict(this.tokenStream, 9, this.context);\n            }\n            this.state = 196;\n            this.match(DaedalusParser.T__4);\n            this.state = 197;\n            this.parentReference();\n            this.state = 198;\n            this.match(DaedalusParser.T__5);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public varDecl(): VarDeclContext {\n        let localContext = new VarDeclContext(this.context, this.state);\n        this.enterRule(localContext, 20, DaedalusParser.RULE_varDecl);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 200;\n            this.match(DaedalusParser.Var);\n            this.state = 201;\n            this.dataType();\n            this.state = 204;\n            this.errorHandler.sync(this);\n            switch (this.interpreter.adaptivePredict(this.tokenStream, 10, this.context) ) {\n            case 1:\n                {\n                this.state = 202;\n                this.varValueDecl();\n                }\n                break;\n            case 2:\n                {\n                this.state = 203;\n                this.varArrayDecl();\n                }\n                break;\n            }\n            this.state = 213;\n            this.errorHandler.sync(this);\n            _la = this.tokenStream.LA(1);\n            while (_la === 2) {\n                {\n                {\n                this.state = 206;\n                this.match(DaedalusParser.T__1);\n                this.state = 209;\n                this.errorHandler.sync(this);\n                switch (this.interpreter.adaptivePredict(this.tokenStream, 11, this.context) ) {\n                case 1:\n                    {\n                    this.state = 207;\n                    this.varValueDecl();\n                    }\n                    break;\n                case 2:\n                    {\n                    this.state = 208;\n                    this.varArrayDecl();\n                    }\n                    break;\n                }\n                }\n                }\n                this.state = 215;\n                this.errorHandler.sync(this);\n                _la = this.tokenStream.LA(1);\n            }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public constArrayDef(): ConstArrayDefContext {\n        let localContext = new ConstArrayDefContext(this.context, this.state);\n        this.enterRule(localContext, 22, DaedalusParser.RULE_constArrayDef);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 216;\n            this.nameNode();\n            this.state = 217;\n            this.match(DaedalusParser.T__6);\n            this.state = 218;\n            this.arraySize();\n            this.state = 219;\n            this.match(DaedalusParser.T__7);\n            this.state = 220;\n            this.constArrayAssignment();\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public constArrayAssignment(): ConstArrayAssignmentContext {\n        let localContext = new ConstArrayAssignmentContext(this.context, this.state);\n        this.enterRule(localContext, 24, DaedalusParser.RULE_constArrayAssignment);\n        try {\n            let alternative: number;\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 222;\n            this.match(DaedalusParser.T__8);\n            this.state = 223;\n            this.match(DaedalusParser.T__2);\n            {\n            this.state = 224;\n            this.expression(0);\n            this.state = 229;\n            this.errorHandler.sync(this);\n            alternative = this.interpreter.adaptivePredict(this.tokenStream, 13, this.context);\n            while (alternative !== 1 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {\n                if (alternative === 1 + 1) {\n                    {\n                    {\n                    this.state = 225;\n                    this.match(DaedalusParser.T__1);\n                    this.state = 226;\n                    this.expression(0);\n                    }\n                    }\n                }\n                this.state = 231;\n                this.errorHandler.sync(this);\n                alternative = this.interpreter.adaptivePredict(this.tokenStream, 13, this.context);\n            }\n            }\n            this.state = 232;\n            this.match(DaedalusParser.T__3);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public constValueDef(): ConstValueDefContext {\n        let localContext = new ConstValueDefContext(this.context, this.state);\n        this.enterRule(localContext, 26, DaedalusParser.RULE_constValueDef);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 234;\n            this.nameNode();\n            this.state = 235;\n            this.constValueAssignment();\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public constValueAssignment(): ConstValueAssignmentContext {\n        let localContext = new ConstValueAssignmentContext(this.context, this.state);\n        this.enterRule(localContext, 28, DaedalusParser.RULE_constValueAssignment);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 237;\n            this.match(DaedalusParser.T__8);\n            this.state = 238;\n            this.expression(0);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public varArrayDecl(): VarArrayDeclContext {\n        let localContext = new VarArrayDeclContext(this.context, this.state);\n        this.enterRule(localContext, 30, DaedalusParser.RULE_varArrayDecl);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 240;\n            this.nameNode();\n            this.state = 241;\n            this.match(DaedalusParser.T__6);\n            this.state = 242;\n            this.arraySize();\n            this.state = 243;\n            this.match(DaedalusParser.T__7);\n            this.state = 245;\n            this.errorHandler.sync(this);\n            _la = this.tokenStream.LA(1);\n            if (_la === 9) {\n                {\n                this.state = 244;\n                this.varArrayAssignment();\n                }\n            }\n\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public varArrayAssignment(): VarArrayAssignmentContext {\n        let localContext = new VarArrayAssignmentContext(this.context, this.state);\n        this.enterRule(localContext, 32, DaedalusParser.RULE_varArrayAssignment);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 247;\n            this.match(DaedalusParser.T__8);\n            this.state = 248;\n            this.match(DaedalusParser.T__2);\n            this.state = 249;\n            this.expression(0);\n            this.state = 254;\n            this.errorHandler.sync(this);\n            _la = this.tokenStream.LA(1);\n            while (_la === 2) {\n                {\n                {\n                this.state = 250;\n                this.match(DaedalusParser.T__1);\n                this.state = 251;\n                this.expression(0);\n                }\n                }\n                this.state = 256;\n                this.errorHandler.sync(this);\n                _la = this.tokenStream.LA(1);\n            }\n            this.state = 257;\n            this.match(DaedalusParser.T__3);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public varValueDecl(): VarValueDeclContext {\n        let localContext = new VarValueDeclContext(this.context, this.state);\n        this.enterRule(localContext, 34, DaedalusParser.RULE_varValueDecl);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 259;\n            this.nameNode();\n            this.state = 261;\n            this.errorHandler.sync(this);\n            _la = this.tokenStream.LA(1);\n            if (_la === 9) {\n                {\n                this.state = 260;\n                this.varValueAssignment();\n                }\n            }\n\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public varValueAssignment(): VarValueAssignmentContext {\n        let localContext = new VarValueAssignmentContext(this.context, this.state);\n        this.enterRule(localContext, 36, DaedalusParser.RULE_varValueAssignment);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 263;\n            this.match(DaedalusParser.T__8);\n            this.state = 264;\n            this.expression(0);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public parameterList(): ParameterListContext {\n        let localContext = new ParameterListContext(this.context, this.state);\n        this.enterRule(localContext, 38, DaedalusParser.RULE_parameterList);\n        let _la: number;\n        try {\n            let alternative: number;\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 266;\n            this.match(DaedalusParser.T__4);\n            this.state = 275;\n            this.errorHandler.sync(this);\n            _la = this.tokenStream.LA(1);\n            if (_la === 35) {\n                {\n                this.state = 267;\n                this.parameterDecl();\n                this.state = 272;\n                this.errorHandler.sync(this);\n                alternative = this.interpreter.adaptivePredict(this.tokenStream, 17, this.context);\n                while (alternative !== 1 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {\n                    if (alternative === 1 + 1) {\n                        {\n                        {\n                        this.state = 268;\n                        this.match(DaedalusParser.T__1);\n                        this.state = 269;\n                        this.parameterDecl();\n                        }\n                        }\n                    }\n                    this.state = 274;\n                    this.errorHandler.sync(this);\n                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 17, this.context);\n                }\n                }\n            }\n\n            this.state = 277;\n            this.match(DaedalusParser.T__5);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public parameterDecl(): ParameterDeclContext {\n        let localContext = new ParameterDeclContext(this.context, this.state);\n        this.enterRule(localContext, 40, DaedalusParser.RULE_parameterDecl);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 279;\n            this.match(DaedalusParser.Var);\n            this.state = 280;\n            this.dataType();\n            this.state = 281;\n            this.nameNode();\n            this.state = 286;\n            this.errorHandler.sync(this);\n            _la = this.tokenStream.LA(1);\n            if (_la === 7) {\n                {\n                this.state = 282;\n                this.match(DaedalusParser.T__6);\n                this.state = 283;\n                this.arraySize();\n                this.state = 284;\n                this.match(DaedalusParser.T__7);\n                }\n            }\n\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public statementBlock(): StatementBlockContext {\n        let localContext = new StatementBlockContext(this.context, this.state);\n        this.enterRule(localContext, 42, DaedalusParser.RULE_statementBlock);\n        let _la: number;\n        try {\n            let alternative: number;\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 288;\n            this.match(DaedalusParser.T__2);\n            this.state = 303;\n            this.errorHandler.sync(this);\n            alternative = this.interpreter.adaptivePredict(this.tokenStream, 23, this.context);\n            while (alternative !== 1 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {\n                if (alternative === 1 + 1) {\n                    {\n                    {\n                    this.state = 299;\n                    this.errorHandler.sync(this);\n                    switch (this.interpreter.adaptivePredict(this.tokenStream, 22, this.context) ) {\n                    case 1:\n                        {\n                        {\n                        this.state = 289;\n                        this.statement();\n                        this.state = 290;\n                        this.match(DaedalusParser.T__0);\n                        }\n                        }\n                        break;\n                    case 2:\n                        {\n                        {\n                        this.state = 294;\n                        this.errorHandler.sync(this);\n                        switch (this.tokenStream.LA(1)) {\n                        case DaedalusParser.If:\n                            {\n                            this.state = 292;\n                            this.ifBlockStatement();\n                            }\n                            break;\n                        case DaedalusParser.While:\n                            {\n                            this.state = 293;\n                            this.whileStatement();\n                            }\n                            break;\n                        default:\n                            throw new antlr.NoViableAltException(this);\n                        }\n                        this.state = 297;\n                        this.errorHandler.sync(this);\n                        _la = this.tokenStream.LA(1);\n                        if (_la === 1) {\n                            {\n                            this.state = 296;\n                            this.match(DaedalusParser.T__0);\n                            }\n                        }\n\n                        }\n                        }\n                        break;\n                    }\n                    }\n                    }\n                }\n                this.state = 305;\n                this.errorHandler.sync(this);\n                alternative = this.interpreter.adaptivePredict(this.tokenStream, 23, this.context);\n            }\n            this.state = 306;\n            this.match(DaedalusParser.T__3);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public statement(): StatementContext {\n        let localContext = new StatementContext(this.context, this.state);\n        this.enterRule(localContext, 44, DaedalusParser.RULE_statement);\n        try {\n            this.state = 315;\n            this.errorHandler.sync(this);\n            switch (this.interpreter.adaptivePredict(this.tokenStream, 24, this.context) ) {\n            case 1:\n                this.enterOuterAlt(localContext, 1);\n                {\n                this.state = 308;\n                this.assignment();\n                }\n                break;\n            case 2:\n                this.enterOuterAlt(localContext, 2);\n                {\n                this.state = 309;\n                this.returnStatement();\n                }\n                break;\n            case 3:\n                this.enterOuterAlt(localContext, 3);\n                {\n                this.state = 310;\n                this.constDef();\n                }\n                break;\n            case 4:\n                this.enterOuterAlt(localContext, 4);\n                {\n                this.state = 311;\n                this.varDecl();\n                }\n                break;\n            case 5:\n                this.enterOuterAlt(localContext, 5);\n                {\n                this.state = 312;\n                this.breakStatement();\n                }\n                break;\n            case 6:\n                this.enterOuterAlt(localContext, 6);\n                {\n                this.state = 313;\n                this.continueStatement();\n                }\n                break;\n            case 7:\n                this.enterOuterAlt(localContext, 7);\n                {\n                this.state = 314;\n                this.expression(0);\n                }\n                break;\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public functionCall(): FunctionCallContext {\n        let localContext = new FunctionCallContext(this.context, this.state);\n        this.enterRule(localContext, 46, DaedalusParser.RULE_functionCall);\n        let _la: number;\n        try {\n            let alternative: number;\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 317;\n            this.nameNode();\n            this.state = 318;\n            this.match(DaedalusParser.T__4);\n            this.state = 327;\n            this.errorHandler.sync(this);\n            _la = this.tokenStream.LA(1);\n            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 100761632) !== 0) || ((((_la - 47)) & ~0x1F) === 0 && ((1 << (_la - 47)) & 991) !== 0)) {\n                {\n                this.state = 319;\n                this.expression(0);\n                this.state = 324;\n                this.errorHandler.sync(this);\n                alternative = this.interpreter.adaptivePredict(this.tokenStream, 25, this.context);\n                while (alternative !== 1 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {\n                    if (alternative === 1 + 1) {\n                        {\n                        {\n                        this.state = 320;\n                        this.match(DaedalusParser.T__1);\n                        this.state = 321;\n                        this.expression(0);\n                        }\n                        }\n                    }\n                    this.state = 326;\n                    this.errorHandler.sync(this);\n                    alternative = this.interpreter.adaptivePredict(this.tokenStream, 25, this.context);\n                }\n                }\n            }\n\n            this.state = 329;\n            this.match(DaedalusParser.T__5);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public assignment(): AssignmentContext {\n        let localContext = new AssignmentContext(this.context, this.state);\n        this.enterRule(localContext, 48, DaedalusParser.RULE_assignment);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 331;\n            this.reference();\n            this.state = 332;\n            this.assignmentOperator();\n            this.state = 333;\n            this.expression(0);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public elseBlock(): ElseBlockContext {\n        let localContext = new ElseBlockContext(this.context, this.state);\n        this.enterRule(localContext, 50, DaedalusParser.RULE_elseBlock);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 335;\n            this.match(DaedalusParser.Else);\n            this.state = 336;\n            this.statementBlock();\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public elseIfBlock(): ElseIfBlockContext {\n        let localContext = new ElseIfBlockContext(this.context, this.state);\n        this.enterRule(localContext, 52, DaedalusParser.RULE_elseIfBlock);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 338;\n            this.match(DaedalusParser.Else);\n            this.state = 339;\n            this.match(DaedalusParser.If);\n            this.state = 340;\n            this.expression(0);\n            this.state = 341;\n            this.statementBlock();\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public ifBlock(): IfBlockContext {\n        let localContext = new IfBlockContext(this.context, this.state);\n        this.enterRule(localContext, 54, DaedalusParser.RULE_ifBlock);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 343;\n            this.match(DaedalusParser.If);\n            this.state = 344;\n            this.expression(0);\n            this.state = 345;\n            this.statementBlock();\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public ifBlockStatement(): IfBlockStatementContext {\n        let localContext = new IfBlockStatementContext(this.context, this.state);\n        this.enterRule(localContext, 56, DaedalusParser.RULE_ifBlockStatement);\n        let _la: number;\n        try {\n            let alternative: number;\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 347;\n            this.ifBlock();\n            this.state = 351;\n            this.errorHandler.sync(this);\n            alternative = this.interpreter.adaptivePredict(this.tokenStream, 27, this.context);\n            while (alternative !== 1 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {\n                if (alternative === 1 + 1) {\n                    {\n                    {\n                    this.state = 348;\n                    this.elseIfBlock();\n                    }\n                    }\n                }\n                this.state = 353;\n                this.errorHandler.sync(this);\n                alternative = this.interpreter.adaptivePredict(this.tokenStream, 27, this.context);\n            }\n            this.state = 355;\n            this.errorHandler.sync(this);\n            _la = this.tokenStream.LA(1);\n            if (_la === 38) {\n                {\n                this.state = 354;\n                this.elseBlock();\n                }\n            }\n\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public returnStatement(): ReturnStatementContext {\n        let localContext = new ReturnStatementContext(this.context, this.state);\n        this.enterRule(localContext, 58, DaedalusParser.RULE_returnStatement);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 357;\n            this.match(DaedalusParser.Return);\n            this.state = 359;\n            this.errorHandler.sync(this);\n            _la = this.tokenStream.LA(1);\n            if ((((_la) & ~0x1F) === 0 && ((1 << _la) & 100761632) !== 0) || ((((_la - 47)) & ~0x1F) === 0 && ((1 << (_la - 47)) & 991) !== 0)) {\n                {\n                this.state = 358;\n                this.expression(0);\n                }\n            }\n\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public whileStatement(): WhileStatementContext {\n        let localContext = new WhileStatementContext(this.context, this.state);\n        this.enterRule(localContext, 60, DaedalusParser.RULE_whileStatement);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 361;\n            this.match(DaedalusParser.While);\n            this.state = 362;\n            this.match(DaedalusParser.T__4);\n            this.state = 363;\n            this.expression(0);\n            this.state = 364;\n            this.match(DaedalusParser.T__5);\n            this.state = 365;\n            this.statementBlock();\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public breakStatement(): BreakStatementContext {\n        let localContext = new BreakStatementContext(this.context, this.state);\n        this.enterRule(localContext, 62, DaedalusParser.RULE_breakStatement);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 367;\n            this.match(DaedalusParser.Break);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public continueStatement(): ContinueStatementContext {\n        let localContext = new ContinueStatementContext(this.context, this.state);\n        this.enterRule(localContext, 64, DaedalusParser.RULE_continueStatement);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 369;\n            this.match(DaedalusParser.Continue);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n\n    public expression(): ExpressionContext;\n    public expression(_p: number): ExpressionContext;\n    public expression(_p?: number): ExpressionContext {\n        if (_p === undefined) {\n            _p = 0;\n        }\n\n        let parentContext = this.context;\n        let parentState = this.state;\n        let localContext = new ExpressionContext(this.context, parentState);\n        let previousContext = localContext;\n        let _startState = 66;\n        this.enterRecursionRule(localContext, 66, DaedalusParser.RULE_expression, _p);\n        try {\n            let alternative: number;\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 380;\n            this.errorHandler.sync(this);\n            switch (this.tokenStream.LA(1)) {\n            case DaedalusParser.T__4:\n                {\n                localContext = new BracketExpressionContext(localContext);\n                this.context = localContext;\n                previousContext = localContext;\n\n                this.state = 372;\n                this.match(DaedalusParser.T__4);\n                this.state = 373;\n                this.expression(0);\n                this.state = 374;\n                this.match(DaedalusParser.T__5);\n                }\n                break;\n            case DaedalusParser.T__14:\n            case DaedalusParser.T__15:\n            case DaedalusParser.T__24:\n            case DaedalusParser.T__25:\n                {\n                localContext = new UnaryExpressionContext(localContext);\n                this.context = localContext;\n                previousContext = localContext;\n                {\n                this.state = 376;\n                (localContext as UnaryExpressionContext)._oper = this.unaryOperator();\n                }\n                this.state = 377;\n                this.expression(11);\n                }\n                break;\n            case DaedalusParser.Null:\n            case DaedalusParser.NoFunc:\n            case DaedalusParser.While:\n            case DaedalusParser.Break:\n            case DaedalusParser.Continue:\n            case DaedalusParser.Identifier:\n            case DaedalusParser.IntegerLiteral:\n            case DaedalusParser.FloatLiteral:\n            case DaedalusParser.StringLiteral:\n                {\n                localContext = new ValueExpressionContext(localContext);\n                this.context = localContext;\n                previousContext = localContext;\n                this.state = 379;\n                this.value();\n                }\n                break;\n            default:\n                throw new antlr.NoViableAltException(this);\n            }\n            this.context!.stop = this.tokenStream.LT(-1);\n            this.state = 420;\n            this.errorHandler.sync(this);\n            alternative = this.interpreter.adaptivePredict(this.tokenStream, 32, this.context);\n            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {\n                if (alternative === 1) {\n                    if (this.parseListeners != null) {\n                        this.triggerExitRuleEvent();\n                    }\n                    previousContext = localContext;\n                    {\n                    this.state = 418;\n                    this.errorHandler.sync(this);\n                    switch (this.interpreter.adaptivePredict(this.tokenStream, 31, this.context) ) {\n                    case 1:\n                        {\n                        localContext = new MultExpressionContext(new ExpressionContext(parentContext, parentState));\n                        this.pushNewRecursionContext(localContext, _startState, DaedalusParser.RULE_expression);\n                        this.state = 382;\n                        if (!(this.precpred(this.context, 10))) {\n                            throw this.createFailedPredicateException(\"this.precpred(this.context, 10)\");\n                        }\n                        {\n                        this.state = 383;\n                        (localContext as MultExpressionContext)._oper = this.multOperator();\n                        }\n                        this.state = 384;\n                        this.expression(11);\n                        }\n                        break;\n                    case 2:\n                        {\n                        localContext = new AddExpressionContext(new ExpressionContext(parentContext, parentState));\n                        this.pushNewRecursionContext(localContext, _startState, DaedalusParser.RULE_expression);\n                        this.state = 386;\n                        if (!(this.precpred(this.context, 9))) {\n                            throw this.createFailedPredicateException(\"this.precpred(this.context, 9)\");\n                        }\n                        {\n                        this.state = 387;\n                        (localContext as AddExpressionContext)._oper = this.addOperator();\n                        }\n                        this.state = 388;\n                        this.expression(10);\n                        }\n                        break;\n                    case 3:\n                        {\n                        localContext = new BitMoveExpressionContext(new ExpressionContext(parentContext, parentState));\n                        this.pushNewRecursionContext(localContext, _startState, DaedalusParser.RULE_expression);\n                        this.state = 390;\n                        if (!(this.precpred(this.context, 8))) {\n                            throw this.createFailedPredicateException(\"this.precpred(this.context, 8)\");\n                        }\n                        {\n                        this.state = 391;\n                        (localContext as BitMoveExpressionContext)._oper = this.bitMoveOperator();\n                        }\n                        this.state = 392;\n                        this.expression(9);\n                        }\n                        break;\n                    case 4:\n                        {\n                        localContext = new CompExpressionContext(new ExpressionContext(parentContext, parentState));\n                        this.pushNewRecursionContext(localContext, _startState, DaedalusParser.RULE_expression);\n                        this.state = 394;\n                        if (!(this.precpred(this.context, 7))) {\n                            throw this.createFailedPredicateException(\"this.precpred(this.context, 7)\");\n                        }\n                        {\n                        this.state = 395;\n                        (localContext as CompExpressionContext)._oper = this.compOperator();\n                        }\n                        this.state = 396;\n                        this.expression(8);\n                        }\n                        break;\n                    case 5:\n                        {\n                        localContext = new EqExpressionContext(new ExpressionContext(parentContext, parentState));\n                        this.pushNewRecursionContext(localContext, _startState, DaedalusParser.RULE_expression);\n                        this.state = 398;\n                        if (!(this.precpred(this.context, 6))) {\n                            throw this.createFailedPredicateException(\"this.precpred(this.context, 6)\");\n                        }\n                        {\n                        this.state = 399;\n                        (localContext as EqExpressionContext)._oper = this.eqOperator();\n                        }\n                        this.state = 400;\n                        this.expression(7);\n                        }\n                        break;\n                    case 6:\n                        {\n                        localContext = new BinAndExpressionContext(new ExpressionContext(parentContext, parentState));\n                        this.pushNewRecursionContext(localContext, _startState, DaedalusParser.RULE_expression);\n                        this.state = 402;\n                        if (!(this.precpred(this.context, 5))) {\n                            throw this.createFailedPredicateException(\"this.precpred(this.context, 5)\");\n                        }\n                        {\n                        this.state = 403;\n                        (localContext as BinAndExpressionContext)._oper = this.binAndOperator();\n                        }\n                        this.state = 404;\n                        this.expression(6);\n                        }\n                        break;\n                    case 7:\n                        {\n                        localContext = new BinOrExpressionContext(new ExpressionContext(parentContext, parentState));\n                        this.pushNewRecursionContext(localContext, _startState, DaedalusParser.RULE_expression);\n                        this.state = 406;\n                        if (!(this.precpred(this.context, 4))) {\n                            throw this.createFailedPredicateException(\"this.precpred(this.context, 4)\");\n                        }\n                        {\n                        this.state = 407;\n                        (localContext as BinOrExpressionContext)._oper = this.binOrOperator();\n                        }\n                        this.state = 408;\n                        this.expression(5);\n                        }\n                        break;\n                    case 8:\n                        {\n                        localContext = new LogAndExpressionContext(new ExpressionContext(parentContext, parentState));\n                        this.pushNewRecursionContext(localContext, _startState, DaedalusParser.RULE_expression);\n                        this.state = 410;\n                        if (!(this.precpred(this.context, 3))) {\n                            throw this.createFailedPredicateException(\"this.precpred(this.context, 3)\");\n                        }\n                        {\n                        this.state = 411;\n                        (localContext as LogAndExpressionContext)._oper = this.logAndOperator();\n                        }\n                        this.state = 412;\n                        this.expression(4);\n                        }\n                        break;\n                    case 9:\n                        {\n                        localContext = new LogOrExpressionContext(new ExpressionContext(parentContext, parentState));\n                        this.pushNewRecursionContext(localContext, _startState, DaedalusParser.RULE_expression);\n                        this.state = 414;\n                        if (!(this.precpred(this.context, 2))) {\n                            throw this.createFailedPredicateException(\"this.precpred(this.context, 2)\");\n                        }\n                        {\n                        this.state = 415;\n                        (localContext as LogOrExpressionContext)._oper = this.logOrOperator();\n                        }\n                        this.state = 416;\n                        this.expression(3);\n                        }\n                        break;\n                    }\n                    }\n                }\n                this.state = 422;\n                this.errorHandler.sync(this);\n                alternative = this.interpreter.adaptivePredict(this.tokenStream, 32, this.context);\n            }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.unrollRecursionContexts(parentContext);\n        }\n        return localContext;\n    }\n    public arrayIndex(): ArrayIndexContext {\n        let localContext = new ArrayIndexContext(this.context, this.state);\n        this.enterRule(localContext, 68, DaedalusParser.RULE_arrayIndex);\n        try {\n            this.state = 425;\n            this.errorHandler.sync(this);\n            switch (this.tokenStream.LA(1)) {\n            case DaedalusParser.IntegerLiteral:\n                this.enterOuterAlt(localContext, 1);\n                {\n                this.state = 423;\n                this.match(DaedalusParser.IntegerLiteral);\n                }\n                break;\n            case DaedalusParser.While:\n            case DaedalusParser.Break:\n            case DaedalusParser.Continue:\n            case DaedalusParser.Identifier:\n                this.enterOuterAlt(localContext, 2);\n                {\n                this.state = 424;\n                this.reference();\n                }\n                break;\n            default:\n                throw new antlr.NoViableAltException(this);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public arraySize(): ArraySizeContext {\n        let localContext = new ArraySizeContext(this.context, this.state);\n        this.enterRule(localContext, 70, DaedalusParser.RULE_arraySize);\n        try {\n            this.state = 429;\n            this.errorHandler.sync(this);\n            switch (this.tokenStream.LA(1)) {\n            case DaedalusParser.IntegerLiteral:\n                this.enterOuterAlt(localContext, 1);\n                {\n                this.state = 427;\n                this.match(DaedalusParser.IntegerLiteral);\n                }\n                break;\n            case DaedalusParser.While:\n            case DaedalusParser.Break:\n            case DaedalusParser.Continue:\n            case DaedalusParser.Identifier:\n                this.enterOuterAlt(localContext, 2);\n                {\n                this.state = 428;\n                this.reference();\n                }\n                break;\n            default:\n                throw new antlr.NoViableAltException(this);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public value(): ValueContext {\n        let localContext = new ValueContext(this.context, this.state);\n        this.enterRule(localContext, 72, DaedalusParser.RULE_value);\n        try {\n            this.state = 438;\n            this.errorHandler.sync(this);\n            switch (this.interpreter.adaptivePredict(this.tokenStream, 35, this.context) ) {\n            case 1:\n                localContext = new IntegerLiteralValueContext(localContext);\n                this.enterOuterAlt(localContext, 1);\n                {\n                this.state = 431;\n                this.match(DaedalusParser.IntegerLiteral);\n                }\n                break;\n            case 2:\n                localContext = new FloatLiteralValueContext(localContext);\n                this.enterOuterAlt(localContext, 2);\n                {\n                this.state = 432;\n                this.match(DaedalusParser.FloatLiteral);\n                }\n                break;\n            case 3:\n                localContext = new StringLiteralValueContext(localContext);\n                this.enterOuterAlt(localContext, 3);\n                {\n                this.state = 433;\n                this.match(DaedalusParser.StringLiteral);\n                }\n                break;\n            case 4:\n                localContext = new NullLiteralValueContext(localContext);\n                this.enterOuterAlt(localContext, 4);\n                {\n                this.state = 434;\n                this.match(DaedalusParser.Null);\n                }\n                break;\n            case 5:\n                localContext = new NoFuncLiteralValueContext(localContext);\n                this.enterOuterAlt(localContext, 5);\n                {\n                this.state = 435;\n                this.match(DaedalusParser.NoFunc);\n                }\n                break;\n            case 6:\n                localContext = new FunctionCallValueContext(localContext);\n                this.enterOuterAlt(localContext, 6);\n                {\n                this.state = 436;\n                this.functionCall();\n                }\n                break;\n            case 7:\n                localContext = new ReferenceValueContext(localContext);\n                this.enterOuterAlt(localContext, 7);\n                {\n                this.state = 437;\n                this.reference();\n                }\n                break;\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public referenceAtom(): ReferenceAtomContext {\n        let localContext = new ReferenceAtomContext(this.context, this.state);\n        this.enterRule(localContext, 74, DaedalusParser.RULE_referenceAtom);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 440;\n            this.nameNode();\n            this.state = 445;\n            this.errorHandler.sync(this);\n            switch (this.interpreter.adaptivePredict(this.tokenStream, 36, this.context) ) {\n            case 1:\n                {\n                this.state = 441;\n                this.match(DaedalusParser.T__6);\n                this.state = 442;\n                this.arrayIndex();\n                this.state = 443;\n                this.match(DaedalusParser.T__7);\n                }\n                break;\n            }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public reference(): ReferenceContext {\n        let localContext = new ReferenceContext(this.context, this.state);\n        this.enterRule(localContext, 76, DaedalusParser.RULE_reference);\n        try {\n            let alternative: number;\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 447;\n            this.referenceAtom();\n            this.state = 452;\n            this.errorHandler.sync(this);\n            alternative = this.interpreter.adaptivePredict(this.tokenStream, 37, this.context);\n            while (alternative !== 2 && alternative !== antlr.ATN.INVALID_ALT_NUMBER) {\n                if (alternative === 1) {\n                    {\n                    {\n                    this.state = 448;\n                    this.match(DaedalusParser.T__9);\n                    this.state = 449;\n                    this.referenceAtom();\n                    }\n                    }\n                }\n                this.state = 454;\n                this.errorHandler.sync(this);\n                alternative = this.interpreter.adaptivePredict(this.tokenStream, 37, this.context);\n            }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public dataType(): DataTypeContext {\n        let localContext = new DataTypeContext(this.context, this.state);\n        this.enterRule(localContext, 78, DaedalusParser.RULE_dataType);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 455;\n            _la = this.tokenStream.LA(1);\n            if(!(((((_la - 37)) & ~0x1F) === 0 && ((1 << (_la - 37)) & 66221) !== 0))) {\n            this.errorHandler.recoverInline(this);\n            }\n            else {\n                this.errorHandler.reportMatch(this);\n                this.consume();\n            }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public nameNode(): NameNodeContext {\n        let localContext = new NameNodeContext(this.context, this.state);\n        this.enterRule(localContext, 80, DaedalusParser.RULE_nameNode);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 457;\n            _la = this.tokenStream.LA(1);\n            if(!(((((_la - 49)) & ~0x1F) === 0 && ((1 << (_la - 49)) & 23) !== 0))) {\n            this.errorHandler.recoverInline(this);\n            }\n            else {\n                this.errorHandler.reportMatch(this);\n                this.consume();\n            }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public parentReference(): ParentReferenceContext {\n        let localContext = new ParentReferenceContext(this.context, this.state);\n        this.enterRule(localContext, 82, DaedalusParser.RULE_parentReference);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 459;\n            this.match(DaedalusParser.Identifier);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public assignmentOperator(): AssignmentOperatorContext {\n        let localContext = new AssignmentOperatorContext(this.context, this.state);\n        this.enterRule(localContext, 84, DaedalusParser.RULE_assignmentOperator);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 461;\n            _la = this.tokenStream.LA(1);\n            if(!((((_la) & ~0x1F) === 0 && ((1 << _la) & 31232) !== 0))) {\n            this.errorHandler.recoverInline(this);\n            }\n            else {\n                this.errorHandler.reportMatch(this);\n                this.consume();\n            }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public addOperator(): AddOperatorContext {\n        let localContext = new AddOperatorContext(this.context, this.state);\n        this.enterRule(localContext, 86, DaedalusParser.RULE_addOperator);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 463;\n            _la = this.tokenStream.LA(1);\n            if(!(_la === 15 || _la === 16)) {\n            this.errorHandler.recoverInline(this);\n            }\n            else {\n                this.errorHandler.reportMatch(this);\n                this.consume();\n            }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public bitMoveOperator(): BitMoveOperatorContext {\n        let localContext = new BitMoveOperatorContext(this.context, this.state);\n        this.enterRule(localContext, 88, DaedalusParser.RULE_bitMoveOperator);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 465;\n            _la = this.tokenStream.LA(1);\n            if(!(_la === 17 || _la === 18)) {\n            this.errorHandler.recoverInline(this);\n            }\n            else {\n                this.errorHandler.reportMatch(this);\n                this.consume();\n            }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public compOperator(): CompOperatorContext {\n        let localContext = new CompOperatorContext(this.context, this.state);\n        this.enterRule(localContext, 90, DaedalusParser.RULE_compOperator);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 467;\n            _la = this.tokenStream.LA(1);\n            if(!((((_la) & ~0x1F) === 0 && ((1 << _la) & 7864320) !== 0))) {\n            this.errorHandler.recoverInline(this);\n            }\n            else {\n                this.errorHandler.reportMatch(this);\n                this.consume();\n            }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public eqOperator(): EqOperatorContext {\n        let localContext = new EqOperatorContext(this.context, this.state);\n        this.enterRule(localContext, 92, DaedalusParser.RULE_eqOperator);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 469;\n            _la = this.tokenStream.LA(1);\n            if(!(_la === 23 || _la === 24)) {\n            this.errorHandler.recoverInline(this);\n            }\n            else {\n                this.errorHandler.reportMatch(this);\n                this.consume();\n            }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public unaryOperator(): UnaryOperatorContext {\n        let localContext = new UnaryOperatorContext(this.context, this.state);\n        this.enterRule(localContext, 94, DaedalusParser.RULE_unaryOperator);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 471;\n            _la = this.tokenStream.LA(1);\n            if(!((((_la) & ~0x1F) === 0 && ((1 << _la) & 100761600) !== 0))) {\n            this.errorHandler.recoverInline(this);\n            }\n            else {\n                this.errorHandler.reportMatch(this);\n                this.consume();\n            }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public multOperator(): MultOperatorContext {\n        let localContext = new MultOperatorContext(this.context, this.state);\n        this.enterRule(localContext, 96, DaedalusParser.RULE_multOperator);\n        let _la: number;\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 473;\n            _la = this.tokenStream.LA(1);\n            if(!((((_la) & ~0x1F) === 0 && ((1 << _la) & 939524096) !== 0))) {\n            this.errorHandler.recoverInline(this);\n            }\n            else {\n                this.errorHandler.reportMatch(this);\n                this.consume();\n            }\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public binAndOperator(): BinAndOperatorContext {\n        let localContext = new BinAndOperatorContext(this.context, this.state);\n        this.enterRule(localContext, 98, DaedalusParser.RULE_binAndOperator);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 475;\n            this.match(DaedalusParser.T__29);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public binOrOperator(): BinOrOperatorContext {\n        let localContext = new BinOrOperatorContext(this.context, this.state);\n        this.enterRule(localContext, 100, DaedalusParser.RULE_binOrOperator);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 477;\n            this.match(DaedalusParser.T__30);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public logAndOperator(): LogAndOperatorContext {\n        let localContext = new LogAndOperatorContext(this.context, this.state);\n        this.enterRule(localContext, 102, DaedalusParser.RULE_logAndOperator);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 479;\n            this.match(DaedalusParser.T__31);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n    public logOrOperator(): LogOrOperatorContext {\n        let localContext = new LogOrOperatorContext(this.context, this.state);\n        this.enterRule(localContext, 104, DaedalusParser.RULE_logOrOperator);\n        try {\n            this.enterOuterAlt(localContext, 1);\n            {\n            this.state = 481;\n            this.match(DaedalusParser.T__32);\n            }\n        }\n        catch (re) {\n            if (re instanceof antlr.RecognitionException) {\n                this.errorHandler.reportError(this, re);\n                this.errorHandler.recover(this, re);\n            } else {\n                throw re;\n            }\n        }\n        finally {\n            this.exitRule();\n        }\n        return localContext;\n    }\n\n    public override sempred(localContext: antlr.ParserRuleContext | null, ruleIndex: number, predIndex: number): boolean {\n        switch (ruleIndex) {\n        case 33:\n            return this.expression_sempred(localContext as ExpressionContext, predIndex);\n        }\n        return true;\n    }\n    private expression_sempred(localContext: ExpressionContext | null, predIndex: number): boolean {\n        switch (predIndex) {\n        case 0:\n            return this.precpred(this.context, 10);\n        case 1:\n            return this.precpred(this.context, 9);\n        case 2:\n            return this.precpred(this.context, 8);\n        case 3:\n            return this.precpred(this.context, 7);\n        case 4:\n            return this.precpred(this.context, 6);\n        case 5:\n            return this.precpred(this.context, 5);\n        case 6:\n            return this.precpred(this.context, 4);\n        case 7:\n            return this.precpred(this.context, 3);\n        case 8:\n            return this.precpred(this.context, 2);\n        }\n        return true;\n    }\n\n    public static readonly _serializedATN: number[] = [\n        4,1,61,484,2,0,7,0,2,1,7,1,2,2,7,2,2,3,7,3,2,4,7,4,2,5,7,5,2,6,7,\n        6,2,7,7,7,2,8,7,8,2,9,7,9,2,10,7,10,2,11,7,11,2,12,7,12,2,13,7,13,\n        2,14,7,14,2,15,7,15,2,16,7,16,2,17,7,17,2,18,7,18,2,19,7,19,2,20,\n        7,20,2,21,7,21,2,22,7,22,2,23,7,23,2,24,7,24,2,25,7,25,2,26,7,26,\n        2,27,7,27,2,28,7,28,2,29,7,29,2,30,7,30,2,31,7,31,2,32,7,32,2,33,\n        7,33,2,34,7,34,2,35,7,35,2,36,7,36,2,37,7,37,2,38,7,38,2,39,7,39,\n        2,40,7,40,2,41,7,41,2,42,7,42,2,43,7,43,2,44,7,44,2,45,7,45,2,46,\n        7,46,2,47,7,47,2,48,7,48,2,49,7,49,2,50,7,50,2,51,7,51,2,52,7,52,\n        1,0,1,0,5,0,109,8,0,10,0,12,0,112,9,0,1,0,1,0,1,1,1,1,1,1,1,1,3,\n        1,120,8,1,1,1,3,1,123,8,1,1,2,1,2,1,2,1,2,3,2,129,8,2,1,2,1,2,1,\n        3,1,3,1,3,1,3,1,3,1,3,1,4,1,4,1,4,1,4,1,4,1,4,1,5,1,5,1,5,1,5,3,\n        5,149,8,5,1,5,1,5,1,5,3,5,154,8,5,5,5,156,8,5,10,5,12,5,159,9,5,\n        1,6,1,6,1,6,1,6,1,6,1,6,5,6,167,8,6,10,6,12,6,170,9,6,1,6,1,6,1,\n        7,1,7,1,7,1,7,1,7,1,7,1,7,1,8,1,8,1,8,1,8,1,8,1,8,1,8,1,9,1,9,1,\n        9,1,9,5,9,192,8,9,10,9,12,9,195,9,9,1,9,1,9,1,9,1,9,1,10,1,10,1,\n        10,1,10,3,10,205,8,10,1,10,1,10,1,10,3,10,210,8,10,5,10,212,8,10,\n        10,10,12,10,215,9,10,1,11,1,11,1,11,1,11,1,11,1,11,1,12,1,12,1,12,\n        1,12,1,12,5,12,228,8,12,10,12,12,12,231,9,12,1,12,1,12,1,13,1,13,\n        1,13,1,14,1,14,1,14,1,15,1,15,1,15,1,15,1,15,3,15,246,8,15,1,16,\n        1,16,1,16,1,16,1,16,5,16,253,8,16,10,16,12,16,256,9,16,1,16,1,16,\n        1,17,1,17,3,17,262,8,17,1,18,1,18,1,18,1,19,1,19,1,19,1,19,5,19,\n        271,8,19,10,19,12,19,274,9,19,3,19,276,8,19,1,19,1,19,1,20,1,20,\n        1,20,1,20,1,20,1,20,1,20,3,20,287,8,20,1,21,1,21,1,21,1,21,1,21,\n        1,21,3,21,295,8,21,1,21,3,21,298,8,21,3,21,300,8,21,5,21,302,8,21,\n        10,21,12,21,305,9,21,1,21,1,21,1,22,1,22,1,22,1,22,1,22,1,22,1,22,\n        3,22,316,8,22,1,23,1,23,1,23,1,23,1,23,5,23,323,8,23,10,23,12,23,\n        326,9,23,3,23,328,8,23,1,23,1,23,1,24,1,24,1,24,1,24,1,25,1,25,1,\n        25,1,26,1,26,1,26,1,26,1,26,1,27,1,27,1,27,1,27,1,28,1,28,5,28,350,\n        8,28,10,28,12,28,353,9,28,1,28,3,28,356,8,28,1,29,1,29,3,29,360,\n        8,29,1,30,1,30,1,30,1,30,1,30,1,30,1,31,1,31,1,32,1,32,1,33,1,33,\n        1,33,1,33,1,33,1,33,1,33,1,33,1,33,3,33,381,8,33,1,33,1,33,1,33,\n        1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,33,\n        1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,33,1,33,\n        1,33,1,33,1,33,1,33,1,33,1,33,1,33,5,33,419,8,33,10,33,12,33,422,\n        9,33,1,34,1,34,3,34,426,8,34,1,35,1,35,3,35,430,8,35,1,36,1,36,1,\n        36,1,36,1,36,1,36,1,36,3,36,439,8,36,1,37,1,37,1,37,1,37,1,37,3,\n        37,446,8,37,1,38,1,38,1,38,5,38,451,8,38,10,38,12,38,454,9,38,1,\n        39,1,39,1,40,1,40,1,41,1,41,1,42,1,42,1,43,1,43,1,44,1,44,1,45,1,\n        45,1,46,1,46,1,47,1,47,1,48,1,48,1,49,1,49,1,50,1,50,1,51,1,51,1,\n        52,1,52,1,52,8,110,168,193,229,272,303,324,351,1,66,53,0,2,4,6,8,\n        10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,\n        54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,84,86,88,90,92,94,96,\n        98,100,102,104,0,9,6,0,37,37,39,40,42,42,44,44,46,46,53,53,2,0,49,\n        51,53,53,2,0,9,9,11,14,1,0,15,16,1,0,17,18,1,0,19,22,1,0,23,24,2,\n        0,15,16,25,26,1,0,27,29,490,0,110,1,0,0,0,2,119,1,0,0,0,4,128,1,\n        0,0,0,6,132,1,0,0,0,8,138,1,0,0,0,10,144,1,0,0,0,12,160,1,0,0,0,\n        14,173,1,0,0,0,16,180,1,0,0,0,18,187,1,0,0,0,20,200,1,0,0,0,22,216,\n        1,0,0,0,24,222,1,0,0,0,26,234,1,0,0,0,28,237,1,0,0,0,30,240,1,0,\n        0,0,32,247,1,0,0,0,34,259,1,0,0,0,36,263,1,0,0,0,38,266,1,0,0,0,\n        40,279,1,0,0,0,42,288,1,0,0,0,44,315,1,0,0,0,46,317,1,0,0,0,48,331,\n        1,0,0,0,50,335,1,0,0,0,52,338,1,0,0,0,54,343,1,0,0,0,56,347,1,0,\n        0,0,58,357,1,0,0,0,60,361,1,0,0,0,62,367,1,0,0,0,64,369,1,0,0,0,\n        66,380,1,0,0,0,68,425,1,0,0,0,70,429,1,0,0,0,72,438,1,0,0,0,74,440,\n        1,0,0,0,76,447,1,0,0,0,78,455,1,0,0,0,80,457,1,0,0,0,82,459,1,0,\n        0,0,84,461,1,0,0,0,86,463,1,0,0,0,88,465,1,0,0,0,90,467,1,0,0,0,\n        92,469,1,0,0,0,94,471,1,0,0,0,96,473,1,0,0,0,98,475,1,0,0,0,100,\n        477,1,0,0,0,102,479,1,0,0,0,104,481,1,0,0,0,106,109,3,2,1,0,107,\n        109,3,4,2,0,108,106,1,0,0,0,108,107,1,0,0,0,109,112,1,0,0,0,110,\n        111,1,0,0,0,110,108,1,0,0,0,111,113,1,0,0,0,112,110,1,0,0,0,113,\n        114,5,0,0,1,114,1,1,0,0,0,115,120,3,8,4,0,116,120,3,12,6,0,117,120,\n        3,14,7,0,118,120,3,16,8,0,119,115,1,0,0,0,119,116,1,0,0,0,119,117,\n        1,0,0,0,119,118,1,0,0,0,120,122,1,0,0,0,121,123,5,1,0,0,122,121,\n        1,0,0,0,122,123,1,0,0,0,123,3,1,0,0,0,124,129,3,6,3,0,125,129,3,\n        10,5,0,126,129,3,20,10,0,127,129,3,18,9,0,128,124,1,0,0,0,128,125,\n        1,0,0,0,128,126,1,0,0,0,128,127,1,0,0,0,129,130,1,0,0,0,130,131,\n        5,1,0,0,131,5,1,0,0,0,132,133,5,52,0,0,133,134,5,39,0,0,134,135,\n        3,78,39,0,135,136,3,80,40,0,136,137,3,38,19,0,137,7,1,0,0,0,138,\n        139,5,39,0,0,139,140,3,78,39,0,140,141,3,80,40,0,141,142,3,38,19,\n        0,142,143,3,42,21,0,143,9,1,0,0,0,144,145,5,34,0,0,145,148,3,78,\n        39,0,146,149,3,26,13,0,147,149,3,22,11,0,148,146,1,0,0,0,148,147,\n        1,0,0,0,149,157,1,0,0,0,150,153,5,2,0,0,151,154,3,26,13,0,152,154,\n        3,22,11,0,153,151,1,0,0,0,153,152,1,0,0,0,154,156,1,0,0,0,155,150,\n        1,0,0,0,156,159,1,0,0,0,157,155,1,0,0,0,157,158,1,0,0,0,158,11,1,\n        0,0,0,159,157,1,0,0,0,160,161,5,41,0,0,161,162,3,80,40,0,162,168,\n        5,3,0,0,163,164,3,20,10,0,164,165,5,1,0,0,165,167,1,0,0,0,166,163,\n        1,0,0,0,167,170,1,0,0,0,168,169,1,0,0,0,168,166,1,0,0,0,169,171,\n        1,0,0,0,170,168,1,0,0,0,171,172,5,4,0,0,172,13,1,0,0,0,173,174,5,\n        45,0,0,174,175,3,80,40,0,175,176,5,5,0,0,176,177,3,82,41,0,177,178,\n        5,6,0,0,178,179,3,42,21,0,179,15,1,0,0,0,180,181,5,46,0,0,181,182,\n        3,80,40,0,182,183,5,5,0,0,183,184,3,82,41,0,184,185,5,6,0,0,185,\n        186,3,42,21,0,186,17,1,0,0,0,187,188,5,46,0,0,188,193,3,80,40,0,\n        189,190,5,2,0,0,190,192,3,80,40,0,191,189,1,0,0,0,192,195,1,0,0,\n        0,193,194,1,0,0,0,193,191,1,0,0,0,194,196,1,0,0,0,195,193,1,0,0,\n        0,196,197,5,5,0,0,197,198,3,82,41,0,198,199,5,6,0,0,199,19,1,0,0,\n        0,200,201,5,35,0,0,201,204,3,78,39,0,202,205,3,34,17,0,203,205,3,\n        30,15,0,204,202,1,0,0,0,204,203,1,0,0,0,205,213,1,0,0,0,206,209,\n        5,2,0,0,207,210,3,34,17,0,208,210,3,30,15,0,209,207,1,0,0,0,209,\n        208,1,0,0,0,210,212,1,0,0,0,211,206,1,0,0,0,212,215,1,0,0,0,213,\n        211,1,0,0,0,213,214,1,0,0,0,214,21,1,0,0,0,215,213,1,0,0,0,216,217,\n        3,80,40,0,217,218,5,7,0,0,218,219,3,70,35,0,219,220,5,8,0,0,220,\n        221,3,24,12,0,221,23,1,0,0,0,222,223,5,9,0,0,223,224,5,3,0,0,224,\n        229,3,66,33,0,225,226,5,2,0,0,226,228,3,66,33,0,227,225,1,0,0,0,\n        228,231,1,0,0,0,229,230,1,0,0,0,229,227,1,0,0,0,230,232,1,0,0,0,\n        231,229,1,0,0,0,232,233,5,4,0,0,233,25,1,0,0,0,234,235,3,80,40,0,\n        235,236,3,28,14,0,236,27,1,0,0,0,237,238,5,9,0,0,238,239,3,66,33,\n        0,239,29,1,0,0,0,240,241,3,80,40,0,241,242,5,7,0,0,242,243,3,70,\n        35,0,243,245,5,8,0,0,244,246,3,32,16,0,245,244,1,0,0,0,245,246,1,\n        0,0,0,246,31,1,0,0,0,247,248,5,9,0,0,248,249,5,3,0,0,249,254,3,66,\n        33,0,250,251,5,2,0,0,251,253,3,66,33,0,252,250,1,0,0,0,253,256,1,\n        0,0,0,254,252,1,0,0,0,254,255,1,0,0,0,255,257,1,0,0,0,256,254,1,\n        0,0,0,257,258,5,4,0,0,258,33,1,0,0,0,259,261,3,80,40,0,260,262,3,\n        36,18,0,261,260,1,0,0,0,261,262,1,0,0,0,262,35,1,0,0,0,263,264,5,\n        9,0,0,264,265,3,66,33,0,265,37,1,0,0,0,266,275,5,5,0,0,267,272,3,\n        40,20,0,268,269,5,2,0,0,269,271,3,40,20,0,270,268,1,0,0,0,271,274,\n        1,0,0,0,272,273,1,0,0,0,272,270,1,0,0,0,273,276,1,0,0,0,274,272,\n        1,0,0,0,275,267,1,0,0,0,275,276,1,0,0,0,276,277,1,0,0,0,277,278,\n        5,6,0,0,278,39,1,0,0,0,279,280,5,35,0,0,280,281,3,78,39,0,281,286,\n        3,80,40,0,282,283,5,7,0,0,283,284,3,70,35,0,284,285,5,8,0,0,285,\n        287,1,0,0,0,286,282,1,0,0,0,286,287,1,0,0,0,287,41,1,0,0,0,288,303,\n        5,3,0,0,289,290,3,44,22,0,290,291,5,1,0,0,291,300,1,0,0,0,292,295,\n        3,56,28,0,293,295,3,60,30,0,294,292,1,0,0,0,294,293,1,0,0,0,295,\n        297,1,0,0,0,296,298,5,1,0,0,297,296,1,0,0,0,297,298,1,0,0,0,298,\n        300,1,0,0,0,299,289,1,0,0,0,299,294,1,0,0,0,300,302,1,0,0,0,301,\n        299,1,0,0,0,302,305,1,0,0,0,303,304,1,0,0,0,303,301,1,0,0,0,304,\n        306,1,0,0,0,305,303,1,0,0,0,306,307,5,4,0,0,307,43,1,0,0,0,308,316,\n        3,48,24,0,309,316,3,58,29,0,310,316,3,10,5,0,311,316,3,20,10,0,312,\n        316,3,62,31,0,313,316,3,64,32,0,314,316,3,66,33,0,315,308,1,0,0,\n        0,315,309,1,0,0,0,315,310,1,0,0,0,315,311,1,0,0,0,315,312,1,0,0,\n        0,315,313,1,0,0,0,315,314,1,0,0,0,316,45,1,0,0,0,317,318,3,80,40,\n        0,318,327,5,5,0,0,319,324,3,66,33,0,320,321,5,2,0,0,321,323,3,66,\n        33,0,322,320,1,0,0,0,323,326,1,0,0,0,324,325,1,0,0,0,324,322,1,0,\n        0,0,325,328,1,0,0,0,326,324,1,0,0,0,327,319,1,0,0,0,327,328,1,0,\n        0,0,328,329,1,0,0,0,329,330,5,6,0,0,330,47,1,0,0,0,331,332,3,76,\n        38,0,332,333,3,84,42,0,333,334,3,66,33,0,334,49,1,0,0,0,335,336,\n        5,38,0,0,336,337,3,42,21,0,337,51,1,0,0,0,338,339,5,38,0,0,339,340,\n        5,36,0,0,340,341,3,66,33,0,341,342,3,42,21,0,342,53,1,0,0,0,343,\n        344,5,36,0,0,344,345,3,66,33,0,345,346,3,42,21,0,346,55,1,0,0,0,\n        347,351,3,54,27,0,348,350,3,52,26,0,349,348,1,0,0,0,350,353,1,0,\n        0,0,351,352,1,0,0,0,351,349,1,0,0,0,352,355,1,0,0,0,353,351,1,0,\n        0,0,354,356,3,50,25,0,355,354,1,0,0,0,355,356,1,0,0,0,356,57,1,0,\n        0,0,357,359,5,43,0,0,358,360,3,66,33,0,359,358,1,0,0,0,359,360,1,\n        0,0,0,360,59,1,0,0,0,361,362,5,49,0,0,362,363,5,5,0,0,363,364,3,\n        66,33,0,364,365,5,6,0,0,365,366,3,42,21,0,366,61,1,0,0,0,367,368,\n        5,50,0,0,368,63,1,0,0,0,369,370,5,51,0,0,370,65,1,0,0,0,371,372,\n        6,33,-1,0,372,373,5,5,0,0,373,374,3,66,33,0,374,375,5,6,0,0,375,\n        381,1,0,0,0,376,377,3,94,47,0,377,378,3,66,33,11,378,381,1,0,0,0,\n        379,381,3,72,36,0,380,371,1,0,0,0,380,376,1,0,0,0,380,379,1,0,0,\n        0,381,420,1,0,0,0,382,383,10,10,0,0,383,384,3,96,48,0,384,385,3,\n        66,33,11,385,419,1,0,0,0,386,387,10,9,0,0,387,388,3,86,43,0,388,\n        389,3,66,33,10,389,419,1,0,0,0,390,391,10,8,0,0,391,392,3,88,44,\n        0,392,393,3,66,33,9,393,419,1,0,0,0,394,395,10,7,0,0,395,396,3,90,\n        45,0,396,397,3,66,33,8,397,419,1,0,0,0,398,399,10,6,0,0,399,400,\n        3,92,46,0,400,401,3,66,33,7,401,419,1,0,0,0,402,403,10,5,0,0,403,\n        404,3,98,49,0,404,405,3,66,33,6,405,419,1,0,0,0,406,407,10,4,0,0,\n        407,408,3,100,50,0,408,409,3,66,33,5,409,419,1,0,0,0,410,411,10,\n        3,0,0,411,412,3,102,51,0,412,413,3,66,33,4,413,419,1,0,0,0,414,415,\n        10,2,0,0,415,416,3,104,52,0,416,417,3,66,33,3,417,419,1,0,0,0,418,\n        382,1,0,0,0,418,386,1,0,0,0,418,390,1,0,0,0,418,394,1,0,0,0,418,\n        398,1,0,0,0,418,402,1,0,0,0,418,406,1,0,0,0,418,410,1,0,0,0,418,\n        414,1,0,0,0,419,422,1,0,0,0,420,418,1,0,0,0,420,421,1,0,0,0,421,\n        67,1,0,0,0,422,420,1,0,0,0,423,426,5,54,0,0,424,426,3,76,38,0,425,\n        423,1,0,0,0,425,424,1,0,0,0,426,69,1,0,0,0,427,430,5,54,0,0,428,\n        430,3,76,38,0,429,427,1,0,0,0,429,428,1,0,0,0,430,71,1,0,0,0,431,\n        439,5,54,0,0,432,439,5,55,0,0,433,439,5,56,0,0,434,439,5,47,0,0,\n        435,439,5,48,0,0,436,439,3,46,23,0,437,439,3,76,38,0,438,431,1,0,\n        0,0,438,432,1,0,0,0,438,433,1,0,0,0,438,434,1,0,0,0,438,435,1,0,\n        0,0,438,436,1,0,0,0,438,437,1,0,0,0,439,73,1,0,0,0,440,445,3,80,\n        40,0,441,442,5,7,0,0,442,443,3,68,34,0,443,444,5,8,0,0,444,446,1,\n        0,0,0,445,441,1,0,0,0,445,446,1,0,0,0,446,75,1,0,0,0,447,452,3,74,\n        37,0,448,449,5,10,0,0,449,451,3,74,37,0,450,448,1,0,0,0,451,454,\n        1,0,0,0,452,450,1,0,0,0,452,453,1,0,0,0,453,77,1,0,0,0,454,452,1,\n        0,0,0,455,456,7,0,0,0,456,79,1,0,0,0,457,458,7,1,0,0,458,81,1,0,\n        0,0,459,460,5,53,0,0,460,83,1,0,0,0,461,462,7,2,0,0,462,85,1,0,0,\n        0,463,464,7,3,0,0,464,87,1,0,0,0,465,466,7,4,0,0,466,89,1,0,0,0,\n        467,468,7,5,0,0,468,91,1,0,0,0,469,470,7,6,0,0,470,93,1,0,0,0,471,\n        472,7,7,0,0,472,95,1,0,0,0,473,474,7,8,0,0,474,97,1,0,0,0,475,476,\n        5,30,0,0,476,99,1,0,0,0,477,478,5,31,0,0,478,101,1,0,0,0,479,480,\n        5,32,0,0,480,103,1,0,0,0,481,482,5,33,0,0,482,105,1,0,0,0,38,108,\n        110,119,122,128,148,153,157,168,193,204,209,213,229,245,254,261,\n        272,275,286,294,297,299,303,315,324,327,351,355,359,380,418,420,\n        425,429,438,445,452\n    ];\n\n    private static __ATN: antlr.ATN;\n    public static get _ATN(): antlr.ATN {\n        if (!DaedalusParser.__ATN) {\n            DaedalusParser.__ATN = new antlr.ATNDeserializer().deserialize(DaedalusParser._serializedATN);\n        }\n\n        return DaedalusParser.__ATN;\n    }\n\n\n    private static readonly vocabulary = new antlr.Vocabulary(DaedalusParser.literalNames, DaedalusParser.symbolicNames, []);\n\n    public override get vocabulary(): antlr.Vocabulary {\n        return DaedalusParser.vocabulary;\n    }\n\n    private static readonly decisionsToDFA = DaedalusParser._ATN.decisionToState.map( (ds: antlr.DecisionState, index: number) => new antlr.DFA(ds, index) );\n}\n\nexport class DaedalusFileContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public EOF(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.EOF, 0)!;\n    }\n    public blockDef(): BlockDefContext[];\n    public blockDef(i: number): BlockDefContext | null;\n    public blockDef(i?: number): BlockDefContext[] | BlockDefContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(BlockDefContext);\n        }\n\n        return this.getRuleContext(i, BlockDefContext);\n    }\n    public inlineDef(): InlineDefContext[];\n    public inlineDef(i: number): InlineDefContext | null;\n    public inlineDef(i?: number): InlineDefContext[] | InlineDefContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(InlineDefContext);\n        }\n\n        return this.getRuleContext(i, InlineDefContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_daedalusFile;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitDaedalusFile) {\n            return visitor.visitDaedalusFile(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class BlockDefContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public functionDef(): FunctionDefContext | null {\n        return this.getRuleContext(0, FunctionDefContext);\n    }\n    public classDef(): ClassDefContext | null {\n        return this.getRuleContext(0, ClassDefContext);\n    }\n    public prototypeDef(): PrototypeDefContext | null {\n        return this.getRuleContext(0, PrototypeDefContext);\n    }\n    public instanceDef(): InstanceDefContext | null {\n        return this.getRuleContext(0, InstanceDefContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_blockDef;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitBlockDef) {\n            return visitor.visitBlockDef(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class InlineDefContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public externFunctionDecl(): ExternFunctionDeclContext | null {\n        return this.getRuleContext(0, ExternFunctionDeclContext);\n    }\n    public constDef(): ConstDefContext | null {\n        return this.getRuleContext(0, ConstDefContext);\n    }\n    public varDecl(): VarDeclContext | null {\n        return this.getRuleContext(0, VarDeclContext);\n    }\n    public instanceDecl(): InstanceDeclContext | null {\n        return this.getRuleContext(0, InstanceDeclContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_inlineDef;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitInlineDef) {\n            return visitor.visitInlineDef(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ExternFunctionDeclContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Extern(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Extern, 0)!;\n    }\n    public Func(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Func, 0)!;\n    }\n    public dataType(): DataTypeContext {\n        return this.getRuleContext(0, DataTypeContext)!;\n    }\n    public nameNode(): NameNodeContext {\n        return this.getRuleContext(0, NameNodeContext)!;\n    }\n    public parameterList(): ParameterListContext {\n        return this.getRuleContext(0, ParameterListContext)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_externFunctionDecl;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitExternFunctionDecl) {\n            return visitor.visitExternFunctionDecl(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class FunctionDefContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Func(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Func, 0)!;\n    }\n    public dataType(): DataTypeContext {\n        return this.getRuleContext(0, DataTypeContext)!;\n    }\n    public nameNode(): NameNodeContext {\n        return this.getRuleContext(0, NameNodeContext)!;\n    }\n    public parameterList(): ParameterListContext {\n        return this.getRuleContext(0, ParameterListContext)!;\n    }\n    public statementBlock(): StatementBlockContext {\n        return this.getRuleContext(0, StatementBlockContext)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_functionDef;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitFunctionDef) {\n            return visitor.visitFunctionDef(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ConstDefContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Const(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Const, 0)!;\n    }\n    public dataType(): DataTypeContext {\n        return this.getRuleContext(0, DataTypeContext)!;\n    }\n    public constValueDef(): ConstValueDefContext[];\n    public constValueDef(i: number): ConstValueDefContext | null;\n    public constValueDef(i?: number): ConstValueDefContext[] | ConstValueDefContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ConstValueDefContext);\n        }\n\n        return this.getRuleContext(i, ConstValueDefContext);\n    }\n    public constArrayDef(): ConstArrayDefContext[];\n    public constArrayDef(i: number): ConstArrayDefContext | null;\n    public constArrayDef(i?: number): ConstArrayDefContext[] | ConstArrayDefContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ConstArrayDefContext);\n        }\n\n        return this.getRuleContext(i, ConstArrayDefContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_constDef;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitConstDef) {\n            return visitor.visitConstDef(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ClassDefContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Class(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Class, 0)!;\n    }\n    public nameNode(): NameNodeContext {\n        return this.getRuleContext(0, NameNodeContext)!;\n    }\n    public varDecl(): VarDeclContext[];\n    public varDecl(i: number): VarDeclContext | null;\n    public varDecl(i?: number): VarDeclContext[] | VarDeclContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(VarDeclContext);\n        }\n\n        return this.getRuleContext(i, VarDeclContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_classDef;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitClassDef) {\n            return visitor.visitClassDef(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class PrototypeDefContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Prototype(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Prototype, 0)!;\n    }\n    public nameNode(): NameNodeContext {\n        return this.getRuleContext(0, NameNodeContext)!;\n    }\n    public parentReference(): ParentReferenceContext {\n        return this.getRuleContext(0, ParentReferenceContext)!;\n    }\n    public statementBlock(): StatementBlockContext {\n        return this.getRuleContext(0, StatementBlockContext)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_prototypeDef;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitPrototypeDef) {\n            return visitor.visitPrototypeDef(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class InstanceDefContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Instance(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Instance, 0)!;\n    }\n    public nameNode(): NameNodeContext {\n        return this.getRuleContext(0, NameNodeContext)!;\n    }\n    public parentReference(): ParentReferenceContext {\n        return this.getRuleContext(0, ParentReferenceContext)!;\n    }\n    public statementBlock(): StatementBlockContext {\n        return this.getRuleContext(0, StatementBlockContext)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_instanceDef;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitInstanceDef) {\n            return visitor.visitInstanceDef(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class InstanceDeclContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Instance(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Instance, 0)!;\n    }\n    public nameNode(): NameNodeContext[];\n    public nameNode(i: number): NameNodeContext | null;\n    public nameNode(i?: number): NameNodeContext[] | NameNodeContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(NameNodeContext);\n        }\n\n        return this.getRuleContext(i, NameNodeContext);\n    }\n    public parentReference(): ParentReferenceContext {\n        return this.getRuleContext(0, ParentReferenceContext)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_instanceDecl;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitInstanceDecl) {\n            return visitor.visitInstanceDecl(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class VarDeclContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Var(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Var, 0)!;\n    }\n    public dataType(): DataTypeContext {\n        return this.getRuleContext(0, DataTypeContext)!;\n    }\n    public varValueDecl(): VarValueDeclContext[];\n    public varValueDecl(i: number): VarValueDeclContext | null;\n    public varValueDecl(i?: number): VarValueDeclContext[] | VarValueDeclContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(VarValueDeclContext);\n        }\n\n        return this.getRuleContext(i, VarValueDeclContext);\n    }\n    public varArrayDecl(): VarArrayDeclContext[];\n    public varArrayDecl(i: number): VarArrayDeclContext | null;\n    public varArrayDecl(i?: number): VarArrayDeclContext[] | VarArrayDeclContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(VarArrayDeclContext);\n        }\n\n        return this.getRuleContext(i, VarArrayDeclContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_varDecl;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitVarDecl) {\n            return visitor.visitVarDecl(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ConstArrayDefContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public nameNode(): NameNodeContext {\n        return this.getRuleContext(0, NameNodeContext)!;\n    }\n    public arraySize(): ArraySizeContext {\n        return this.getRuleContext(0, ArraySizeContext)!;\n    }\n    public constArrayAssignment(): ConstArrayAssignmentContext {\n        return this.getRuleContext(0, ConstArrayAssignmentContext)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_constArrayDef;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitConstArrayDef) {\n            return visitor.visitConstArrayDef(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ConstArrayAssignmentContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public expression(): ExpressionContext[];\n    public expression(i: number): ExpressionContext | null;\n    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_constArrayAssignment;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitConstArrayAssignment) {\n            return visitor.visitConstArrayAssignment(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ConstValueDefContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public nameNode(): NameNodeContext {\n        return this.getRuleContext(0, NameNodeContext)!;\n    }\n    public constValueAssignment(): ConstValueAssignmentContext {\n        return this.getRuleContext(0, ConstValueAssignmentContext)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_constValueDef;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitConstValueDef) {\n            return visitor.visitConstValueDef(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ConstValueAssignmentContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public expression(): ExpressionContext {\n        return this.getRuleContext(0, ExpressionContext)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_constValueAssignment;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitConstValueAssignment) {\n            return visitor.visitConstValueAssignment(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class VarArrayDeclContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public nameNode(): NameNodeContext {\n        return this.getRuleContext(0, NameNodeContext)!;\n    }\n    public arraySize(): ArraySizeContext {\n        return this.getRuleContext(0, ArraySizeContext)!;\n    }\n    public varArrayAssignment(): VarArrayAssignmentContext | null {\n        return this.getRuleContext(0, VarArrayAssignmentContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_varArrayDecl;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitVarArrayDecl) {\n            return visitor.visitVarArrayDecl(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class VarArrayAssignmentContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public expression(): ExpressionContext[];\n    public expression(i: number): ExpressionContext | null;\n    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_varArrayAssignment;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitVarArrayAssignment) {\n            return visitor.visitVarArrayAssignment(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class VarValueDeclContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public nameNode(): NameNodeContext {\n        return this.getRuleContext(0, NameNodeContext)!;\n    }\n    public varValueAssignment(): VarValueAssignmentContext | null {\n        return this.getRuleContext(0, VarValueAssignmentContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_varValueDecl;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitVarValueDecl) {\n            return visitor.visitVarValueDecl(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class VarValueAssignmentContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public expression(): ExpressionContext {\n        return this.getRuleContext(0, ExpressionContext)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_varValueAssignment;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitVarValueAssignment) {\n            return visitor.visitVarValueAssignment(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ParameterListContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public parameterDecl(): ParameterDeclContext[];\n    public parameterDecl(i: number): ParameterDeclContext | null;\n    public parameterDecl(i?: number): ParameterDeclContext[] | ParameterDeclContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ParameterDeclContext);\n        }\n\n        return this.getRuleContext(i, ParameterDeclContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_parameterList;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitParameterList) {\n            return visitor.visitParameterList(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ParameterDeclContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Var(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Var, 0)!;\n    }\n    public dataType(): DataTypeContext {\n        return this.getRuleContext(0, DataTypeContext)!;\n    }\n    public nameNode(): NameNodeContext {\n        return this.getRuleContext(0, NameNodeContext)!;\n    }\n    public arraySize(): ArraySizeContext | null {\n        return this.getRuleContext(0, ArraySizeContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_parameterDecl;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitParameterDecl) {\n            return visitor.visitParameterDecl(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class StatementBlockContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public statement(): StatementContext[];\n    public statement(i: number): StatementContext | null;\n    public statement(i?: number): StatementContext[] | StatementContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(StatementContext);\n        }\n\n        return this.getRuleContext(i, StatementContext);\n    }\n    public ifBlockStatement(): IfBlockStatementContext[];\n    public ifBlockStatement(i: number): IfBlockStatementContext | null;\n    public ifBlockStatement(i?: number): IfBlockStatementContext[] | IfBlockStatementContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(IfBlockStatementContext);\n        }\n\n        return this.getRuleContext(i, IfBlockStatementContext);\n    }\n    public whileStatement(): WhileStatementContext[];\n    public whileStatement(i: number): WhileStatementContext | null;\n    public whileStatement(i?: number): WhileStatementContext[] | WhileStatementContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(WhileStatementContext);\n        }\n\n        return this.getRuleContext(i, WhileStatementContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_statementBlock;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitStatementBlock) {\n            return visitor.visitStatementBlock(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class StatementContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public assignment(): AssignmentContext | null {\n        return this.getRuleContext(0, AssignmentContext);\n    }\n    public returnStatement(): ReturnStatementContext | null {\n        return this.getRuleContext(0, ReturnStatementContext);\n    }\n    public constDef(): ConstDefContext | null {\n        return this.getRuleContext(0, ConstDefContext);\n    }\n    public varDecl(): VarDeclContext | null {\n        return this.getRuleContext(0, VarDeclContext);\n    }\n    public breakStatement(): BreakStatementContext | null {\n        return this.getRuleContext(0, BreakStatementContext);\n    }\n    public continueStatement(): ContinueStatementContext | null {\n        return this.getRuleContext(0, ContinueStatementContext);\n    }\n    public expression(): ExpressionContext | null {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_statement;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitStatement) {\n            return visitor.visitStatement(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class FunctionCallContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public nameNode(): NameNodeContext {\n        return this.getRuleContext(0, NameNodeContext)!;\n    }\n    public expression(): ExpressionContext[];\n    public expression(i: number): ExpressionContext | null;\n    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_functionCall;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitFunctionCall) {\n            return visitor.visitFunctionCall(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class AssignmentContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public reference(): ReferenceContext {\n        return this.getRuleContext(0, ReferenceContext)!;\n    }\n    public assignmentOperator(): AssignmentOperatorContext {\n        return this.getRuleContext(0, AssignmentOperatorContext)!;\n    }\n    public expression(): ExpressionContext {\n        return this.getRuleContext(0, ExpressionContext)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_assignment;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitAssignment) {\n            return visitor.visitAssignment(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ElseBlockContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Else(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Else, 0)!;\n    }\n    public statementBlock(): StatementBlockContext {\n        return this.getRuleContext(0, StatementBlockContext)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_elseBlock;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitElseBlock) {\n            return visitor.visitElseBlock(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ElseIfBlockContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Else(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Else, 0)!;\n    }\n    public If(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.If, 0)!;\n    }\n    public expression(): ExpressionContext {\n        return this.getRuleContext(0, ExpressionContext)!;\n    }\n    public statementBlock(): StatementBlockContext {\n        return this.getRuleContext(0, StatementBlockContext)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_elseIfBlock;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitElseIfBlock) {\n            return visitor.visitElseIfBlock(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class IfBlockContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public If(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.If, 0)!;\n    }\n    public expression(): ExpressionContext {\n        return this.getRuleContext(0, ExpressionContext)!;\n    }\n    public statementBlock(): StatementBlockContext {\n        return this.getRuleContext(0, StatementBlockContext)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_ifBlock;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitIfBlock) {\n            return visitor.visitIfBlock(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class IfBlockStatementContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public ifBlock(): IfBlockContext {\n        return this.getRuleContext(0, IfBlockContext)!;\n    }\n    public elseIfBlock(): ElseIfBlockContext[];\n    public elseIfBlock(i: number): ElseIfBlockContext | null;\n    public elseIfBlock(i?: number): ElseIfBlockContext[] | ElseIfBlockContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ElseIfBlockContext);\n        }\n\n        return this.getRuleContext(i, ElseIfBlockContext);\n    }\n    public elseBlock(): ElseBlockContext | null {\n        return this.getRuleContext(0, ElseBlockContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_ifBlockStatement;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitIfBlockStatement) {\n            return visitor.visitIfBlockStatement(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ReturnStatementContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Return(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Return, 0)!;\n    }\n    public expression(): ExpressionContext | null {\n        return this.getRuleContext(0, ExpressionContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_returnStatement;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitReturnStatement) {\n            return visitor.visitReturnStatement(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class WhileStatementContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public While(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.While, 0)!;\n    }\n    public expression(): ExpressionContext {\n        return this.getRuleContext(0, ExpressionContext)!;\n    }\n    public statementBlock(): StatementBlockContext {\n        return this.getRuleContext(0, StatementBlockContext)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_whileStatement;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitWhileStatement) {\n            return visitor.visitWhileStatement(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class BreakStatementContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Break(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Break, 0)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_breakStatement;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitBreakStatement) {\n            return visitor.visitBreakStatement(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ContinueStatementContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Continue(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Continue, 0)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_continueStatement;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitContinueStatement) {\n            return visitor.visitContinueStatement(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ExpressionContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_expression;\n    }\n    public override copyFrom(ctx: ExpressionContext): void {\n        super.copyFrom(ctx);\n    }\n}\nexport class BitMoveExpressionContext extends ExpressionContext {\n    public _oper?: BitMoveOperatorContext;\n    public constructor(ctx: ExpressionContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public expression(): ExpressionContext[];\n    public expression(i: number): ExpressionContext | null;\n    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    public bitMoveOperator(): BitMoveOperatorContext | null {\n        return this.getRuleContext(0, BitMoveOperatorContext);\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitBitMoveExpression) {\n            return visitor.visitBitMoveExpression(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class ValueExpressionContext extends ExpressionContext {\n    public constructor(ctx: ExpressionContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public value(): ValueContext {\n        return this.getRuleContext(0, ValueContext)!;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitValueExpression) {\n            return visitor.visitValueExpression(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class EqExpressionContext extends ExpressionContext {\n    public _oper?: EqOperatorContext;\n    public constructor(ctx: ExpressionContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public expression(): ExpressionContext[];\n    public expression(i: number): ExpressionContext | null;\n    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    public eqOperator(): EqOperatorContext | null {\n        return this.getRuleContext(0, EqOperatorContext);\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitEqExpression) {\n            return visitor.visitEqExpression(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class AddExpressionContext extends ExpressionContext {\n    public _oper?: AddOperatorContext;\n    public constructor(ctx: ExpressionContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public expression(): ExpressionContext[];\n    public expression(i: number): ExpressionContext | null;\n    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    public addOperator(): AddOperatorContext | null {\n        return this.getRuleContext(0, AddOperatorContext);\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitAddExpression) {\n            return visitor.visitAddExpression(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class CompExpressionContext extends ExpressionContext {\n    public _oper?: CompOperatorContext;\n    public constructor(ctx: ExpressionContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public expression(): ExpressionContext[];\n    public expression(i: number): ExpressionContext | null;\n    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    public compOperator(): CompOperatorContext | null {\n        return this.getRuleContext(0, CompOperatorContext);\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitCompExpression) {\n            return visitor.visitCompExpression(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class LogOrExpressionContext extends ExpressionContext {\n    public _oper?: LogOrOperatorContext;\n    public constructor(ctx: ExpressionContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public expression(): ExpressionContext[];\n    public expression(i: number): ExpressionContext | null;\n    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    public logOrOperator(): LogOrOperatorContext | null {\n        return this.getRuleContext(0, LogOrOperatorContext);\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitLogOrExpression) {\n            return visitor.visitLogOrExpression(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class BinAndExpressionContext extends ExpressionContext {\n    public _oper?: BinAndOperatorContext;\n    public constructor(ctx: ExpressionContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public expression(): ExpressionContext[];\n    public expression(i: number): ExpressionContext | null;\n    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    public binAndOperator(): BinAndOperatorContext | null {\n        return this.getRuleContext(0, BinAndOperatorContext);\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitBinAndExpression) {\n            return visitor.visitBinAndExpression(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class BinOrExpressionContext extends ExpressionContext {\n    public _oper?: BinOrOperatorContext;\n    public constructor(ctx: ExpressionContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public expression(): ExpressionContext[];\n    public expression(i: number): ExpressionContext | null;\n    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    public binOrOperator(): BinOrOperatorContext | null {\n        return this.getRuleContext(0, BinOrOperatorContext);\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitBinOrExpression) {\n            return visitor.visitBinOrExpression(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class MultExpressionContext extends ExpressionContext {\n    public _oper?: MultOperatorContext;\n    public constructor(ctx: ExpressionContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public expression(): ExpressionContext[];\n    public expression(i: number): ExpressionContext | null;\n    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    public multOperator(): MultOperatorContext | null {\n        return this.getRuleContext(0, MultOperatorContext);\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitMultExpression) {\n            return visitor.visitMultExpression(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class BracketExpressionContext extends ExpressionContext {\n    public constructor(ctx: ExpressionContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public expression(): ExpressionContext {\n        return this.getRuleContext(0, ExpressionContext)!;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitBracketExpression) {\n            return visitor.visitBracketExpression(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class UnaryExpressionContext extends ExpressionContext {\n    public _oper?: UnaryOperatorContext;\n    public constructor(ctx: ExpressionContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public expression(): ExpressionContext {\n        return this.getRuleContext(0, ExpressionContext)!;\n    }\n    public unaryOperator(): UnaryOperatorContext | null {\n        return this.getRuleContext(0, UnaryOperatorContext);\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitUnaryExpression) {\n            return visitor.visitUnaryExpression(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class LogAndExpressionContext extends ExpressionContext {\n    public _oper?: LogAndOperatorContext;\n    public constructor(ctx: ExpressionContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public expression(): ExpressionContext[];\n    public expression(i: number): ExpressionContext | null;\n    public expression(i?: number): ExpressionContext[] | ExpressionContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ExpressionContext);\n        }\n\n        return this.getRuleContext(i, ExpressionContext);\n    }\n    public logAndOperator(): LogAndOperatorContext | null {\n        return this.getRuleContext(0, LogAndOperatorContext);\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitLogAndExpression) {\n            return visitor.visitLogAndExpression(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ArrayIndexContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public IntegerLiteral(): antlr.TerminalNode | null {\n        return this.getToken(DaedalusParser.IntegerLiteral, 0);\n    }\n    public reference(): ReferenceContext | null {\n        return this.getRuleContext(0, ReferenceContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_arrayIndex;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitArrayIndex) {\n            return visitor.visitArrayIndex(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ArraySizeContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public IntegerLiteral(): antlr.TerminalNode | null {\n        return this.getToken(DaedalusParser.IntegerLiteral, 0);\n    }\n    public reference(): ReferenceContext | null {\n        return this.getRuleContext(0, ReferenceContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_arraySize;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitArraySize) {\n            return visitor.visitArraySize(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ValueContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_value;\n    }\n    public override copyFrom(ctx: ValueContext): void {\n        super.copyFrom(ctx);\n    }\n}\nexport class IntegerLiteralValueContext extends ValueContext {\n    public constructor(ctx: ValueContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public IntegerLiteral(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.IntegerLiteral, 0)!;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitIntegerLiteralValue) {\n            return visitor.visitIntegerLiteralValue(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class FunctionCallValueContext extends ValueContext {\n    public constructor(ctx: ValueContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public functionCall(): FunctionCallContext {\n        return this.getRuleContext(0, FunctionCallContext)!;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitFunctionCallValue) {\n            return visitor.visitFunctionCallValue(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class FloatLiteralValueContext extends ValueContext {\n    public constructor(ctx: ValueContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public FloatLiteral(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.FloatLiteral, 0)!;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitFloatLiteralValue) {\n            return visitor.visitFloatLiteralValue(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class StringLiteralValueContext extends ValueContext {\n    public constructor(ctx: ValueContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public StringLiteral(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.StringLiteral, 0)!;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitStringLiteralValue) {\n            return visitor.visitStringLiteralValue(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class NoFuncLiteralValueContext extends ValueContext {\n    public constructor(ctx: ValueContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public NoFunc(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.NoFunc, 0)!;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitNoFuncLiteralValue) {\n            return visitor.visitNoFuncLiteralValue(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class NullLiteralValueContext extends ValueContext {\n    public constructor(ctx: ValueContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public Null(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Null, 0)!;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitNullLiteralValue) {\n            return visitor.visitNullLiteralValue(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\nexport class ReferenceValueContext extends ValueContext {\n    public constructor(ctx: ValueContext) {\n        super(ctx.parent, ctx.invokingState);\n        super.copyFrom(ctx);\n    }\n    public reference(): ReferenceContext {\n        return this.getRuleContext(0, ReferenceContext)!;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitReferenceValue) {\n            return visitor.visitReferenceValue(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ReferenceAtomContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public nameNode(): NameNodeContext {\n        return this.getRuleContext(0, NameNodeContext)!;\n    }\n    public arrayIndex(): ArrayIndexContext | null {\n        return this.getRuleContext(0, ArrayIndexContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_referenceAtom;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitReferenceAtom) {\n            return visitor.visitReferenceAtom(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ReferenceContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public referenceAtom(): ReferenceAtomContext[];\n    public referenceAtom(i: number): ReferenceAtomContext | null;\n    public referenceAtom(i?: number): ReferenceAtomContext[] | ReferenceAtomContext | null {\n        if (i === undefined) {\n            return this.getRuleContexts(ReferenceAtomContext);\n        }\n\n        return this.getRuleContext(i, ReferenceAtomContext);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_reference;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitReference) {\n            return visitor.visitReference(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class DataTypeContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Identifier(): antlr.TerminalNode | null {\n        return this.getToken(DaedalusParser.Identifier, 0);\n    }\n    public Void(): antlr.TerminalNode | null {\n        return this.getToken(DaedalusParser.Void, 0);\n    }\n    public Int(): antlr.TerminalNode | null {\n        return this.getToken(DaedalusParser.Int, 0);\n    }\n    public Float(): antlr.TerminalNode | null {\n        return this.getToken(DaedalusParser.Float, 0);\n    }\n    public String(): antlr.TerminalNode | null {\n        return this.getToken(DaedalusParser.String, 0);\n    }\n    public Func(): antlr.TerminalNode | null {\n        return this.getToken(DaedalusParser.Func, 0);\n    }\n    public Instance(): antlr.TerminalNode | null {\n        return this.getToken(DaedalusParser.Instance, 0);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_dataType;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitDataType) {\n            return visitor.visitDataType(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class NameNodeContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Identifier(): antlr.TerminalNode | null {\n        return this.getToken(DaedalusParser.Identifier, 0);\n    }\n    public While(): antlr.TerminalNode | null {\n        return this.getToken(DaedalusParser.While, 0);\n    }\n    public Break(): antlr.TerminalNode | null {\n        return this.getToken(DaedalusParser.Break, 0);\n    }\n    public Continue(): antlr.TerminalNode | null {\n        return this.getToken(DaedalusParser.Continue, 0);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_nameNode;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitNameNode) {\n            return visitor.visitNameNode(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class ParentReferenceContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public Identifier(): antlr.TerminalNode {\n        return this.getToken(DaedalusParser.Identifier, 0)!;\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_parentReference;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitParentReference) {\n            return visitor.visitParentReference(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class AssignmentOperatorContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_assignmentOperator;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitAssignmentOperator) {\n            return visitor.visitAssignmentOperator(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class AddOperatorContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_addOperator;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitAddOperator) {\n            return visitor.visitAddOperator(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class BitMoveOperatorContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_bitMoveOperator;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitBitMoveOperator) {\n            return visitor.visitBitMoveOperator(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class CompOperatorContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_compOperator;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitCompOperator) {\n            return visitor.visitCompOperator(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class EqOperatorContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_eqOperator;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitEqOperator) {\n            return visitor.visitEqOperator(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class UnaryOperatorContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_unaryOperator;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitUnaryOperator) {\n            return visitor.visitUnaryOperator(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class MultOperatorContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_multOperator;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitMultOperator) {\n            return visitor.visitMultOperator(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class BinAndOperatorContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_binAndOperator;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitBinAndOperator) {\n            return visitor.visitBinAndOperator(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class BinOrOperatorContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_binOrOperator;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitBinOrOperator) {\n            return visitor.visitBinOrOperator(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class LogAndOperatorContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_logAndOperator;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitLogAndOperator) {\n            return visitor.visitLogAndOperator(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n\n\nexport class LogOrOperatorContext extends antlr.ParserRuleContext {\n    public constructor(parent: antlr.ParserRuleContext | null, invokingState: number) {\n        super(parent, invokingState);\n    }\n    public override get ruleIndex(): number {\n        return DaedalusParser.RULE_logOrOperator;\n    }\n    public override accept<Result>(visitor: DaedalusVisitor<Result>): Result | null {\n        if (visitor.visitLogOrOperator) {\n            return visitor.visitLogOrOperator(this);\n        } else {\n            return visitor.visitChildren(this);\n        }\n    }\n}\n","// Generated from ./g4/Daedalus.g4 by ANTLR 4.13.1\n\nimport { AbstractParseTreeVisitor } from \"antlr4ng\";\n\n\nimport { DaedalusFileContext } from \"./DaedalusParser.js\";\nimport { BlockDefContext } from \"./DaedalusParser.js\";\nimport { InlineDefContext } from \"./DaedalusParser.js\";\nimport { ExternFunctionDeclContext } from \"./DaedalusParser.js\";\nimport { FunctionDefContext } from \"./DaedalusParser.js\";\nimport { ConstDefContext } from \"./DaedalusParser.js\";\nimport { ClassDefContext } from \"./DaedalusParser.js\";\nimport { PrototypeDefContext } from \"./DaedalusParser.js\";\nimport { InstanceDefContext } from \"./DaedalusParser.js\";\nimport { InstanceDeclContext } from \"./DaedalusParser.js\";\nimport { VarDeclContext } from \"./DaedalusParser.js\";\nimport { ConstArrayDefContext } from \"./DaedalusParser.js\";\nimport { ConstArrayAssignmentContext } from \"./DaedalusParser.js\";\nimport { ConstValueDefContext } from \"./DaedalusParser.js\";\nimport { ConstValueAssignmentContext } from \"./DaedalusParser.js\";\nimport { VarArrayDeclContext } from \"./DaedalusParser.js\";\nimport { VarArrayAssignmentContext } from \"./DaedalusParser.js\";\nimport { VarValueDeclContext } from \"./DaedalusParser.js\";\nimport { VarValueAssignmentContext } from \"./DaedalusParser.js\";\nimport { ParameterListContext } from \"./DaedalusParser.js\";\nimport { ParameterDeclContext } from \"./DaedalusParser.js\";\nimport { StatementBlockContext } from \"./DaedalusParser.js\";\nimport { StatementContext } from \"./DaedalusParser.js\";\nimport { FunctionCallContext } from \"./DaedalusParser.js\";\nimport { AssignmentContext } from \"./DaedalusParser.js\";\nimport { ElseBlockContext } from \"./DaedalusParser.js\";\nimport { ElseIfBlockContext } from \"./DaedalusParser.js\";\nimport { IfBlockContext } from \"./DaedalusParser.js\";\nimport { IfBlockStatementContext } from \"./DaedalusParser.js\";\nimport { ReturnStatementContext } from \"./DaedalusParser.js\";\nimport { WhileStatementContext } from \"./DaedalusParser.js\";\nimport { BreakStatementContext } from \"./DaedalusParser.js\";\nimport { ContinueStatementContext } from \"./DaedalusParser.js\";\nimport { BitMoveExpressionContext } from \"./DaedalusParser.js\";\nimport { ValueExpressionContext } from \"./DaedalusParser.js\";\nimport { EqExpressionContext } from \"./DaedalusParser.js\";\nimport { AddExpressionContext } from \"./DaedalusParser.js\";\nimport { CompExpressionContext } from \"./DaedalusParser.js\";\nimport { LogOrExpressionContext } from \"./DaedalusParser.js\";\nimport { BinAndExpressionContext } from \"./DaedalusParser.js\";\nimport { BinOrExpressionContext } from \"./DaedalusParser.js\";\nimport { MultExpressionContext } from \"./DaedalusParser.js\";\nimport { BracketExpressionContext } from \"./DaedalusParser.js\";\nimport { UnaryExpressionContext } from \"./DaedalusParser.js\";\nimport { LogAndExpressionContext } from \"./DaedalusParser.js\";\nimport { ArrayIndexContext } from \"./DaedalusParser.js\";\nimport { ArraySizeContext } from \"./DaedalusParser.js\";\nimport { IntegerLiteralValueContext } from \"./DaedalusParser.js\";\nimport { FloatLiteralValueContext } from \"./DaedalusParser.js\";\nimport { StringLiteralValueContext } from \"./DaedalusParser.js\";\nimport { NullLiteralValueContext } from \"./DaedalusParser.js\";\nimport { NoFuncLiteralValueContext } from \"./DaedalusParser.js\";\nimport { FunctionCallValueContext } from \"./DaedalusParser.js\";\nimport { ReferenceValueContext } from \"./DaedalusParser.js\";\nimport { ReferenceAtomContext } from \"./DaedalusParser.js\";\nimport { ReferenceContext } from \"./DaedalusParser.js\";\nimport { DataTypeContext } from \"./DaedalusParser.js\";\nimport { NameNodeContext } from \"./DaedalusParser.js\";\nimport { ParentReferenceContext } from \"./DaedalusParser.js\";\nimport { AssignmentOperatorContext } from \"./DaedalusParser.js\";\nimport { AddOperatorContext } from \"./DaedalusParser.js\";\nimport { BitMoveOperatorContext } from \"./DaedalusParser.js\";\nimport { CompOperatorContext } from \"./DaedalusParser.js\";\nimport { EqOperatorContext } from \"./DaedalusParser.js\";\nimport { UnaryOperatorContext } from \"./DaedalusParser.js\";\nimport { MultOperatorContext } from \"./DaedalusParser.js\";\nimport { BinAndOperatorContext } from \"./DaedalusParser.js\";\nimport { BinOrOperatorContext } from \"./DaedalusParser.js\";\nimport { LogAndOperatorContext } from \"./DaedalusParser.js\";\nimport { LogOrOperatorContext } from \"./DaedalusParser.js\";\n\n\n/**\n * This interface defines a complete generic visitor for a parse tree produced\n * by `DaedalusParser`.\n *\n * @param <Result> The return type of the visit operation. Use `void` for\n * operations with no return type.\n */\nexport class DaedalusVisitor<Result> extends AbstractParseTreeVisitor<Result> {\n    /**\n     * Visit a parse tree produced by `DaedalusParser.daedalusFile`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitDaedalusFile?: (ctx: DaedalusFileContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.blockDef`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitBlockDef?: (ctx: BlockDefContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.inlineDef`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitInlineDef?: (ctx: InlineDefContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.externFunctionDecl`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitExternFunctionDecl?: (ctx: ExternFunctionDeclContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.functionDef`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitFunctionDef?: (ctx: FunctionDefContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.constDef`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitConstDef?: (ctx: ConstDefContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.classDef`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitClassDef?: (ctx: ClassDefContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.prototypeDef`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitPrototypeDef?: (ctx: PrototypeDefContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.instanceDef`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitInstanceDef?: (ctx: InstanceDefContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.instanceDecl`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitInstanceDecl?: (ctx: InstanceDeclContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.varDecl`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitVarDecl?: (ctx: VarDeclContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.constArrayDef`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitConstArrayDef?: (ctx: ConstArrayDefContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.constArrayAssignment`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitConstArrayAssignment?: (ctx: ConstArrayAssignmentContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.constValueDef`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitConstValueDef?: (ctx: ConstValueDefContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.constValueAssignment`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitConstValueAssignment?: (ctx: ConstValueAssignmentContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.varArrayDecl`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitVarArrayDecl?: (ctx: VarArrayDeclContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.varArrayAssignment`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitVarArrayAssignment?: (ctx: VarArrayAssignmentContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.varValueDecl`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitVarValueDecl?: (ctx: VarValueDeclContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.varValueAssignment`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitVarValueAssignment?: (ctx: VarValueAssignmentContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.parameterList`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitParameterList?: (ctx: ParameterListContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.parameterDecl`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitParameterDecl?: (ctx: ParameterDeclContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.statementBlock`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitStatementBlock?: (ctx: StatementBlockContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.statement`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitStatement?: (ctx: StatementContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.functionCall`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitFunctionCall?: (ctx: FunctionCallContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.assignment`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitAssignment?: (ctx: AssignmentContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.elseBlock`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitElseBlock?: (ctx: ElseBlockContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.elseIfBlock`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitElseIfBlock?: (ctx: ElseIfBlockContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.ifBlock`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitIfBlock?: (ctx: IfBlockContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.ifBlockStatement`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitIfBlockStatement?: (ctx: IfBlockStatementContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.returnStatement`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitReturnStatement?: (ctx: ReturnStatementContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.whileStatement`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitWhileStatement?: (ctx: WhileStatementContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.breakStatement`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitBreakStatement?: (ctx: BreakStatementContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.continueStatement`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitContinueStatement?: (ctx: ContinueStatementContext) => Result;\n    /**\n     * Visit a parse tree produced by the `bitMoveExpression`\n     * labeled alternative in `DaedalusParser.expression`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitBitMoveExpression?: (ctx: BitMoveExpressionContext) => Result;\n    /**\n     * Visit a parse tree produced by the `valueExpression`\n     * labeled alternative in `DaedalusParser.expression`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitValueExpression?: (ctx: ValueExpressionContext) => Result;\n    /**\n     * Visit a parse tree produced by the `eqExpression`\n     * labeled alternative in `DaedalusParser.expression`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitEqExpression?: (ctx: EqExpressionContext) => Result;\n    /**\n     * Visit a parse tree produced by the `addExpression`\n     * labeled alternative in `DaedalusParser.expression`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitAddExpression?: (ctx: AddExpressionContext) => Result;\n    /**\n     * Visit a parse tree produced by the `compExpression`\n     * labeled alternative in `DaedalusParser.expression`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitCompExpression?: (ctx: CompExpressionContext) => Result;\n    /**\n     * Visit a parse tree produced by the `logOrExpression`\n     * labeled alternative in `DaedalusParser.expression`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitLogOrExpression?: (ctx: LogOrExpressionContext) => Result;\n    /**\n     * Visit a parse tree produced by the `binAndExpression`\n     * labeled alternative in `DaedalusParser.expression`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitBinAndExpression?: (ctx: BinAndExpressionContext) => Result;\n    /**\n     * Visit a parse tree produced by the `binOrExpression`\n     * labeled alternative in `DaedalusParser.expression`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitBinOrExpression?: (ctx: BinOrExpressionContext) => Result;\n    /**\n     * Visit a parse tree produced by the `multExpression`\n     * labeled alternative in `DaedalusParser.expression`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitMultExpression?: (ctx: MultExpressionContext) => Result;\n    /**\n     * Visit a parse tree produced by the `bracketExpression`\n     * labeled alternative in `DaedalusParser.expression`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitBracketExpression?: (ctx: BracketExpressionContext) => Result;\n    /**\n     * Visit a parse tree produced by the `unaryExpression`\n     * labeled alternative in `DaedalusParser.expression`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitUnaryExpression?: (ctx: UnaryExpressionContext) => Result;\n    /**\n     * Visit a parse tree produced by the `logAndExpression`\n     * labeled alternative in `DaedalusParser.expression`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitLogAndExpression?: (ctx: LogAndExpressionContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.arrayIndex`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitArrayIndex?: (ctx: ArrayIndexContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.arraySize`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitArraySize?: (ctx: ArraySizeContext) => Result;\n    /**\n     * Visit a parse tree produced by the `integerLiteralValue`\n     * labeled alternative in `DaedalusParser.value`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitIntegerLiteralValue?: (ctx: IntegerLiteralValueContext) => Result;\n    /**\n     * Visit a parse tree produced by the `floatLiteralValue`\n     * labeled alternative in `DaedalusParser.value`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitFloatLiteralValue?: (ctx: FloatLiteralValueContext) => Result;\n    /**\n     * Visit a parse tree produced by the `stringLiteralValue`\n     * labeled alternative in `DaedalusParser.value`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitStringLiteralValue?: (ctx: StringLiteralValueContext) => Result;\n    /**\n     * Visit a parse tree produced by the `nullLiteralValue`\n     * labeled alternative in `DaedalusParser.value`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitNullLiteralValue?: (ctx: NullLiteralValueContext) => Result;\n    /**\n     * Visit a parse tree produced by the `noFuncLiteralValue`\n     * labeled alternative in `DaedalusParser.value`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitNoFuncLiteralValue?: (ctx: NoFuncLiteralValueContext) => Result;\n    /**\n     * Visit a parse tree produced by the `functionCallValue`\n     * labeled alternative in `DaedalusParser.value`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitFunctionCallValue?: (ctx: FunctionCallValueContext) => Result;\n    /**\n     * Visit a parse tree produced by the `referenceValue`\n     * labeled alternative in `DaedalusParser.value`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitReferenceValue?: (ctx: ReferenceValueContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.referenceAtom`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitReferenceAtom?: (ctx: ReferenceAtomContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.reference`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitReference?: (ctx: ReferenceContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.dataType`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitDataType?: (ctx: DataTypeContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.nameNode`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitNameNode?: (ctx: NameNodeContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.parentReference`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitParentReference?: (ctx: ParentReferenceContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.assignmentOperator`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitAssignmentOperator?: (ctx: AssignmentOperatorContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.addOperator`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitAddOperator?: (ctx: AddOperatorContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.bitMoveOperator`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitBitMoveOperator?: (ctx: BitMoveOperatorContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.compOperator`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitCompOperator?: (ctx: CompOperatorContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.eqOperator`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitEqOperator?: (ctx: EqOperatorContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.unaryOperator`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitUnaryOperator?: (ctx: UnaryOperatorContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.multOperator`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitMultOperator?: (ctx: MultOperatorContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.binAndOperator`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitBinAndOperator?: (ctx: BinAndOperatorContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.binOrOperator`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitBinOrOperator?: (ctx: BinOrOperatorContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.logAndOperator`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitLogAndOperator?: (ctx: LogAndOperatorContext) => Result;\n    /**\n     * Visit a parse tree produced by `DaedalusParser.logOrOperator`.\n     * @param ctx the parse tree\n     * @return the visitor result\n     */\n    visitLogOrOperator?: (ctx: LogOrOperatorContext) => Result;\n}\n\n","import {\n  ClassDefContext,\n  PrototypeDefContext,\n  InstanceDefContext,\n  FunctionDefContext,\n  ConstValueDefContext,\n  ConstArrayDefContext,\n  VarValueDeclContext,\n  VarArrayDeclContext,\n  InstanceDeclContext,\n} from './generated/DaedalusParser.js'\nimport { DaedalusVisitor } from './generated/DaedalusVisitor.js'\n\nexport type Symb = {\n  name: string\n  file: string\n  line: number\n}\nexport type SymbolTable = Symb[]\n\nexport class UnscopedVisitor extends DaedalusVisitor<SymbolTable> {\n  constructor(protected readonly symbolTable: SymbolTable = []) {\n    super()\n  }\n\n  protected defaultResult(): SymbolTable {\n    return this.symbolTable\n  }\n\n  private visitDef = (\n    ctx:\n      | ClassDefContext\n      | PrototypeDefContext\n      | InstanceDefContext\n      | FunctionDefContext\n      | ConstValueDefContext\n      | ConstArrayDefContext\n      | VarValueDeclContext\n      | VarArrayDeclContext\n  ): SymbolTable => {\n    const identifier = ctx.nameNode().Identifier()\n    if (identifier) {\n      const symbol = identifier.getSymbol()\n      if (symbol.text) this.symbolTable.push({ name: symbol.text, file: '', line: symbol.line })\n    }\n    return this.symbolTable\n  }\n\n  public visitClassDef = (ctx: ClassDefContext): SymbolTable => {\n    return this.visitDef(ctx)\n  }\n\n  public visitPrototypeDef = (ctx: PrototypeDefContext): SymbolTable => {\n    return this.visitDef(ctx)\n  }\n  public visitInstanceDef = (ctx: InstanceDefContext): SymbolTable => {\n    return this.visitDef(ctx)\n  }\n\n  public visitFunctionDef = (ctx: FunctionDefContext): SymbolTable => {\n    return this.visitDef(ctx)\n  }\n\n  public visitConstValueDef = (ctx: ConstValueDefContext): SymbolTable => {\n    return this.visitDef(ctx)\n  }\n\n  public visitConstArrayDef = (ctx: ConstArrayDefContext): SymbolTable => {\n    return this.visitDef(ctx)\n  }\n\n  public visitVarValueDecl = (ctx: VarValueDeclContext): SymbolTable => {\n    return this.visitDef(ctx)\n  }\n\n  public visitVarArrayDecl = (ctx: VarArrayDeclContext): SymbolTable => {\n    return this.visitDef(ctx)\n  }\n\n  public visitInstanceDecl = (ctx: InstanceDeclContext): SymbolTable => {\n    ctx.nameNode().forEach((node) => {\n      const identifier = node.Identifier()\n      if (identifier) {\n        const symbol = identifier.getSymbol()\n        if (symbol.text) this.symbolTable.push({ name: symbol.text, file: '', line: symbol.line })\n      }\n    })\n    return this.symbolTable\n  }\n}\n","import * as core from '@actions/core'\nimport { CharStream, CommonTokenStream } from 'antlr4ng'\nimport { DaedalusLexer } from './generated/DaedalusLexer.js'\nimport { DaedalusParser } from './generated/DaedalusParser.js'\nimport { UnscopedVisitor, SymbolTable } from './class.js'\nimport fs from 'fs'\nimport path from 'path'\n\nconst lineD: RegExp = /^.*\\.d(?=\\n)/gim\nconst lineSrc: RegExp = /^.*\\.src(?=\\n)/gim\nconst wildcards: RegExp = /\\*|\\?/g\n\nexport async function parseCandidates(basePath: string): Promise<SymbolTable> {\n  const candidateNames = ['Content', 'Menu', 'PFX', 'SFX', 'VFX', 'Music', 'Camera', 'Fight']\n  const suffixes = ['_G1', '_G112', '_G130', '_G2']\n  const candidates = candidateNames\n    .map((name) => {\n      const suffix = name !== 'Content' ? suffixes.concat(['']) : suffixes\n      return suffix.map((s) => path.join(basePath, name + s + '.src'))\n    })\n    .flat()\n  return parse(candidates)\n}\n\nexport async function parse(filepath: string | string[]): Promise<SymbolTable> {\n  const filepaths = Array.isArray(filepath) ? filepath : [filepath]\n  const symbolTables = await Promise.all(filepaths.map(parseSrc))\n  const symbolTable = symbolTables.flat()\n\n  // Sort by file and line\n  const symbols = symbolTable.sort((a, b) => {\n    if (a.file < b.file) return -1\n    if (a.file > b.file) return 1\n    if (a.line < b.line) return -1\n    if (a.line > b.line) return 1\n    return 0\n  })\n\n  // Remove duplicates\n  for (let i = 0; i < symbols.length - 1; i++) {\n    if (JSON.stringify(symbols[i]) === JSON.stringify(symbols[i + 1])) {\n      symbols.splice(i, 1)\n      i--\n    }\n  }\n\n  return symbols\n}\n\nexport async function parseSrc(filepath: string): Promise<SymbolTable> {\n  filepath = core.toPosixPath(filepath)\n  if (wildcards.test(filepath)) throw new Error('Wildcards are not supported')\n  if (path.extname(filepath) !== '.src' || !fs.existsSync(filepath)) return []\n  const input = fs.readFileSync(filepath, 'ascii')\n  const relPath = path.dirname(filepath)\n  const d = input.match(lineD)\n  const src = input.match(lineSrc)\n  const dList = d ? d.map((file) => parseD(path.join(relPath, file))) : []\n  const srcList = src ? src.map((file) => parseSrc(path.join(relPath, file))) : []\n  const symbolLists = await Promise.all([...dList, ...srcList])\n  return symbolLists.flat()\n}\n\nexport async function parseD(filepath: string): Promise<SymbolTable> {\n  filepath = core.toPosixPath(filepath)\n  if (wildcards.test(filepath)) throw new Error('Wildcards are not supported')\n  if (path.extname(filepath) !== '.d' || !fs.existsSync(filepath)) return []\n  const input = fs.readFileSync(filepath, 'ascii')\n  const wd = core.toPosixPath(process.env['GITHUB_WORKSPACE'] ?? '')\n  const file = filepath.replace(wd, '').replace(/^\\//, '')\n  const inputStream = CharStream.fromString(input)\n  const lexer = new DaedalusLexer(inputStream)\n  const tokenStream = new CommonTokenStream(lexer)\n  const parser = new DaedalusParser(tokenStream)\n  const tree = parser.daedalusFile()\n  const visitor = new UnscopedVisitor()\n  const symbolTable = visitor.visit(tree)?.map((s) => ({ ...s, file }))\n  // istanbul ignore next\n  return symbolTable ?? []\n}\n","import { SymbolTable } from './class.js'\nimport * as core from '@actions/core'\n\nexport function formatFilters(patchName: string, prefix: string[], ignore: string[]): { prefix: string[]; ignore: string[] } {\n  const patchNameU = patchName.toUpperCase()\n\n  // Format and extend prefixes\n  const prefixForm = prefix.map((p) => p.replace(/_$/, '').toUpperCase() + '_')\n  const prefixPatch = prefixForm.map((p) => 'PATCH_' + p)\n  prefix = [...new Set([...prefixForm, ...prefixPatch, patchNameU + '_', 'PATCH_' + patchNameU + '_'])]\n\n  // Format and extend ignore list\n  const ignoreForm = ignore.map((i) => i.toUpperCase())\n  ignore = [...new Set([...ignoreForm, `NINJA_${patchNameU}_INIT`, `NINJA_${patchNameU}_MENU`])]\n\n  // Report filters\n  core.info(`Ignore:   ${ignore.join(', ')}`)\n  core.info(`Prefixes: ${prefix.join(', ')}`)\n\n  return { prefix, ignore }\n}\n\nexport function validate(symbols: SymbolTable, prefix: string[], ignore: string[]): SymbolTable {\n  const invalidSymbols = symbols.filter((symbol) => {\n    const name = symbol.name.toUpperCase()\n    const hasPrefix = prefix.some((p) => name.includes(p))\n    const isIgnored = ignore.includes(name)\n    return !hasPrefix && !isIgnored\n  })\n  return invalidSymbols\n}\n","import * as core from '@actions/core'\nimport * as github from '@actions/github'\nimport { posix } from 'path'\nimport fs from 'fs'\nimport YAML from 'yaml'\n\nexport function loadInputs(): { relPath: string; basePath: string; patchName: string; prefix: string[]; ignore: string[] } {\n  const wd = core.toPosixPath(process.env['GITHUB_WORKSPACE'] ?? '')\n  const patchName = core.getInput('patchName') || github.context.payload.repository?.name\n  if (!patchName) throw new Error('Patch name is not available. Please provide it as an input to the action')\n\n  // Make paths\n  const relRootPath = posix.normalize(core.toPosixPath(core.getInput('rootPath'))) // Relative path to patch root\n  const relBasePath = posix.join(relRootPath, 'Ninja', patchName) // Relative path to src files\n  const rootPath = posix.join(wd, relRootPath) // Absolute path to patch root\n  const basePath = posix.join(wd, relBasePath) // Aboslute path to src files\n  if (!fs.existsSync(basePath)) throw new Error(`Base path '${relBasePath}' not found`)\n\n  // Read config file\n  const configPath = posix.join(rootPath, '.validator.yml')\n  if (!fs.existsSync(configPath)) throw new Error(`Configuration file '${configPath}' not found`)\n  const configStr = fs.readFileSync(configPath, 'utf8')\n  const config = YAML.parse(configStr) as { prefix: string | string[] | undefined; ignore: string | string[] | undefined }\n\n  // Populate configuration\n  const prefix = (config.prefix ? [config.prefix] : []).flat()\n  const ignore = (config.ignore ? [config.ignore] : []).flat()\n\n  // Validate configuration\n  if (prefix.some((p) => p.length < 3)) throw new Error('Prefix must be at least three characters long')\n\n  return { relPath: relBasePath, basePath, patchName, prefix, ignore }\n}\n","import * as core from '@actions/core'\nimport * as github from '@actions/github'\nimport { SymbolTable } from './class.js'\n\nexport function symbols(symbolTable: SymbolTable, symbolTableInvalid: SymbolTable): void {\n  core.startGroup('Global Symbols')\n  const symbolNamesInvalid = symbolTableInvalid.map((s) => s.name)\n  symbolTable.map((s) => {\n    const colorPrefix = symbolNamesInvalid.includes(s.name) ? '\\u001b[31m' : '\\u001b[32m'\n    core.info(colorPrefix + s.name + '\\u001b[0m')\n  })\n  core.endGroup()\n}\n\nexport async function annotations(\n  symbolTableInvalid: SymbolTable,\n  numSymbols: number,\n  prefix: string[],\n  startedAt: Date,\n  duration: string\n): Promise<string | null> {\n  const numErr = symbolTableInvalid.length\n  const details = `The patch validator checked ${numSymbols} global symbol name${numSymbols !== 1 ? 's' : ''}.\n\nFor more details, see [Ninja documentation](https://github.com/szapp/Ninja/wiki/Inject-Changes#naming-conventions).`\n\n  const prefixes = prefix.slice(0, 3).join(', ')\n  const annotations: {\n    path: string\n    start_line: number\n    end_line: number\n    annotation_level: 'failure' | 'notice' | 'warning'\n    message: string\n    title: string\n  }[] = symbolTableInvalid.map((s) => ({\n    path: s.file,\n    start_line: s.line,\n    end_line: s.line,\n    annotation_level: 'failure',\n    message: `The symbol ${s.name} poses a compatibility risk. Add a prefix to its name (e.g. ${prefixes}). If overwriting this symbol is intended, add it to the ignore list.`,\n    title: 'Naming convention violation',\n  }))\n  const octokit = github.getOctokit(core.getInput('token'))\n  const {\n    data: { details_url },\n  } = await octokit.rest.checks.create({\n    ...github.context.repo,\n    name: 'Naming Convention',\n    head_sha: github.context.sha,\n    started_at: startedAt.toISOString(),\n    completed_at: new Date().toISOString(),\n    conclusion: numErr ? 'failure' : 'success',\n    output: {\n      title: `${numErr || 'No'} violation${numErr !== 1 ? 's' : ''}`,\n      summary: `The patch validator found ${numErr || 'no'} invalid symbol name${numErr !== 1 ? 's' : ''} (${duration})`,\n      text: details,\n      annotations,\n    },\n  })\n  return details_url\n}\n\nexport async function summary(\n  symbolTableInvalid: SymbolTable,\n  numSymbols: number,\n  relPath: string,\n  details_url: string | null,\n  duration: string\n): Promise<void> {\n  const relPathRE = RegExp(`^${relPath}${relPath.length > 1 && !relPath.endsWith('/') ? '/' : ''}`)\n  const rows =\n    symbolTableInvalid.length > 0\n      ? symbolTableInvalid.map((s) => [' Fail', s.name, `${s.file.replace(relPathRE, '')}:${s.line}`])\n      : [[' Pass', '-', '-']]\n  await core.summary\n    .addHeading('Validation Results')\n    .addTable([\n      [\n        { data: 'Test result ', header: true },\n        { data: 'Symbol ', header: true },\n        { data: 'File ', header: true },\n      ],\n      ...rows,\n    ])\n    .addEOL()\n    .addRaw(`Violations: ${symbolTableInvalid.length}/${numSymbols}. Duration: ${duration}.`, true)\n    .addEOL()\n    .addRaw(details_url !== null ? `<a href=\"${details_url}\">Details</a>.` : '', true)\n    .write({ overwrite: false })\n}\n\nexport default { symbols, annotations, summary }\n","import * as core from '@actions/core'\nimport { parseCandidates } from './parse.js'\nimport { validate, formatFilters } from './validate.js'\nimport { loadInputs } from './inputs.js'\nimport write from './write.js'\nimport humanizeDuration from 'humanize-duration'\n\nexport async function run(): Promise<void> {\n  try {\n    // Start timer\n    const startedAt = new Date()\n    const startTime = performance.now()\n\n    // Format inputs\n    const { relPath, basePath, patchName, prefix: prefixList, ignore: ignoreList } = loadInputs()\n\n    // Collect global symbols\n    const symbolTable = await parseCandidates(basePath)\n\n    // Validate symbols by naming convention\n    const { prefix, ignore } = formatFilters(patchName, prefixList, ignoreList)\n    const symbolTableInvalid = validate(symbolTable, prefix, ignore)\n\n    // Write outputs\n    write.symbols(symbolTable, symbolTableInvalid)\n    const duration = humanizeDuration(performance.now() - startTime, { round: true, largest: 2, units: ['m', 's', 'ms'] })\n    const details_url = await write.annotations(symbolTableInvalid, symbolTable.length, prefix, startedAt, duration)\n    await write.summary(symbolTableInvalid, symbolTable.length, relPath, details_url, duration)\n  } catch (error) {\n    const msg: string = error instanceof Error ? error.message : String(error)\n    core.setFailed(msg)\n  }\n}\n","import { run } from './main.js'\n\nrun()\n"],"names":[],"sourceRoot":""}